compresses files using the Burrows-Wheeler block sorting
text compression algorithm, and Huffman coding.  Compression is
generally considerably better than that achieved by more conventional
family of statistical compressors.

The command-line options are deliberately very similar to 
those of 
but they are not identical.

expects a list of file names to accompany the
command-line flags.  Each file is replaced by a compressed version of
itself, with the name "original_name.bz2".  
Each compressed file
has the same modification date, permissions, and, when possible,
ownership as the corresponding original, so that these properties can
be correctly restored at decompression time.  File name handling is
naive in the sense that there is no mechanism for preserving original
file names, permissions, ownerships or dates in filesystems which lack
these concepts, or have serious file name length restrictions, such as
MS-DOS.

and
will by default not overwrite existing

If no file names are specified,
compresses from standard
input to standard output.  In this case,
will decline to
write compressed output to a terminal, as this would be entirely
incomprehensible and therefore pointless.

(or
decompresses all
specified files.  Files which were not created by 
will be detected and ignored, and a warning issued.  
attempts to guess the filename for the decompressed file 
from that of the compressed file as follows:

       filename.bz2    becomes   filename
       filename.bz     becomes   filename
       filename.tbz2   becomes   filename.tar
       filename.tbz    becomes   filename.tar
       anyothername    becomes   anyothername.out

If the file does not end in one of the recognised endings, 
or
complains that it cannot
guess the name of the original file, and uses the original name
with
appended.

As with compression, supplying no
filenames causes decompression from 
standard input to standard output.

will correctly decompress a file which is the
concatenation of two or more compressed files.  The result is the
concatenation of the corresponding uncompressed files.  Integrity
of concatenated 
compressed files is also supported.

You can also compress or decompress files to the standard output by
decompressed like this.  The resulting outputs are fed sequentially to
stdout.  Compression of multiple files 
in this manner generates a stream
containing multiple compressed file representations.  Such a stream
can be decompressed correctly only by
version 0.9.0 or
later.  Earlier versions of
will stop after decompressing
the first file in the stream.

(or
decompresses all specified files to
the standard output.

will read arguments from the environment variables
and
in that order, and will process them
before any arguments read from the command line.  This gives a 
convenient way to supply default arguments.

Compression is always performed, even if the compressed 
file is slightly
larger than the original.  Files of less than about one hundred bytes
tend to get larger, since the compression mechanism has a constant
overhead in the region of 50 bytes.  Random data (including the output
of most file compressors) is coded at about 8.05 bits per byte, giving
an expansion of around 0.5%.

As a self-check for your protection, 
bzip2
uses 32-bit CRCs to
make sure that the decompressed version of a file is identical to the
original.  This guards against corruption of the compressed data, and
against undetected bugs in
(hopefully very unlikely).  The
chances of data corruption going undetected is microscopic, about one
chance in four billion for each file processed.  Be aware, though, that
the check occurs upon decompression, so it can only tell you that
something is wrong.  It can't help you 
recover the original uncompressed
data.  You can use 
to try to recover data from
damaged files.

Return values: 0 for a normal exit, 1 for environmental problems (file
compressed file, 3 for an internal consistency error (eg, bug) which
caused
to panic.

Compress or decompress to standard output.
Force decompression.  
and
are
really the same program, and the decision about what actions to take is
done on the basis of which name is used.  This flag overrides that
mechanism, and forces 
to decompress.
invocation name.
Check integrity of the specified file(s), but don't decompress them.
This really performs a trial decompression and throws away the result.
Force overwrite of output files.  Normally,
will not overwrite
existing output files.  Also forces 
to break hard links
to files, which it otherwise wouldn't do.

bzip2 normally declines to decompress files which don't have the
correct magic header bytes.  If forced (-f), however, it will pass
such files through unmodified.  This is how GNU gzip behaves.
Keep (don't delete) input files during compression
or decompression.
Reduce memory usage, for compression, decompression and testing.  Files
are decompressed and tested using a modified algorithm which only
requires 2.5 bytes per block byte.  This means any file can be
decompressed in 2300k of memory, albeit at about half the normal speed.

memory use to around the same figure, at the expense of your compression
ratio.  In short, if your machine is low on memory (8 megabytes or
Suppress non-essential warning messages.  Messages pertaining to
Verbose mode -- show the compression ratio for each file processed.
information which is primarily of interest for diagnostic purposes.
Display the software version, license terms and conditions.
Set the block size to 100 k, 200 k ..  900 k when compressing.  Has no
effect when decompressing.  See MEMORY MANAGEMENT below.
significantly faster.  
Treats all subsequent arguments as file names, even if they start
with a dash.  This is so you can handle files with names beginning
These flags are redundant in versions 0.9.5 and above.  They provided
some coarse control over the behaviour of the sorting algorithm in
earlier versions, which was sometimes useful.  0.9.5 and above have an
improved algorithm which renders these flags irrelevant.

compresses large files in blocks.  The block size affects
both the compression ratio achieved, and the amount of memory needed for
specify the block size to be 100,000 bytes through 900,000 bytes (the
default) respectively.  At decompression time, the block size used for
compression is read from the header of the compressed file, and
then allocates itself just enough memory to decompress
the file.  Since block sizes are stored in compressed files, it follows
during decompression.

Compression and decompression requirements, 
in bytes, can be estimated as:

       Compression:   400k + ( 8 x block size )

       Decompression: 100k + ( 4 x block size ), or
                      100k + ( 2.5 x block size )

Larger block sizes give rapidly diminishing marginal returns.  Most of
the compression comes from the first two or three hundred k of block
size, a fact worth bearing in mind when using
on small machines.
It is also important to appreciate that the decompression memory
requirement is set at compression time by the choice of block size.

For files compressed with the default 900k block size,
will require about 3700 kbytes to decompress.  To support decompression
of any file on a 4 megabyte machine, 
has an option to
decompress using approximately half this amount of memory, about 2300
kbytes.  Decompression speed is also halved, so you should use this
option only where necessary.  The relevant flag is -s.

In general, try and use the largest block size memory constraints allow,
since that maximises the compression achieved.  Compression and
decompression speed are virtually unaffected by block size.

Another significant point applies to files which fit in a single block
-- that means most files you'd encounter using a large block size.  The
amount of real memory touched is proportional to the size of the file,
since the file is smaller than a block.  For example, compressing a file
20,000 bytes long with the flag -9 will cause the compressor to
allocate around 7600k of memory, but only touch 400k + 20000 * 8 = 560
kbytes of it.  Similarly, the decompressor will allocate 3700k but only
touch 100k + 20000 * 4 = 180 kbytes.

Here is a table which summarises the maximum memory usage for different
block sizes.  Also recorded is the total compressed size for 14 files of
the Calgary Text Compression Corpus totalling 3,141,622 bytes.  This
column gives some feel for how compression varies with block size.
These figures tend to understate the advantage of larger block sizes for
larger files, since the Corpus is dominated by smaller files.

           Compress   Decompress   Decompress   Corpus
    Flag     usage      usage       -s usage     Size

     -1      1200k       500k         350k      914704
     -2      2000k       900k         600k      877703
     -3      2800k      1300k         850k      860338
     -4      3600k      1700k        1100k      846899
     -5      4400k      2100k        1350k      845160
     -6      5200k      2500k        1600k      838626
     -7      6100k      2900k        1850k      834096
     -8      6800k      3300k        2100k      828642
     -9      7600k      3700k        2350k      828642

compresses files in blocks, usually 900kbytes long.  Each
block is handled independently.  If a media or transmission error causes
a multi-block .bz2
file to become damaged, it may be possible to
recover data from the undamaged blocks in the file.

The compressed representation of each block is delimited by a 48-bit
pattern, which makes it possible to find the block boundaries with
reasonable certainty.  Each block also carries its own 32-bit CRC, so
damaged blocks can be distinguished from undamaged ones.

is a simple program whose purpose is to search for
blocks in .bz2 files, and write each block out into its own .bz2 
file.  You can then use
to test the
integrity of the resulting files, and decompress those which are
undamaged.

takes a single argument, the name of the damaged file, 
and writes a number of files "rec00001file.bz2",
"rec00002file.bz2", etc, containing the  extracted  blocks.
The  output  filenames  are  designed  so  that the use of
wildcards in subsequent processing -- for example,  
"bzip2 -dc  rec*file.bz2 > recovered_data" -- processes the files in
the correct order.

should be of most use dealing with large .bz2
files,  as  these will contain many blocks.  It is clearly
futile to use it on damaged single-block  files,  since  a
damaged  block  cannot  be recovered.  If you wish to minimise 
any potential data loss through media  or  transmission errors, 
you might consider compressing with a smaller
block size.

The sorting phase of compression gathers together similar strings in the
file.  Because of this, files containing very long runs of repeated
symbols, like "aabaabaabaab ..."  (repeated several hundred times) may
compress more slowly than normal.  Versions 0.9.5 and above fare much
better than previous versions in this respect.  The ratio between
worst-case and average-case compression time is in the region of 10:1.
For previous versions, this figure was more like 100:1.  You can use the

Decompression speed is unaffected by these phenomena.

usually allocates several megabytes of memory to operate
in, and then charges all over it in a fairly random fashion.  This means
that performance, both for compressing and decompressing, is largely
determined by the speed at which your machine can service cache misses.
Because of this, small changes to the code to reduce the miss rate have
been observed to give disproportionately large performance improvements.
I imagine 
will perform best on machines with very large caches.

what the problem is sometimes seem rather misleading.

This manual page pertains to version 1.0.6 of
Compressed data created by this version is entirely forwards and
backwards compatible with the previous public releases, versions
0.1pl2, 0.9.0, 0.9.5, 1.0.0, 1.0.1, 1.0.2 and above, but with the following
exception: 0.9.0 and above can correctly decompress multiple
concatenated compressed files.  0.1pl2 cannot do this; it will stop
after decompressing just the first file in the stream.

versions prior to 1.0.2 used 32-bit integers to represent
bit positions in compressed files, so they could not handle compressed
files more than 512 megabytes long.  Versions 1.0.2 and above use
64-bit ints on some platforms which support them (GNU supported
targets, and Windows).  To establish whether or not bzip2recover was
built with such a limitation, run it without arguments.  In any event
you can build yourself an unlimited version if you can recompile it
with MaybeUInt64 set to be an unsigned 64-bit integer.



Julian Seward, jsewardbzip.org.


The ideas embodied in
are due to (at least) the following
people: Michael Burrows and David Wheeler (for the block sorting
transformation), David Wheeler (again, for the Huffman coder), Peter
Fenwick (for the structured coding model in the original
and many refinements), and Alistair Moffat, Radford Neal and Ian Witten
(for the arithmetic coder in the original
I am much
indebted for their help, support and advice.  See the manual in the
source distribution for pointers to sources of documentation.  Christian
von Roques encouraged me to look for faster sorting algorithms, so as to
speed up compression.  Bela Lubkin encouraged me to improve the
worst-case compression performance.  
Donna Robinson XMLised the documentation.
The bz* scripts are derived from those of GNU gzip.
Many people sent patches, helped
with portability problems, lent machines, gave advice and were generally
helpful.

[
]
[ 
]
[ 
]

compresses files using the Burrows-Wheeler block sorting
text compression algorithm, and Huffman coding.  Compression is
generally considerably better than that achieved by more conventional
family of statistical compressors.

The command-line options are deliberately very similar to 
those of 
but they are not identical.

expects a list of file names to accompany the
command-line flags.  Each file is replaced by a compressed version of
itself, with the name "original_name.bz2".  
Each compressed file
has the same modification date, permissions, and, when possible,
ownership as the corresponding original, so that these properties can
be correctly restored at decompression time.  File name handling is
naive in the sense that there is no mechanism for preserving original
file names, permissions, ownerships or dates in filesystems which lack
these concepts, or have serious file name length restrictions, such as
MS-DOS.

and
will by default not overwrite existing

If no file names are specified,
compresses from standard
input to standard output.  In this case,
will decline to
write compressed output to a terminal, as this would be entirely
incomprehensible and therefore pointless.

(or
decompresses all
specified files.  Files which were not created by 
will be detected and ignored, and a warning issued.  
attempts to guess the filename for the decompressed file 
from that of the compressed file as follows:

       filename.bz2    becomes   filename
       filename.bz     becomes   filename
       filename.tbz2   becomes   filename.tar
       filename.tbz    becomes   filename.tar
       anyothername    becomes   anyothername.out

If the file does not end in one of the recognised endings, 
or
complains that it cannot
guess the name of the original file, and uses the original name
with
appended.

As with compression, supplying no
filenames causes decompression from 
standard input to standard output.

will correctly decompress a file which is the
concatenation of two or more compressed files.  The result is the
concatenation of the corresponding uncompressed files.  Integrity
of concatenated 
compressed files is also supported.

You can also compress or decompress files to the standard output by
decompressed like this.  The resulting outputs are fed sequentially to
stdout.  Compression of multiple files 
in this manner generates a stream
containing multiple compressed file representations.  Such a stream
can be decompressed correctly only by
version 0.9.0 or
later.  Earlier versions of
will stop after decompressing
the first file in the stream.

(or
decompresses all specified files to
the standard output.

will read arguments from the environment variables
and
in that order, and will process them
before any arguments read from the command line.  This gives a 
convenient way to supply default arguments.

Compression is always performed, even if the compressed 
file is slightly
larger than the original.  Files of less than about one hundred bytes
tend to get larger, since the compression mechanism has a constant
overhead in the region of 50 bytes.  Random data (including the output
of most file compressors) is coded at about 8.05 bits per byte, giving
an expansion of around 0.5%.

As a self-check for your protection, 
bzip2
uses 32-bit CRCs to
make sure that the decompressed version of a file is identical to the
original.  This guards against corruption of the compressed data, and
against undetected bugs in
(hopefully very unlikely).  The
chances of data corruption going undetected is microscopic, about one
chance in four billion for each file processed.  Be aware, though, that
the check occurs upon decompression, so it can only tell you that
something is wrong.  It can't help you 
recover the original uncompressed
data.  You can use 
to try to recover data from
damaged files.

Return values: 0 for a normal exit, 1 for environmental problems (file
compressed file, 3 for an internal consistency error (eg, bug) which
caused
to panic.

Compress or decompress to standard output.
Force decompression.  
and
are
really the same program, and the decision about what actions to take is
done on the basis of which name is used.  This flag overrides that
mechanism, and forces 
to decompress.
invocation name.
Check integrity of the specified file(s), but don't decompress them.
This really performs a trial decompression and throws away the result.
Force overwrite of output files.  Normally,
will not overwrite
existing output files.  Also forces 
to break hard links
to files, which it otherwise wouldn't do.

bzip2 normally declines to decompress files which don't have the
correct magic header bytes.  If forced (-f), however, it will pass
such files through unmodified.  This is how GNU gzip behaves.
Keep (don't delete) input files during compression
or decompression.
Reduce memory usage, for compression, decompression and testing.  Files
are decompressed and tested using a modified algorithm which only
requires 2.5 bytes per block byte.  This means any file can be
decompressed in 2300k of memory, albeit at about half the normal speed.

memory use to around the same figure, at the expense of your compression
ratio.  In short, if your machine is low on memory (8 megabytes or
Suppress non-essential warning messages.  Messages pertaining to
Verbose mode -- show the compression ratio for each file processed.
information which is primarily of interest for diagnostic purposes.
Display the software version, license terms and conditions.
Set the block size to 100 k, 200 k ..  900 k when compressing.  Has no
effect when decompressing.  See MEMORY MANAGEMENT below.
significantly faster.  
Treats all subsequent arguments as file names, even if they start
with a dash.  This is so you can handle files with names beginning
These flags are redundant in versions 0.9.5 and above.  They provided
some coarse control over the behaviour of the sorting algorithm in
earlier versions, which was sometimes useful.  0.9.5 and above have an
improved algorithm which renders these flags irrelevant.

compresses large files in blocks.  The block size affects
both the compression ratio achieved, and the amount of memory needed for
specify the block size to be 100,000 bytes through 900,000 bytes (the
default) respectively.  At decompression time, the block size used for
compression is read from the header of the compressed file, and
then allocates itself just enough memory to decompress
the file.  Since block sizes are stored in compressed files, it follows
during decompression.

Compression and decompression requirements, 
in bytes, can be estimated as:

       Compression:   400k + ( 8 x block size )

       Decompression: 100k + ( 4 x block size ), or
                      100k + ( 2.5 x block size )

Larger block sizes give rapidly diminishing marginal returns.  Most of
the compression comes from the first two or three hundred k of block
size, a fact worth bearing in mind when using
on small machines.
It is also important to appreciate that the decompression memory
requirement is set at compression time by the choice of block size.

For files compressed with the default 900k block size,
will require about 3700 kbytes to decompress.  To support decompression
of any file on a 4 megabyte machine, 
has an option to
decompress using approximately half this amount of memory, about 2300
kbytes.  Decompression speed is also halved, so you should use this
option only where necessary.  The relevant flag is -s.

In general, try and use the largest block size memory constraints allow,
since that maximises the compression achieved.  Compression and
decompression speed are virtually unaffected by block size.

Another significant point applies to files which fit in a single block
-- that means most files you'd encounter using a large block size.  The
amount of real memory touched is proportional to the size of the file,
since the file is smaller than a block.  For example, compressing a file
20,000 bytes long with the flag -9 will cause the compressor to
allocate around 7600k of memory, but only touch 400k + 20000 * 8 = 560
kbytes of it.  Similarly, the decompressor will allocate 3700k but only
touch 100k + 20000 * 4 = 180 kbytes.

Here is a table which summarises the maximum memory usage for different
block sizes.  Also recorded is the total compressed size for 14 files of
the Calgary Text Compression Corpus totalling 3,141,622 bytes.  This
column gives some feel for how compression varies with block size.
These figures tend to understate the advantage of larger block sizes for
larger files, since the Corpus is dominated by smaller files.

           Compress   Decompress   Decompress   Corpus
    Flag     usage      usage       -s usage     Size

     -1      1200k       500k         350k      914704
     -2      2000k       900k         600k      877703
     -3      2800k      1300k         850k      860338
     -4      3600k      1700k        1100k      846899
     -5      4400k      2100k        1350k      845160
     -6      5200k      2500k        1600k      838626
     -7      6100k      2900k        1850k      834096
     -8      6800k      3300k        2100k      828642
     -9      7600k      3700k        2350k      828642

compresses files in blocks, usually 900kbytes long.  Each
block is handled independently.  If a media or transmission error causes
a multi-block .bz2
file to become damaged, it may be possible to
recover data from the undamaged blocks in the file.

The compressed representation of each block is delimited by a 48-bit
pattern, which makes it possible to find the block boundaries with
reasonable certainty.  Each block also carries its own 32-bit CRC, so
damaged blocks can be distinguished from undamaged ones.

is a simple program whose purpose is to search for
blocks in .bz2 files, and write each block out into its own .bz2 
file.  You can then use
to test the
integrity of the resulting files, and decompress those which are
undamaged.

takes a single argument, the name of the damaged file, 
and writes a number of files "rec00001file.bz2",
"rec00002file.bz2", etc, containing the  extracted  blocks.
The  output  filenames  are  designed  so  that the use of
wildcards in subsequent processing -- for example,  
"bzip2 -dc  rec*file.bz2 > recovered_data" -- processes the files in
the correct order.

should be of most use dealing with large .bz2
files,  as  these will contain many blocks.  It is clearly
futile to use it on damaged single-block  files,  since  a
damaged  block  cannot  be recovered.  If you wish to minimise 
any potential data loss through media  or  transmission errors, 
you might consider compressing with a smaller
block size.

The sorting phase of compression gathers together similar strings in the
file.  Because of this, files containing very long runs of repeated
symbols, like "aabaabaabaab ..."  (repeated several hundred times) may
compress more slowly than normal.  Versions 0.9.5 and above fare much
better than previous versions in this respect.  The ratio between
worst-case and average-case compression time is in the region of 10:1.
For previous versions, this figure was more like 100:1.  You can use the

Decompression speed is unaffected by these phenomena.

usually allocates several megabytes of memory to operate
in, and then charges all over it in a fairly random fashion.  This means
that performance, both for compressing and decompressing, is largely
determined by the speed at which your machine can service cache misses.
Because of this, small changes to the code to reduce the miss rate have
been observed to give disproportionately large performance improvements.
I imagine 
will perform best on machines with very large caches.

what the problem is sometimes seem rather misleading.

This manual page pertains to version 1.0.6 of
Compressed data created by this version is entirely forwards and
backwards compatible with the previous public releases, versions
0.1pl2, 0.9.0, 0.9.5, 1.0.0, 1.0.1, 1.0.2 and above, but with the following
exception: 0.9.0 and above can correctly decompress multiple
concatenated compressed files.  0.1pl2 cannot do this; it will stop
after decompressing just the first file in the stream.

versions prior to 1.0.2 used 32-bit integers to represent
bit positions in compressed files, so they could not handle compressed
files more than 512 megabytes long.  Versions 1.0.2 and above use
64-bit ints on some platforms which support them (GNU supported
targets, and Windows).  To establish whether or not bzip2recover was
built with such a limitation, run it without arguments.  In any event
you can build yourself an unlimited version if you can recompile it
with MaybeUInt64 set to be an unsigned 64-bit integer.



Julian Seward, jsewardbzip.org.


The ideas embodied in
are due to (at least) the following
people: Michael Burrows and David Wheeler (for the block sorting
transformation), David Wheeler (again, for the Huffman coder), Peter
Fenwick (for the structured coding model in the original
and many refinements), and Alistair Moffat, Radford Neal and Ian Witten
(for the arithmetic coder in the original
I am much
indebted for their help, support and advice.  See the manual in the
source distribution for pointers to sources of documentation.  Christian
von Roques encouraged me to look for faster sorting algorithms, so as to
speed up compression.  Bela Lubkin encouraged me to improve the
worst-case compression performance.  
Donna Robinson XMLised the documentation.
The bz* scripts are derived from those of GNU gzip.
Many people sent patches, helped
with portability problems, lent machines, gave advice and were generally
helpful.
[ name ...  ]
[ name ...  ]
In the following description,
and
can be used interchangeably with
and
is a filter which allows examination of compressed or plain text files
one screenful at a time on a soft-copy terminal.
works on files compressed with
and also on uncompressed files.
If a file does not exist,
looks for a file of the same name with the addition of a .bz2 suffix.
normally pauses after each screenful, printing --More--
at the bottom of the screen.
If the user then types a carriage return, one more line is displayed.
If the user hits a space,
another screenful is displayed.  Other possibilities are enumerated later.
looks in the file
to determine terminal characteristics,
and to determine the default window size.
On a terminal capable of displaying 24 lines,
the default window size is 22 lines.
Other sequences which may be typed when
argument, defaulting to 1) :
display
more lines, (or another screenful if no argument is given)
display 11 more lines (a ``scroll'').
If
same as ^D (control-D)
window size.  Note that the window size reverts back to the default at the
end of the current file.
quit reading the current file; go on to the next (if any)
When the prompt --More--(Next file: 
is printed, this command causes bzmore to exit.
When the prompt --More--(Next file: 
is printed, this command causes bzmore to skip the next file and continue.
Display the current line number.
If the pattern is not found,
goes on to the next file (if any).
Otherwise, a screenful is displayed, starting two lines before the place
where the expression was found.
The user's erase and kill characters may be used to edit the regular
expression.
Erasing back past the first column cancels the search command.
The character `!' in "command" are replaced with the
quit reading the current file; go on to the next (if any)
(same as q or Q).
(dot) repeat the previous command.
The commands take effect immediately, i.e., it is not necessary to
type a carriage return.
Up to the time when the command character itself is given,
the user may hit the line kill character to cancel the numerical
argument being formed.
In addition, the user may hit the erase character to redisplay the
--More-- message.
At any time when output is being sent to the terminal, the user can
will stop sending output, and will display the usual --More--
prompt.
The user may then enter one of the above commands in the normal manner.
Unfortunately, some output is lost when this is done, due to the
fact that any characters waiting in the terminal's output queue
are flushed when the quit signal occurs.
The terminal is set to
mode by this program so that the output can be continuous.
commands.
If the standard output is not a teletype, then
acts just like
except that a header is printed before each file.
more(1), less(1), bzip2(1), bzdiff(1), bzgrep(1)
[ name ...  ]
[ name ...  ]
In the following description,
and
can be used interchangeably with
and
is a filter which allows examination of compressed or plain text files
one screenful at a time on a soft-copy terminal.
works on files compressed with
and also on uncompressed files.
If a file does not exist,
looks for a file of the same name with the addition of a .bz2 suffix.
normally pauses after each screenful, printing --More--
at the bottom of the screen.
If the user then types a carriage return, one more line is displayed.
If the user hits a space,
another screenful is displayed.  Other possibilities are enumerated later.
looks in the file
to determine terminal characteristics,
and to determine the default window size.
On a terminal capable of displaying 24 lines,
the default window size is 22 lines.
Other sequences which may be typed when
argument, defaulting to 1) :
display
more lines, (or another screenful if no argument is given)
display 11 more lines (a ``scroll'').
If
same as ^D (control-D)
window size.  Note that the window size reverts back to the default at the
end of the current file.
quit reading the current file; go on to the next (if any)
When the prompt --More--(Next file: 
is printed, this command causes bzmore to exit.
When the prompt --More--(Next file: 
is printed, this command causes bzmore to skip the next file and continue.
Display the current line number.
If the pattern is not found,
goes on to the next file (if any).
Otherwise, a screenful is displayed, starting two lines before the place
where the expression was found.
The user's erase and kill characters may be used to edit the regular
expression.
Erasing back past the first column cancels the search command.
The character `!' in "command" are replaced with the
quit reading the current file; go on to the next (if any)
(same as q or Q).
(dot) repeat the previous command.
The commands take effect immediately, i.e., it is not necessary to
type a carriage return.
Up to the time when the command character itself is given,
the user may hit the line kill character to cancel the numerical
argument being formed.
In addition, the user may hit the erase character to redisplay the
--More-- message.
At any time when output is being sent to the terminal, the user can
will stop sending output, and will display the usual --More--
prompt.
The user may then enter one of the above commands in the normal manner.
Unfortunately, some output is lost when this is done, due to the
fact that any characters waiting in the terminal's output queue
are flushed when the quit signal occurs.
The terminal is set to
mode by this program so that the output can be continuous.
commands.
If the standard output is not a teletype, then
acts just like
except that a header is printed before each file.
more(1), less(1), bzip2(1), bzdiff(1), bzgrep(1)
that you can write many functions with the same name, providing that
each function takes parameters of different types.  In order to be
encode them into a low-level assembler name which uniquely identifies
[1]
names into user-level names so that they can be read.
Every alphanumeric word (consisting of letters, digits, underscores,
dollars, or periods) seen in the input is a potential mangled name.
low-level name in the output, otherwise the original word is output.
In this way you can pass an entire assembler source file, containing
containing demangled names.
passing them on the command line:
names from the standard input instead.  All the results are printed on
the standard output.  The difference between reading names from the
command line versus reading names from the standard input is that
command line arguments are expected to be just mangled names and no
checking is performed to separate them from surrounding text.  Thus
for example:
will not work.  (Note the extra comma at the end of the mangled
name which makes it invalid).  This command however will work:
trailing comma.  This behaviour is because when the names are read
from the standard input it is expected that they might be part of an
assembler source file where there might be extra, extraneous
characters trailing after a mangled name.  eg:
syntax.
Do not remove the initial underscore.
When demangling the name of a function, do not display the types of
the function's parameters.
Attempt to demangle types as well as function names.  This is disabled
by default since mangled types are normally only used internally in
the compiler, and they can be confused with non-mangled names.  eg
Do not include implementation details (if any) in the demangled
output.
different compilers.  The argument to this option selects which
method it uses:
Automatic selection based on executable (the default method)
the one used by the Lucid compiler (lcc)
does not exist, or cannot be read, then the option will be treated
literally, and not removed.  
character may be included in an option by surrounding the entire
option in either single or double quotes.  Any character (including a
backslash) may be included by prefixing the character to be included
Copyright (c) 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,
2000, 2001, 2002, 2003, 2004, 2005, 2006 Free Software Foundation, Inc.
or any later version published by the Free Software Foundation;
with no Invariant Sections, with no Front-Cover Texts, and with no
Back-Cover Texts.  A copy of the license is included in the
The following is the old c2ph.doc documentation by Tom Christiansen
<tchrist@perl.com>
Once upon a time, I wrote a program called pstruct.  It was a perl
program that tried to parse out C structures and display their member
offsets for you.  This was especially useful for people looking at
binary dumps or poking around the kernel.
Pstruct was not a pretty program.  Neither was it particularly robust.
The problem, you see, was that the C compiler was much better at parsing
C than I could ever hope to be.
So I got smart:  I decided to be lazy and let the C compiler parse the C,
which would spit out debugger stabs for me to read.  These were much
easier to parse.  It's still not a pretty program, but at least it's more
robust.
Pstruct takes any .c or .h files, or preferably .s ones, since that's
the format it is going to massage them into anyway, and spits out
listings like this:
etc.
Actually, this was generated by a particular set of options.  You can control
the formatting of each column, whether you prefer wide or fat, hex or decimal,
leading zeroes or whatever.
All you need to be able to use this is a C compiler than generates
should get this for you.
will be provided.  There are a fair number of possibilities.
If you're only a C programmer, than this is the end of the message for you.
You can quit right now, and if you care to, save off the source and run it
when you feel like it.  Or not.
But if you're a perl programmer, then for you I have something much more
wondrous than just a structure offset printer.
You see, if you call pstruct by its other incybernation, c2ph, you have a code
generator that translates C code into perl code!  Well, structure and union
declarations at least, but that's quite a bit.
Prior to this point, anyone programming in perl who wanted to interact
with C programs, like the kernel, was forced to guess the layouts of
the C structures, and then hardwire these into his program.  Of course,
when you took your wonderfully crafted program to a system where the
sgtty structure was laid out differently, your program broke.  Which is
a shame.
We've had Larry's h2ph translator, which helped, but that only works on
cpp symbols, not real C, which was also very much needed.  What I offer
you is a symbolic way of getting at all the C structures.  I've couched
them in terms of packages and functions.  Consider the following program:
As you see, the name of the package is the name of the structure.  Regular
fields are just their own names.  Plus the following accessor functions are
provided for your convenience:
The way I see this being used is like basically this:
It's a little tricker with c2ph because you have to get the includes right.
I can't know this for your system, but it's not usually too terribly difficult.
been less cavalier in how the parts of the program communicated with each
other, etc.  It might also have helped if I didn't have to divine the makeup
of the stabs on the fly, and then account for micro differences between my
compiler and gcc.
Anyway, here it is.  Should run on perl v4 or greater.  Maybe less.
The following is the old c2ph.doc documentation by Tom Christiansen
<tchrist@perl.com>
Once upon a time, I wrote a program called pstruct.  It was a perl
program that tried to parse out C structures and display their member
offsets for you.  This was especially useful for people looking at
binary dumps or poking around the kernel.
Pstruct was not a pretty program.  Neither was it particularly robust.
The problem, you see, was that the C compiler was much better at parsing
C than I could ever hope to be.
So I got smart:  I decided to be lazy and let the C compiler parse the C,
which would spit out debugger stabs for me to read.  These were much
easier to parse.  It's still not a pretty program, but at least it's more
robust.
Pstruct takes any .c or .h files, or preferably .s ones, since that's
the format it is going to massage them into anyway, and spits out
listings like this:
etc.
Actually, this was generated by a particular set of options.  You can control
the formatting of each column, whether you prefer wide or fat, hex or decimal,
leading zeroes or whatever.
All you need to be able to use this is a C compiler than generates
should get this for you.
will be provided.  There are a fair number of possibilities.
If you're only a C programmer, than this is the end of the message for you.
You can quit right now, and if you care to, save off the source and run it
when you feel like it.  Or not.
But if you're a perl programmer, then for you I have something much more
wondrous than just a structure offset printer.
You see, if you call pstruct by its other incybernation, c2ph, you have a code
generator that translates C code into perl code!  Well, structure and union
declarations at least, but that's quite a bit.
Prior to this point, anyone programming in perl who wanted to interact
with C programs, like the kernel, was forced to guess the layouts of
the C structures, and then hardwire these into his program.  Of course,
when you took your wonderfully crafted program to a system where the
sgtty structure was laid out differently, your program broke.  Which is
a shame.
We've had Larry's h2ph translator, which helped, but that only works on
cpp symbols, not real C, which was also very much needed.  What I offer
you is a symbolic way of getting at all the C structures.  I've couched
them in terms of packages and functions.  Consider the following program:
As you see, the name of the package is the name of the structure.  Regular
fields are just their own names.  Plus the following accessor functions are
provided for your convenience:
The way I see this being used is like basically this:
It's a little tricker with c2ph because you have to get the includes right.
I can't know this for your system, but it's not usually too terribly difficult.
been less cavalier in how the parts of the program communicated with each
other, etc.  It might also have helped if I didn't have to divine the makeup
of the stabs on the fly, and then account for micro differences between my
compiler and gcc.
Anyway, here it is.  Should run on perl v4 or greater.  Maybe less.
The following is the old c2ph.doc documentation by Tom Christiansen
<tchrist@perl.com>
Once upon a time, I wrote a program called pstruct.  It was a perl
program that tried to parse out C structures and display their member
offsets for you.  This was especially useful for people looking at
binary dumps or poking around the kernel.
Pstruct was not a pretty program.  Neither was it particularly robust.
The problem, you see, was that the C compiler was much better at parsing
C than I could ever hope to be.
So I got smart:  I decided to be lazy and let the C compiler parse the C,
which would spit out debugger stabs for me to read.  These were much
easier to parse.  It's still not a pretty program, but at least it's more
robust.
Pstruct takes any .c or .h files, or preferably .s ones, since that's
the format it is going to massage them into anyway, and spits out
listings like this:
etc.
Actually, this was generated by a particular set of options.  You can control
the formatting of each column, whether you prefer wide or fat, hex or decimal,
leading zeroes or whatever.
All you need to be able to use this is a C compiler than generates
should get this for you.
will be provided.  There are a fair number of possibilities.
If you're only a C programmer, than this is the end of the message for you.
You can quit right now, and if you care to, save off the source and run it
when you feel like it.  Or not.
But if you're a perl programmer, then for you I have something much more
wondrous than just a structure offset printer.
You see, if you call pstruct by its other incybernation, c2ph, you have a code
generator that translates C code into perl code!  Well, structure and union
declarations at least, but that's quite a bit.
Prior to this point, anyone programming in perl who wanted to interact
with C programs, like the kernel, was forced to guess the layouts of
the C structures, and then hardwire these into his program.  Of course,
when you took your wonderfully crafted program to a system where the
sgtty structure was laid out differently, your program broke.  Which is
a shame.
We've had Larry's h2ph translator, which helped, but that only works on
cpp symbols, not real C, which was also very much needed.  What I offer
you is a symbolic way of getting at all the C structures.  I've couched
them in terms of packages and functions.  Consider the following program:
As you see, the name of the package is the name of the structure.  Regular
fields are just their own names.  Plus the following accessor functions are
provided for your convenience:
The way I see this being used is like basically this:
It's a little tricker with c2ph because you have to get the includes right.
I can't know this for your system, but it's not usually too terribly difficult.
been less cavalier in how the parts of the program communicated with each
other, etc.  It might also have helped if I didn't have to divine the makeup
of the stabs on the fly, and then account for micro differences between my
compiler and gcc.
Anyway, here it is.  Should run on perl v4 or greater.  Maybe less.
The
utility displays a simple calendar in traditional format and
offers an alternative layout, more options and the date of easter.
The new format is a little cramped but it makes a year fit
on a 25x80 terminal.
If arguments are not specified,
the current month is displayed.
The options are as follows:
Display Julian Calendar, if combined with the
option, display date of easter according to the Julian Calendar.
Display date of easter (for western churches).
Display Julian days (days one-based, numbered from January 1).
Display the specified
Display date of orthodox easter (Greek and Russian
Orthodox Churches).
Print the country codes and switching days from Julian to Gregorian
Calendar as they are assumed by
The country code as determined from the local environment is marked
with an asterisk.
Assume the switch from Julian to Gregorian Calendar at the date
associated with the
If not specified,
tries to guess the switch date from the local environment or
falls back to September 2, 1752.
This was when Great
Britain and her colonies switched to the Gregorian Calendar.
Print the number of the week below each week column.
Display a calendar for the specified year.
A single parameter specifies the year (1 - 9999) to be displayed;
note the year must be fully specified:
will
display a calendar for 1989.
Two parameters denote the month and year; the month is either a number between
1 and 12, or a full or abbreviated name as specified by the current locale.
Month and year default to those of the current system clock and time zone (so
will display a calendar for the month of August in the current year).
A year starts on Jan 1.
A
command appeared in
The
command appeared in
The
command and manual were written by
country codes is historically naive for many countries.
The
utility checks the current directory for a file named
and displays lines that begin with either today's date
or tomorrow's.
On the day before a weekend (normally Friday), events for the next
three days are displayed.
The following options are available:
Print lines from today and the next
days (forward, future).
Process the ``calendar'' files of all users and mail the results
to them.
This requires super-user privileges.
Print lines from today and the previous
days (backward, past).
Specify which day of the week is ``Friday'' (the day before the
weekend begins).
Default is 5.
Use
as the default calendar file.
For test purposes only: set date directly to argument values.
Print lines from today and the next
days (forward, future).
Ignore weekends when calculating the number of days.
To handle calendars in your national code table you can specify
in the calendar file as early as possible.
To handle national Easter
names in the calendars
(for Catholic Easter) or
(for Orthodox Easter) can be used.
Other lines should begin with a month and day.
They may be entered in almost any format, either numeric or as character
strings.
If the proper locale is set, national month and weekday
names can be used.
A single asterisk (``*'') matches every month.
A day without a month matches that day of every week.
A month without a day matches the first of that month.
Two numbers default to the month followed by the day.
Lines with leading tabs default to the last entered date, allowing
multiple line specifications for a single date.
``Easter'', is Easter for this year, and may be followed by a positive
or negative integer.
``Paskha'', is Orthodox Easter for this year, and may be followed by a
positive or negative integer.
last, first, second, third, fourth) for moving events like
``the last Monday in April''.
By convention, dates followed by an asterisk are not fixed, i.e., change
from year to year.
Day descriptions start after the first <tab> character in the line;
if the line does not contain a <tab> character, it is not displayed.
If the first character in the line is a <tab> character, it is treated as
a continuation of the previous line.
The ``calendar'' file is preprocessed by
allowing the inclusion of shared files such as lists of company holidays or
meetings.
If the shared file is not referenced by a full pathname,
searches in the current (or home) directory first, and then in the
directory
Empty lines and lines protected by the C commenting syntax
are ignored.
Some possible calendar entries (<tab> characters highlighted by
LANG=C
Easter=Ostern

#include <calendar.usholiday>
#include <calendar.birthday>



file in current directory
HOME directory.
A chdir is done into this directory if it exists.
calendar file to use if no calendar file exists in the current directory.
do not send mail if this file exists.
The following default calendar files are provided:
File which includes all the default files.
Calendar of events in Australia.
Births and deaths of famous (and not-so-famous) people.
Christian holidays.
This calendar should be updated yearly by the local system administrator
so that roving holidays are set correctly for the current year.
Days of special significance to computer people.
Calendar of events in Croatia.
Birthdays of
committers.
Calendar of events in France.
Calendar of events in Germany.
Other holidays, including the not-well-known, obscure, and
obscure.
Jewish holidays.
This calendar should be updated yearly by the local system administrator
so that roving holidays are set correctly for the current year.
Musical events, births, and deaths.
Strongly oriented toward rock 'n' roll.
Calendar of events in New Zealand.
Russian calendar.
Calendar of events in South Africa.
This calendar should be updated yearly by the local system administrator
so that roving holidays are set correctly for the current year.
Includes all calendar files except for national files.
The
program previously selected lines which had the correct date anywhere
in the line.
This is no longer true, the date is only recognized when it occurs
at the beginning of a line.
A
command appeared in
The
utility does not handle Jewish holidays and moon phases.
builds a hashed database out of the
logical database constructed by the concatenation of the specified
files .
The database is named by the basename of the first file argument and
the string
The
routines can access the database in this form much more quickly
than they can the original text file(s).
The ``tc'' capabilities of the records are expanded before the
record is stored into the database.
The options as as follows:
Specify a different database basename.
Print out the number of capability records in the database.
Each record is stored in the database using two different types of keys.
The first type is a key which consists of the first capability of
the record (not including the trailing colon (``:'')) with a data
field consisting of a special byte followed by the rest of the record.
The special byte is either a 0 or 1, where a 0 means that the record
is okay, and a 1 means that there was a ``tc'' capability in the record
that couldn't be expanded.
The second type is a key which consists of one of the names from the
first capability of the record with a data field consisting a special
byte followed by the the first capability of the record.
The special byte is a 2.
In normal operation names are looked up in the database, resulting
pair of the first type which has the real data associated with the
name.
The
utility exits 0 on success and >0 if an error occurs.
The
utility reads files sequentially, writing them to the standard output.
The
operands are processed in command-line order.
If
is a single dash
or absent,
reads from the standard input.
If
is a
domain socket,
connects to it and then reads it until
This complements the
domain binding capability available in
The options are as follows:
Number the non-blank output lines, starting at 1.
Display non-printing characters (see the
option), and display a dollar sign
at the end of each line.
Number the output lines, starting at 1.
Squeeze multiple adjacent empty lines, causing the output to be
single spaced.
Display non-printing characters (see the
option), and display tab characters as
Disable output buffering.
Display non-printing characters so they are visible.
Control characters print as
for control-X; the delete
character (octal 0177) prints as
characters (with the high bit set) are printed as
(for meta) followed by the character for the low 7 bits.
The command:
will print the contents of
to the standard output.
The command:
will sequentially print the contents of
and
to the file
truncating
if it already exists.
See the manual page for your shell (i.e.,
for more information on redirection.
The command:
will print the contents of
print data it receives from the standard input until it receives an
character, print the contents of
read and output contents of the standard input again, then finally output
the contents of
Note that if the standard input referred to a file, the second dash
on the command-line would have no effect, since the entire contents of the file
would have already been read and printed by
when it encountered the first
operand.
The
utility is compliant with the
specification.
The flags
are extensions to the specification.
A
utility appeared in
designed and wrote the first man page.
It appears to have been
Because of the shell language mechanism used to perform output
redirection, the command
will cause the original data in file1 to be destroyed!
The
utility does not recognize multibyte characters when the
or
option is in effect.
Use the .Nm macro to refer to your program throughout the man page like such:
Underlining is accomplished with the .Ar macro like this:
A list of items with descriptions:
Description of item a
Description of item b
A list of flags and their descriptions:
Description of -a flag
Description of -b flag
FILE_1 description
FILE_2 description
Use the .Nm macro to refer to your program throughout the man page like such:
Underlining is accomplished with the .Ar macro like this:
A list of items with descriptions:
Description of item a
Description of item b
A list of flags and their descriptions:
Description of -a flag
Description of -b flag
FILE_1 description
FILE_2 description
Use the .Nm macro to refer to your program throughout the man page like such:
Underlining is accomplished with the .Ar macro like this:
A list of items with descriptions:
Description of item a
Description of item b
A list of flags and their descriptions:
Description of -a flag
Description of -b flag
FILE_1 description
FILE_2 description
Use the .Nm macro to refer to your program throughout the man page like such:
Underlining is accomplished with the .Ar macro like this:
A list of items with descriptions:
Description of item a
Description of item b
A list of flags and their descriptions:
Description of -a flag
Description of -b flag
FILE_1 description
FILE_2 description

use with Keychains
command [command-args] [options]
c [options]
r outFileName [options]
v infileName [options]
C domainName [options]
i inFileName [options]
d inFileName [options]
I inFileName [options]
D inFileName [options]
y [options]
Create keypair and Certificate
Create CSR
Verify CSR
Create a System Identity
Import Certificate
Display Certificate
Import CRL
Display CRL
Import a CRL
Display all certs and CRLs in keychain
Create the keychain, if one is needed.
Create a CSR in DER format; default is PEM
Specify the keychain passphrase when creating
Optional private key, for Import Certificate only
Extended Key Usage: a=Any; s=SSL Client; S=SSL Server; m=SMIME
Generate private key with default ACL
Generate private key with ACL limiting access to current user
Don't create System Identity if one already exists for specified domain
Print usage message
Execute in verbose mode.
is a UNIX command-line program which is used to create key pairs, certificates,
and certificate signing requests; to import externally generated certificates
and Certificate Revocation Lists (CRLs) into a Keychain, and to display the 
contents of certificates and CRLs. 
This command generates a key pair and a self-signed (root) certificate
and places them in a keychain. The root cert is signed by the private
key generated during this command. The cert generated by this command 
is totally untrustworthy and cannot be used in the "real world"; the 
primary use of this command is to facilitate early development of SSL 
server applications based on SecureTransport. In particular, 
"real world" SSL clients (e.g., web browsers) will complain to
varying degrees when they attempt to connect to an SSL server which
presents a cert which is generated by this command. Some broswers,
after a fair amount of handholding, will allow you to conditionally
"trust" this cert. 
# CertTool c [options]
The available options are:
k=keyChainName 
Where "keyChainName" is the name of the keychain into which keys and the cert
will be added. The specified keychain must exist. If it doesn't exist and
you want the keychain created for you, specify the 'c' option. If no keychain
is specified, keys and certs are added to the default keychain. 
c 
Specifies that the designated keychain is to be created.
x=[aSsm]
a
Results the the private key being created with a default ACL. If not specified, the private key is created with no ACL. 
u
Create the private key with an ACL limiting access to the current user. 
This is an interactive command; you will be prompted for a number of different
items which are used to generate the keypair and the cert. A sample session
follows. 
# CertTool k=certkc 
Enter key and certificate label: testCert 

Please specify parameters for the key pair you will generate. 

	r RSA 
	d DSA 
	f FEE 

Select key algorithm by letter: r 

Valid key sizes for RSA are 512..2048; default is 512 
Enter key size in bits or CR for default: 512 

You have selected algorithm RSA, key size 512 bits. 
 ...Generating key pair... 

Note: you will be prompted for the Keychain's passphrase by the Keychain
system at this point if the specified keychain is not open and you have not specified the passphrase via the 'p' option. 
Please specify the algorithm with which your certificate will be signed. 

	5 RSA with MD5 
	s RSA with SHA1 

Select signature algorithm by letter: s 

You have selected algorithm RSA with SHA1. 
You will now specify the various components of the certificate's 
Relative Distinguished Name (RDN). An RDN has a number of 
components, all of which are optional, but at least one of 
which must be present. 
Note that if you are creating a certificate for use in an 
exactly the host name of the server. This must not be an IP 
address, but the actual domain name, e.g. www.apple.com. 
Entering a CR for a given RDN component results in no value for 
that component. 
Common Name       (e.g. www.apple.com) : 10.0.61.5
Country           (e.g. US) : 
Organization      (e.g. Apple Computer, Inc.) : Apple 
Organization Unit (e.g. Apple Data Security) : 
Email Address     (e.g. johngalt@rand.com) : 
You have specified: 
 Common Name	: 10.0.61.5 
 Organization	: Apple 
#
The "Common Name" portion of the RDN - in the above case, "10.0.61.5" - MUST
the test machine doesn't have an actual hostname; it's DHCP'd behind a firewall
which is why "10.0.61.5" was specified for Common Name.) This is part of SSL's
certificate verification; it prevents an attack using DNS spoofing. 
is that the server cert specified in SSLSetCertificate() is capable of both
signing and encryption. If this cert is only capable of signing, you must
create a second keychain containing a cert which is capable of encryption, and
pass that to SSLSetEncryptionCertificate(). 
A CSR is the standard means by which an administrator of a web server provides
information to a Certificate Authority (CA) in order to obtain a valid
certificate which is signed by the CA. This type of cert is used in the real
world; certs signed by CAs such as Verisign and Thawte are recognized by most web
browsers when performing SSL transactions. 
The general procedure for obtaining a "real" cert is: 
Generate a key pair
Generate a CSR
CA sends you a certificate which is signed by the CA.
You import that certificate, obtained from the CA, into your keychain.
The
items in that keychain can now be used in SecureTransport's SSLSetCertificate()
call.
This command performs the first two steps in the above procedure. See the 
section below entitled "Importing a Certificate" for information on 
importing the resulting certificate into your keychain. The format of 
this command is 
# CertTool r outFileName [options] 
The resulting CSR will be written to "outFileName". 
The available options are: 
k=keyChainName 
Where "KeyChainName" is the name of the keychain into which keys and the cert
will be added. If no keychain is specified, keys and certs are added to the
default keychain. The specified keychain must exist unless you specify the 'c'
option.
 d 
The 'd' option tells CertTool to create the CSR in DER-encoded format. The
default is PEM-encoded, which is what most CAs expect. PEM encoded data consists
of printable ASCII text which can, for example, be pasted into an email message.
DER-encoded data is nonprintable binary data.
 c 
Specifies that the designated keychain is to be created.
a
Results the the private key being created with a default ACL. If not specified, the private key is created with no ACL. 
u
Create the private key with an ACL limiting access to the current user. 
This is an interactive command; you will be prompted for a number of different
items which are used to generate the keypair and the CSR. The prompts given, and
the format of the data you must supply, are identical to the data shown in the
sample session in Section 2. 
A CSR contains, among other things, the public key which was generated in
as described above. The CSR is signed with the associated private key. Thus the
integrity of a CSR can be verified by extracting its public key and verifying the signature of the CSR. This command performs this integrity check. The format of this command is 
# CertTool v inFileName [options] 
The only available option is the 'd' flag, which as described above in the
section entitled "Generating a Certificate Signing Request", indiciates 
that the CSR is in DER format rather than the default PEM format. 
A typical (successful) run of this command is like so: 
# CertTool v myCsr.pem 
 ...CSR verified successfully. 
A large number of things can go wrong if the verification fails; suffice it to
say that if you see anything other than the above success message, you have a
bad or corrupted CSR. 
This creates a key pair and a self-signed (root) certificate in the System keychain, and registers the result in the System Identity database as being the IDentity associated with the specified domain name. The domain name is typically a string of the form "com.apple.somedomain...". You must be running as root to execute this command. 
The format of this command is 
# CertTool C domainName [options] 
The available options are:
u
Create the private key with an ACL limiting access to the current user. If not specified, the private key wil be created with a default ACL. 
P
Don't create system identity if one already exists for specified domain.
Once you have negotiated with your CA, and provided them with the CSR generated
as described above as well as any other information, documentation, and payment they
require, the CA will provide you with a certificate. Use this command to add
that certificate to the keychain containing the keypair you generated previously.
The format of this command is 
# CertTool i inFileName [options] 
The cert to import is obtained from "inFileName". The available options are: 
k=keyChainName 
Where "keyChainName" is the name of the keychain to which the cert will be
added. If no keychain is specified, the cert is added to the default keychain.
The specified keychain typically contains the keypair you generated previously.
(Note you can import a certificate into a keychain which does not contain keys
you generated but there will be no linkage between the imported certificate and
a private key if you do this.) If the keychain is not open when this command is
executed, you will be prompted by the Keychain system for its passphrase.
r=privateKeyFileName
f=privateKeyFormat
Where "privateKeyFormat" is the format of the private key specified with the 'r' option. The formats are: '1' for PKCS1 (OpenSSL format), '8' (PKCS8), and 'f' (FIPS186, BSAFE format). The default is OpenSSL format for both RSA and DSA keys.   
 d 
Specifies DER format as described above. The default is PEM format.
 c 
Specifies that the designated keychain is to be created.
This displays the contents of an existing certificate, obtained from a file. 
The format of this command is 
# CertTool d inFileName [options] 
The cert to display is obtained from "inFileName". 
The only available option is the 'd' flag, specifying DER format as described above. The default is PEM format. Actually, in the absence of this option, certtool will correctly determine the format of the certificate (PEM or DER). 
This command is used to add a Certificate Revocation List (CRL) to a keychain. 
The format of this command is 
# CertTool I inFileName [options] 
The CRL to import is obtained from "inFileName".  The available options are: 
k=keyChainName 
Where "KeyChainName" is the name of the keychain to which the CRL will be added.
If no keychain is specified, the cert is added to the default keychain.  If the
keychain is not open when this command is executed, you will be prompted by the
Keychain system for its passphrase.
 d 
Specifies DER format as described above. The default is PEM format.
 c 
Specifies that the designated keychain is to be created.
This displays the contents of an existing Certificate Revocation List (CRL),
obtained from a file. The format of this command is 
# CertTool D inFileName [options] 
The cert to display is obtained from "inFileName". 
The only available option is the 'd' flag, specifying DER format as described
above. The default is PEM format.
This displays the contents of all certificates and CRLs in a keychain. The format of this command is 
# CertTool y [options] 
The available options are: 
k=keyChainName 
Where "KeyChainName" is the name of the keychain to display.
v
Specifies verbose mode.
As mentioned above, the general procedure for obtaining a "real" cert is: 
Generate a key pair
Generate a CSR
CA sends you a certificate which is signed by the CA.
You import that certificate, obtained from the CA, into your keychain.
The items in that keychain can now be used in SecureTranspoert's SSLSetCertificate()
call.
One CA with an excellent web-based interface for obtaining a cert is Verisign
trial certificate using nothing but CertTool, Verisign's web site, and email.
You need to provide some personal information. Paste the CSR
generated as described in the section entitled "Generating a Certificate 
Signing Request" into a form on the web site. A few minutes later Verisign
emails you a certificate, which you import into your keychain.
The whole process takes less than 10 minutes. The free certificate obtained in
this manner is signed by a temporary root cert which is not recognized by any
browsers, but Verisign also provides a means of installing this temporary root
cert into your browser, directly from their web site. Typically one would use
the free, temporary cert to perform initial configuration of a server and to
ring out the general SSL infrastructure. Once you feel comfortable with the
operation of the server, then it's time to buy a "real" certificate which will
allow your web server to be trusted by any browser. 
System root certificate database
System Keychain
Use
to exercise the content filter subsystem.
The flags have the following meaning:
Auto start filtering with given offset.
Default values for offset passin, peekin, passout, peekout, pass or peek.
Display this help.
Interactive mode.
Peek mode with increment.
Pass loopback traffic.
Maximum dump length.
Pass mode (all or after given offset if it is > 0).
Decrease verbosity.
Random drop rate.
display content filter statistics (all, sock, filt, cfil).
Pass delay in microseconds.
NECP filter control unit.
Increase verbosity.
checks the integrity of a LocalKDC and its principals.
The script is non-destructive and can be run multiple times.
does not own, but references the following files:
first appeared in version 10.7 of Mac OS X.
The
utility checks a list of
or
input files for certain kinds of errors
involving mismatched opening and closing delimiters
and unknown commands.
If no files are specified,
checks the standard input.
The following options are available:
Add additional pairs of macros to the list of known macros.
This must be followed by groups of six characters, each group defining
a pair of macros.
The six characters are
a period,
the first macro name,
another period,
and the second macro name.
For example, to define a pair .BS and .ES, use
Define commands which would otherwise be complained about
as undefined.
Request
to ignore
font changes.
Ignore
size changes.
Delimiters checked are:
the .TS and .TE macros which must always come in pairs.
The
utility is intended for use on documents that are prepared with
in mind, much the same as
It expects a certain document writing style for
and
commands,
in that each
must be terminated with
and
each
must be terminated with
While it will work to directly go into the next font or explicitly
specify the original font or point size,
and many existing documents actually do this,
such a practice will produce complaints from
Since it is probably better to use the
and
forms anyway,
you should think of this as a contribution to your document
preparation style.
The
utility knows about the
and
macro packages.
Complaints about unmatched delimiters.
Complaints about unrecognized commands.
Various complaints about the syntax of commands.
There is no way to define a 1 character macro name using
Does not correctly recognize certain reasonable constructs,
such as conditionals.
The
command appeared in
The
utility modifies the file flags of the listed files
as specified by the
operand.
The options are as follows:
Do not display a diagnostic message if
could not modify the flags for
nor modify the exit status to reflect such failures.
If the
option is specified, symbolic links on the command line are followed.
(Symbolic links encountered in the tree traversal are not followed.)
If the
is a symbolic link,
change the file flags of the link itself rather than the file to which it points.
If the
option is specified, all symbolic links are followed.
If the
option is specified, no symbolic links are followed.
This is the default.
Change the file flags for the file hierarchies rooted
in the files instead of just the files themselves.
Cause
to be verbose, showing filenames as the flags are modified.
If the
option is specified more than once, the old and new flags of the file
will also be printed, in octal notation.
The flags are specified as an octal number or a comma separated list
of keywords.
The following keywords are currently defined:
set the archived flag (super-user only)
set the opaque flag (owner or super-user only).
[Directory is opaque when viewed through a union mount]
set the nodump flag (owner or super-user only)
set the system append-only flag (super-user only)
set the system immutable flag (super-user only)
set the user append-only flag (owner or super-user only)
set the user immutable flag (owner or super-user only)
set the hidden flag
[Hide item from GUI]
As discussed in
the
and
flags may only be unset when the system is in single-user mode.
Putting the letters
before or removing the letters
from a keyword causes the flag to be cleared.
For example:
clear the user immutable flag (owner or super-user only)
clear the nodump flag (owner or super-user only)
Unless the
or
options are given,
on a symbolic link always succeeds and has no effect.
The
and
options are ignored unless the
option is specified.
In addition, these options override each other and the
command's actions are determined by the last one specified.
You can use "ls -lO" to see the flags of existing files.
The
command first appeared in
Only a limited number of utilities are
aware.
Some of these tools include
and
In particular a tool which is not currently
aware is the
utility.
The
utility sets the group ID of the file named by each
operand to the
ID specified by the group operand.
The following options are available:
The force option ignores errors, except for usage errors and doesn't
query about strange modes (unless the user does not have proper permissions).
If the
option is specified, symbolic links on the command line are followed.
(Symbolic links encountered in the tree traversal are not followed).
If the file is a symbolic link, the group ID of the link itself is changed
rather than the file that is pointed to.
If the
option is specified, all symbolic links are followed.
If the
option is specified, no symbolic links are followed.
This is the default. Use
to change the group ID of a symbolic link.
Change the group ID for the file hierarchies rooted
in the files instead of just the files themselves.
Cause
to be verbose, showing files as the group is modified.
The
and
options are ignored unless the
option is specified.
In addition, these options override each other and the
command's actions are determined by the last one specified.
The
operand can be either a group name from the group database,
or a numeric group ID.
If a group name is also a numeric group ID, the operand is used as a
group name.
The user invoking
must belong to the specified group and be the owner of the file,
or be the super-user.
In previous versions of this system, symbolic links did not have groups.
The
option is non-standard and its use in scripts is not recommended.
group ID file
The
utility is expected to be
compatible.
The
utility modifies the file mode bits of the listed files
as specified by the
operand. It may also be used to modify the Access Control
Lists (ACLs) associated with the listed files.
The generic options are as follows:
Do not display a diagnostic message if
could not modify the mode for
If the
option is specified, symbolic links on the command line are followed.
(Symbolic links encountered in the tree traversal are not followed by
default.)
If the file is a symbolic link, change the mode of the link itself
rather than the file that the link points to.
If the
option is specified, all symbolic links are followed.
If the
option is specified, no symbolic links are followed.
This is the default.
Change the modes of the file hierarchies rooted in the files
instead of just the files themselves.
Cause
to be verbose, showing filenames as the mode is modified.
If the
flag is specified more than once, the old and new modes of the file
will also be printed, in both octal and symbolic notation.
The
and
options are ignored unless the
option is specified.
In addition, these options override each other and the
command's actions are determined by the last one specified.
Only the owner of a file or the super-user is permitted to change
the mode of a file.
Modes may be absolute or symbolic.
An absolute mode is an octal number constructed from the sum of
one or more of the following values:
(the set-user-ID-on-execution bit) Executable files with this bit set
will run with effective uid set to the uid of the file owner.
Directories with the set-user-id bit set will force all files and
sub-directories created in them to be owned by the directory owner
and not by the uid of the creating process, if the underlying file
system supports this feature: see
and the
option to
(the set-group-ID-on-execution bit) Executable files with this bit set
will run with effective gid set to the gid of the file owner.
(the sticky bit)
See
and
Allow read by owner.
Allow write by owner.
For files, allow execution by owner.
For directories, allow the owner to
search in the directory.
Allow read by group members.
Allow write by group members.
For files, allow execution by group members.
For directories, allow
group members to search in the directory.
Allow read by others.
Allow write by others.
For files, allow execution by others.
For directories allow others to
search in the directory.
For example, the absolute mode that permits read, write and execute by
the owner, read and execute by group members, read and execute by
others, and no set-uid or set-gid behaviour is 755
(400+200+100+040+010+004+001).
The symbolic mode is described by the following grammar:
mode         ::= clause [, clause ...]
clause       ::= [who ...] [action ...] action
action       ::= op [perm ...]
who          ::= a | u | g | o
perm         ::= r | s | t | w | x | X | u | g | o
The
symbols ``u'', ``g'', and ``o'' specify the user, group, and other parts
of the mode bits, respectively.
The
symbol ``a'' is equivalent to ``ugo''.
The
symbols represent the portions of the mode bits as follows:
The read bits.
The set-user-ID-on-execution and set-group-ID-on-execution bits.
The sticky bit.
The write bits.
Operations with the
symbol ``X'' are only meaningful in conjunction with the
symbol ``+'', and are ignored in all other cases.
The user permission bits in the original mode of the file.
The group permission bits in the original mode of the file.
The other permission bits in the original mode of the file.
The
symbols represent the operation performed, as follows:
If no value is supplied for
the ``+'' operation has no effect.
If no value is supplied for
each permission bit specified in
for which the corresponding bit in the file mode creation mask
is clear, is set.
Otherwise, the mode bits represented by the specified
and
values are set.
If no value is supplied for
If no value is supplied for
each permission bit specified in
for which the corresponding bit in the file mode creation mask
is clear, is cleared.
Otherwise, the mode bits represented by the specified
and
values are cleared.
The mode bits specified by the
value are cleared, or, if no who value is specified, the owner, group
and other mode bits are cleared.
Then, if no value is supplied for
each permission bit specified in
for which the corresponding bit in the file mode creation mask
is clear, is set.
Otherwise, the mode bits represented by the specified
and
values are set.
Each
specifies one or more operations to be performed on the mode
bits, and each operation is applied to the mode bits in the
order specified.
Operations upon the other permissions only (specified by the symbol
``o'' by itself), in combination with the
symbols ``s'' or ``t'', are ignored.
make a file readable by anyone and writable by the owner only.
deny write permission to group and others.
set the read and write permissions to the usual defaults, but
retain any execute permissions that are currently set.
clear all mode bits for group and others.
set the group bits equal to the user bits, but clear the group write bit.
ACLs are manipulated using extensions to the symbolic mode
grammar.  Each file has one ACL, containing an ordered list of entries.
Each entry refers to a user or group, and grants or denies a set of
permissions.
In cases where a user and a group exist with the same name, the
specify the type of name.
If the user or group name contains spaces you can use ':' as the delimiter
between name and permission.
The following permissions are applicable to all filesystem objects:
Delete the item.  Deletion may be granted by either this permission
on an object or the delete_child right on the containing directory.
Read an objects basic attributes.  This is implicitly granted if 
the object can be looked up and not explicitly denied.
Write an object's basic attributes.
Read extended attributes.
Write extended attributes.
Read an object's extended security information (ACL).
Write an object's security information (ownership, mode, ACL).
Change an object's ownership.
The following permissions are applicable to directories:
List entries.
Look up files by name.
Add a file.
Add a subdirectory.
Delete a contained object.  See the file delete permission above.
The following permissions are applicable to non-directory filesystem objects:
Open for reading.
Open for writing.
Open for writing, but in a fashion that only allows writes into areas of 
the file not previously written.
Execute the file as a script or program.
ACL inheritance is controlled with the following permissions words, which
may only be applied to directories:
Inherit to files.
Inherit to directories.
This flag is only relevant to entries inherited by subdirectories; it
causes the directory_inherit flag to be cleared in the entry that is
inherited, preventing further nested subdirectories from also
inheriting the entry.
The entry is inherited by created items but not considered when processing
the ACL.
The ACL manipulation options are as follows:
The +a mode parses a new ACL entry from the next argument on
the commandline and inserts it into the canonical location in the
ACL. If the supplied entry refers to an identity already listed, the
two entries are combined.
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
 # chmod +a "admin allow write" file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: admin allow write
 # chmod +a "guest deny read" file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: admin allow write
 # chmod +a "admin allow delete" file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: admin allow write,delete
 # chmod +a "User 1:allow:read" file
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: User 1 allow read
   3: admin allow write,delete
The +a mode strives to maintain correct canonical form for the ACL.
                 local deny
                 local allow
                 inherited deny
                 inherited allow
By default, chmod adds entries to the top of the local deny and local
allow lists. Inherited entries are added by using the +ai mode.
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: admin allow write,delete
   3: juser inherited deny delete
   4: admin inherited allow delete
   5: backup inherited deny read
   6: admin inherited allow write-security
 # chmod +ai "others allow read" file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: admin allow write,delete
   3: juser inherited deny delete
   4: others inherited allow read
   5: admin inherited allow delete
   6: backup inherited deny read
   7: admin inherited allow write-security
When a specific ordering is required, the exact location at which an
entry will be inserted is specified with the +a# mode.
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: admin allow write
 # chmod +a# 2 "others deny read" file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: others deny read
   3: admin allow write
The +ai# mode may be used to insert inherited entries at a specific
location. Note that these modes allow non-canonical ACL ordering to
be constructed.
The -a mode is used to delete ACL entries. All entries exactly
matching the supplied entry will be deleted. If the entry lists a
subset of rights granted by an entry, only the rights listed are
removed. Entries may also be deleted by index using the -a# mode.
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: admin allow write,delete
 # chmod -a# 1 file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: admin allow write,delete
 # chmod -a "admin allow write" file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: admin allow delete
Inheritance is not considered when processing the -a mode; rights and
entries will be removed regardless of their inherited state.
If the user or group name contains spaces you can use ':' as the delimiter
 # chmod +a "User 1:allow:read" file
Individual entries are rewritten using the =a# mode.
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: admin allow delete
 # chmod =a# 1 "admin allow write,chown"
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: admin allow write,chown
This mode may not be used to add new entries.
Reads the ACL information from stdin, as a sequential list
of ACEs, separated by newlines.  If the information parses correctly,
the existing information is replaced.
Returns false if any of the named files have ACLs in non-canonical order.
Removes the 'inherited' bit from all entries in the named file(s) ACLs.
Removes all inherited entries from the named file(s) ACL(s).
Removes the ACL from the named file(s).
The
option is non-standard and its use in scripts is not recommended.
The
utility is expected to be
compatible with the exception of the
symbol
which is not included in that standard.
A
command appeared in
The
utility
allows editing of the user database information associated
with
or, by default, the current user.
The
utility 
change the user's password on Open Directory
systems.  Use the
utility instead.
The
and
utilities behave identically to
(There is only one program.)
The information is formatted and supplied to an editor for changes.
Only the information that the user is allowed to change is displayed.
The options are as follows:
If not specified,
will perform a search for the user record on all available
Open Directory nodes.
When specified,
will edit the user record on the directory node at the given
The user name to use when authenticating to the directory node containing the
user.
Attempt to change the user's shell to
Possible display items are as follows:
user's login name
user's login
user's login group
user's UUID
user's real name
user's office location
user's office phone
user's home phone
user's home directory
user's login shell
The
field is the user name used to access the computer account.
The
field is the number associated with the
field.
Both of these fields should be unique across the system (and often
across a group of systems) as they control file access.
While it is possible to have multiple entries with identical login names
Routines
that manipulate these files will often return only one of the multiple
entries, and that one by random selection.
The
field is the group that the user will be placed in at login.
Since
supports multiple groups (see
this field currently has little special meaning.
This field may be filled in with either a number or a group name (see
The
field is the globally unique identifier (UUID) for the user.
The
field contains the full name of the user.
The user's
is the full
path name where the user
will be placed at login.
The
field is the command interpreter the user prefers.
If the
field is empty, the Bourne shell,
is assumed.
When altering a login shell, and not the super-user, the user
may not change from a non-standard shell or to a non-standard
shell.
Non-standard is defined as a shell not found in
The
field is the path to a picture to be displayed for the user.
User database entries are under the control of
and may be physically located in many different places,
including the local Directory Service node, 
and remote LDAP servers.
This version of
uses Open Directory to change user database information.
It does not interact with the historic flat file
database
The
editor will be used unless the environment variable
is set to
an alternate editor.
When the editor terminates, the information is re-read and used to
update the user database itself.
Only the user, or the super-user, may edit the information associated
with the user.
temporary copy of the data to edit
the list of approved shells
The
utility appeared in
The
utility writes to the standard output three whitespace separated
fields for each input file.
These fields are a checksum
the total number of octets in the file and the file name.
If no file name is specified, the standard input is used and no file name
is written.
The
utility is identical to the
utility, except that it defaults to using historic algorithm 1, as
described below.
It is provided for compatibility only.
The options are as follows:
Use historic algorithms instead of the (superior) default one.
Algorithm 1 is the algorithm used by historic
systems as the
algorithm and by historic
systems as the
algorithm when using the
option.
This is a 16-bit checksum, with a right rotation before each addition;
overflow is discarded.
Algorithm 2 is the algorithm used by historic
systems as the
default
algorithm.
This is a 32-bit checksum, and is defined as follows:
s = sum of all bytes;
Algorithm 3 is what is commonly called the
algorithm.
This is a 32-bit checksum.
Both algorithm 1 and 2 write to the standard output the same fields as
the default algorithm except that the size of the file in bytes is
replaced with the size of the file in blocks.
For historic reasons, the block size is 1024 for algorithm 1 and 512
for algorithm 2.
Partial blocks are rounded up.
The default
used is based on the polynomial used for
error checking
in the networking standard
The
checksum encoding is defined by the generating polynomial:
G(x) = x^32 + x^26 + x^23 + x^22 + x^16 + x^12 +
     x^11 + x^10 + x^8 + x^7 + x^5 + x^4 + x^2 + x + 1
Mathematically, the
value corresponding to a given file is defined by
the following procedure:
The
bits to be evaluated are considered to be the coefficients of a mod 2
polynomial M(x) of degree
These
bits are the bits from the file, with the most significant bit being the most
significant bit of the first octet of the file and the last bit being the least
significant bit of the last octet, padded with zero bits (if necessary) to
achieve an integral number of octets, followed by one or more octets
representing the length of the file as a binary value, least significant octet
first.
The smallest number of octets capable of representing this integer are used.
M(x) is multiplied by x^32 (i.e., shifted left 32 bits) and divided by
G(x) using mod 2 division, producing a remainder R(x) of degree <= 31.
The coefficients of R(x) are considered to be a 32-bit sequence.
The bit sequence is complemented and the result is the CRC.
The default calculation is identical to that given in pseudo-code
in the following
article.
The
utility is expected to conform to
The
utility appeared in
figure out how to clear the screen.
version 5.7 (patch 20081102).
Compare two files byte by byte.
Print differing bytes.
Skip the first SKIP bytes of input.
Skip the first SKIP1 bytes of FILE1 and the first SKIP2 bytes of FILE2.
Output byte numbers and values of all differing bytes.
Compare at most LIMIT bytes.
Output nothing; yield exit status only.
Output version info.
Output this help.
SKIP1 and SKIP2 are the number of bytes to skip in each file.
SKIP values may be followed by the following multiplicative suffixes:
kB 1000, K 1024, MB 1,000,000, M 1,048,576,
GB 1,000,000,000, G 1,073,741,824, and so on for T, P, E, Z, Y.
If a FILE is `-' or missing, read standard input.
Written by Torbjorn Granlund and David MacKenzie.
Report bugs to <bug-gnu-utils@gnu.org>.
This program comes with NO WARRANTY, to the extent permitted by law.
You may redistribute copies of this program
under the terms of the GNU General Public License.
For more information about these matters, see the file named COPYING.
The full documentation for
is maintained as a Texinfo manual.  If the
and
programs are properly installed at your site, the command
should give you access to the complete manual.
The
command is used to create, check, and display code signatures, as well as
inquire into the dynamic status of signed code in the system.
requires exactly one
option to determine what action is to be performed, as well as any number of
other options to modify its behavior. It can act on any number of objects per invocation,
but performs the same operation on all of them.
accepts single-character (classic) options, as well as GNU-style long
options of the form --name and --name=value. Common options have both
forms; less frequent and specialized options have only long form.
Note that the form --name value (without equal sign) will not work as expected
on options with optional values.
The options are as follows:
When verifying a code signature on code that has a universal ("fat") Mach-O binary,
separately verify each architecture contained. This is the default unless overridden
with the -a (--architecture) option.
When verifying or displaying signatures, explicitly select the Mach-O architecture
given. The
can be specified either by name (e.g. i386) or by number; if by number, a sub-architecture
may be appended separated by a comma.
This option applies only to Mach-O binary code and is ignored for other types.
If the
uses the Mach-O format and contains no code of the given architecture, the command will fail.
The default for verification is --all-architectures, to verify all architectures present.
The default for display is to report on the native architecture of the host system.
When signing,
will always sign all architectures contained in a universal Mach-O file.
When handling versioned bundles such as frameworks, explicitly specify the version
to operate on. This must be one of the names in the "Versions" directory of the bundle.
If not specified,
uses the bundle's default version.
Note that most frameworks delivered with the system have only one version, and thus
this option is irrelevant for them.
There is currently no facility for operating on all versions of a bundle at once.
Display information about the code at the path(s) given. Increasing levels
of verbosity produce more output.
The format is designed to be moderately easy to parse by simple scripts while still
making sense to human eyes.
In addition, the -r, --file-list, --extract-certificates, and --entitlements options can be used to retrieve additional information.
When signing, designates that a detached signature should be written to
the specified file. The code being signed is not modified and need not be
writable.
When verifying, designates a file containing a detached signature to be used
for verification. Any embedded signature in the code is ignored.
When signing a bundle, specifies that nested code content such as helpers, frameworks,
and plug-ins, should be recursively signed in turn. Beware that all signing options you
specify will apply, in turn, to such nested content.
When verifying a bundle, specifies that any nested code content will be recursively
verified as to its full content. By default, verification of nested content is limited
to a shallow investigation that may not detect changes to the nested code.
When displaying a signature, specifies that a list of directly nested code should be
written to the display output. This lists only code directly nested within the subject;
anything nested indirectly will require recursive application of the
command.
When signing, specifies that a detached signature should be generated as with
the --detached option, but that the resulting signature should be written into a system
database, from where it is made automatically available whenever apparently unsigned
code is validated on the system.
Writing to this system database requires elevated process privileges that are
not available to ordinary users.
When signing, causes
to replace any existing signature on the path(s) given. Without this option,
existing signatures will not be replaced, and the signing operation fails.
Constructs and prints the hosting chain of a running program. The
arguments must denote running code (pids etc.) With verbose options, this also
displays the individual dynamic validity status of each element of the hosting chain.
During signing, explicitly specify the unique identifier string that is embedded
in code signatures. If this option is omitted, the identifier is derived from
either the Info.plist (if present), or the filename of the executable being signed,
possibly modified by the --prefix option.
During signing, specifies a set of option flags to be embedded in the code
signature. The value takes the form of a comma-separated list of names (with
no spaces). Alternatively, a numeric value can be used to directly
specify the option mask (CodeDirectory flag word). See OPTION FLAGS below.
Indicates the granularity of code signing. Pagesize must be a power of two.
Chunks of pagesize bytes are separately signed and can thus be independently verified as needed.
As a special case, a pagesize of zero
indicates that the entire code should be signed and verified as a single,
possibly gigantic page. This option only applies to the main executable and has
no effect on the sealing of associated data, including resources.
During signing, indicates that internal requirements should be embedded in the
code path(s) as specified. See "specifying requirements" below.
Defaults will be applied to requirement types that are not explicitly specified;
if you want to defeat such a default, specify "never" for that type.
During display, indicates where to write the code's internal requirements. Use -r-
to write them to standard output.
During verification, indicates that the path(s) given should be verified against
the code requirement specified. If this option is omitted, the code is verified
only for internal integrity and against its own designated requirement.
Sign the code at the path(s) given using this identity. See SIGNING IDENTITIES below.
Sets (with a numeric value) or increments the verbosity level of output. Without
the verbose option, no output is produced upon success, in the classic UNIX style.
If no other options request a different action, the first -v encountered will be
interpreted as --verify instead (and does not increase verbosity).
Requests verification of code signatures.
If other actions (sign, display, etc.) are also requested, -v is interpreted
to mean --verbose.
Instructs
to continue processing path arguments even if processing one fails.
If this option is given, exit due to operational errors is deferred until
all path arguments have been considered. The exit code will then indicate
the most severe failure (or, with equal severity, the first such failure encountered).
During signing, performs almost all signing operations, but does not actually
write the result anywhere. Cryptographic signatures are still generated,
actually using the given signing identity and triggering any access control
checks normally, though the resulting signature is then discarded.
When signing, take the file at the given
and embed its contents in the signature as entitlement data. If the data at
does not already begin with a suitable binary ("blob") header, one is attached automatically.
When displaying a signature, extract any entitlement data from the signature
and write it to the
given. Use "-" to write to standard output.
By default, the binary "blob" header is returned intact; prefix the path with a colon ":"
to automatically strip it off.
If the signature has no entitlement data,
nothing is written (this is not an error).
When displaying a signature, extract the certificates in the embedded certificate chain
and write them to individual files. The
argument is appended with numbers 0, 1, ... to form the filenames, which can be relative
or absolute. Certificate 0 is the leaf (signing) certificate, and as many files are written
as there are certificates in the signature. The files are in ASN.1 (DER) form.
If
is omitted, the default prefix is "codesign" in the current directory.
When signing or displaying a signature,
writes to the given path a list of
files that may have been modified as part of the signing process. This is useful
for installer or patcher programs that need to know what was changed or what files
are needed to make up the "signature" of a program. The file given is appended-to,
with one line per absolute path written. An argument of "-" (single dash) denotes standard
output.
Note that the list may be
somewhat pessimistic - all files not listed are guaranteed to be unchanged by the
signing process, but some of the listed files may not actually have changed.
Also note that changes may have been made to extended attributes of these
files.
During static validation, do not validate the contents of the code's resources.
In effect, this will pass validation on code whose resources have been corrupted
(or inappropriately signed). On large programs, it will also substantially speed
up static validation, since all the resources will not be read into memory.
Obviously, the outcome of such a validation should be considered on its merits.
During signing, only search for the signing identity in the keychain file
specified. This can be used to break any matching ties if you have multiple
similarly-named identities in several keychains on the user's search list.
Note that the standard keychain search path is still consulted while constructing
the certificate chain being embedded in the signature.
Note that
will not be searched to resolve the signing identity's certificate chain unless it
is also on the user's keychain search list.
If no explicit unique identifier is specified (using the -i option), and if
the implicitly generated identifier does not contain any dot (.) characters,
then the given string is prefixed to the identifier before use. If the implicit
identifier contains a dot, it is used as-is. Typically,
this is used to deal with command tools without Info.plists, whose default
identifier is simply the command's filename; the conventional prefix used
is com.domain. (note that the final dot needs to be explicit).
When re-signing code that is already signed, reuse some information from the old signature.
If new data is specified explicitly, it is preferred.
You still need to specify the -f (--force) option to enable overwriting signatures at all.
If this option is absent, any old signature has no effect on the signing process.
This option takes a comma-separated list of names, which you may reasonably abbreviate:
Preserve the signing identifier (--identifier) instead of generating a default identifier.
Preserve the entitlement data (--entitlements).
Preserve the internal requirements (--requirements option), including any explicit Designated
Requirement. Note that all internal requirements are preserved or regenerated as a whole; you
cannot pick and choose individual elements with this option.
For historical reasons, this option can be given without a value, which preserves all
of these values as presently known. This use is deprecated and will eventually be removed;
always specify an explicit list of preserved items.
If this option is given without a value, a default server provided by Apple is used.
Note that this server may not support signatures made with identities not furnished by Apple.
If the timestamp authority service cannot be contacted over the Internet, or it malfunctions
If this option is not given at all, a system-specific default behavior is invoked.
This may result in some but not all code signatures being timestamped.
In the first synopsis form,
attempts to sign the code objects at the
given, using the
provided. Internal
and
are embedded if requested. Internal requirements not specified may be assigned suitable
default values. Defaulting applies separately to each type of internal requirement.
If an
is explicitly given, it is sealed into all
Otherwise, each path derives its
independently from its Info.plist or pathname.
Code nested within bundle directories
option is given, in which case any unsigned nested code will be recursively signed
before proceeding, using the same signing options and parameters. If the
option is given, any existing top-level signature is replaced, subject to any
options also present. Combining the
and
options results in forcible replacement of all signatures within the target bundle.
In the second synopsis form,
verifies the code signatures on all the
given. The verification confirms that the code at those
is signed, that the signature is valid, and that all sealed components are
unaltered. If a
is given, each
is also checked against this requirement (but see DIAGNOSTICS below).
If verbose verification is requested, the program is also checked against its own
designated requirement, which should never fail for a properly signed program.
If a
begins with a decimal digit, it is interpreted as the process id of a running
process in the system, and dynamic validation is performed on that process instead.
This checks the code's dynamic status and just enough static data to close the
nominal security envelope. Add at least one level of verbosity to also perform
a full static check.
In the third synopsis form,
displays the contents of the signatures on the
given. More information is displayed as the verbosity level increases.
This form may not completely verify the signatures
on the
though it may perform some verification steps in the process of obtaining information
about the
If the
option is given, internal requirements will be extracted from the
and written to
specify a dash "-" to write to standard output. If the code does not contain
an explicit designated requirement, the implied one will be retrieved and written
out as a source comment.
If the
option is given, embedded entitlement data will be extracted likewise and written to
the file specified.
In the fourth synopsis form,
constructs the hosting path for each
given and writes it, one host per line, to standard output. The hosting path is the
chain of code signing hosts starting with the most specific code known to be running,
and ending with the root of trust (the kernel). If the
option is given, the dynamic validity status of each host is also displayed, separated
from the path by a tab character.
Note that hosting chains can at times be constructed for invalid or even unsigned code,
and the output of this form of the
command should not be taken as a statement of formal code validity. Only
can do that; and in fact, formal verification constructs the hosting chain as part of
its operation (but does not display it).
To be used for code signing, a digital identity must be stored in a keychain that
is on the calling user's keychain search list.
All keychain sources are supported if properly configured. In particular, it is
possible to sign code with an identity stored on a supported smart card.
If your signing identity is stored in a different form, you need to make it available
in keychain form to sign code with it.
If the
argument is used,
is only looked-for in the
specific keychain given. This is meant to help disambiguate references to identities.
Even in that case, the full keychain search list is still
consulted for additional certificates needed to complete the signature.
The
If such a preference exists, it directly names the identity used.
Otherwise, the identity is located by searching
string given. If there are multiple matches, the operation fails and no signing
is performed; however, an exact match is preferred over a partial match.
These comparisons are case sensitive.
Multiple instances of the exactly same certificate in multiple keychains are tolerated
as harmless.
If
consists of exactly forty hexadecimal digits, it is instead
interpreted as the SHA-1 hash of the certificate part of the desired identity.
In this case, the identity's subject name is not considered.
a particular signing identity regardless of name. Identity preferences are global
are very explicit and local. These choices, combined with what is placed into Xcode
designation of signing identities.
If
Ad-hoc signing does not use an identity at all, and identifies exactly one instance
of code. Significant restrictions apply to the use of ad-hoc signed code; consult
documentation before using this.
will attempt to embed the entire certificate chain documenting the signing identity
in the code signature it generates, including any intermediate certificates and
the anchor certificate. It looks for those in the keychain search list of the user
performing the signing operation. If it cannot generate the entire certificate chain,
signing may still succeed, but verification may fail if the verifying code does not
The
arguments (-r and -R) can be given in various forms. A plain text argument is taken
to be a path to a file containing the requirement(s).
will accept both binary files containing properly compiled requirements code, and source files
that are automatically compiled before use.
An argument of "-" requests that the requirement(s) are read from standard input.
Finally, an argument that begins with an equal sign "=" is taken as a literal
requirements source text, and is compiled accordingly for use.
When signing, a set of option flags can be specified to change the behavior
of the system when using the signed code. The following flags are recognized
by
other flags may exist at the API level. Note that you can specify any valid
flags by giving a (single) numeric value instead of a list of option names.
Forces the signed code's kill flag to be set when the code begins execution.
Code with the kill flag set will die when it becomes dynamically invalid. It is
therefore safe to assume that code marked this way, once validated, will have continue
to have a valid identity while alive.
Forces the signed code's hard flag to be set when the code begins execution.
The hard flag is a hint to the system that the code prefers to be denied
access to resources if gaining such access would invalidate its identity.
Marks the code as capable of hosting guest code. You must set this option
if you want the code to act as a code signing host, controlling subsidiary
("guest") code. This flag is set automatically if you specify an internal
guest requirement.
Forces any validation of the code to consider expiration of the certificates
involved. Code signatures generated with this flag will fail to verify once any of
the certificates in the chain has expired, regardless of the intentions of the
verifier. Note that this flag does not affect any other checks that may cause
signature validation to fail, including checks for certificate revocation.
Forces the signed code's library validation flag to be set when the code begins execution.
The code will only be able to link against system libraries and frameworks, or libraries, frameworks, 
and plug-in bundles with the same team identifier embedded in the code directory. 
Team identifiers are automatically recorded in signatures when signing with suitable Apple-issued signing certificates. 
Note that the flag is not supported for i386 binaries, and only applies to the main executable. 
The flag has no effect when set on frameworks and libraries.
Note that code can set the hard and kill flags on itself at any time. The signing
options only affect their initial state. Once set by any means, these flags
cannot be cleared for the lifetime of the code. Therefore, specifying such flags
as signing options guarantees that they will be set whenever the signed code runs.
If the code being signed has an Info.plist that contains a key named CSFlags,
the value of that key is taken as the default value for the options. The value
of CSFlags can be a string in the same form as the --options option, or an
integer number specifying the absolute numeric value. Note however that while you
can abbreviate flag names on the command lines, you must spell them out in the Info.plist.
To sign application Terminal.app with a signing identity named "authority":
To sign the command-line tool "helper" with the same identity, overwriting
any existing signature, using the signing identifier "com.mycorp.helper",
and embedding a custom designated requirement
To verify the signature on Terminal.app and produce some verbose output:
To verify the dynamic validity of process 666:
To display all information about Terminal.app's code signature:
To extract the internal requirements from Terminal.app to standard output:
exits 0 if all operations succeed. This indicates that all codes were
signed, or all codes verified properly as requested. If a signing or verification
operation fails, the exit code is 1. Exit code 2 indicates invalid arguments
or parameters. Exit code 3 indicates that during verification, all path(s) were
properly signed but at least one of them failed to satisfy the requirement specified
with the
option.
For verification, all path arguments are always investigated before the program exits.
For all other operations, the program exits upon the first error encountered,
and any further path arguments are ignored, unless the --continue option was
specified, in which case
will defer the failure exit until after it has attempted to process all path
arguments in turn.
When a signing operation fails for a particular code, the code may already have been modified
in certain ways by adding requisite signature data. Such information will not
change the operation of the code, and the code will not be considered signed even with
these pieces in place. You may repeat the signing operation without difficulty.
Note however that a previous valid signature may have been effectively destroyed
if you specified the -f option.
If you require atomicity of signing stricter than provided by
you need to make an explicit copy of your code and sign that.
If the CODESIGN_ALLOCATE environment variable is set, it identifies a substitute codesign_allocate
tool used to allocate space for code signatures in Mach-O binaries. This is used by Xcode SDK
distributions to provide architectural support for non-native platforms such as iPhones.
The system will not accept such substitutes unless they are specially signed (by Apple).
System-wide database of detached code signatures for unsigned code.
The
command first appeared in Mac OS 10.5.0 (Leopard).
Some options only apply to particular operations, and
ignores them (without complaining)
if you specify them for an operation for which they have no meaning.
The --preserve-metadata option used to take no value, and varied across releases in what exactly
it preserved. The ensuing confusion is still with you if you need to make backward-compatible
scripts.
The dual meaning of the
option, indicating either verbosity or verification, confuses some people. If you find it confusing,
use the unambiguous long forms
and
instead.
The Xcode build system invokes
automatically if the CODE_SIGN_IDENTITY build variable is set.
You can express any combination of
options with additional build variables there.
is fundamentally a shell around the code signing APIs, and performs nothing of the underlying work.
Replacing it with older or newer versions is unlikely to have a useful effect.
has several operations and options that are purposely left undocumented in this manual page because they
are either experimental (and subject to change at any time), or unadvised to the unwary.
The interminably curious are referred to the published source code.
The
utility filters out reverse (and half reverse) line feeds so that the output is
in the correct order with only forward and half forward line
feeds, and replaces white-space characters with tabs where possible.
This can be useful in processing the output of
and
The
utility reads from the standard input and writes to the standard output.
The options are as follows:
Do not output any backspaces, printing only the last character
written to each column position.
Forward half line feeds are permitted (``fine'' mode).
Normally characters printed on a half line boundary are printed
on the following line.
Do not output multiple spaces instead of tabs (default).
Buffer at least
lines in memory.
By default, 128 lines are buffered.
Force unknown control sequences to be passed through unchanged.
Normally,
will filter out any control sequences from the input other than those
recognized and interpreted by itself, which are listed below.
Output multiple spaces instead of tabs.
The control sequences for carriage motion that
understands and their decimal values are listed in the following
table:
reverse line feed (escape then 7)
half reverse line feed (escape then 8)
half forward line feed (escape then 9)
moves back one column (8); ignored in the first column
(13)
forward line feed (10); also does carriage return
shift to normal character set (15)
shift to alternate character set (14)
moves forward one column (32)
moves forward to next tab stop (9)
reverse line feed (11)
All unrecognized control characters and escape sequences are
discarded.
The
utility keeps track of the character set as characters are read and makes
sure the character set is correct when they are output.
If the input attempts to back up to the last flushed line,
will display a warning message.
The
and
environment variables affect the execution of
as described in
The
utility conforms to
A
command
appeared in
The
utility provides virtual half-line and reverse line feed sequences
for terminals without such capability, and on which overstriking
is destructive.
are placed on new lines in between the normal output lines.
The following options are available:
Suppress all underlining.
This option is especially useful for previewing
tables from
Cause all half-lines to be printed, effectively double spacing the output.
Normally, a minimal space output format is used which will suppress empty
lines.
The program never suppresses two consecutive empty lines, however.
The
option is useful for sending output to the line printer when the output
contains superscripts and subscripts which would otherwise be invisible.
The
and
environment variables affect the execution of
as described in
A typical use of
would be
Should fold underlines onto blanks even with the
option so that
a true underline character would show.
Can't back up more than 102 lines.
General overstriking is lost;
as a special case
overstruck with
or underline becomes
Lines are trimmed to 132 characters.
Some provision should be made for processing superscripts and subscripts
in documents which are already double-spaced.
Characters that take up more than one column position may not be
underlined correctly.
The
command appeared in
The
utility converts a collation sequence source definition
into a format usable by the
and
functions.
It is used to define the many ways in which
strings can be ordered and collated.
The
function transforms
its first argument and places the result in its second
argument.
The transformed string is such that it can be
correctly ordered with other transformed strings by using
or
The
function transforms its arguments and does a
comparison.
The
utility reads the collation sequence source definition
from the standard input and stores the converted definition in filename.
The output file produced contains the
database with collating sequence information in a form
usable by system commands and routines.
The following options are available:
Set directory name where
files can be found, current directory by default.
Set output file name,
by default.
The collation sequence definition specifies a set of collating elements and
the rules defining how strings containing these should be ordered.
This is most useful for different language definitions.
The specification file can consist of three statements:
and
Of these, only the
statement is required.
When
or
is
supplied, these statements must be ordered as above.
Any
statements after the order statement are ignored.
Lines in the specification file beginning with a
are
treated as comments and are ignored.
Blank lines are also
ignored.
defines where a mapping of the character
and collating element symbols to the actual
character encoding can be found.
The format of
is shown below.
Symbol
names are separated from their values by TAB or
SPACE characters.
Symbol-value can be specified in
representation, and can be only one character in length.
symbol-name1 symbol-value1
symbol-name2 symbol-value2
Symbol names cannot be specified in
fields.
The
statement is optional.
substitute "symbol" with "repl_string"
The
statement substitutes the character
with the string
Symbol names cannot be specified in
field.
The
statement is optional.
is a list of symbols, separated by semi colons, that defines the
collating sequence.
The
special symbol
specifies, in a short-hand
form, symbols that are sequential in machine code
order.
An order list element
can be represented in any one of the following
ways:
The symbol itself (for example,
for the lower-case letter
The symbol in octal representation (for example,
for the letter
The symbol in hexadecimal representation (for example,
for the letter
The symbol name as defined in the
file (for example,
for
record in
If character map name have
character, it must be escaped as
single
must be escaped as
Symbols
are permitted in its usual C-language meaning.
The symbol chain (for example:
The symbol range (for example,
Comma-separated symbols, ranges and chains enclosed in parenthesis (for example
are assigned the
same primary ordering but different secondary
ordering.
Comma-separated symbols, ranges and chains enclosed in curly brackets (for example
are assigned the same primary ordering only.
The backslash character
is used for continuation.
In this case, no characters are permitted
after the backslash character.
The
utility exits with the following values:
No errors were found and the output was successfully created.
Errors were found.
The standard shared location for collation orders
under the locale
The
utility removes selected columns from the lines of a file.
A column is defined as a single character in a line.
Input is read from the standard input.
Output is written to the standard output.
If only the
column is specified, columns numbered less than the
column will be written.
If both
and
columns are specified, columns numbered less than the
column
or greater than the
column will be written.
Column numbering starts with one, not zero.
Tab characters increment the column count to the next multiple of eight.
Backspace characters decrement the column count by one.
The
and
environment variables affect the execution of
as described in
The
command appeared in
The
utility formats its input into multiple columns.
Rows are filled before columns.
Input is taken from
operands, or, by default, from the standard input.
Empty lines are ignored.
The options are as follows:
Output is formatted for a display
wide.
Specify a set of characters to be used to delimit columns for the
option.
Determine the number of columns the input contains and create a table.
Columns are delimited with whitespace, by default, or with the characters
supplied using the
option.
Useful for pretty-printing displays.
Fill columns before filling rows.
The
and
environment variables affect the execution of
as described in
The
command appeared in
Input lines are limited to
(2048) bytes in length.
The
utility reads
and
which should be
sorted lexically, and produces three text
columns as output: lines only in
lines only in
and lines in both files.
The filename ``-'' means the standard input.
The following options are available:
Suppress printing of column 1.
Suppress printing of column 2.
Suppress printing of column 3.
Case insensitive comparison of lines.
Each column will have a number of tab characters prepended to it
equal to the number of lower numbered columns that are being printed.
For example, if column number two is being suppressed, lines printed
in column number one will not have any tabs preceding them, and lines
printed in column number three will have one.
The
utility assumes that the files are lexically sorted; all characters
participate in line comparisons.
The
and
environment variables affect the execution of
as described in
The
utility conforms to
The
option is an extension to the
standard.
A
command appeared in
Input lines are limited to
(2048) characters in length.
The
utility reduces the size of files using adaptive Lempel-Ziv coding.
Each
is renamed to the same name plus the extension
A
argument with a
extension will be ignored except it will cause an
error exit after other arguments are processed.
If compression would not reduce the size of a
the file is ignored.
The
utility restores compressed files to their original form, renaming the
files by deleting the
extensions.
A file specification need not include the file's
extension.
If a file's name in its file system does not have a
extension, it will not be uncompressed and it will cause
an error exit after other arguments are processed.
If renaming the files would cause files to be overwritten and the standard
input device is a terminal, the user is prompted (on the standard error
output) for confirmation.
If prompting is not possible or confirmation is not received, the files
are not overwritten.
As many of the modification time, access time, file flags, file mode,
user ID, and group ID as allowed by permissions are retained in the
new file.
If no files are specified or a
argument is a single dash
the standard input is compressed or uncompressed to the standard output.
If either the input and output files are not regular files, the checks for
reduction in size and file overwriting are not performed, the input file is
not removed, and the attributes of the input file are not retained
in the output file.
The options are as follows:
The code size (see below) is limited to
which must be in the range 9..16.
The default is 16.
Compressed or uncompressed output is written to the standard output.
No files are modified.
The
option is ignored.
Compression is attempted even if the results will be larger than the
original.
Files are overwritten without prompting for confirmation.
Also, for
files are compressed even if they are not actually reduced in size.
Print the percentage reduction of each file.
Ignored by
or if the
option is also used.
The
utility uses a modified Lempel-Ziv algorithm.
Common substrings in the file are first replaced by 9-bit codes 257 and up.
When code 512 is reached, the algorithm switches to 10-bit codes and
continues to use more bits until the
limit specified by the
option or its default is reached.
After the limit is reached,
periodically checks the compression ratio.
If it is increasing,
continues to use the existing code dictionary.
However, if the compression ratio decreases,
discards the table of substrings and rebuilds it from scratch.
This allows
the algorithm to adapt to the next "block" of the file.
The
option is unavailable for
since the
parameter specified during compression
is encoded within the output, along with
a magic number to ensure that neither decompression of random data nor
recompression of compressed data is attempted.
The amount of compression obtained depends on the size of the
input, the number of
per code, and the distribution of common substrings.
Compression is generally much better than that achieved by Huffman
coding (as used in the historical command pack), or adaptive Huffman
coding (as used in the historical command compact), and takes less
time to compute.
The
utility exits 2 if attempting to compress a file would not reduce its size
and the
option was not specified and if no other error occurs.
The
and
utilities conform to
The
command appeared in
Some of these might be considered otherwise-undocumented features.
If the utility does not compress a file because doing so would not
reduce its size, and a file of the same name except with an
extension exists, the named file is not really ignored as stated above;
it causes a prompt to confirm the overwriting of the file with the extension.
If the operation is confirmed, that file is deleted.
If an empty file is compressed (using
the resulting
file is also empty.
That seems right, but if
is then used on that file, an error will occur.
Both utilities: If a
argument is used and the utility prompts the user, the standard input
is taken as the user's reply to the prompt.
Both utilities:
If the specified file does not exist, but a similarly-named one with (for
or without (for
a
extension does exist, the utility will waste the user's time by not
immediately emitting an error message about the missing file and
continuing.
Instead, it first asks for confirmation to overwrite
the existing file and then does not overwrite it.
formalization and abstraction of the systems that people like Andreas
have developed independently.
The configuration system employed here was developed in the context of
was taken by all those other systems mentioned in the previous
configuration data, as well as publicly accessible methods for
querying and setting (yes, actually re-writing) the configuration
reading) is merely a front-end for those methods.  If you wish, you
may create alternate front-ends.
including references to complex data structures.  It must, however, be
0) value.
configuration of a single module.  On the command line, specify which
module's configuration you're interested in, and pass options to get
supported:
Specifies the name of the module to configure (required).
be 1 if the feature is enabled, 0 if the feature is not enabled, or
empty if the feature is unknown.  When no feature name is supplied,
the names and values of all known features will be shown.
When no config name is supplied, the names and values of all known
config entries will be shown.
as either 1 or 0.
evaluated as perl code before being stored.  This allows moderately
complicated data structures to be stored.  For really complicated
structures, you probably shouldn't use this command-line interface,
Prints a help message, including a few examples, and exits.
Ken Williams, kwilliams@cpan.org
Copyright (c) 1999, Ken Williams.  All rights reserved.
it under the same terms as Perl itself.
formalization and abstraction of the systems that people like Andreas
have developed independently.
The configuration system emplyed here was developed in the context of
was taken by all those other systems mentioned in the previous
configuration data, as well as publically accessible methods for
querying and setting (yes, actually re-writing) the configuration
reading) is merely a front-end for those methods.  If you wish, you
may create alternate front-ends.
including references to complex data structures.  It must, however, be
0) value.
configuration of a single module.  On the command line, specify which
module's configuration you're interested in, and pass options to get
supported:
Specifies the name of the module to configure (required).
be 1 if the feature is enabled, 0 if the feature is not enabled, or
empty if the feature is unknown.  When no feature name is supplied,
the names and values of all known features will be shown.
When no config name is supplied, the names and values of all known
config entries will be shown.
as either 1 or 0.
evaluated as perl code before being stored.  This allows moderately
complicated data structures to be stored.  For really complicated
structures, you probably shouldn't use this command-line interface,
Prints a help message, including a few examples, and exits.
Ken Williams, kwilliams@cpan.org
Copyright (c) 1999, Ken Williams.  All rights reserved.
it under the same terms as Perl itself.
formalization and abstraction of the systems that people like Andreas
have developed independently.
The configuration system employed here was developed in the context of
was taken by all those other systems mentioned in the previous
configuration data, as well as publicly accessible methods for
querying and setting (yes, actually re-writing) the configuration
reading) is merely a front-end for those methods.  If you wish, you
may create alternate front-ends.
including references to complex data structures.  It must, however, be
0) value.
configuration of a single module.  On the command line, specify which
module's configuration you're interested in, and pass options to get
supported:
Specifies the name of the module to configure (required).
be 1 if the feature is enabled, 0 if the feature is not enabled, or
empty if the feature is unknown.  When no feature name is supplied,
the names and values of all known features will be shown.
When no config name is supplied, the names and values of all known
config entries will be shown.
as either 1 or 0.
evaluated as perl code before being stored.  This allows moderately
complicated data structures to be stored.  For really complicated
structures, you probably shouldn't use this command-line interface,
Prints a help message, including a few examples, and exits.
Ken Williams, kwilliams@cpan.org
Copyright (c) 1999, Ken Williams.  All rights reserved.
it under the same terms as Perl itself.
generates a LocalKDC and provisions LKDC service principals.
The script is non-destructive and can be run multiple times.
does not own, but references the following files:
first appeared in version 10.5 of Mac OS X.
See Module::CoreList for one.
lists all versions of the given module (or the matching modules, in case you
used a module regexp) in the perls Module::CoreList knows about.
finds the first perl version where a module has been released by
date, and not by version number (as is the default).
Given two versions of perl, this prints a human-readable table of all module
changes between the two.  The output format may change in the future, and is
all of the help
lists all of the perl release versions we got the CoreList for.
you get a list of all the modules and their respective versions.
In module filtering context, it can be used as Perl version filter.
lists all of the perl releases and when they were released
If you pass a perl version you get the release date for that version only.
lists the first version bundle of each named feature given
the version number of the Unicode Character Database bundled with the
requested perl versions.
This program is distributed under the same terms as perl itself.
See Module::CoreList for one.
lists all versions of the given module (or the matching modules, in case you
used a module regexp) in the perls Module::CoreList knows about.
finds the first perl version where a module has been released by
date, and not by version number (as is the default).
Given two versions of perl, this prints a human-readable table of all module
changes between the two.  The output format may change in the future, and is
all of the help
lists all of the perl release versions we got the CoreList for.
you get a list of all the modules and their respective versions.
In module filtering context, it can be used as Perl version filter.
lists all of the perl releases and when they were released
If you pass a perl version you get the release date for that version only.
the version number of the Unicode Character Database bundled with the
requested perl versions.
This program is distributed under the same terms as perl itself.
See Module::CoreList for one.
lists all versions of the given module (or the matching modules, in case you
used a module regexp) in the perls Module::CoreList knows about.
finds the first perl version where a module has been released by
date, and not by version number (as is the default).
Given two versions of perl, this prints a human-readable table of all module
changes between the two.  The output format may change in the future, and is
all of the help
lists all of the perl release versions we got the CoreList for.
you get a list of all the modules and their respective versions.
In module filtering context, it can be used as Perl version filter.
lists all of the perl releases and when they were released
If you pass a perl version you get the release date for that version only.
lists the first version bundle of each named feature given
the version number of the Unicode Character Database bundled with the
requested perl versions.
This program is distributed under the same terms as perl itself.
In the first synopsis form, the
utility copies the contents of the
to the
In the second synopsis form,
the contents of each named
is copied to the destination
The names of the files themselves are not changed.
If
detects an attempt to copy a file to itself, the copy will fail.
The following options are available:
Same as 
options. Preserves structure and attributes of files
but not directory structure.
If the destination file cannot be opened, remove it and
create a new file, without prompting for confirmation
regardless of its permissions.
(The
option overrides any previous
option.)
The target file is not unlinked before the copy.
Thus, any existing access rights will be retained.
If the
option is specified, symbolic links on the command line are followed.
(Symbolic links encountered in the tree traversal are not followed.)
Cause
to write a prompt to the standard error output before copying a file
that would overwrite an existing file.
If the response from the standard input begins with the character
or
the file copy is attempted.
(The
option overrides any previous
option.)
If the
option is specified, all symbolic links are followed.
Do not overwrite an existing file.
(The
option overrides any previous
or
options.)
If the
option is specified, no symbolic links are followed.
This is the default.
Cause
to preserve the following attributes of each source
file in the copy: modification time, access time,
file flags, file mode, user ID, and group ID, as allowed by permissions.
Access Control Lists (ACLs) and Extended Attributes (EAs),
including resource forks, will also be preserved.
If the user ID and group ID cannot be preserved, no error message
is displayed and the exit value is not altered.
If the source file has its set-user-ID bit on and the user ID cannot
be preserved, the set-user-ID bit is not preserved
in the copy's permissions.
If the source file has its set-group-ID bit on and the group ID cannot
be preserved, the set-group-ID bit is not preserved
in the copy's permissions.
If the source file has both its set-user-ID and set-group-ID bits on,
and either the user ID or group ID cannot be preserved, neither
the set-user-ID nor set-group-ID bits are preserved in the copy's
permissions.
If
designates a directory,
copies the directory and the entire subtree connected at that point.
If the
ends in a
the contents of the directory are copied rather than the
directory itself.
This option also causes symbolic links to be copied, rather than
indirected through, and for
to create special files rather than copying them as normal files.
Created directories have the same mode as the corresponding source
directory, unmodified by the process' umask.
In
mode,
will continue copying even if errors are detected. 
Note that
copies hard-linked files as separate files.
If you need to preserve hard links, consider using
or
instead.
Cause
to be verbose, showing files as they are copied.
Do not copy Extended Attributes (EAs) or resource forks.
For each destination file that already exists, its contents are
overwritten if permissions allow.
Its mode, user ID, and group
ID are unchanged unless the
option was specified.
In the second synopsis form,
must exist unless there is only one named
which is a directory and the
flag is specified.
If the destination file does not exist, the mode of the source file is
used as modified by the file mode creation mask
see
If the source file has its set-user-ID bit on, that bit is removed
unless both the source file and the destination file are owned by the
same user.
If the source file has its set-group-ID bit on, that bit is removed
unless both the source file and the destination file are in the same
group and the user is a member of that group.
If both the set-user-ID and set-group-ID bits are set, all of the above
conditions must be fulfilled or both bits are removed.
Appropriate permissions are required for file creation or overwriting.
Symbolic links are always followed unless the
flag is set, in which case symbolic links are not followed, by default.
The
or
flags (in conjunction with the
flag) cause symbolic links to be followed as described above.
The
and
options are ignored unless the
option is specified.
In addition, these options override each other and the
command's actions are determined by the last one specified.
If
receives a
(see the
argument for
signal, the current input and output file and the percentage complete
will be written to the standard output.
Historic versions of the
utility had a
option.
This implementation supports that option;
however, its use is strongly discouraged,
as it does not correctly copy special files, symbolic links, or fifo's.
The
and
options are non-standard and their use in scripts is not recommended.
In legacy mode,
will override
Also, under the
option, the target file is always unlinked before the copy.
Thus, new access rights will always be set.
In
mode, copying will terminate if an error is encountered.
For more information about legacy mode, see
The
command is expected to be
compatible.
A
command appeared in
Shows the primary maintainers for the specified modules.
Runs a `make clean` in the specified module's directories.
Show the module details.
Force the specified action, when it normally would have failed. Use this
to install a module even if its tests fail. When you use this option,
this since you might end up with multiple scripts trying to muck in the
same directory. This isn't so much of a concern if you're loading a special
Downloads to the current directory the latest distribution of the module.
Download to the current directory the latest distribution of the
modules, unpack each distribution, and create a git repository for each
distribution.
distribution.
of the other options and arguments.
Install the specified modules.
for checking the configuration as well as using the dump as a starting point
for a new, custom configuration.
List all installed modules wth their versions
List the modules by the specified authors.
Make the specified modules.
Show the out-of-date modules.
Ping the configured mirrors
Find the best mirrors you could be using (but doesn't configure them just yet)
Run a `make test` on the specified modules.
Do not test modules. Simply install them.
Upgrade all installed modules. Blindly doing this can really break things,
so keep a backup.
Print detailed information about the cpan client.
Turn on cpan warnings. This checks various things, like directory permissions,
and tells you about problems you might have.
before it processes the command-line arguments. For instance, if you always
The script exits with zero if it thinks that everything worked, or a 
positive number if it thinks that something failed. Note, however, that
in some cases it has to divine a failure by the output of things it does
not control. For now, the exit codes are vague:
* one shot configuration values from the command line
* none noted
Most behaviour, including environment variables and configuration,
This code is in Github:
Jim Brandt suggest and provided the initial implementation for the
up-to-date and Changes features.
where this script ends up with a .bat extension
You may redistribute this under the same terms as Perl itself.
you specify, including its prerequisites. These packages can then be
installed using the corresponding package manager for the format.
Note, you can also do this interactively from the default shell,
as well as the documentation of your format of choice for any format
specific documentation.
Options:
Examples:
Some modules you'd rather not package. Some because they
are part of core-perl and you dont want a new package.
Some because they won't build on your system. Some because
your package manager of choice already packages them for you.
lists that catch common cases. You can use these built-in lists
if you like, or supply your own if need be.
You can use this list of regexes to ignore modules matching
to be listed as prerequisites of a package. Particularly useful
if they are bundled with core-perl anyway and they have known
issues building.
You can use this list of regexes to disable building of these
modules altogether.
CPANPLUS::Dist, CPANPLUS::Module, CPANPLUS::Shell::Default,
This module by Jos Boumans <kane@cpan.org>.
under the same terms as Perl itself.
you specify, including its prerequisites. These packages can then be
installed using the corresponding package manager for the format.
Note, you can also do this interactively from the default shell,
as well as the documentation of your format of choice for any format
specific documentation.
Options:
Examples:
Some modules you'd rather not package. Some because they
are part of core-perl and you dont want a new package.
Some because they won't build on your system. Some because
your package manager of choice already packages them for you.
lists that catch common cases. You can use these built-in lists
if you like, or supply your own if need be.
You can use this list of regexes to ignore modules matching
to be listed as prerequisites of a package. Particularly useful
if they are bundled with core-perl anyway and they have known
issues building.
You can use this list of regexes to disable building of these
modules altogether.
CPANPLUS::Dist, CPANPLUS::Module, CPANPLUS::Shell::Default,
This module by Jos Boumans <kane@cpan.org>.
under the same terms as Perl itself.
you specify, including its prerequisites. These packages can then be
installed using the corresponding package manager for the format.
Note, you can also do this interactively from the default shell,
as well as the documentation of your format of choice for any format
specific documentation.
Options:
Examples:
Some modules you'd rather not package. Some because they
are part of core-perl and you dont want a new package.
Some because they won't build on your system. Some because
your package manager of choice already packages them for you.
lists that catch common cases. You can use these built-in lists
if you like, or supply your own if need be.
You can use this list of regexes to ignore modules matching
to be listed as prerequisites of a package. Particularly useful
if they are bundled with core-perl anyway and they have known
issues building.
You can use this list of regexes to disable building of these
modules altogether.
CPANPLUS::Dist, CPANPLUS::Module, CPANPLUS::Shell::Default,
This module by Jos Boumans <kane@cpan.org>.
under the same terms as Perl itself.
Shows the primary maintainers for the specified modules.
Runs a `make clean` in the specified module's directories.
Show the module details. This prints one line for each out-of-date module
version.
Force the specified action, when it normally would have failed. Use this
to install a module even if its tests fail. When you use this option,
this since you might end up with multiple scripts trying to muck in the
same directory. This isn't so much of a concern if you're loading a special
Downloads to the current directory the latest distribution of the module.
Download to the current directory the latest distribution of the
modules, unpack each distribution, and create a git repository for each
distribution.
distribution.
of the other options and arguments.
Install the specified modules.
for checking the configuration as well as using the dump as a starting point
for a new, custom configuration.
List the modules by the specified authors.
Make the specified modules.
Show the out-of-date modules.
Run a `make test` on the specified modules.
The script exits with zero if it thinks that everything worked, or a 
positive number if it thinks that something failed. Note, however, that
in some cases it has to divine a failure by the output of things it does
not control. For now, the exit codes are vague:
* one shot configuration values from the command line
* none noted
Most behaviour, including environment variables and configuration,
This code is in Github:
Jim Brandt suggest and provided the initial implementation for the
up-to-date and Changes features.
where this script ends up with a .bat extension
You may redistribute this under the same terms as Perl itself.
Shows the primary maintainers for the specified modules.
Runs a `make clean` in the specified module's directories.
Show the module details.
Force the specified action, when it normally would have failed. Use this
to install a module even if its tests fail. When you use this option,
this since you might end up with multiple scripts trying to muck in the
same directory. This isn't so much of a concern if you're loading a special
Downloads to the current directory the latest distribution of the module.
Download to the current directory the latest distribution of the
modules, unpack each distribution, and create a git repository for each
distribution.
distribution.
of the other options and arguments.
Install the specified modules.
for checking the configuration as well as using the dump as a starting point
for a new, custom configuration.
List all installed modules wth their versions
List the modules by the specified authors.
Make the specified modules.
Show the out-of-date modules.
Ping the configured mirrors
Find the best mirrors you could be using (but doesn't configure them just yet)
Run a `make test` on the specified modules.
Do not test modules. Simply install them.
Upgrade all installed modules. Blindly doing this can really break things,
so keep a backup.
Print detailed information about the cpan client.
Turn on cpan warnings. This checks various things, like directory permissions,
and tells you about problems you might have.
before it processes the command-line arguments. For instance, if you always
The script exits with zero if it thinks that everything worked, or a 
positive number if it thinks that something failed. Note, however, that
in some cases it has to divine a failure by the output of things it does
not control. For now, the exit codes are vague:
* one shot configuration values from the command line
* none noted
Most behaviour, including environment variables and configuration,
This code is in Github:
Jim Brandt suggest and provided the initial implementation for the
up-to-date and Changes features.
where this script ends up with a .bat extension
You may redistribute this under the same terms as Perl itself.
from the command line. If it's invoked without arguments, an interactive
shell is executed by default.
Optionally, it can take a single-letter switch and one or more argument,
to perform the associated action on each arguments.  A summary of the
Example: To skip a module's tests,
for an explanation to their meanings.
Example: To download a module's tarball to the current directory,
from the command line. If it's invoked without arguments, an interactive
shell is executed by default.
Optionally, it can take a single-letter switch and one or more argument,
to perform the associated action on each arguments.  A summary of the
Example: To skip a module's tests,
for an explanation to their meanings.
Example: To download a module's tarball to the current directory,
from the command line. If it's invoked without arguments, an interactive
shell is executed by default.
Optionally, it can take a single-letter switch and one or more argument,
to perform the associated action on each arguments.  A summary of the
Example: To skip a module's tests,
for an explanation to their meanings.
Example: To download a module's tarball to the current directory,
copies files between archives and directories.
This implementation can extract from tar, pax, cpio, zip, jar, ar,
and ISO 9660 cdrom images and can create tar, pax, cpio, ar,
and shar archives.
The first option to
is a mode indicator from the following list:
Input.
Read an archive from standard input (unless overriden) and extract the
contents to disk or (if the
option is specified)
list the contents to standard output.
If one or more file patterns are specified, only files matching
one of the patterns will be extracted.
Output.
Read a list of filenames from standard input and produce a new archive
on standard output (unless overriden) containing the specified items.
Pass-through.
Read a list of filenames from standard input and copy the files to the
specified directory.
Unless specifically stated otherwise, options are applicable in
all operating modes.
Read filenames separated by NUL characters instead of newlines.
This is necessary if any of the filenames being read might contain newlines.
(o mode only)
Append to the specified archive.
(Not yet implemented.)
(o and p modes)
Reset access times on files after they are read.
(o mode only)
Block output to records of 5120 bytes.
(o mode only)
Block output to records of
bytes.
(o mode only)
Use the old POSIX portable character format.
Equivalent to
(i and p modes)
Create directories as necessary.
(i mode only)
Read list of file name patterns from
to list and extract.
Read archive from or write archive to
(i mode only)
Ignore files that match
(o mode only)
Produce the output archive in the specified format.
Supported formats include:
Synonym for
The SVR4 portable cpio format.
The old POSIX.1 portable octet-oriented cpio format.
The POSIX.1 pax format, an extension of the ustar format.
The POSIX.1 tar format.
The default format is
See
for more complete information about the
formats currently supported by the underlying
library.
Synonym for
Print usage information.
Read archive from
Input mode.
See above for description.
(i and p mode only)
Disable security checks during extraction or copying.
This allows extraction via symbolic links and path names containing
in the name.
(o mode only)
Compress the file with xz-compatible compression before writing it.
In input mode, this option is ignored; xz compression is recognized
automatically on input.
Synonym for
(o and p modes)
All symbolic links will be followed.
Normally, symbolic links are archived and copied as symbolic links.
With this option, the target of the link will be archived or copied instead.
(p mode only)
Create links from the target directory to the original files,
instead of copying.
(o mode only)
Compress the file with lzma-compatible compression before writing it.
In input mode, this option is ignored; lzma compression is recognized
automatically on input.
(i and p modes)
Set file modification time on created files to match
those in the source.
(i mode, only with
Display numeric uid and gid.
By default,
displays the user and group names when they are provided in the
archive, or looks up the user and group names in the system
password database.
(i mode only)
Do not attempt to restore file ownership.
This is the default when run by non-root users.
Write archive to
Output mode.
See above for description.
Pass-through mode.
See above for description.
(i mode only)
Restore file ownership.
This is the default when run by the root user.
Suppress unnecessary messages.
If group is specified with no user
(for example,
then the group will be set but not the user.
If the user is specified with a trailing colon and no group
(for example,
then the group will be set to the user's default group.
If the user is specified with no trailing colon, then
the user will be set but not the group.
In
and
modes, this option can only be used by the super-user.
(For compatibility, a period can be used in place of the colon.)
(All modes.)
Rename files interactively.
For each file, a prompt is written to
containing the name of the file and a line is read from
If the line read is blank, the file is skipped.
If the line contains a single period, the file is processed normally.
Otherwise, the line is taken to be the new name of the file.
(i mode only)
List the contents of the archive to stdout;
do not restore the contents to disk.
(i and p modes)
Unconditionally overwrite existing files.
Ordinarily, an older file will not overwrite a newer file on disk.
Print the name of each file to stderr as it is processed.
With
provide a detailed listing of each file.
Print the program version information and exit.
(o mode only)
Compress the archive with bzip2-compatible compression before writing it.
In input mode, this option is ignored;
bzip2 compression is recognized automatically on input.
(o mode only)
Compress the archive with compress-compatible compression before writing it.
In input mode, this option is ignored;
compression is recognized automatically on input.
(o mode only)
Compress the archive with gzip-compatible compression before writing it.
In input mode, this option is ignored;
gzip compression is recognized automatically on input.
The following environment variables affect the execution of
The locale to use.
See
for more information.
The timezone to use when displaying dates.
See
for more information.
The
command is traditionally used to copy file heirarchies in conjunction
with the
command.
The first example here simply copies all files from
to
By carefully selecting options to the
command and combining it with other standard utilities,
it is possible to exercise very fine control over which files are copied.
This next example copies files from
to
that are more than 2 days old and whose names match a particular pattern:
This example copies files from
to
that are more than 2 days old and which contain the word
The mode options i, o, and p and the options
a, B, c, d, f, l, m, r, t, u, and v comply with SUSv2.
The old POSIX.1 standard specified that only
and
were interpreted as command-line options.
Each took a single argument of a list of modifier
characters.
For example, the standard syntax allows
but does not support
or
since
and
are only modifiers to
they are not command-line options in their own right.
The syntax supported by this implementation is backwards-compatible
with the standard.
For best compatibility, scripts should limit themselves to the
standard syntax.
There is no current POSIX standard for the cpio command; it appeared
in
but was dropped from
The cpio, ustar, and pax interchange file formats are defined by
for the pax command.
The original
and
utilities were written by Dick Haight
while working in AT&T's Unix Support Group.
system developed for use within AT&T.
They were first released outside of AT&T as part of System III Unix in 1981.
As a result,
actually predates
even though it was not well-known outside of AT&T until some time later.
This is a complete re-implementation based on the
library.
The cpio archive format has several basic limitations:
It does not store user and group names, only numbers.
As a result, it cannot be reliably used to transfer
files between systems with dissimilar user and group numbering.
Older cpio formats limit the user and group numbers to
16 or 18 bits, which is insufficient for modern systems.
The cpio archive formats cannot support files over 4 gigabytes,
except for the
variant, which can support files up to 8 gigabytes.
provides several options for creating and populating home directories.
creates home directories for server home paths only (default).
creates home directories for local home paths only.
creates home directories for both server and local home paths.
creates home directories for users defined in all directory domains of the server's search path.
creates home directories for users defined in the local directory domain.
creates home directories for users defined in a specific directory domain in the server's search path.
creates a home directory for a specific user defined in the domain(s) identified in the -a, -l, or -n parameter. If you omit the -a, -l, and -n parameters when you use the -u parameter, -a is assumed.
reads username list from standard input and creates specified home directories. Each username should be on its own line.
usage help.
location of tool
When using the -a option, search limits of various directory servers (such as Open Directory or Active Directory) can prevent all possible home directories from being created. In this case, you may need to specify the usernames explicitly.

command [command-args] [options]
r [options]
f URL [options]
F URI [options]
Refresh the entire CRL cache
Fetch a CRL from specified URL
Fetch a Certificate from specified URL
Crlrefresh is also use to fetch specific CRLs and certificates from the network; CRLs fetched via 
will be added to the CRL cache as well as provided to the specified output file (or to stdout if no output file is provided). The URL specified in the 
and 
commands must have schema "http:" or "ldap:".
Typically,
would be run on a regular basis via one of the configuration files used by the 
program.
Specify the time in days which, having elapsed after a CRL is expired, that the CRL is deleted fromt he CRL cache. The default is 10 days.
Specify the time in seconds prior to a CRL's expiration when a refresh action will attempt to replace the CRL with a fresh copy.
Purge all entries from the CRL cache, ensuring refresh with fresh CRLs. Normally, CRLs whose expiration date is more than expire_overlap past the current time are not refreshed.
Perform full cryptographic verification of all CRLs in the CRL cache. Normally this step is only performed when a CRL is actually used to validate a certificate.
Provide verbose output during operation. 
When fetching a CRL or certificate, specifies the destination to which the fetched entity will be written. If this is not specified then the fetched entity is sent to stdout.
When fetching a CRL, this inhibits the addition of the fetched CRL to the system CRL cache.
Execute in verbose mode.
System CRL cache database
{
}
The
utility is the program used to install, deinstall or list the tables
used to drive the
daemon in Vixie Cron.
Each user can have their own crontab, and
they are not intended to be edited directly.
(Darwin note: Although
and
are officially supported under Darwin, their functionality has been
absorbed into
which provides a more flexible way of automatically executing commands.
See
for more information.)
If the
file exists, then you must be listed therein in order to be allowed to use
this command.
If the
file does not exist but the
file does exist, then you must
be listed in the
file in order to use this command.
If neither of these files exists, then
depending on site-dependent configuration parameters, only the super user
will be allowed to use this command, or all users will be able to use this
command.
The format of these files is one username per line,
with no leading or trailing whitespace.
Lines of other formats will be ignored,
and so can be used for comments.
The first form of this command is used to install a new crontab from some
named file or standard input if the pseudo-filename
is given.
The following options are available:
Specify the name of the user whose crontab is to be
tweaked.
If this option is not given,
examines
crontab, i.e., the crontab of the person executing the
command.
Note that
can confuse
and that if you are running inside of
you should always use the
option for safety's sake.
Display the current crontab on standard output.
Remove the current crontab.
Edit the current crontab using the editor specified by
the
or
environment variables.
The specified editor
edit the file in place;
any editor that unlinks the file and recreates it cannot be used.
After you exit
from the editor, the modified crontab will be installed automatically.
A fairly informative usage message appears if you run it with a bad command
line.
The
command conforms to
The new command syntax
differs from previous versions of Vixie Cron, as well as from the classic
SVR3 syntax.
collects information to help Apple investigate issues related to CoreStorage (File Vault 2, Fusion Drive, File Vault Everywhere, etc).  This tool invokes sudo, so you will be asked to authenticate.
This script requires
to be installed in the PATH.
If
is not given, all disks in the system will be inspected.  This is the recommended method of invoking
Advanced users can provide a list of
in the form of
or
Only information of the given
is collected.  To fully collect information of a CoreStorage volume, the CoreStorage Physical Volume (i.e., the Apple_CoreStorage partition), the Apple_Boot partition after the physical volume, and the Logical Volume published by CoreStorage (which can be found out using the
command) should all be provided on the command line.
The following information is collected:
OS version.
system logs, kernel logs, install logs, filesystem logs, and other useful information for CoreStorage debugging from
output of
output of
output of
of every Apple_CoreStorage partition, which includes the CoreStorage metadata.  If a list of
is provided, only information on the partitions included in the list will be collected.
of every Apple_Boot partition.  If a list of
is provided, only information on the partitions included in the list will be collected.
The following user information is contained in the collected file:
Number and types of disks attached to the system.
The volume names, UUIDs, and size of each partition.
Encrypted versions of the volume key(s) that unlock the encrypted disk(s) attached to the system.  Refer to
for what information could leak from the volume key(s).
User names, pictures, and password hints for the users.
No other user information (such as directory structures, file names,
file content, etc) is collected.
The following options are available:
Show this help information.
Specify an output path which will hold the file generated by this script.  By default this will be the user's Desktop folder.  The given path must already exist.
Verbose mode, which prints every command it invokes.
The
utility first appeared along with CoreStorage in OS X 10.10.0.
gathers CoreStorage metadata for diagnosis.  It works in two modes.
In the first mode where -G and a list of devices are provided, CoreStorage
metadata on these list of devices will be collected.  The collected
information includes the size and UUID of the CoreStorage logical and
physical volumes, the name of the logical volumes, the wrapped (encrypted)
volume key (which can
only be decrypted by a brute-force attack), user name and user login image
file.  No other user information (such as directory structure, file names,
file content, etc) is collected.
In the second mode where -r is provided, the encryption
context which includes the wrapped volume key (which can only be decrypted by
a brute-force attack), user name and user login image file will be collected.
If the wrapped volume key is decrypted by a brute-force attack, the volume
key used to encrypt data on CoreStorage Logical Volumes is in the clear.  It
is not mathematically possible to derive the user's passphrase from the
volume key.  The volume key is only useful when the attacker has access to
the encrypted data in the CoreStorage Logical Volume, which are not collected
by
The following options are available:
Gather all CoreStorage metadata and write into the specified directory.  The given directory
must not already exist.
Specify the output file generated by the -r option.  If not given, use standard output.
Find out the CoreStorage logical volume identified by the given mount point, and print its encryption
context to the file given in the -o option.
The
utility first appeared along with CoreStorage in OS X 10.10.0.
It is a command language interpreter usable both as an interactive login
shell and a shell script command processor.
and a C-like syntax.
Throughout this manual, features of
but not usually documented are labeled with `(u)'.
login shell.  A login shell can be also specified by invoking the shell with
The rest of the flag arguments are interpreted as follows:
Forces a ``break'' from option processing, causing any
further shell arguments to be treated as non-option arguments.  The remaining
arguments will not be interpreted as shell options.  This may be used to pass
options to a shell script without confusion or possible subterfuge.  The shell
will not run a set-user ID script without this option.
Commands are read from the following argument (which must be present, and
must be a single argument),
The shell exits if any invoked command terminates abnormally or
yields a non-zero exit status.
The shell does not load any resource or startup files, or perform any 
command hashing, and thus starts faster.
The shell is interactive and prompts for its top-level input, even if
it appears to not be a terminal.  Shells are interactive without this option if
their inputs and outputs are terminals.
flag specified.
The shell parses commands but does not execute them.
This aids in debugging shell scripts.
it is used under a debugger.  Job control is disabled. (u)
Command input is taken from the standard input.
escape the newline at the end of this line and continue onto another line.
command input is echoed after history substitution.
immediately before execution.
Print a help message on the standard output and exit. (+)
After processing of flag arguments, if arguments remain but none of the
argument is taken as the name of a file of commands, or ``script'', to
be executed.  The shell opens this file and saves its name for possible
resubstitution by `$0'.  Because many systems use either the standard
version 6 or version 7 shells whose shell scripts are not compatible
with this shell, the shell uses such a `standard' shell to execute a script
whose first character is not a `#', i.e., that does not start with a
comment.
A login shell begins by executing commands from the system files
For examples of startup files, please consult
In the normal case, the shell begins reading commands from the terminal,
prompting with `> '.  (Processing of arguments and the use of the shell to
process files containing command scripts are described later.)
The shell repeatedly reads a line of command input, breaks it into words,
places it on the command history list, parses it and executes each command
in the line.
One can log out by typing `^D' on an empty line, `logout' or `login' or
`normal' or `automatic' as appropriate, then
executes commands from the files
The names of the system login and logout files vary from system to system for
describe two sets of functionality that are implemented as editor commands
but which deserve their own treatment.
the editor commands specific to the shell and their default bindings.
Command-line input can be edited using key sequences much like those used in
it is by default in interactive shells.
Emacs-style key bindings are used by default
environment variable) to
down
up
left
right
unless doing so would alter another single-character binding.
to prevent these bindings.
commands with a short description of each.
Note that editor commands do not have the same notion of a ``word'' as does the
shell.  The editor delimits words with any non-alphanumeric characters not in
and some of the characters with special meanings to it, listed under
The shell is often able to complete words when given a unique abbreviation.
replacing the incomplete word with the complete word in the input buffer.
end of completed directories and a space to the end of other completed words,
to speed typing and provide a visual indicator of successful completion.
the terminal bell rings.
system, or perhaps you were thinking too far ahead and typed the whole thing)
Completion works anywhere in the line, not at just the end; completed
text pushes the rest of the line to the right.  Completion in the middle of a word
often results in leftover characters to the right of the cursor that need
to be deleted.
Commands and variables can be completed in much the same way.
For example, typing `em[tab]' would complete `em' to
given a full pathname.
Typing `echo $ar[tab]' would complete `$ar' to `$argv'
if no other variable began with `ar'.
The shell parses the input buffer to determine whether the word you want to
complete should be completed as a filename, command or variable.
The first word in the buffer and the first word following
`;', `|', `|&', `&&' or `||' is considered to be a command.
A word beginning with `$' is considered to be a variable.
Anything else is a filename.  An empty line is `completed' as a filename.
You can list the possible completions of a word at any time by typing `^D'
and reprints the prompt and unfinished command line, for example:
choices (if any) whenever completion fails:
> set autolist
libtermcap.a@ libtermlib.a@
completion fails and adds no new characters to the word being completed.
A filename to be completed can contain variables, your own or others' home
directory stack entries abbreviated with `='
> ls ~k[^D]
kahn    kas     kellogg
> ls ~ke[tab]
or
> ls $lo[tab]
Note that variables can also be expanded explicitly with the
in the middle of a line it deletes the character under the cursor and
(not bound to any keys by default) can be used to cycle up and down through
the list of possible completions, replacing the current word with the next or
previous word in the list.
ignored by completion.  Consider the following:
> ls
Makefile        condiments.h~   main.o          side.c
README          main.c          meal            side.o
condiments.h    main.c~
> emacs ma[^D]
main.c   main.c~  main.o
> emacs ma[tab]
> emacs main.c
`main.c~' and `main.o' are ignored by completion (but not listing),
1) ignores case and 2) considers periods, hyphens and underscores
be equivalent.  If you had the following files
comp.lang.c      comp.lang.perl   comp.std.c++
comp.lang.c++    comp.std.c
A_silly_file    a-hyphenated-file    another_silly_file
would list all three files, because case is ignored and hyphens and
underscores are equivalent.  Periods, however, are not equivalent to
hyphens or underscores.
ignores case and differences between a hyphen and an underscore word
separator only when the user types a lowercase character or a hyphen.
Entering an uppercase character or an underscore will not match the 
corresponding lowercase character or hyphen word separator.  
`A_silly_file' and typing `rm a__file[^D]' would match just `A_silly_file' 
and `another_silly_file' because the user explicitly used an uppercase 
or an underscore character.  
Completion and listing are affected by several other shell variables:
match, even if more typing might result in a longer match:
> ls
fodder   foo      food     foonly
> set recexact
> rm fo[tab]
just beeps, because `fo' could expand to `fod' or `foo', but if we type
another `o',
> rm foo[tab]
> rm foo
the completion completes on `foo', even though `food' and `foonly'
also match.
commands automatically after one hits `return'.
those directories.
and rows (respectively) that are listed without asking first.
executables when listing commands, but it is quite slow.
to complete words other than filenames, commands and variables.
equivalent functions for glob-patterns.
The shell can sometimes correct the spelling of filenames, commands and variable names
as well as completing and listing them.
editor command (usually bound to M-s and M-S)
command name or `all' to correct the entire line each time return is typed,
before each completion attempt.
When spelling correction is invoked in any of these ways and
the shell thinks that any part of the command line is misspelled,
it prompts with the corrected line:
> set correct = cmd
One can answer `y' or space to execute the corrected line,
`e' to leave the uncorrected command in the input buffer,
`a' to abort the command as if `^C' had been hit, and
anything else to execute the original line unchanged.
Spelling correction recognizes user-defined completions (see the
which a completion is defined resembles a word in the completion list,
spelling correction registers a misspelling and suggests the latter
word as a correction.  However, if the input word does not match any of
the possible completions for that position, spelling correction does
not register a misspelling.
Like completion, spelling correction works anywhere in the line,
pushing the rest of the line to the right and possibly leaving
extra characters to the right of the cursor.
Beware: spelling correction is not guaranteed to work the way one intends,
and is provided mostly as an experimental feature.
Suggestions and improvements are welcome.
editor commands.
Only new or especially interesting editor commands are described here.
key bindings.
The character or characters to which each command is bound by default is
on terminals without a meta key.  Case counts, but commands that are bound
to letters by default are bound to both lower- and uppercase letters for
convenience.
Replaces the current word with the first word in the list of possible
completions.  May be repeated to step down through the list.
At the end of the list, beeps and reverts to the incomplete word.
Copies the previous word in the current line into the input buffer.
Expands the current word to the most recent preceding one for which
the current is a leading substring, wrapping around the history list
(once) if necessary.
changes to the next previous word etc., skipping identical matches
Deletes the character under the cursor.
See also those three commands, each of which does only a single action, and
each of which does a different two out of the three.
shell variable (q.v.) is set to prevent this.
Expands history substitutions in the current word.
Expands the glob-pattern to the left of the cursor.
expands history substitutions in each word in the input buffer.
Expands the variable to the left of the cursor.
Searches backwards through the history list for a command beginning with
the current contents of the input buffer up to the cursor and copies it
into the input buffer.
containing `*', `?', `[]' or `{}'.
appropriate point in the history list.
Emacs mode only.
into the input buffer with the cursor positioned at the end of the pattern,
and prompts with `bck: ' and the first match.  Additional characters may be
searching with the same pattern, wrapping around the history list if
single character for this to work) or one of the following special characters
may be typed:
^W
Appends the rest of the word under the cursor to the search pattern.
Undoes the effect of the last character typed and deletes a character
from the search pattern if appropriate.
^G
If the previous search was successful, aborts the entire search.
If not, goes back to the last successful search.
escape
Ends the search, leaving the current line in the input buffer.
search, leaving the current line in the input buffer, and
is then interpreted as normal input.  In particular, a carriage return
causes the current line to be executed.
Emacs mode only.
Inserts the last word of the previous input line (`!$') into the input buffer.
Expands history substitutions in the current line,
but is not bound by default.
Searches for the current word in PATH and, if it is found, replaces it with
the full path to the executable.  Special characters are quoted.  Aliases are
expanded and quoted but commands within aliases are not.  This command is
Expands the current word as described under the `expand' setting
Toggles between input and overwrite modes.
Saves the current input line and
looks for a stopped job with a name equal to the last component of the
or, if neither is set, `ed' or `vi'.
typed.  This is used to toggle back and forth between an editor and
the shell easily.  Some people bind this command to `^Z' so they
can do this even more easily.
Searches for documentation on the current command, using the same notion of
`current command' as the completion routines, and prints it.  There is no way
command name as a sole argument.  Else,
If there is more than one help file only the first is printed.
In insert mode (the default), inserts the typed character into the input line after the character under the cursor.
In overwrite mode, replaces the character under the cursor with the typed character.
The input mode is normally preserved between lines, but the
editor in that mode at the beginning of each line.
Indicates that the following characters are part of a
multi-key sequence.  Binding a command to a multi-key sequence really creates
whole sequence to the command.  All sequences beginning with a character
unless bound to another command.
Attempts to correct the spelling of each word in the input buffer, like
with switches, substitutions and the like.
Attempts to correct the spelling of the current word as described
Checks each component of a word which appears to be a pathname.
Expands or `unexpands' history substitutions in the input buffer.
Beeps.
Copies the previous entry in the history list into the input buffer.
May be repeated to step up through the history list, stopping at the top.
Prompts with `?' for a search string (which may be a glob-pattern, as with
input buffer.  The bell rings if no match is found.
Hitting return ends the search and leaves the last match in the input
buffer.
Hitting escape ends the search and executes the match.
first word of the input buffer.
replaces the yanked string with the next previous string from the
killring. This also has the effect of rotating the killring, such that
this string will be considered the most recently killed by a later
killring any number of times.
The shell splits input lines into words at blanks and tabs.  The special
characters `&', `|', `;', `<', `>', `(', and `)' and the doubled characters
`&&', `||', `<<' and `>>' are always separate words, whether or not they are
surrounded by whitespace.
When the shell's input is not a terminal, the character `#' is taken to begin a
comment.  Each `#' and the rest of the input line on which it appears is
discarded before further parsing.
A special character (including a blank or tab) may be prevented from having
its special meaning, and possibly made part of another word, by preceding it
is equivalent to a blank, but inside quotes this sequence results in a
newline.
can be prevented by enclosing the strings (or parts of strings)
in which they appear with single quotes or by quoting the crucial character(s)
substitution of the alias.  The usual way of quoting an alias is to precede it
backslashes but not by single quotes.  Strings quoted with double or backward
substitutions are prevented.
Text inside single or double quotes becomes a single word (or part of one).
Metacharacters in these strings, including blanks and tabs, do not form
below) can a double-quoted string yield parts of more than one word;
single-quoted strings never do.  Backward quotes are special: they signal
Quoting complex strings, particularly strings which themselves contain quoting
characters, can be confusing.  Remember that quotes need not be used as they are
in human writing!  It may be easier to quote not an entire string, but only
those parts of the string which need quoting, using different types of quoting
to do so if appropriate.
We now describe the various transformations the shell performs on the input in
the order in which they occur.  We note in passing the data structures involved
and the commands and variables which affect them.  Remember that substitutions
Each command, or ``event'', input from the terminal is saved in the history
shell variable can be set to not save duplicate events or consecutive duplicate
events.
Saved commands are numbered sequentially from 1 and stamped with the time.
It is not usually necessary to use event numbers, but the current event number
The shell actually saves history in expanded and literal (unexpanded) forms.
history use the literal form.
and clear the history list at any time,
store the history list automatically on logout and restore it on login.
History substitutions introduce words from the history list into the input
stream, making it easy to repeat commands, repeat arguments of a previous
command in the current command, or fix spelling mistakes in the previous
command with little typing and a high degree of confidence.
History substitutions begin with the character `!'.  They may begin anywhere in
prevent its special meaning; for convenience, a `!' is passed unchanged when it
is followed by a blank, tab, newline, `=' or `('.  History substitutions also
occur when an input line begins with `^'.  This special abbreviation will be
described later.  The characters used to signal history substitution (`!' and
line which contains a history substitution is printed before it is executed.
A history substitution may have an ``event specification'', which indicates
the event from which words are to be taken, a ``word designator'',
which manipulates the selected words.
An event specification can be
A number, referring to a particular event
#
The current event.
!
The second `?' can be omitted if it is immediately followed by a newline.
For example, consider this bit of someone's history list:
10  8:31    cp wumpus.man wumpus.man.old
11  8:36    vi wumpus.man
12  8:37    diff wumpus.man.old wumpus.man
The commands are shown with their event numbers and time stamps.
The current event, which we haven't typed in yet, is event 13.
`!!' refers to the previous event, 12.  `!!' can be abbreviated `!' if it is
followed by `:' (`:' is described below).
`!n' refers to event 9, which begins with `n'.
`!?old?' also refers to event 12, which contains `old'.
Without word designators or modifiers history references simply expand to the
entire event, so we might type `!cp' to redo the copy command or `!!|more'
if the `diff' output scrolled off the top of the screen.
History references may be insulated from the surrounding text with braces if
necessary.  For example, `!vdoc' would look for a command beginning with
`vdoc', and, in this example, not find one, but `!{v}doc' would expand
unambiguously to `vi wumpus.mandoc'.
Even in braces, history substitutions do not nest.
with `3d'; only completely numeric arguments are treated as event numbers.
This makes it possible to recall events beginning with numbers.
To select words from an event we can follow the event specification by a `:'
and a designator for the desired words.  The words of an input line are
numbered from 0, the first (usually command) word being 0, the second word
(first argument) being 1, etc.  The basic word designators are:
0
The first (command) word
^
The first argument, equivalent to `1'
$
The last argument
%
A range of words
*
Selected words are inserted into the command line separated by single blanks.
For example, the `diff' command in the previous example might have been
typed as `diff !!:1.old !!:1' (using `:1' to select the first argument
arguments from the `cp' command.  If we didn't care about the order of the
The `cp' command might have been written `cp wumpus.man !#:1.old', using `#'
to refer to the current event.
The `:' separating the event specification from the word designator can be
For example, our `diff' command might have been `diff !!^.old !!^' or,
equivalently, `diff !!$.old !!$'.  However, if `!!' is abbreviated `!',
specification.
A history reference may have a word designator but no event specification.
It then references the previous command.
Continuing our `diff' example, we could have said simply `diff
!^.old !^' or, to get the arguments in the opposite order, just `diff !*'.
The word or words in a history reference can be edited, or ``modified'',
by following it with one or more modifiers, each preceded by a `:':
h
Remove a trailing pathname component, leaving the head.
t
Remove all leading pathname components, leaving the tail.
r
Remove a filename extension `.xxx', leaving the root name.
e
Remove all but the extension.
u
Uppercase the first lowercase letter.
l
Lowercase the first uppercase letter.
The trailing delimiter may be omitted if it is immediately followed by a newline.
&
Repeat the previous substitution.
g
Apply the following modifier once to each word.
a (+)
Apply the following modifier as many times as possible to a single word.
`a' and `g' can be used together to apply a modifier globally.
With the `s' modifier, only the patterns contained in the original word are
substituted, not patterns that contain any substitution result.
p
Print the new command line but do not execute it.
q
Quote the substituted words, preventing further substitutions.
x
Like q, but break into words at blanks, tabs and newlines.
Modifiers are applied to only the first modifiable word (unless `g' is used).
It is an error for no word to be modifiable.
For example, the `diff' command might have been written as `diff wumpus.man.old
!#^:r', using `:r' to remove `.old' from the first argument on the same line
(`!#^').  We could say `echo hello out there', then `echo !*:u' to capitalize
`hello', `echo !*:au' to say it out loud, or `echo !*:agu' to really shout.
different approach).
There is a special abbreviation for substitutions.
`^', when it is the first character on an input line, is equivalent to `!:s^'.
Thus we might have said `^rot^root' to make the spelling correction in the
previous example.
This is the only history substitution which does not explicitly begin with `!'.
% man !$:t:r
man wumpus
colon may need to be insulated from it with braces:
> setenv PATH !$:h:$PATH
Bad ! modifier: $.
rather than `$'.
Finally, history can be accessed through the editor as well as through
the substitutions just described.
events in the history list and copy them into the input buffer.
expanded and literal forms of history lines in the input buffer.
in the current word and in the entire input buffer respectively.
The shell maintains a list of aliases which can be set, unset and printed by
left-to-right, is checked to see if it has an alias.  If so, the first word is
replaced by the alias.  If the alias contains a history reference, it undergoes
previous input line.  If the alias does not contain a history reference, the
argument list is left untouched.
Alias substitution is repeated until the first word of the command has no
alias.  If an alias substitution does not change the first word (as in the
previous example) it is flagged to prevent a loop.  Other loops are detected and
cause an error.
The shell maintains a list of variables, each of which has as value a list of
zero or more words.
The values of shell variables can be displayed and changed with the
The system maintains its own list of ``environment'' variables.
Read-only variables may not be modified or unset;
attempting to do so will cause an error.
Once made read-only, a variable cannot be made writable,
Environment variables cannot be made read-only.
Some variables are set by the shell or referred to by it.
list, and words of this variable's value are referred to in special ways.
Some of the variables referred to by the shell are toggles;
the shell does not care what their value is, only whether they are set or not.
Other operations treat variables numerically.  The `@' command permits numeric
calculations to be performed and the result assigned to a variable.  Variable
values are, however, always represented as (zero or more) strings.  For the
purposes of numeric operations, the null string is considered to be zero, and
the second and subsequent words of multi-word values are ignored.
After the input line is aliased and parsed, and before each command is
executed, variable substitution is performed keyed by `$' characters.  This
below) so `$' substitution does not occur there until later,
if at all.  A `$' is passed unchanged if followed by a blank, tab, or
end-of-line.
variable expanded separately.  Otherwise, the command name and entire argument
list are expanded together.  It is thus possible for the first (command) word
(to this point) to generate more than one word, the first of which becomes the
command name, and the rest of which become arguments.
Unless enclosed in `"' or given the `:q' modifier the results of variable
substitution may eventually be command and filename substituted.  Within `"', a
variable whose value consists of multiple words expands to a (portion of a)
single word, with the words of the variable's value separated by blanks.  When
the `:q' modifier is applied to a substitution the variable will expand to
multiple words with each word separated by a blank and quoted to prevent later
command or filename substitution.
The following metasequences are provided for introducing variable values into
the shell input.  Except as noted, it is an error to reference a variable which
is not set.
otherwise be part of it.  Shell variables have names consisting of
letters and digits starting with a letter.  The underscore character is
environment, then that value is returned (but some of the other forms
given below are not available in this case).
The first word of a variable's value is numbered `1'.
If the first number of a range is omitted it defaults to `1'.
It is not an error for a range to be empty if the
second argument is omitted or in range.
$0
Substitutes the name of the file from which command input
is being read.  An error occurs if the name is not known.
$*
Equivalent to `$argv', which is equivalent to `$argv[*]'.
can be applied to the substitutions above.  More than one may be used.  (+)
Braces may be needed to insulate a variable substitution from a literal colon
within the braces.
The following substitutions can not be modified with `:' modifiers.
$?0
Substitutes `1' if the current input filename is known, `0' if it is not.
Always `0' in interactive shells.
$#
Equivalent to `$#argv'.  (+)
$?
Equivalent to `$status'.  (+)
$$
Substitutes the (decimal) process number of the (parent) shell.
$!
Substitutes the (decimal) process number of the last
background process started by this shell.  (+)
$_
Substitutes the command line of the last command executed.  (+)
$<
Substitutes a line from the standard input, with no further interpretation
thereafter.  It can be used to read from the keyboard in a shell script.
typed the user may type an interrupt to interrupt the sequence into
can be used to interactively expand individual variables.
The remaining substitutions are applied selectively to the arguments of builtin
commands.  This means that portions of expressions which are not evaluated are
not subjected to these expansions.  For commands which are not internal to the
shell, the command name is substituted separately from the argument list.  This
occurs very late, after input-output redirection is performed, and in a child
of the main shell.
Command substitution is indicated by a command enclosed in ``'.  The output
from such a command is broken into separate words at blanks, tabs and newlines,
and null words are discarded.  The output is variable and command substituted
and put in place of the original string.
Command substitutions inside double
quotes (`"') retain blanks and tabs; only newlines force new words.  The single
final newline does not force a new word in any case.  It is thus possible for a
command substitution to yield only part of a word, even if the command outputs
a complete line.
By default, the shell since version 6.12 replaces all newline and carriage 
return characters in the command by spaces.  If this is switched off by
If a word contains any of the characters `*', `?', `[' or `{' or begins with
the character `~' it is a candidate for filename substitution, also known as
``globbing''.  This word is then regarded as a pattern (``glob-pattern''), and
replaced with an alphabetically sorted list of file names which match the
pattern.
In matching filenames, the character `.' at the beginning of a filename or
explicitly (unless either
or
or both are set(+)).  The character `*' matches any string of characters, 
including the null string.  The character `?' matches any single character.  
The sequence `[...]' matches any one of the characters enclosed.  
Within `[...]', a pair of
(+) Some glob-patterns can be negated:
An entire glob-pattern can also be negated with `^':
> echo *
bang crash crunch ouch
> echo ^cr*
bang ouch
Glob-patterns which do not use `?', `*', or `[]' or which use `{}' or `~'
(below) are not negated correctly.
The metanotation `a{b,c,d}e' is a shorthand for `abe ace ade'.
sorted separately at a low level to preserve this order:
(Note that `memo' was not sorted with the results of matching `*box'.)
It is not an error when this construct expands to files which do not exist,
but it is possible to get an error from a command to which the expanded list
is passed.
This construct may be nested.
As a special case the words `{', `}' and `{}' are passed undisturbed.
The character `~' at the beginning of a filename refers to home directories.
Standing alone, i.e., `~', it expands to the invoker's home directory as
user with that name and substitutes their home directory; thus `~ken' might
than at the beginning of a word, it is left undisturbed.
therefore, do home directory substitution as one might hope.
It is an error for a glob-pattern containing `*', `?', `[' or `~', with or
without `^', not to match any files.  However, only one pattern in a list of
glob-patterns must match a file (so that, e.g., `rm *.a *.c *.o' would fail
only if there were no files in the current directory ending in `.a', `.c', or
of patterns) which matches nothing is left unchanged rather than causing
an error.
recursively traversing any existing sub-directories.  For example, 
`ls **.c' will list all the .c files in the current directory tree.
If used by itself, it will match match zero or more sub-directories
in a subdirectory name or in the filename itself).
To prevent problems with recursion, the `**' glob-pattern will not 
descend into a symbolic link containing a directory.  To override this,
use `***' (+)
used to interactively expand individual filename substitutions.
The directory stack is a list of directories, numbered from zero, used by the
store the directory stack automatically on logout and restore it on login.
set to put arbitrary directories into the directory stack.
The character `=' followed by one or more digits expands to an entry in
the stack.  For example,
> echo =1
editor command apply to directory stack as well as filename substitutions.
There are several more transformations involving filenames, not strictly
related to the above but mentioned here for completeness.
Quoting prevents this expansion, and
full paths on demand.
This is not a substitution at all, but an abbreviation recognized by only
those commands.  Nonetheless, it too can be prevented by quoting.
The next three sections describe how the shell executes commands and
deals with their input and output.
A simple command is a sequence of words, the first of which specifies the
command to be executed.  A series of simple commands joined by `|' characters
forms a pipeline.  The output of each command in a pipeline is connected to the
input of the next.
Simple commands and pipelines may be joined into sequences with `;', and will
be executed sequentially.  Commands and pipelines can also be joined into
sequences with `||' or `&&', indicating, as in the C language, that the second
is to be executed only if the first fails or succeeds respectively.
A simple command, pipeline or sequence may be placed in parentheses, `()',
to form a simple command, which may in turn be a component of a pipeline or
sequence.  A command, pipeline or sequence can be executed
without waiting for it to terminate by following it with an `&'.
Builtin commands are executed within the shell.  If any component of a
pipeline except the last is a builtin command, the pipeline is executed
in a subshell.
Parenthesized commands are always executed in a subshell.
(cd; pwd); pwd
(printing this after the home directory), while
cd; pwd
When a command to be executed is found not to be a builtin command the shell
hashes the names in these directories into an internal table so that it will
command resides there.  This greatly speeds command location when a large
number of directories are present in the search path. This hashing mechanism is
not used:
In the above four cases the shell concatenates each component of the path
vector with the given command name to form a path name of a file which it
then attempts to execute it. If execution is successful, the search stops.
If the file has execute permissions but is not an executable to the system
(i.e., it is neither an executable binary nor a script that specifies its
interpreter), then it is assumed to be a file containing shell commands and
to specify an interpreter other than the shell itself.
On systems which do not understand the `#!' script interpreter convention
variable.  If so, the shell checks the first line of the file to
file to it on standard input.
The standard input and standard output of a command may be redirected with the
following syntax:
expanded) as the standard input.
is not subjected to variable, filename or command substitution, and each input
and newlines preserved, except for the final newline which is dropped.  The
resultant text is placed in an anonymous temporary file which is given to the
command as standard input.
then it is created; if the file exists, it is truncated, its previous contents
being lost.
This helps prevent accidental destruction of files.  In this case the `!' forms
can be used to suppress this check.
The forms involving `&' route the diagnostic output into the specified file as
input filenames are.
A command receives the environment in which the shell was invoked as modified
by the input-output parameters and the presence of the command in a pipeline.
Thus, unlike some previous shells, commands run from a file of shell commands
have no access to the text of the commands by default; rather they receive the
original standard input of the shell.  The `<<' mechanism should be used to
present inline data.  This permits shell command scripts to function as
components of pipelines and allows the shell to block read its input.  Note
If this is a terminal and if the process attempts to read from the terminal,
Diagnostic output may be directed through a pipe with the standard output.
Simply use the form `|&' rather than just `|'.
The shell cannot presently redirect diagnostic output without also redirecting
Having described how the shell accepts, parses and executes
command lines, we now turn to a variety of its useful features.
The shell contains a number of commands which can be used to regulate the
flow of control in command files (shell scripts) and (in limited but
useful ways) from terminal input.  These commands all operate by forcing the
shell to reread or skip in its input and, due to the implementation,
restrict the placement of some of the commands.
keywords appear in a single simple command on an input line as shown below.
If the shell's input is not seekable, the shell buffers up input whenever
a loop is being read and performs seeks in this internal buffer to
accomplish the rereading implied by the loop.  (To the extent that this
use expressions with a common syntax.  The expressions can include any
builtin command (q.v.) has its own separate syntax.
These operators are similar to those of C and have the same precedence.
They include
||  &&  |  ^  &  ==  !=  =~  !~  <=  >=
Here the precedence increases to the right, `==' `!=' `=~' and `!~', `<='
groups, at the same level.  The `==' `!=' `=~' and `!~' operators compare
their arguments as strings; all others operate on numbers.  The operators
`=~' and `!~' are like `!=' and `==' except that the right hand side is a
builtin command in shell scripts when all that is really needed is
pattern matching.
Null or
missing arguments are considered `0'.  The results of all expressions are
strings, which represent decimal numbers.  It is important to note that
no two components of an expression can appear in the same word; except
when adjacent to components of expressions which are syntactically
significant to the parser (`&' `|' `<' `>' `(' `)') they should be
surrounded by spaces.
Commands can be executed in expressions and their exit status
returned by enclosing them in braces (`{}').  Remember that the braces should
be separated from the words of the command by spaces.  Command executions
succeed, returning true, i.e., `1', if the command exits with status 0,
otherwise they fail, returning false, i.e., `0'.  If more detailed status
information is required then the command should be executed outside of an
Read access
Write access
Execute access
Existence
Ownership
Zero size
Non-zero size (+)
Plain file
Directory
Symbolic link (+) *
Block special file (+)
Character special file (+)
Named pipe (fifo) (+) *
Socket special file (+) *
Set-user-ID bit is set (+)
Set-group-ID bit is set (+)
Sticky bit is set (+)
for a terminal device (+)
Has been migrated (Convex only) (+)
Applies subsequent operators in a multiple-operator test to a symbolic link
rather than to the file to which the link points (+) *
does not exist or is inaccessible or, for the operators indicated by `*',
if the specified file type does not exist on the current system,
then all enquiries return false, i.e., `0'.
(returns `1') for plain executable files, but not for directories.
to a symbolic link rather than to the file to which the link points.
in a multiple-operator test; see below.
It is possible but not useful, and sometimes misleading, to combine operators
can lead to particularly strange results.
Other operators return other information, i.e., not just `0' or `1'.  (+)
Last file access time, as the number of seconds since the epoch
Last file modification time
Last inode modification time
Device number
Inode number
The name of the file pointed to by a symbolic link
Number of (hard) links
Permissions, in octal, without leading zero
and `0' if by neither
Numeric userid
Username, or the numeric userid if the username is unknown
Numeric groupid
Groupname, or the numeric groupid if the groupname is unknown
Size, in bytes
Only one of these operators may appear in a multiple-operator test, and it
elsewhere in a multiple-operator test.  Because `0' is a valid return value
for many of these operators, they do not return `0' when they fail: most
variable), the result of a file inquiry is based on the permission bits of
ordinarily allow writing but which is on a file system mounted read-only,
the test will succeed in a POSIX shell but fail in a non-POSIX shell.
command (q.v.) (+).
numbers.  When a job is started asynchronously with `&', the shell prints a
line which looks like
[1] 1234
indicating that the job which was started asynchronously was job number 1 and
had one (top-level) process, whose process id was 1234.
If you are running a job and wish to do something else you may hit the suspend
key (usually `^Z'),
which sends a STOP signal to the current job.  The shell will then normally
indicate that the job has been `Suspended' and print another prompt.
You can then manipulate the state of the suspended job.
You can put it in the
A `^Z' takes effect immediately and is like an interrupt
in that pending output and unread input are discarded when it is typed.
jobs to complete.
The `^]' key sends a delayed suspend signal, which does not generate a STOP
This can usefully be typed ahead when you have prepared some commands for a
job which you wish to stop after it has read them.
`^Y' is an editing command.  (+)
A job being run in the background stops if it tries to read from the
terminal.  Background jobs are normally allowed to produce output, but this can
be disabled by giving the command `stty tostop'.  If you set this tty option,
then background jobs will stop when they try to produce output like they do
when they try to read input.
There are several ways to refer to jobs in the shell.  The character `%'
introduces a job name.  If you wish to refer to job number 1, you can name it
as `%1'.  Just naming a job brings it to the foreground; thus `%1' is a synonym
for `fg %1', bringing job 1 back into the foreground.  Similarly, saying `%1 &'
resumes job 1 in the background, just like `bg %1'.  A job can also be named
by an unambiguous prefix of the string typed in to start it: `%ex' would
job whose name began with the string `ex'.  It is also possible to say
is only one such job.
The shell maintains a notion of the current and previous jobs.  In output
pertaining to jobs, the current job is marked with a `+' and the previous job
to the previous job.
on some systems.  It is an artifact from a `new' implementation of the tty
driver which allows generation of interrupt characters from the keyboard to
details on setting options in the new tty driver.
The shell learns immediately whenever a process changes state.  It normally
informs you whenever a job becomes blocked so that no further progress is
possible, but only right before it prints a prompt.  This is done so that it
does not otherwise disturb your work.  If, however, you set the shell variable
single process so that its status changes will be immediately reported.  By
starting a background job to mark it.
When you try to leave the shell while jobs are stopped, you will be
see what they are.  If you do this or immediately try to exit again, the shell
will not warn you a second time, and the suspended jobs will be terminated.
There are various ways to run commands and take other actions automatically
at various times in the ``life cycle'' of the shell.  They are summarized here,
to be executed by the shell at a given time.
minutes, before each prompt, before each command gets executed, after each
command gets executed, and when a job is started or is brought into the
foreground.
after a given number of minutes of inactivity.
of commands which exit with a status other than zero.
typed, if that is really what was meant.
command after the completion of any process that takes more than a given
number of CPU seconds.
on those users at any time.
The shell is eight bit clean
and thus supports character sets needing this capability.
NLS support differs depending on whether or not
In either case, 7-bit ASCII is the default character code
(e.g., the classification of which characters are printable) and sorting,
causes a check for possible changes in these respects.
(e.g., a 'en_CA.UTF-8' would yield "UTF-8" as a character code).
environment variables; refer to the system documentation for further details.
When not using the system's NLS, the shell simulates it by assuming that the
ISO 8859-1 character set is used
their values.  Sorting is not affected for the simulated NLS.
In addition, with both real and simulated NLS, all printable
left alone.
is set.  This may be useful for the simulated NLS or a primitive real NLS
is of course still possible.
Unknown characters (i.e., those that are neither printable nor control
If the tty is not in 8 bit mode, other 8 bit characters are printed by
converting them to ASCII and using standout mode.  The shell
use a meta key) may need to explicitly set
A number of new builtin commands are provided to support features in
particular operating systems.  All are described in detail in the
On systems that support TCF (aix-ibm370, aix-ps2),
prints the site on which each job is executing.
operating system.
universe.
indicate respectively the vendor, operating system and machine type
(microprocessor class or machine model) of the
system on which the shell thinks it is running.
These are particularly useful when sharing one's home directory between several
types of machines; one can, for example,
appropriate directory.
variable indicates what options were chosen when the shell was compiled.
Login shells catch the terminate signal, but non-login shells inherit the
terminate behavior from their parents.
Other signals have the values which the shell inherited from its parent.
In shell scripts, the shell's handling of interrupt and terminate signals
default, the shell's children do too, but the shell does not send them a
The shell uses three different sets of terminal (``tty'') modes:
`edit', used when editing, `quote', used when quoting literal characters,
and `execute', used when executing commands.
The shell holds some settings in each mode constant, so commands which leave
the tty in a confused state do not interfere with the shell.
The shell also matches changes in the speed and padding of the tty.
The list of tty modes that are kept constant
Note that although the editor uses CBREAK mode (or its equivalent),
it takes typed-ahead characters anyway.
manipulate and debug terminal capabilities from the command line.
On systems that support SIGWINCH or SIGWINDOW, the shell
adapts to window resizing automatically and adjusts the environment
them to reflect the new window size.
The next sections of this manual describe all of the available
Does nothing, successfully.
The first form prints the values of all shell variables.
must already exist.
Without arguments, prints all aliases.
Shows the amount of dynamic memory acquired, broken down into used and free
memory.  With an argument shows the number of free and used blocks in each size
category.  The categories start at size 8 and double at each step.  This
command's output may vary across system types, because systems other than the VAX
may use a different memory allocator.
Puts the specified jobs (or, without arguments, the current job)
into the background, continuing each if it is stopped.
Without options, the first form lists all bound keys and the editor command to which each is bound,
Options include:
Lists all editor commands and a short description of each.
Binds all keys to the standard bindings for the default editor.
Binds all keys to the standard GNU Emacs-like bindings.
Lists or changes key-bindings in the alternative key map.
`down', `up', `left' or `right'.
editor command.
reinterpreted, and this continues for ten levels of interpretation.
Prints a usage message.
If a command is bound to a string, the first character of the string is bound to
written caret-character style, e.g., `^A'.  Delete is written `^?'
Bell
Backspace
Escape
Form feed
Newline
Carriage return
Horizontal tab
Vertical tab
execution. Only non-interactive commands can be executed, and it is
not possible to execute any command that would overlay the image
current line are executed.  Multi-level breaks are thus
possible by writing them all on one line.
Prints the names of all builtin commands.
Available only if the shell was so compiled;
Without arguments, lists all completions.
is to be completed, and may be one of the following:
Current-word completion.
Next-word completion.
the command line.
Position-dependent completion.
variables, which must include the current word.
Aliases
Bindings (editor commands)
Commands (builtin or external commands)
External commands which begin with the supplied path prefix
Directories
Directories which begin with the supplied path prefix
Environment variables
Filenames
Filenames which begin with the supplied path prefix
Groupnames
Jobs
Limits
Nothing
Shell variables
Signals
Plain (``text'') files
Plain (``text'') files which begin with the supplied path prefix
Any variables
Usernames
Completions
(...)
Words from the given list
`...`
Words from the output of command
completion.  If null, no character is appended.  If omitted (in which
case the fourth delimiter can also be omitted), a slash is appended to
directories and a space to other words.
contains (as its name indicates) contents of the current (already
typed in) command line. One can examine and use contents of the
sophisticated completions (see completion for svn(1) included in
this package).
Now for some examples.  Some commands take only directories as arguments,
so there's no point completing plain files.
> co[^D]
complete compress
> co[^D]
> compress
which begin with `co' (thus matching `co*') to `compress' (the only
word in the list).
ambiguous commands.
These complete words following `alias' with aliases, `man' with commands,
and `set' with shell variables.
is attempted and prints `Truth has no options.' when completion choices are listed.
Words can be completed from a variable evaluated at completion time,
> set hostnames = (rtfm.mit.edu tesla.ee.cornell.edu)
> ftp [^D]
rtfm.mit.edu tesla.ee.cornell.edu
> ftp [^C]
> set hostnames = (rtfm.mit.edu tesla.ee.cornell.edu uunet.uu.net)
> ftp [^D]
rtfm.mit.edu tesla.ee.cornell.edu uunet.uu.net
or from a command run at completion time:
23113 23377 23380 23406 23429 23529 23530 PID
so the braces, space and `$' in `{print $1}' must be quoted explicitly.
One command can have multiple completions:
completes the second argument to `dbx' with the word `core' and all other
arguments with commands.  Note that the positional completion is specified
before the next-word completion.
Because completions are evaluated from left to right, if
the next-word completion were specified first it would always match
and the positional completion would never be executed.  This is a
common mistake when defining a completion.
particular forms as arguments.  For example,
completes `cc' arguments to files ending in only `.c', `.a', or `.o'.
to exclude precious source code from `rm' completion.  Of course, one
could still type excluded names manually or override the completion
editor commands (q.v.).
restrict completion to files beginning with a particular path prefix.  For
example, the Elm mail program uses `=' as an abbreviation for one's mail
directory.  One might use
`$HOME' instead of `~' because home directory substitution works at only the
beginning of a word.
completes arguments to `finger' from the list of users, appends an `@',
and then completes after the `@' from the `hostnames' variable.  Note
again the order in which the completions are specified.
Finally, here's a complex example for inspiration:
(note the pattern which matches both) to files,
and `group' to users and groups respectively
given lists.  It also completes the switches themselves from the given list
and completes anything not otherwise completed to a directory.  Whew.
Remember that programmed completions are ignored if the word being completed
is a tilde substitution (beginning with `~') or a variable (beginning with `$').
in future versions of the shell.
The rest of the commands on the current line are executed.
The first form prints the directory stack.  The top of the stack is at the
left and the first directory in the stack is the current directory.
mechanism.
The last form clears the directory stack.
output, separated by spaces and terminated with a newline.
For example, 'echotc home' sends the cursor to the home position,
in the status line.
value of that capability ("yes" or "no" indicating that the terminal does
or does not have that capability).  One might use this to make the output
from a shell script less verbose on slow terminals, or limit command
output to the number of lines on the screen:
> set history=`echotc lines`
Termcap strings may contain wildcards which will not echo correctly.
One should use double quotes when setting a shell variable to a terminal
capability string, as in the following example that places the date in
the status line:
> set tosl="`echotc ts 0`"
> set frsl="`echotc fs`"
than causing an error.
Treats the arguments as input to the
shell and executes the resulting command(s) in the context
of the current shell.  This is usually used to execute commands
generated as the result of command or variable substitution,
because parsing occurs before these substitutions.
Executes the specified command in place of the current shell.
Brings the specified jobs (or, without arguments, the current job)
into the foreground, continuing each if it is stopped.
space-separated list.
must appear alone on separate lines.)  The builtin command
When this command is read from the terminal, the loop is read once
the loop are executed.  If you make a mistake typing in a
loop at the terminal you can rub it out.
Prints the system execution path.  (TCF only)
Prints the experimental version prefix.  (TCF only)
delimited by null characters in the output.  Useful for
programs which wish to use the shell to filename expand a list of words.
yield a string of the form `label'.  The shell rewinds its
input as much as possible, searches for a line of the
form `label:', possibly preceded by blanks or tabs, and
continues execution after that line.
Prints a statistics line indicating how effective the
internal hash table has been at locating commands (and avoiding
hash buckets.
The first form prints the history event list.
(This can be used to
first rather than oldest first.
number, at most that many lines are saved.  If the second word of
existing history file instead of replacing it (if there is one) and
sorted by time stamp.  (+) Merging is intended for an environment like
the X Window System
with several shells in simultaneous use.  Currently it succeeds
only when the shells quit nicely one after another.
to the history list.
into the history list and sorted by timestamp.
filename.
(unexpanded) form of the history list.
The last form clears the history list.
signal and arranges for the shell to send it a hangup signal when the shell
exits.
Without an argument, causes the non-interactive shell only to
exit on a hangup for the remainder of the script.
or a parenthesized command list, but it may have arguments.
IDs in addition to the normal information.  On TCF systems, prints
the site on which each job is executing.
is given, the TERM (terminate) signal) to the specified jobs or processes.
Signals are either given by number or by name (as given in
to the current job.  If the signal being sent is TERM (terminate)
or HUP (hangup), then the job or process is sent a
CONT (continue) signal as well.
The third form lists the signal names.
Limits the consumption by the current process and each
hard limits are used instead of the current limits.  The
hard limits impose a ceiling on the values of the current
limits.  Only the super-user may raise the hard limits, but
a user may lower or raise the current limits within the legal range.
Controllable resources currently include (if supported by the OS):
the maximum number of cpu-seconds to be used by each process
the largest single file which can be created
the maximum growth of the data+stack region via sbrk(2) beyond
the end of the program text
the maximum size of the automatically-extended stack region
the size of the largest core dump that will be created
the maximum amount of physical memory a process
may have allocated to it at a given time
the maximum amount of virtual memory a process
may have allocated to it at a given time (address space)
the maximum amount of virtual memory a process
may have allocated to it at a given time
the maximum amount of memory a process
the maximum number of open files for this process
the maximum number of threads for this process
the maximum size which a process may lock into memory using mlock(2)
the maximum number of simultaneous processes for this user id
the maximum size of socket buffer usage for this user
the maximum amount of swap space reserved or used for this user
the maximum number of locks for this user
the maximum number of pending signals for this user
the maximum number of bytes in POSIX mqueues for this user
the maximum nice priority the user is allowed to raise mapped from [19...-20]
to [0...39] for this user
the maximum realtime priority for this user
the timeout for RT tasks in microseconds for this user.
integer) number followed by a scale factor.  For all limits
(1024 bytes); a scale factor of `m' or `megabytes' or `g' or `gigabytes'
while `m' for minutes or `h' for hours, or a time of the
form `mm:ss' giving minutes and seconds may be used.
prefixes of the names suffice.
Terminates a login shell, replacing it with an instance of
special file in the listing with a special character:
Directory
*
Executable
#
Block device
%
Character device
|
Named pipe (systems with named pipes only)
=
Socket (systems with sockets only)
@
Symbolic link (systems with symbolic links only)
+
:
in more detail (on only systems that have them, of course):
@
Symbolic link to a non-directory
>
Symbolic link to a directory
&
Symbolic link to nowhere
files pointed to by symbolic links to be mounted.
The first form migrates the process or job to the site specified or the
default site determined by the system path.
current process to the specified site.  Migrating the shell
itself can cause unexpected behavior, because the shell
does not like to lose its tty.  (TCF only)
Available only if the shell was so compiled;
priority.
the process gets.  The super-user may specify negative
executed in a sub-shell, and the restrictions placed on
Without an argument, causes the non-interactive shell only to
ignore hangups for the remainder of the script.
Causes the shell to notify the user asynchronously when the status of any
instead of waiting until the next prompt as is usual.
Controls the action of the shell on interrupts.  Without arguments,
restores the default action of the shell on interrupts,
which is to terminate shell scripts or to return to the
terminal command input level.
when an interrupt is received or a child process terminates because it was
interrupted.
Without arguments, pops the directory stack and returns to the new top directory.
Prints the names and values of all environment variables or,
Without arguments, exchanges the top two elements of the directory stack.
from the stack before pushing it onto the stack.  (+)
directory stack around to be the top element and changes to it.
directory, pushes it onto the top of the stack and changes to it.  (+)
Causes the internal hash table of the contents of the
automatically, except in the special case where another command of
the same name which is located in a different directory already
exists in the hash table.  Also flushes the cache of home directories
built by tilde expansion.
The first form prints the scheduled-event list.
the scheduled-event list is printed.
For example,
causes the shell to echo `It's eleven o'clock.' at 11 AM.
or may be relative to the current time:
> sched
     2  Wed Apr  4 17:00  set prompt=[%h] It's after 5; go home: >
> sched
A command in the scheduled-event list is executed just before the first
prompt is printed after the time when the command is scheduled.
It is possible to miss the exact time when the command is to be run, but
an overdue command will execute at the next prompt.
A command which comes due while the shell
is waiting for user input is executed immediately.
However, normal operation of an already-running command will not
be interrupted so that a scheduled-event list element may be run.
command on some Unix systems.
Its major disadvantage is that it may not run a command at exactly the
specified time.
the shell, it has access to shell variables and other structures.
This provides a mechanism for changing one's working environment
based on the time of day.
The first form of the command prints the value of all shell variables.
Variables which contain more than a single word print as a
parenthesized word list.
this component must already exist.
The sixth form lists only the names of all shell variables that are read-only.
The eighth form is the same as the third form, but
in a single set command.  Note, however, that variable expansion
happens for all arguments before any setting occurs.  Note also that `=' can
whitespace, but cannot be adjacent to only one or the other.
Without arguments, prints the names and values of all environment variables.
Sets the system execution path.  (TCF only)
No sanity checking is done.
Concept terminal users may have to `settc xn no' to get proper
wrapping at the rightmost column.
the shell does not allow to change.
on the `edit', `quote' or `execute' set of tty modes respectively; without
The available modes, and thus the display, vary from system to system.
whether or not they are fixed.
For example, `setty +echok echoe' fixes `echok' mode on and allows commands
to turn `echoe' mode on or off, both when the shell is executing commands.
The commands are not placed on the history list.
if they are nested too deeply the shell may run out of file descriptors.
Stops the specified jobs or processes which are executing in the background.
the current job.
Causes the shell to stop in its tracks, much as if it had
Each case label is successively matched, against the
The file metacharacters `*', `?' and `[...]'  may be used
in the case labels, which are variable expanded.  If none
of the labels match before a `default' label is found, then
the execution begins after the default label.  Each case
label and the default label must appear at the beginning of
labels and default labels as in C.  If no label matches and
terminfo(5) database. Prints the terminal type to stdout and returns 0
if an entry is present otherwise returns 1.
a pipeline, a command list or a parenthesized command list)
If necessary, an extra shell is created to print the time statistic when
the command completes.
children.
Common values for the mask are
002, giving all access to the group and read and execute access to others, and
022, giving read and execute access to the group and others.
`unalias *' thus removes all aliases.
`uncomplete *' thus removes all completions.
Disables use of the internal hash table to speed location of
executed programs.
Only the super-user may do this.
`unset *' thus removes all variables unless they are read-only;
this is a bad idea.
`unsetenv *' thus removes all environment variables;
this is a bad idea.
The shell waits for all background jobs.  If the shell is interactive, an
interrupt will disrupt the wait and cause the shell to print the names and job
numbers of all outstanding jobs.
Available only if the shell was so compiled;
Displays the command that will be executed by the shell after substitutions,
evaluates non-zero.
loop prematurely.
If the input is a terminal, the user is prompted the first time
If set, each of these aliases executes automatically at the indicated time.
They are all initially undefined.
Runs when the shell wants to ring the terminal bell.
Runs after every change of working directory.  For example, if the user is
to be the name of the host, a colon, and the full current working directory.
A fancier way to do that is
This will put the hostname and working directory on the title bar but
only the hostname in the icon manager menu.
may cause an infinite loop.  It is the author's opinion that anyone doing
so will get what they deserve.
Runs before each command gets executed, or when the command changes state.
is sought is passed as sole argument.
For example, if one does
then the help display of the command itself will be invoked, using the GNU
help calling convention.
Currently there is no easy way to account for various calling conventions (e.g.,
the customary Unix `-h'), except by using a table of many commands.
checking on common but infrequent changes such as new mail.  For example,
if one does
> set tperiod = 30
> alias periodic checknews
Runs just before each prompt is printed.  For example, if one does
> alias precmd date
should be used.
Runs before each command gets executed.
Specifies the interpreter for executable scripts which do not themselves
specify an interpreter.  The first word should be a full path name to the
The variables described in this section have special meaning to the shell.
startup; they do not change thereafter unless changed by the user.  The shell
whenever the environment variable changes the shell changes the corresponding
shell variable to match (unless the shell variable is read-only) and vice
are not synchronized in this manner, and that the shell automatically
to the end of normal files when they are matched exactly.
Set by default.
the local username for kerberos authentication.
i.e., `$1' is replaced by `$argv[1]', etc.
Set by default, but usually empty in interactive shells.
each completion attempt.
only history will be expanded and a second completion will expand filenames.
If set, possibilities are listed after an ambiguous completion.
If set to `ambiguous', possibilities are listed only when no new
characters are added by completion.
The first word is the number of minutes of inactivity before automatic
logout.  The optional second word is the number of minutes of inactivity
before automatic locking.
When the shell automatically logs out, it prints `auto-logout', sets the
When the shell automatically locks, the user is required to enter his password
to continue working.  Five incorrect attempts result in automatic logout.
Set to `60' (automatic logout after 60 minutes, and no locking) by default
in login and superuser shells, but not if the shell thinks it is running
the tty is a pseudo-tty (pty) or the shell was not so compiled (see the
If set, the internal hash table of the contents of the directories in the
table.  In addition, the list of available commands will be rebuilt for each
command completion or spelling correction attempt if set to `complete' or
`correct' respectively; if set to `always', this will be done for both
cases.
scripts.
The file name of the message catalog.
If set, tcsh use `tcsh.${catalog}' as a message catalog instead of
default `tcsh'.
subdirectories if they aren't found in the current directory.
If set, it enables color escape sequence for NLS message files.
And display colorful NLS messages.
If set, the shell will evaluate expressions right to left, like the original
If set to `igncase', the completion becomes case insensitive.
If set to `enhance', completion ignores case and considers
hyphens and underscores to be equivalent; it will also treat
separators.
If set to `Enhance', completion matches uppercase and underscore
characters explicitly and matches lowercase and hyphens in a
case-insensivite manner; it will treat periods, hypens and underscores
as word separators.
If set to a list of commands, the shell will continue the listed
commands, instead of starting a new one.
Same as continue, but the shell will execute:
If set to `cmd', commands are automatically spelling-corrected.
If set to `complete', commands are automatically completed.
If set to `all', the entire command line is corrected.
If set, newlines and carriage returns in command substitution are
replaced by spaces.  Set by default.
The full pathname of the current directory.
stack rather than rotating it to the top.
An array of all the directories on the directory stack.
`$dirstack[1]' is the current working directory, `$dirstack[2]'
the first directory on the stack, etc.
Note that the current working directory is `$dirstack[1]' but `=0' in
directory stack substitutions, etc.
but the first element (the current working directory) is always correct.
If set to `euc', it enables display and editing EUC-kanji(Japanese) code.
If set to `sjis', it enables display and editing Shift-JIS(Japanese) code.
If set to `big5', it enables display and editing Big5(Chinese) code.
If set to `utf8', it enables display and editing Utf8(Unicode) code.
If set to the following format, it enables display and editing of original
multi-byte code format:
> set dspmbyte = 0000....(256 bytes)....0000
corresponds (from left to right) to the ASCII codes 0x00, 0x01, ... 0xff.  Each
character
is set to number 0,1,2 and 3.  Each number has the following meaning:
  0 ... not used for multi-byte characters.
  1 ... used for the first byte of a multi-byte character.
  2 ... used for the second byte of a multi-byte character.
  3 ... used for both the first byte and second byte of a multi-byte character.
  Example:
If set to `001322', the first character (means 0x00 of the ASCII code) and
second character (means 0x01 of ASCII code) are set to `0'.  Then, it is not
used for multi-byte characters.  The 3rd character (0x02) is set to '1',
indicating that it is used for the first byte of a multi-byte character.
The 4th character(0x03) is set '3'.  It is used for both the first byte and
the second byte of a multi-byte character.  The 5th and 6th characters
(0x04,0x05) are set to '2', indicating that they are used for the second
byte of a multi-byte character.
The GNU fileutils version of ls cannot display multi-byte
filenames without the -N ( --literal ) option.   If you are using
this version, set the second word of dspmbyte to "ls".  If not, for
example, "ls-F -l" cannot display multi-byte filenames.
  Note:
This variable can only be used if KANJI and DSPMBYTE has been defined at
compile time.
from the stack before pushing it onto the stack.
If set, each command with its arguments is echoed just before it is
executed.  For non-builtin commands all expansions occur before
echoing.  Builtin commands are echoed before command and filename
substitution, because these substitutions are then done selectively.
bsd
sysv
Recognize backslashed escape sequences in echo strings.
both
none
Recognize neither.
Set by default to the local system default.  The BSD and System V
systems.
If set, the command-line editor is used.  Set by default in interactive
shells.
shell variable) indicate skipped directories with an ellipsis (`...')
The user's effective user ID.
The first matching passwd entry name corresponding to the effective user ID.
Lists file name suffixes to be ignored by completion.
by default. If 
The user's real group ID.
If set, wild-card glob patterns will match files and directories beginning
with `.' except for `.' and `..'
If set, the `**' and `***' file glob patterns will match any string of 
`ls **.c' will list all the .c files in the current directory tree).
If used by itself, it will match match zero or more sub-directories
To prevent problems with recursion, the `**' glob-pattern will not 
descend into a symbolic link containing a directory.  To override this,
use `***'
The user's group name.
highlighted in reverse video.
Highlighting requires more frequent terminal writes, which introduces extra
overhead. If you care about terminal performance, you may want to leave this
unset.
the history substitution character, replacing the default character
`!'.  The second character of its value replaces the character `^' in
quick substitutions.
Controls handling of duplicate entries in the history list.  If set to
`all' only unique history events are entered in the history list.  If
set to `prev' and the last history event is the same as the current
command, then the current command is not entered in the history.  If
set to `erase' and the same event is found in the history list, that
old event gets erased and the current one gets inserted.  Note that the
`prev' and `all' options renumber history events so there are no gaps.
useful when sharing the same home directory between different machines,
or when saving separate histories on different terminals.  Because only
use the literal (unexpanded) form of lines in the history list.  See
The first word indicates the number of history events to save.  The
optional second word (+) indicates the format in which history is
`%R'.  Set to `100' by default.
Initialized to the home directory of the invoker.  The filename
If set to the empty string or `0' and the input device is a terminal,
`^D' on an empty line) causes the shell to print `Use "exit" to leave
tcsh.' instead of exiting.  This prevents the shell from accidentally
being killed.  Historically this setting exited after 26 successive
single `^D'.
If set, the shell treats a directory name typed as a command as though
the change of directory is echoed to the standard output.  This behavior
is inhibited in non-interactive shell scripts, or for command strings
with more than one word.  Changing directory takes precedence over
executing a like-named command, but it is done after alias
substitutions.  Tilde and variable expansions work as expected.
If set to `insert' or `overwrite', puts the editor into that input mode
at the beginning of each line.
Controls handling of duplicate entries in the kill ring.  If set to
`all' only unique strings are entered in the kill ring.  If set to
`prev' and the last killed string is the same as the current killed
string, then the current string is not entered in the ring.  If set
to `erase' and the same string is found in the kill ring, the old
string is erased and the current one is inserted.
Indicates the number of killed strings to keep in memory.  Set to `30'
by default.  If unset or set to less than `2', the shell will only
keep the most recently killed string.
Strings are put in the killring by the editor commands that delete
can be used to yank earlier killed strings.
If set to `x', `a' or `A', or any combination thereof (e.g., `xA'), they
files (even if they start with a `.'), `A' shows all files but `.' and
`..', and `x' sorts across instead of down.  If the second word of
If set, all jobs are listed when a job is suspended.  If set to `long',
the listing is in long format.
each symbolic link points.
will list without asking first.
command will list without asking first.
Set by the shell if it is a login shell.  Setting or unsetting it
Set by the shell to `normal' before a normal logout, `automatic' before
an automatic logout, and `hangup' if the shell was killed by a hangup
shell variable.
A list of files and directories to check for incoming mail, optionally
preceded by a numeric word.  Before each prompt, if 10 minutes have
passed since the last check, the shell checks each file and says `You
and has a modification time greater than its access time.
If you are in a login shell, then no mail file is reported unless it has
been modified after the time the shell has started up, to prevent
redundant notifications.  Most login programs will tell you whether or not
you have mail when you log in.
file within that directory as a separate message, and will report `You have
This functionality is provided primarily for those systems which store mail
in this manner, such as the Andrew Mail System.
checking interval, in seconds.
Under very rare circumstances, the shell may report `You have mail.' instead
of `You have new mail.'
If set to `never', completion never beeps.
If set to `nomatch', it beeps only when there is no match.
If set to `ambiguous', it beeps when there are multiple matches.
If set to `notunique', it beeps when there is one exact and other longer matches.
If unset, `ambiguous' is used.
If set, beeping is completely disabled.
If set, restrictions are placed on output redirection to insure that files
are not accidentally destroyed and that `>>' redirections refer to existing
specifiers at the change of hour.
(q.v.) are inhibited.  This is most useful in shell scripts which do not deal
with filenames, or after a list of filenames has been obtained and further
expansions are not desirable.
it is disabled so that the meta key can be used.
(q.v.) which does not match any
existing files is left untouched rather than causing an error.
It is still an error for the substitution to be
malformed, e.g., `echo [' still gives an error.
A list of directories (or glob-patterns which match directories; see
completion operation.  This is usually used to exclude directories which
If set, the shell announces job completions asynchronously.
The default is to present job completions just before printing a prompt.
If set, enable the printing of padding '0' for hours, in 24 and 12 hour
formats.  E.G.: 07:45:42 vs. 7:45:42.
To retain compatibily with older versions numeric variables starting with
0 are not interpreted as octal. Setting this variable enables proper octal
parsing.
A list of directories in which to look for executable commands.
A null word specifies the current directory.
If set and an interactive program exits with a non-zero status, the shell
The string which is printed before reading each command from the terminal.
are replaced by the given information:
The current working directory.
%~
The current working directory, but with one's home directory
represented by `~' and other users' home directories represented by
in the current session.
are represented by an ellipsis so the whole becomes `...trailing'.
`~' substitution is done as in `%~' above, but the `~' component
is ignored when counting trailing components.
%C
Like %c, but without `~' substitution.
%h, %!, !
The current history event number.
%M
The full hostname.
%m
The hostname up to the first `.'.
%S (%s)
Start (stop) standout mode.
%B (%b)
Start (stop) boldfacing mode.
%U (%u)
Start (stop) underline mode.
%t, %@
%T
%p
%P
%%
A single `%'.
%n
The user name.
%N
The effective user name.
%j
The number of jobs.
%d
The weekday in `Day' format.
%D
The day in `dd' format.
%w
The month in `Mon' format.
%W
The month in `mm' format.
%y
The year in `yy' format.
%Y
The year in `yyyy' format.
%l
The shell's tty.
%L
Clears from the end of the prompt to end of the display or the end of the line.
%$
Expands the shell or environment variable name immediately after the `$'.
%#
for the superuser.
It should be used only to change terminal attributes and
should not move the cursor location.  This
%?
The return code of the command executed just before the prompt.
%R
The bold, standout and underline sequences are often used to distinguish a
superuser shell.  For example,
then print `DING!' on the change of hour (i.e, `:00' minutes) instead of
the actual time.
Set by default to `%# ' in interactive shells.
note the variable meaning of `%R'.
Set by default to `%R? ' in interactive shells.
The string with which to prompt when confirming automatic spelling correction.
note the variable meaning of `%R'.
Set by default to `CORRECT>%R (y|n|e|a)? ' in interactive shells.
If set (to a two-character string), the `%#' formatting sequence in the
normal users and the second character for the superuser.
If set, completion completes on an exact match even if a longer match is
possible.
If set, command listing displays only files in the path that are
executable.  Slow.
If set, the user is prompted before `rm *' is executed.
The string to print on the right-hand side of the screen (after
the command input) when the prompt is being displayed on the left.
It will automatically disappear and reappear as necessary, to ensure that
command input isn't obscured, and will appear only if the prompt,
command input, and itself will fit together on the first line.
the prompt and before the command input.
If the first word is set to a number, at most that many directory stack
entries are saved.
If the first word is set to a number, at most that many lines are saved.
If the second word is set to `merge', the history list is merged with
the existing history file instead of replacing it (if there is one) and
sorted by time stamp and the most recent events are retained.  (+)
note the variable meaning of `%R'.
The file in which the shell resides.  This is used in forking
shells to interpret files which have execute bits set, but
which are not executable by the system.  (See the description
(system-dependent) home of the shell.
The number of nested shells.
Reset to 1 in login shells.
The status returned by the last command, unless the variable
is set, and any error in a pipeline or a backquote expansion will be
propagated (this is the default
behavior, and the current
default). If it terminated
abnormally, then 0200 is added to the status.  Builtin commands
which fail return exit status `1', all other builtin commands
return status `0'.
Can be set to several different values to control symbolic link (`symlink')
resolution:
If set to `chase', whenever the current directory changes to a directory
containing a symbolic link, it is expanded to the real name of the directory
to which the link points.  This does not work for the user's home directory;
this is a bug.
If set to `ignore', the shell tries to construct a current directory
relative to the current directory before the link was crossed.
returns one to the original directory.  This affects only builtin commands
and filename completion.
If set to `expand', the shell tries to fix symbolic links by actually expanding
arguments which look like path names.  This affects any command, not just
builtins.  Unfortunately, this does not work for hard-to-recognize filenames,
such as those embedded in command options.  Expansion may be prevented by
quoting.  While this setting is usually the most convenient, it is sometimes
misleading and sometimes confusing when it fails to recognize an argument
which should be expanded.  A compromise is to use `ignore' and use the
Some examples are in order.  First, let's set up some play directories:
> cd ..; echo $cwd
> cd ..; echo $cwd
> cd ..; echo $cwd
> cd ..; echo $cwd
> cd ".."; echo $cwd
Note that `expand' expansion 1) works just like `ignore' for builtins
filenames are passed to non-builtin commands.
The version number of the shell in the format `R.VV.PP',
where `R' is the major release number, `VV' the current version
and `PP' the patchlevel.
after each command which takes more than that many CPU seconds.
If there is a second word, it is used as a format string for the output
format string:
%U
The time the process spent in user mode in cpu seconds.
%S
The time the process spent in kernel mode in cpu seconds.
%E
The elapsed (wall clock) time in seconds.
%P
%W
Number of times the process was swapped.
%X
The average amount in (shared) text space used in Kbytes.
%D
%K
The total space used (%X + %D) in Kbytes.
%M
The maximum memory the process had in use at any time in Kbytes.
%F
The number of major page faults (page needed to be brought from disk).
%R
The number of minor page faults.
%I
The number of input operations.
%O
The number of output operations.
%r
The number of socket messages received.
%s
The number of socket messages sent.
%k
The number of signals received.
%w
The number of voluntary context switches (waits).
%c
The number of involuntary context switches.
Only the first four sequences are supported on systems without BSD resource
limit functions.
The default time format is `%Uu %Ss %E %P %X+%Dk %I+%Oio %Fpf+%Ww' for
systems that support resource usage reporting and `%Uu %Ss %E %P' for
systems that do not.
available, but the following additional sequences are:
%Y
The number of system calls performed.
%Z
The number of pages which are zero-filled on demand.
%i
The number of times a process's resident set size was increased by the kernel.
%d
The number of times a process's resident set size was decreased by the kernel.
%l
The number of read system calls performed.
%m
The number of write system calls performed.
%p
The number of reads from raw disk devices.
%q
The number of writes to raw disk devices.
and the default time format is `%Uu %Ss %E %P %I+%Oio %Fpf+%Ww'.
Note that the CPU percentage can be higher than 100% on multi-processors.
The name of the tty, or empty if not attached to one.
The user's real user ID.
The user's login name.
If set, causes the words of each
command to be printed, after history substitution (if any).
list of options which were set at compile time.
Options which are set by default in the distribution are noted.
8b
The shell is eight bit clean; default
7b
The shell is not eight bit clean
wide
The shell is multibyte encoding clean (like UTF-8)
nls
The system's NLS is used; default for systems with NLS
lf
dl
nd
vi
dtr
Login shells drop DTR when exiting
bye
al
kan
Kanji is used if appropriate according to locale settings,
sm
hb
The `#!<program> <args>' convention is emulated when executing shell scripts
ng
rh
afs
The shell verifies your password with the kerberos server if local
An administrator may enter additional strings to indicate differences
in the local version.
If set, a screen flash is used rather than the audible bell.
If either the user is `any' all terminals are watched for the given user
and vice versa.
For example,
set watch = (george ttyd1 any console $user any)
reports activity of the user `george' on ttyd1, any user on the console, and
oneself (or a trespasser) on any terminal.
Logins and logouts are checked every 10 minutes by default, but the first
For example,
set watch = (1 any any)
are replaced by the given information:
%n
%a
%l
%M
from the local host.
%m
The hostname of the remote host up to the first `.'.
The full name is printed if it is an IP address or an X Window System display.
%M and %m are available on only systems that store the remote hostname in
If unset, `%n has %a %l from %m.' is used, or `%n has %a %l.' on systems
which don't store the remote hostname.
A list of non-alphanumeric characters to be considered part of a word by the
The pathname to a default editor.
Initialized to the name of the machine on which the shell
Initialized to the type of machine on which the shell
is running, as determined at compile time.  This variable is obsolete and
will be removed in a future version.
command looks for command documentation.
Gives the preferred character environment.
If set, only ctype character handling is changed.
file format; a colon-separated list of expressions of the form
variables with their associated defaults are:
no	0
Normal (non-filename) text
fi	0
Regular file
di	01;34
Directory
ln	01;36
Symbolic link
pi	33
Named pipe (FIFO)
so	01;35
Socket
do	01;35
Door
bd	01;33
Block device
cd	01;32
Character device
ex	01;32
Executable file
mi	(none)
Missing file (defaults to fi)
or	(none)
Orphaned symbolic link (defaults to ln)
lc	^[[
Left code
rc	m
Right code
ec	(none)
End code (replaces lc+no+rc)
You need to include only the variables you want to change from
the default.
File names can also be colorized based on filename extension.
to use, but less general.  The left, right and end codes are
provided so you don't have to type common parts over and over
again and to support weird terminals; you will generally not
need to change them at all unless your terminal does not use
ISO 6429 color sequences but a different system.
If your terminal does use ISO 6429 color codes, you can
most common commands are:
0
to restore default color
1
for brighter colors
4
for underlined text
5
for flashing text
30
for black foreground
31
for red foreground
32
for green foreground
33
for yellow (or brown) foreground
34
for blue foreground
35
for purple foreground
36
for cyan foreground
37
for white (or gray) foreground
40
for black background
41
for red background
42
for green background
43
for yellow (or brown) background
44
for blue background
45
for purple background
46
for cyan background
47
for white (or gray) background
Not all commands will work on all systems or display devices.
A few terminal programs do not recognize the default end code
properly.  If all text gets colorized after you do a directory
numerical codes for your standard fore- and background colors.
The machine type (microprocessor class or machine model), as determined at compile time.
The operating system, as determined at compile time.
A colon-separated list of directories in which to look for executables.
updated only after an actual directory change.
The host from which the user has logged in remotely, if this is the case and
the shell is able to determine it.  Set only if the shell was so compiled;
The vendor, as determined at compile time.
The pathname to a default full-screen editor.
Read first by every shell.
Read by login shells at logout.
Used to interpret shell scripts not starting with a `#'.
Temporary file for `<<'.
Source of home directories for `~name' substitutions.
The order in which startup files are read may differ if the shell was so
Programmable, interactive word completion and listing.
builtin commands.
An enhanced history mechanism.  Events in the history list are time-stamped.
the previously undocumented `#' event specifier and new modifiers
Enhanced directory parsing and directory stack handling.
builtin which uses them.
scheduled events, special aliases, automatic logout and terminal locking,
command timing and watching for logins and logouts.
Support for the Native Language System
OS variant features
New variables that make useful information easily available to the shell.
variables.
A new syntax for including useful information in the prompt string
and special prompts for loops and spelling correction
When a suspended command is restarted, the shell prints the directory
it started in if this is different from the current directory.  This can
be misleading (i.e., wrong) as the job may have changed directories internally.
of the form `a ; b ; c' are also not handled gracefully when stopping is
attempted.  If you suspend `b', the shell will then immediately execute
`c'.  This is especially noticeable if this expansion results from an
to a subshell, i.e., `( a ; b ; c )'.
Control over tty output after processes are started is primitive; perhaps
this will inspire someone to work on a good virtual terminal interface.
In a virtual terminal interface much more interesting things could be
done with output control.
Alias substitution is most often used to clumsily simulate shell procedures;
shell procedures should be provided rather than aliases.
Control structures should be parsed rather than being recognized as
built-in commands.  This would allow control commands to be placed anywhere,
to be combined with `|', and to be used with `&' and `;' metasyntax.
It should be possible to use the `:' modifiers on the output of command
substitutions.
The screen update for lines longer than the screen width is very poor
if the terminal cannot move the cursor up (i.e., terminal type `dumb').
Glob-patterns which do not use `?', `*' or `[]' or which use `{}' or `~'
are not negated correctly.
the expression is false and the command is not executed.
and does not handle control characters in filenames well.  It cannot be
interrupted.
Command substitution supports multiple commands and conditions, but not
help maintain and test tcsh, send mail to tcsh-request@mx.gw.com with the
text `subscribe tcsh' on a line by itself in the body.
In 1964, DEC produced the PDP-6.  The PDP-10 was a later re-implementation.  It
was re-christened the DECsystem-10 in 1970 or so when DEC brought out the
second model, the KI10.
TENEX was created at Bolt, Beranek & Newman (a Cambridge, Massachusetts
think tank) in
1972 as an experiment in demand-paged virtual memory operating systems.  They
built a new pager for the DEC PDP-10 and created the OS to go with it.  It was
extremely successful in academia.
In 1975, DEC brought out a new model of the PDP-10, the KL10; they intended to
have only a version of TENEX, which they had licensed from BBN, for the new
box.  They called their version TOPS-20 (their capitalization is trademarked).
A lot of TOPS-10 users (`The OPerating System for PDP-10') objected; thus DEC
found themselves supporting two incompatible systems on the same hardware--but
then there were 6 on the PDP-11!
TENEX, and TOPS-20 to version 3, had command completion
via a user-code-level subroutine library called ULTCMD.  With version 3, DEC
moved all that capability and more into the monitor (`kernel' for you Unix
types), accessed by the COMND% JSYS (`Jump to SYStem' instruction, the
supervisor call mechanism [are my IBM roots also showing?]).
The creator of tcsh was impressed by this feature and several others of TENEX
and TOPS-20, and created a version of csh which mimicked them.
The system limits argument lists to ARG_MAX characters.
The number of arguments to a command which involves filename expansion is
Command substitutions may substitute no more characters than are allowed in
an argument list.
substitutions on a single line to 20.
csh(1), emacs(1), ls(1), newgrp(1), sh(1), setpath(1), stty(1), su(1),
tset(1), vi(1), x(1), access(2), execve(2), fork(2), killpg(2),
pipe(2), setrlimit(2), sigvec(2), stat(2), umask(2), vfork(2), wait(2),
malloc(3), setlocale(3), tty(4), a.out(5), termcap(5), environ(7),
termio(7), Introduction to the C Shell
This manual documents tcsh 6.18.01 (Astron) 2012-02-14.
William Joy
J.E. Kulp, IIASA, Laxenburg, Austria
Job control and directory stack features
Ken Greer, HP Labs, 1981
File name completion
Mike Ellis, Fairchild, 1983
Paul Placeway, Ohio State CIS Dept., 1983-1993
Command line editor, prompt routines, new glob syntax and numerous fixes
and speedups
Karl Kleinpaste, CCI 1983-4
scheduled events, and the idea of the new prompt format
Rayan Zachariassen, University of Toronto, 1984
and speedups
Chris Kingsley, Caltech
Fast storage allocator routines
Chris Grevstad, TRW, 1987
Christos S. Zoulas, Cornell U. EE Dept., 1987-94
Ports to HPUX, SVR2 and SVR3, a SysV version of getwd.c, SHORT_STRINGS support
and a new version of sh.glob.c
James J Dempsey, BBN, and Paul Placeway, OSU, 1988
Daniel Long, NNSC, 1988
Patrick Wolfe, Kuck and Associates, Inc., 1988
David C Lawrence, Rensselaer Polytechnic Institute, 1989
Alec Wolman, DEC, 1989
Newlines in the prompt
Matt Landau, BBN, 1989
Ray Moody, Purdue Physics, 1989
Magic space bar history expansion
Mordechai ????, Intel, 1989
printprompt() fixes and additions
Kazuhiro Honda, Dept. of Computer Science, Keio University, 1989
Per Hedeland, Ellemtel, Sweden, 1990-
Various bugfixes, improvements and manual updates
Hans J. Albertsson (Sun Sweden)
Michael Bloom
Interrupt handling fixes
Michael Fine, Digital Equipment Corp
Extended key support
Eric Schnoebelen, Convex, 1990
save and restore of directory stack
Ron Flax, Apple, 1990
Dan Oscarsson, LTH Sweden, 1990
NLS support and simulated NLS support for non NLS sites, fixes
Johan Widen, SICS Sweden, 1990
Matt Day, Sanyo Icon, 1990
POSIX termio support, SysV limit fixes
Jaap Vermeulen, Sequent, 1990-91
Vi mode fixes, expand-line, window change fixes, Symmetry port
Martin Boyer, Institut de recherche d'Hydro-Quebec, 1991
the whole string from the beginning of the line to the cursor.
Scott Krotz, Motorola, 1991
Minix port
David Dawes, Sydney U. Australia, Physics Dept., 1991
SVR4 job control fixes
Jose Sousa, Interactive Systems Corp., 1991
Marc Horowitz, MIT, 1991
Bruce Sterling Woodcock, sterling@netcom.com, 1991-1995
various other portability changes and bug fixes
Jeff Fink, 1992
Harry C. Pulley, 1992
Coherent port
Andy Phillips, Mullard Space Science Lab U.K., 1992
VMS-POSIX port
Beto Appleton, IBM Corp., 1992
POSIX file tests, POSIX SIGHUP
Scott Bolte, Cray Computer Corp., 1992
CSOS port
Kaveh R. Ghazi, Rutgers University, 1992
Tek, m88k, Titan and Masscomp ports and fixes.  Added autoconf support.
Mark Linderman, Cornell University, 1992
Mika Liljeberg, liljeber@kruuna.Helsinki.FI, 1992
Linux port
Tim P. Starrin, NASA Langley Research Center Operations, 1993
Read-only variables
Dave Schweisguth, Yale University, 1993-4
New man page and tcsh.man2html
Larry Schwimmer, Stanford University, 1993
AFS and HESIOD patches
Luke Mewburn, RMIT University, 1994-6
Enhanced directory printing in prompt,
Edward Hutchins, Silicon Graphics Inc., 1996
Added implicit cd.
Martin Kraemer, 1997
Ported to Siemens Nixdorf EBCDIC machine
Amol Deshpande, Microsoft, 1997
and message catalog code to interface to Windows.
Taga Nayuta, 1998
Color ls additions.
Bryan Dunlap, Clayton Elwell, Karl Kleinpaste, Bob Manson, Steve Romig,
Diana Smetters, Bob Sutterfield, Mark Verber, Elizabeth Zwicky and all
the other people at Ohio State for suggestions and encouragement
All the people on the net, for putting up with,
reporting bugs in, and suggesting new additions to each and every version
Richard M. Alderson III, for writing the `T in tcsh' section
The
utility splits
into pieces using the patterns
If
is
a dash
reads from standard input.
The options are as follows:
Give created files names beginning with
The default is
Do not remove output files if an error occurs or a
or
signal is received.
Use
of decimal digits after the
to form the file name.
The default is 2.
Do not write the size of each output file to standard output as it is
created.
The
operands may be a combination of the following patterns:
Create a file containing the input from the current line to (but not including)
the next line matching the given basic regular expression.
An optional
from the line that matched may be specified.
Same as above but a file is not created for the output.
Create containing the input from the current line to (but not including)
the specified line number.
Repeat the previous pattern the specified number of times.
If it follows a line number pattern, a new file will be created for each
lines,
times.
The first line of the file is line number 1 for historic reasons.
After all the patterns have been processed, the remaining input data
(if there is any) will be written to a new file.
Requesting to split at a line before the current line number or past the
end of the file will result in an error.
The
and
environment variables affect the execution of
as described in
Split the
file
into one file for each section (up to 20):
Split standard input after the first 99 lines and every 100 lines thereafter:
The
utility conforms to
A
command appeared in PWB UNIX.
Input lines are limited to
(2048) bytes in length.
The
command manipulates Code Signing Requirement data.
It reads one requirement from a file or command arguments, converts it into
internal form, checks it, and then optionally outputs it in a different form.
The options are as follows:
Requests that the requirement read be written in binary form to the path given.
Specifies the input requirement. See "specifying requirements" below. This is
exactly the same format as is accepted by the -r and -R options of the codesign(1)
command.
Requests that the requirement read be written as text to standard output.
Increases the verbosity of output. Multiple instances of -v produce increasing levels
of commentary output.
In the first synopsis form,
reads a Code Requirement and writes it to standard output as canonical source text.
Note that with text input, this actually compiles the requirement into internal
form and then converts it back to text, giving you the system's view of the requirement code.
In the second synopsis form,
reads a Code Requirement and writes its binary representation to a file. This is the
same form produced by the SecRequirementCopyData API, and is readily acceptable
as input to Code Signing verification APIs. It can also be used as input to subsequent
invocations of
by passing the filename to the -r option.
The
argument (-r) can be given in various forms. A plain text argument is taken
to be a path to a file containing the requirement. This program will accept
both binary files containing properly compiled requirements code, and source files
that are automatically compiled for use.
An argument of "-" requests that the requirement(s) are read from standard input.
Again, standard input can contain either binary form or text.
Finally, an argument that begins with an equal sign "=" is taken as a literal
requirements source text, and is compiled accordingly for use.
To compile an explicit requirement program and write its binary form to file "output":
To display the requirement program embedded at offset 1234 of file "foo":
The
program exits 0 on success or 1 on failure. Errors in arguments yield exit code 2.
The
command first appeared in
Mac OS 10.5.0 .
[ options ] [ system | phone | "dir" ]
The
command is used to call up another system and act as a dial in
terminal.  It can also do simple file transfers with no error
checking.

takes a single argument, besides the options.  If the argument is the
string "dir" cu will make a direct connection to the port.  This may
only be used by users with write access to the port, as it permits
reprogramming the modem.

Otherwise, if the argument begins with a digit, it is taken to be a
phone number to call.  Otherwise, it is taken to be the name of a
system to call.  The
or
option may be used to name a system beginning with a digit, and the
or
option may be used to name a phone number that does not begin with a
digit.

locates a port to use in the UUCP configuration files.  If a simple
system name is given, it will select a port appropriate for that
system.  The
and
options may be used to control the port selection.

When a connection is made to the remote system,
forks into two processes.  One reads from the port and writes to the
terminal, while the other reads from the terminal and writes to the
port.

provides several commands that may be used during the conversation.
The commands all begin with an escape character, initially
(tilde).  The escape character is only recognized at the beginning of
a line.  To send an escape character to the remote system at the start
of a line, it must be entered twice.  All commands are either a single
character or a word beginning with
(percent sign).

recognizes the following commands:

Terminate the conversation.
Run command in a shell.  If command is empty, starts up a shell.
Run command, sending the standard output to the remote system.
Run command, taking the standard input from the remote system.
Run command, taking the standard input from the remote system and
sending the standard output to the remote system.
Send a break signal, if possible.
Change the local directory.
Send a file to the remote system.  This just dumps the file over the
communication line.  It is assumed that the remote system is expecting
it.
Receive a file from the remote system.  This prompts for the local
file name and for the remote command to execute to begin the file
transfer.  It continues accepting data until the contents of the
variable are seen.
Send a file to a remote Unix system.  This runs the appropriate
commands on the remote system.
Retrieve a file from a remote Unix system.  This runs the appropriate
commands on the remote system.
Set a
variable to the given value.  If value is not given, the variable is
set to
Set a
variable to
Suspend the cu session.  This is only supported on some systems.  On
systems for which ^Z may be used to suspend a job, 
will also suspend the session.
List all the variables and their values.
List all commands.

also supports several variables.  They may be listed with the
command, and set with the
or
commands.

The escape character.  Initially
(tilde).
If this variable is true,
will delay for a second after recognizing the escape character before
printing the name of the local system.  The default is true.
The list of characters which are considered to finish a line.  The
escape character is only recognized after one of these is seen.  The
default is carriage return, ^U, ^C, ^O, ^D, ^S, ^Q, ^R.
Whether to transfer binary data when sending a file.  If this is
false, then newlines in the file being sent are converted to carriage
returns.  The default is false.
A string used before sending a binary character in a file transfer, if
the
variable is true.  The default is ^V.
Whether to check file transfers by examining what the remote system
echoes back.  This probably doesn't work very well.  The default is
false.
The character to look for after sending each line in a file.  The
default is carriage return.
The timeout to use, in seconds, when looking for a character, either
when doing echo checking or when looking for the
character.  The default is 30.
The character to use delete a line if the echo check fails.  The
default is ^U.
The number of times to resend a line if the echo check continues to
fail.  The default is 10.
The string to write after sending a file with the
command.  The default is ^D.
The string to look for when receiving a file with the
command.  The default is $, which is intended to be a typical shell
prompt.
Whether to print accumulated information during a file transfer.  The
default is true.
The following options may be given to
Use even parity.
Use odd parity.
Use no parity.  No parity is also used if both
and
are given.
Echo characters locally (half-duplex mode).
Set the escape character.  Initially
(tilde).  To eliminate the escape character, use
The system to call.
The phone number to call.
Name the port to use.
Equivalent to
Name the line to use by giving a device name.  This may be used to
dial out on ports that are not listed in the UUCP configuration files.
Write access to the device is required.
The speed (baud rate) to use.
Where # is a number, equivalent to
Prompt for the phone number to use.
Enter debugging mode.  Equivalent to
Turn on particular debugging types.  The following types are
recognized: abnormal, chat, handshake, uucp-proto, proto, port,
config, spooldir, execute, incoming, outgoing.  Only abnormal, chat,
handshake, port, config, incoming and outgoing are meaningful for

Multiple types may be given, separated by commas, and the
option may appear multiple times.  A number may also be given, which
will turn on that many types from the foregoing list; for example,
is equivalent to
may be used to turn on all debugging options.
Set configuration file to use.  This option may not be available,
depending upon how
was compiled.
Report version information and exit.
Print a help message and exit.
This program does not work very well.
Ian Lance Taylor
<ian@airs.com>
displays information about the curl and libcurl installation.
Displays the built-in path to the CA cert bundle this libcurl uses.
Displays the compiler used to build libcurl.
Set of compiler options (CFLAGS) to use when compiling files that use
libcurl. Currently that is only the include path to the curl include files.
Specify the oldest possible libcurl version string you want, and this
script will return 0 if the current installation is new enough or it
returns 1 and outputs a text saying that the current version is not new
enough. (Added in 7.15.4)
Displays the arguments given to configure when building curl.
Lists what particular main features the installed libcurl was built with. At
the time of writing, this list may include SSL, KRB4 or IPv6. Do not assume
any particular order. The keywords will be separated by newlines. There may be
none, one, or several keywords in the list.
Displays the available options.
Shows the complete set of libs and other linker options you will need in order
to link your application with libcurl.
This is the prefix used when libcurl was installed. Libcurl is then installed
on. The prefix is set with "configure --prefix".
Lists what particular protocols the installed libcurl was built to support. At
the time of writing, this list may include HTTP, HTTPS, FTP, FTPS, FILE,
TELNET, LDAP, DICT. Do not assume any particular order. The protocols will
be listed using uppercase and are separated by newlines. There may be none,
one, or several protocols in the list. (Added in 7.13.0)
Shows the complete set of libs and other linker options you will need in order
to link your application with libcurl statically. (Added in 7.17.1)
Outputs version information about the installed libcurl.
Outputs version information about the installed libcurl, in numerical mode.
This outputs the version number, in hexadecimal, with 8 bits for each part;
major, minor, patch. So that libcurl 7.7.4 would appear as 070704 and libcurl
12.13.14 would appear as 0c0d0e... Note that the initial zero might be
omitted. (This option was broken in the 7.15.0 release.)
What linker options do I need when I link with libcurl?

  $ curl-config --libs

What compiler options do I need when I compile using libcurl functions?

  $ curl-config --cflags

How do I know if libcurl was built with SSL support?

  $ curl-config --feature | grep SSL

What's the installed libcurl version?

  $ curl-config --version

How do I build a single file with a one-line command?

  $ `curl-config --cc --cflags` -o example example.c `curl-config --libs`
is a tool to transfer data from or to a server, using one of the supported
protocols (DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP,
LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET
and TFTP). The command is designed to work without user interaction.

curl offers a busload of useful tricks like proxy support, user
authentication, FTP upload, HTTP post, SSL connections, cookies, file transfer
resume, Metalink, and more. As you will see below, the number of features will
make your head spin!

curl is powered by libcurl for all transfer-related features. See
The URL syntax is protocol-dependent. You'll find a detailed description in
RFC 3986.

You can specify multiple URLs or parts of URLs by writing part sets within
braces as in:


or you can get sequences of alphanumeric series by using [] as in:




Nested sequences are not supported, but you can use several ones next to each
other:


You can specify any amount of URLs on the command line. They will be fetched
in a sequential manner in the specified order.

You can specify a step counter for the ranges to get every Nth number or
letter:



When using [] or {} sequences when invoked from a command line prompt, you
probably have to put the full URL within double quotes to avoid the shell from
interfering with it. This also goes for other characters treated special, like
for example '&', '?' and '*'.

Provide the IPv6 zone index in the URL with an escaped percentage sign and the
interface name. Like in


protocol you might want. It will then default to HTTP but try other protocols
based on often-used host name prefixes. For example, for host names starting
with "ftp." curl will assume you want to speak FTP.

curl will do its best to use what you pass to it as a URL. It is not trying to
validate it as a syntactically correct URL by any means but is instead

curl will attempt to re-use connections for multiple file transfers, so that
handshakes. This improves speed. Of course this is only done on files
specified on a single command line and cannot be used between separate curl
invokes.
curl normally displays a progress meter during operations, indicating the
amount of transferred data, transfer speeds and estimated time left, etc.

curl displays this data to the terminal by default, so if you invoke curl to
do an operation and it is about to write data to the terminal, it
mixing progress meter and response data.

If you want a progress meter for HTTP POST or PUT requests, you need to
redirect the response output to a file, using shell redirect (>), -o [file] or
similar.

It is not the same case for FTP upload as that operation does not spit out
any response data to the terminal.

friend.
Options start with one or two dashes. Many of the options require an
additional value next to them.

The short "single-dash" form of the options, -d for example, may be used with
or without a space between it and its value, although a space is a recommended
separator. The long "double-dash" form, --data for example, requires a space
between it and its value.

Short version options that don't need any additional values can be used
immediately next to each other, like for example you can specify all the
options -O, -L and -v at once as -OLv.

but prefix it with "no-". However, in this list we mostly only list and show
the --option version of them. (This concept with --no options was added in
same command line option.)
Make curl display progress as a simple progress bar instead of the standard,
more informational, meter.
Tells curl to use a separate operation for the following URL and associated
options. This allows you to send several URL requests, each with their own
specific options, for example, such as different user names or custom requests
for each. (Added in 7.36.0)
(HTTP) Tells curl to use HTTP version 1.0 instead of using its internally
preferred: HTTP 1.1.
(HTTP) Tells curl to use HTTP version 1.1. This is the internal default
version. (Added in 7.33.0)
(HTTP) Tells curl to issue its requests using HTTP 2. This requires that the
underlying libcurl was built to support it. (Added in 7.33.0)
Disable the NPN TLS extension. NPN is enabled by default if libcurl was built
with an SSL library that supports NPN. NPN is used by a libcurl that supports
HTTP 2 to negotiate HTTP 2 support with the server during https sessions.

(Added in 7.36.0)
Disable the ALPN TLS extension. ALPN is enabled by default if libcurl was built
with an SSL library that supports ALPN. ALPN is used by a libcurl that supports
HTTP 2 to negotiate HTTP 2 support with the server during https sessions.

(Added in 7.36.0)
(SSL)
Forces curl to use TLS version 1.x when negotiating with a remote TLS server.
control the TLS version more precisely (if the SSL backend in use supports such
a level of control).
(SSL) Forces curl to use SSL version 2 when negotiating with a remote SSL
server. Sometimes curl is built without SSLv2 support. SSLv2 is widely
considered insecure.
(SSL) Forces curl to use SSL version 3 when negotiating with a remote SSL
server. Sometimes curl is built without SSLv3 support.
This option tells curl to resolve names to IPv4 addresses only, and not for
example try IPv6.
This option tells curl to resolve names to IPv6 addresses only, and not for
example try IPv4.
instead of overwriting it. If the remote file doesn't exist, it will be
created.  Note that this flag is ignored by some SFTP servers (including
OpenSSH).
(HTTP) Specify the User-Agent string to send to the HTTP server. Some badly
the string, surround the string with single quote marks. This can also be set

If this option is used several times, the last one will be used.
(HTTP) Tells curl to figure out authentication method by itself, and use the
most secure one the remote site claims to support. This is done by first
doing a request and checking the response-headers, thus possibly inducing an
extra network round-trip. This is used instead of setting a specific

Note that using --anyauth is not recommended if you do uploads from stdin,
since it may require data to be sent twice and then the client must be able to
rewind. If the need should arise when uploading from stdin, the upload
operation will fail.
(HTTP) Pass the data to the HTTP server as a cookie. It is supposedly the data
previously received from the server in a "Set-Cookie:" line.  The data should
be in the format "NAME1=VALUE1; NAME2=VALUE2".

If no '=' symbol is used in the line, it is treated as a filename to use to
read previously stored cookie lines from, which should be used in this session
if they match. Using this method also activates the "cookie parser" which will
make curl record incoming cookies too, which may be handy if you're using this
cookie file format.

option.

If this option is used several times, the last one will be used.
an URL that ends with ";type=A". This option causes data sent to stdout to be
in text mode for win32 systems.
(HTTP) Tells curl to use HTTP Basic authentication with the remote host. This
is the default and this option is usually pointless, unless you use it to
override a previously set option that sets a different authentication method


(HTTP) Specify to which file you want curl to write all cookies after a
completed operation. Curl writes all cookies previously read from a specified
file as well as all cookies received from remote server(s). If no cookies are
known, no data will be written. The file will be written using the Netscape
cookie file format. If you set the file name to a single dash, "-", the
cookies will be written to stdout.

This command line option will activate the cookie engine that makes curl

If the cookie jar can't be created or written to, the whole curl operation
won't fail or even report an error clearly. Using -v will get a warning
displayed, but that is the only visible feedback you get about this possibly
lethal situation.

If this option is used several times, the last specified file name will be
used.
is the exact number of bytes that will be skipped, counting from the beginning
of the source file before it is transferred to the destination.  If used with
uploads, the FTP server command SIZE will not be used by curl.


If this option is used several times, the last one will be used.
(SSL) Specifies which ciphers to use in the connection. The list of ciphers
must specify valid ciphers. Read up on SSL cipher list details on this URL:

NSS ciphers are done differently than OpenSSL and GnuTLS. The full list of NSS
ciphers is in the NSSCipherSuite entry at this URL:

If this option is used several times, the last one will be used.
(HTTP) Request a compressed response using one of the algorithms curl
supports, and save the uncompressed document.  If this option is used and the
server sends an unsupported encoding, curl will report an error.
Maximum time in seconds that you allow curl's connection to take.  This only
limits the connection phase, so if curl connects within the given period it
will continue - if not it will exit.  Since version 7.32.0, this option
accepts decimal values.


If this option is used several times, the last one will be used.
necessary local directory hierarchy as needed. This option creates the dirs
uses no dir or if the dirs it mentions already exist, no dir will be created.

To create remote directories when using FTP or SFTP, try

(SMTP added in 7.40.0)
List that may specify peer certificates that are to be considered revoked.

If this option is used several times, the last one will be used.

(Added in 7.19.7)
(HTTP) Sends the specified data in a POST request to the HTTP server, in the
same way that a browser does when a user has filled in an HTML form and
presses the submit button. This will cause curl to pass the data to the server

the same but does not have a special interpretation of the @ character. To

If any of these options is used more than once on the same command line, the
data pieces specified will be merged together with a separating
&-symbol. Thus, using '-d name=daniel -d skill=lousy' would generate a post

If you start the data with the letter @, the rest should be a file name to
read the data from, or - if you want curl to read the data from
stdin. Multiple files can also be specified. Posting data from a file
told to read from a file like that, carriage returns and newlines will be
stripped out. If you don't want the @ character to have a special
Write the protocol headers to the specified file.

This option is handy to use when you want to store the headers that an HTTP
site sends to you. Cookies from the headers could then be read in a second

When used in FTP, the FTP server response lines are considered being "headers"
and thus are saved there.

If this option is used several times, the last one will be used.
(HTTP) This posts data exactly as specified with no extra processing
whatsoever.

If you start the data with the letter @, the rest should be a filename.  Data
and carriage returns are preserved and conversions are never done.

If this option is used several times, the ones following the first will append
(Added in 7.43.0)
(HTTP) This posts data, similar to the other --data options with the exception
that this performs URL-encoding. (Added in 7.18.0)

by a separator and a content specification. The <data> part can be passed to
curl using one of the following syntaxes:
This will make curl URL-encode the content and pass that on. Just be careful
so that the content doesn't contain any = or @ symbols, as that will then make
the syntax match one of the other cases below!
This will make curl URL-encode the content and pass that on. The preceding =
symbol is not included in the data.
This will make curl URL-encode the content part and pass that on. Note that
the name part is expected to be URL-encoded already.
This will make curl load data from the given file (including any newlines),
URL-encode that data and pass it on in the POST.
This will make curl load data from the given file (including any newlines),
URL-encode that data and pass it on in the POST. The name part gets an equal
name is expected to be URL-encoded already.
Don't allow any delegation.
Delegates if and only if the OK-AS-DELEGATE flag is set in the Kerberos
service ticket, which is a matter of realm policy.
Unconditionally allow the server to delegate.
(HTTP) Enables HTTP Digest authentication. This is an authentication scheme
that prevents the password from being sent over the wire in clear text. Use
related options.

If this option is used several times, only the first one is used.
(FTP) Tell curl to disable the use of the EPRT and LPRT commands when doing
active FTP transfers. Curl will normally always first attempt to use EPRT,
then LPRT before using PORT, but with this option, it will use PORT right
away. EPRT and LPRT are extensions to the original FTP protocol, and may not
work on all servers, but they enable more functionality in a better way than
the traditional PORT command.


Disabling EPRT only changes the active behavior. If you want to switch to
(FTP) Tell curl to disable the use of the EPSV command when doing passive FTP
transfers. Curl will normally always first attempt to use EPSV before PASV,
but with this option, it will not try using EPSV.


Disabling EPSV only changes the passive behavior. If you want to switch to
Tell curl to send outgoing DNS requests through <interface>. This option
supplied string must be an interface name (not an address).

This option requires that libcurl was built with a resolver backend that
supports this operation. The c-ares backend is the only such one. (Added in
7.33.0)
Tell curl to bind to <ip-address> when making IPv4 DNS requests, so that
the DNS requests originate from this address. The argument should be a
single IPv4 address.

This option requires that libcurl was built with a resolver backend that
supports this operation. The c-ares backend is the only such one.  (Added in
7.33.0)
Tell curl to bind to <ip-address> when making IPv6 DNS requests, so that
the DNS requests originate from this address. The argument should be a
single IPv6 address.

This option requires that libcurl was built with a resolver backend that
supports this operation. The c-ares backend is the only such one.  (Added in
7.33.0)
Set the list of DNS servers to be used instead of the system default.
The list of IP addresses should be separated with commas. Port numbers
address.

This option requires that libcurl was built with a resolver backend that
supports this operation. The c-ares backend is the only such one.  (Added in
7.33.0)
(HTTP) Sends the "Referrer Page" information to the HTTP server. This can also
automatically set the previous URL when it follows a Location: header. The

If this option is used several times, the last one will be used.
(SSL) Tells curl to use the specified client certificate file when getting a
file with HTTPS, FTPS or another SSL-based protocol. The certificate must be
in PKCS#12 format if using Secure Transport, or PEM format if using any other
engine.  If the optional password isn't specified, it will be queried

If curl is built against the NSS SSL library then this option can tell
curl the nickname of the certificate to use within the NSS database defined
NSS PEM PKCS#11 module (libnsspem.so) is available then PEM files may be
loaded. If you want to use a file from the current directory, please precede

(iOS and Mac OS X only) If curl is built against Secure Transport, then the
system or user keychain, or the path to a PKCS#12-encoded certificate and
private key. If you want to use a file from the current directory, please

If this option is used several times, the last one will be used.
Select the OpenSSL crypto engine to use for cipher
engines. Note that not all (or none) of the engines may be available at
run-time.
(RISC OS ONLY) Sets a range of environment variables, using the names the
after having run curl.
(SSL) Specify the path name to the Entropy Gathering Daemon socket. The socket
is used to seed the random engine for SSL connections. See also the
(SSL) Tells curl what certificate type the provided certificate is in. PEM,
DER and ENG are recognized types.  If not specified, PEM is assumed.

If this option is used several times, the last one will be used.
(SSL) Tells curl to use the specified certificate file to verify the peer. The
file may contain multiple CA certificates. The certificate(s) must be in PEM
format. Normally curl is built to use a default file for this, so this option
is typically used to alter that default file.

curl recognizes the environment variable named 'CURL_CA_BUNDLE' if it is
set, and uses the given path as a path to a CA cert bundle. This option
overrides that variable.

The windows version of curl will automatically look for a CA certs file named
Current Working Directory, or in any folder along your PATH.

If curl is built against the NSS SSL library, the NSS PEM PKCS#11 module
(libnsspem.so) needs to be available for this option to work properly.

If this option is used several times, the last one will be used.
(SSL) Tells curl to use the specified certificate directory to verify the
peer. Multiple paths can be provided by separating them with ":" (e.g.
built against OpenSSL, the directory must have been processed using the
OpenSSL-powered curl to make SSL-connections much more efficiently than using

If this option is set, the default capath value will be ignored, and if it is
used several times, the last one will be used.
(SSL) Tells curl to use the specified public key file to verify the peer. The
file must contain a single public key in PEM or DER format.

When negotiating a TLS or SSL connection, the server sends a certificate
indicating its identity. A public key is extracted from this certificate and
if it does not exactly match the public key provided to this option, curl will
abort the connection before sending or receiving any data.

Added in 7.39.0 for OpenSSL, GnuTLS and GSKit. Added in 7.43.0 for NSS and

If this option is used several times, the last one will be used.
(SSL) Tells curl to verify the status of the server certificate by using the
Certificate Status Request (aka. OCSP stapling) TLS extension.

If this option is enabled and the server sends an invalid (e.g. expired)
response, if the response suggests that the server certificate has been revoked,
or no response at all is received, the verification fails.

This is currently only implemented in the OpenSSL, GnuTLS and NSS backends.
(Added in 7.41.0)

(SSL) Tells curl to use false start during the TLS handshake. False start is a
mode where a TLS client will start sending application data before verifying
the server's Finished message, thus saving a round trip when performing a full
handshake.

This is currently only implemented in the NSS and Secure Transport (on iOS 7.0
or later, or OS X 10.9 or later) backends.
(Added in 7.42.0)
(HTTP) Fail silently (no output at all) on server errors. This is mostly done
to better enable scripts etc to better deal with failed attempts. In normal
cases when an HTTP server fails to deliver a document, it returns an HTML
document stating so (which often also describes why and more). This flag will
prevent curl from outputting that and return error 22.

This method is not fail-safe and there are occasions where non-successful
response codes will slip through, especially when authentication is involved
(response codes 401 and 407).
(HTTP) This lets curl emulate a filled-in form in which a user has pressed the
submit button. This causes curl to POST data using the Content-Type
files etc. To force the 'content' part to be a file, prefix the file name with
an @ sign. To just get the content part from a file, prefix the file name with
the symbol <. The difference between @ and < is then that @ makes a file get
attached in the post as a file upload, while the < makes a text field and just
get the contents for that text field from a file.

Example, to send your password file to the server, where
input:


To read content from stdin instead of a file, use - as the filename. This goes
for both @ and < constructs.

You can also tell curl what Content-Type to use by using 'type=', in a manner
similar to:


or


You can also explicitly change the name field of a file upload part by setting
filename=, like this:




or


or backslash within the filename must be escaped by backslash.

See further examples and details in the MANUAL.

This option can be used multiple times.
(FTP) When an FTP server asks for "account data" after user name and password
has been provided, this data is sent off using the ACCT command. (Added in
7.13.0)

If this option is used several times, the last one will be used.
(FTP) If authenticating with the USER and PASS commands fails, send this
command.  When connecting to Tumbleweed's Secure Transport server over FTPS
using a client certificate, using "SITE AUTH" will tell the server to retrieve
the username from the certificate. (Added in 7.15.5)
currently exist on the server, the standard behavior of curl is to
fail. Using this option, curl will instead attempt to create missing
directories.
(FTP) Control what method curl should use to reach a file on an FTP(S)
server. The method argument should be one of the following alternatives:
curl does a single CWD operation for each path part in the given URL. For deep
hierarchies this means very many commands. This is how RFC 1738 says it should
be done. This is the default but the slowest behavior.
curl does no CWD at all. curl will do SIZE, RETR, STOR etc and give a full
path to the server for all these commands. This is the fastest behavior.
curl does one CWD with the full target directory and then operates on the file
compliant than 'nocwd' but without the full penalty of 'multicwd'.
(Added in 7.15.1)
(FTP) Use passive mode for the data connection. Passive is the internal default
behavior, but using this option can be used to override a previous

If this option is used several times, only the first one is used. Undoing an
enforced passive really isn't doable but you must then instead enforce the

Passive mode means that curl will try the EPSV command first and then PASV,
(FTP) Tell curl to not use the IP address the server suggests in its response
to curl's PASV command when curl connects the data connection. Instead curl
will re-use the same IP address it already uses for the control
connection. (Added in 7.14.2)

This option has no effect if PORT, EPRT or EPSV is used instead of PASV.
(FTP) Tell curl to send a PRET command before PASV (and EPSV). Certain
FTP servers, mainly drftpd, require this non-standard command for
directory listings as well as up and downloads in PASV mode.
(Added in 7.20.x)
(FTP) Use CCC (Clear Command Channel)
control channel communication will be unencrypted. This allows
NAT routers to follow the FTP transaction. The default mode is
(Added in 7.16.1)
(FTP) Use CCC (Clear Command Channel)
Sets the CCC mode. The passive mode will not initiate the shutdown, but
instead wait for the server to do it, and will not reply to the
shutdown from the server. The active mode initiates the shutdown and
waits for a reply from the server.
(Added in 7.16.2)
authentication, but non-encrypted data transfers for efficiency.  Fails the
that can still be used but will be removed in a future version.
This option switches off the "URL globbing parser". When you set this option,
you can specify URLs that contain the letters {}[] without having them being
interpreted by curl itself. Note that these letters are not normal legal URL
contents but they should be encoded according to the URI standard.
request instead of the POST request that otherwise would be used. The data
will be appended to the URL with a '?' separator.

If used in combination with -I, the POST data will instead be appended to the
URL with a HEAD request.

If this option is used several times, only the first one is used. This is
because undoing a GET doesn't make sense, but you should then instead enforce
the alternative method you prefer.
(HTTP) Extra header to include in the request when sending HTTP to a
server. You may specify any number of extra headers. Note that if you should
add a custom header that has the same name as one of the internal ones curl
would use, your externally set header will be used instead of the internal
one. This allows you to make even trickier stuff than curl would normally
do. You should not replace internally set headers without knowing perfectly
well what you're doing. Remove an internal header by giving a replacement
send the custom header with no-value then its header must be terminated with a

content: do not add newlines or carriage returns, they will only mess things up
for you.


intended for a proxy.

Example:


can lead to the header being sent to other hosts than the original host, so
sensitive headers should be used with caution combined with following
redirects.

be the 128 bit MD5 checksum of the remote host's public key, curl will refuse
the connection with the host unless the md5sums match. (Added in 7.17.1)
(HTTP)
Ignore the Content-Length header. This is particularly useful for servers
running Apache 1.x, which will report incorrect Content-Length for files
larger than 2 gigabytes.
(HTTP) Include the HTTP-header in the output. The HTTP-header includes things
like server-name, date of the document, HTTP-version and more...
Fetch the HTTP-header only! HTTP-servers feature the command HEAD
which this uses to get nothing but the header of a document. When used
on an FTP or FILE file, curl displays the file size and last modification
time only.
Perform an operation using a specified interface. You can enter interface
name, IP address or host name. An example could look like:


If this option is used several times, the last one will be used.
(HTTP) When curl is told to read cookies from a given file, this option will
make it discard all "session cookies". This will basically have the same effect
as if a new session is started. Typical browsers always discard session
cookies when they're closed down.
server-specified Content-Disposition filename instead of extracting a filename
from the URL.

There's no attempt to decode %-sequences (yet) in the provided file name, so
this option may provide you with rather unexpected file names.
(SSL) This option explicitly allows curl to perform "insecure" SSL connections
and transfers. All SSL connections are attempted to be made secure by using
the CA certificate bundle installed by default. This makes all connections

See this online resource for further details:
Specify which config file to read curl arguments from. The config file is a
text file in which command line arguments can be written which then will be
used as if they were written on the actual command line.

Options and their parameters must be specified on the same config file line,
separated by whitespace, colon, or the equals sign. Long option names can
optionally be given in the config file without the initial double dashes and
if so, the colon or equals characters can be used as separators. If the option
is specified with one or two dashes, there can be no colon or equals character
between the option and its parameter.

If the parameter is to contain whitespace, the parameter must be enclosed
within quotes. Within double quotes, the following escape sequences are
letter is ignored. If the first column of a config line is a '#' character,
the rest of the line will be treated as a comment. Only write one option per
physical line in the config file.

Specify the filename to -K, --config as '-' to make curl read the file from
stdin.

Note that to be able to specify a URL in the config file, you need to specify
line. So, it could look similar to this:


config file and uses it if found. The default config file is checked for in
the following places in this order:

1) curl tries to find the "home dir": It first checks for the CURL_HOME and
then the HOME environment variables. Failing that, it uses getpwuid() on
Unix-like systems (which returns the home dir given the current user in your
system). On Windows, it then checks for the APPDATA variable, or as a last

2) On windows, if there is no _curlrc file in the home dir, it checks for one
in the same dir the curl executable is placed. On Unix-like systems, it will
simply try to load .curlrc from the determined home dir.

# --- Example file ---
# this is a comment
url = "curl.haxx.se"
output = "curlhere.html"

# and fetch another URL too
-O
# --- End of example file ---

This option can be used multiple times to load multiple config files.
This option sets the time a connection needs to remain idle before sending
keepalive probes and the time between individual keepalive probes. It is
currently effective on operating systems offering the TCP_KEEPIDLE and
TCP_KEEPINTVL socket options (meaning Linux, recent AIX, HP-UX and more). This

If this option is used several times, the last one will be used. If
unspecified, the option defaults to 60 seconds.
separate file. For SSH, if not specified, curl tries the following candidates

If this option is used several times, the last one will be used.
private key is. DER, PEM, and ENG are supported. If not specified, PEM is
assumed.

If this option is used several times, the last one will be used.
(FTP) Enable Kerberos authentication and use. The level must be entered and
should be one of 'clear', 'safe', 'confidential', or 'private'. Should you use
a level that is not one of these, 'private' will instead be used.

This option requires a library built with kerberos4 support. This is not

If this option is used several times, the last one will be used.
(FTP)
When listing an FTP directory, this switch forces a name-only view. This is
especially useful if the user wants to machine-parse the contents of an FTP
directory since the normal directory view doesn't use a standard look or
format. When used like this, the option causes a NLST command to be sent to
the server instead of LIST.

Note: Some FTP servers list only files in their response to NLST; they do not
include sub-directories and symbolic links.

(POP3)
When retrieving a specific email from POP3, this switch forces a LIST command
to be performed instead of RETR. This is particularly useful if the user wants
to see if a specific message id exists on the server and what size it is.

to send an UIDL command instead, so the user may use the email's unique
identifier rather than it's message id to make the request. (Added in 7.21.5)
different location (indicated with a Location: header and a 3XX response code),
this option will make curl redo the request on the new place. If used together
will be shown. When authentication is used, curl only sends its credentials to
the initial host. If a redirect takes curl to a different host, it won't be
to change this. You can limit the amount of redirects to follow by using the

When curl follows a redirect and the request is not a plain GET (for example
POST or PUT), it will do the following request with a GET if the HTTP response
was 301, 302, or 303. If the response code was any other 3xx code, curl will
re-send the following request using the same unmodified method.

You can tell curl to not change the non-GET request method to GET after a 30x
Append this option to any ordinary curl command line, and you will get a
libcurl-using C source code written to the file that does the equivalent
of what your command-line operation does!

If this option is used several times, the last given file name will be
used. (Added in 7.16.1)
Specify the maximum transfer rate you want curl to use - for both downloads
and uploads. This feature is useful if you have a limited pipe and you'd like
your transfer not to use your entire bandwidth. To make it slower than it
otherwise would be.

Appending 'k' or 'K' will count the number as kilobytes, 'm' or M' makes it
megabytes, while 'g' or 'G' makes it gigabytes. Examples: 200K, 3m and 1G.

The given rate is the average speed counted during the entire transfer. It
means that curl might use higher transfer speeds in short bursts, but over
time it uses no more than the given rate.

precedence and might cripple the rate-limiting slightly, to help keeping the
speed-limit logic working.

If this option is used several times, the last one will be used.
Set a preferred number or range of local port numbers to use for the
connection(s).  Note that port numbers by nature are a scarce resource that
will be busy at times so setting this range to something too narrow might
cause unnecessary connection setup failures. (Added in 7.15.2)
password to all hosts that the site may redirect to. This may or may not
introduce a security breach if the site redirects you to a site to which
you'll send your authentication info (which is plaintext in the case of HTTP
Basic authentication).
Maximum time in seconds that you allow the whole operation to take.  This is
useful for preventing your batch jobs from hanging for hours due to slow
networks or links going down.  Since 7.32.0, this option accepts decimal
values, but the actual timeout will decrease in accuracy as the specified
option.

If this option is used several times, the last one will be used.
Specify the login options to use during server authentication.

You can use the login options to specify protocol specific options that may
be used during authentication. At present only IMAP, POP3 and SMTP support
login options. For more information about the login options please see
RFC 2384, RFC 5092 and IETF draft draft-earhart-url-smtp-00.txt (Added in
7.34.0).

If this option is used several times, the last one will be used.
(SMTP) Specify a single address. This will be used to specify the
authentication address (identity) of a submitted message that is being relayed
to another server.

(Added in 7.25.0)
(SMTP) Specify a single address that the given mail should get sent from.

(Added in 7.20.0)
Specify the maximum size (in bytes) of a file to download. If the file
requested is larger than this value, the transfer will not start and curl will
return with exit code 63.

files this option has no effect even if the file transfer ends up being larger
than this given limit. This concerns both FTP and HTTP transfers.
(SMTP) Specify a single address, user name or mailing list name.

When performing a mail transfer, the recipient should specify a valid email
address to send the mail to. (Added in 7.20.0)

When performing an address verification (VRFY command), the recipient should be
specified as the user name or user name and domain (as per Section 3.5 of
RFC5321). (Added in 7.34.0)

When performing a mailing list expand (EXPN command), the recipient should be
specified using the mailing list name, such as "Friends" or "London-Office".
(Added in 7.34.0)
is used, this option can be used to prevent curl from following redirections
option to -1 to make it limitless.

If this option is used several times, the last one will be used.
This option can tell curl to parse and process a given URI as Metalink file
(both version 3 and 4 (RFC 5854) are supported) and make use of the mirrors
listed within for failover if there are errors (such as the file or server not
being available). It will also verify the hash of the file after the download
completes. The Metalink file itself is downloaded and processed in memory and
not stored in the local file system.

Example to use a remote Metalink file:


To use a Metalink file in the local file system, use FILE protocol


Please note that if FILE protocol is disabled, there is no way to use
a local Metalink file at the time of this writing. Also note that if
ignored. This is because including headers in the response will break
Metalink parser and if the headers are included in the file described
in Metalink file, hash check will fail.

(Added in 7.27.0, if built against the libmetalink library.)
home directory for login name and password. This is typically used for FTP on
Unix. If used with HTTP, curl will enable user authentication. See
complain if that file doesn't have the right permissions (it should not be
either world- or group-readable). The environment variable "HOME" is used to
find the home directory.


Disables the buffering of the output stream. In normal work situations, curl
will use a standard buffered output stream that will have the effect that it
will output the data in chunks, not necessarily exactly when the data arrives.
Using this option will disable that buffering.

Note that this is the negated option name documented. You can thus use
(absolute or relative) to the netrc file that Curl should use.
You can only specify one netrc file per invocation. If several
(Added in 7.21.5)



(HTTP) Enables Negotiate (SPNEGO) authentication.

If you want to enable Negotiate (SPNEGO) for proxy authentication, then use


activate the authentication code properly. Sending a '-u :' is enough as the

If this option is used several times, only the first one is used.
Disables the use of keepalive messages on the TCP connection, as by default
curl enables them.

Note that this is the negated option name documented. You can thus use
(SSL) Disable curl's use of SSL session-ID caching.  By default all transfers
are done using the cache. Note that while nothing should ever get hurt by
attempting to reuse SSL session-IDs, there seem to be broken SSL
implementations in the wild that may require you to disable this in order for
you to succeed. (Added in 7.16.0)

Note that this is the negated option name documented. You can thus use
Comma-separated list of hosts which do not use a proxy, if one is specified.
The only wildcard is a single * character, which matches all hosts, and
effectively disables the proxy. Each name in this list is matched as either
a domain which contains the hostname, or the hostname itself. For example,
local.com would match local.com, local.com:80, and www.local.com, but not
www.notlocal.com.  (Added in 7.19.4).
(HTTP) Enables NTLM authentication. The NTLM authentication method was
designed by Microsoft and is used by IIS web servers. It is a proprietary
protocol, reverse-engineered by clever people and implemented in curl based
on their efforts. This kind of behavior should not be endorsed, you should
encourage everyone who uses NTLM to switch to a public and documented
authentication method instead, such as Digest.

If you want to enable NTLM for your proxy authentication, then use

This option requires a library built with SSL support. Use

If this option is used several times, only the first one is used.
Write output to <file> instead of stdout. If you are using {} or [] to fetch
multiple documents, you can use '#' followed by a number in the <file>
specifier. That variable will be replaced with the current string for the URL
being fetched. Like in:


or use several variables like:


You may use this option as many times as the number of URLs you have.

dynamically. Specifying the output as '-' (a single dash) will force the
output to be done to stdout.
Write output to a local file named like the remote file we get. (Only the file
part of the remote file is used, the path is cut off.)

The remote file name to use for saving is extracted from the given URL,
nothing else.

Consequentially, the file will be saved in the current working directory. If
you want the file saved in a different directory, make sure you change current

There is no URL decoding done on the file name. If it has %20 or other URL
encoded parts of the name, they will end up as-is as file name.

You may use this option as many times as the number of URLs you have.
(IMAP, POP3, SMTP)
Specify the Bearer Token for OAUTH 2.0 server authentication. The Bearer Token
is used in conjunction with the user name which can be specified as part of the

The Bearer Token and user name are formatted according to RFC 6750.

If this option is used several times, the last one will be used.
(HTTP) Extra header to include in the request when sending HTTP to a
proxy. You may specify any number of extra headers. This is the equivalent
CONNECT requests when you want a separate header sent to the proxy to what is
sent to the actual remote host.

content: do not add newlines or carriage returns, they will only mess things
up for you.

Headers specified with this option will not be included in requests that curl
knows will not be sent to a proxy.


(Added in 7.37.0)
protocols to attempt to tunnel through the proxy instead of merely using it to
do HTTP-like operations. The tunnel approach is made with the HTTP proxy
CONNECT request and requires that the proxy allows direct connect to the
remote port number curl wants to tunnel through to.
FTP. This switch makes curl use active mode. In practice, curl then tells the
server to connect back to the client's specified address and port, while
passive mode asks the server to setup an IP address and port for it to connect
to. <address> should be one of:
i.e "eth0" to specify which interface's IP address you want to use (Unix only)
i.e "192.168.10.1" to specify the exact IP address
i.e "my.host.domain" to specify the machine
make curl pick the same IP address that is already used for the control
connection
If this option is used several times, the last one will be used. Disable the

address, to tell curl what TCP port range to use. That means you specify a
port range, from a lower to a higher number. A single number works as well,
but do note that it increases the risk of failure since the port may not be
available.

If this option is used several times, the last one will be used.
path. Normally curl will squash or merge them according to standards but with
this option set you tell it not to do that.

(Added in 7.42.0)
into GET requests when following a 301 redirection. The non-RFC behaviour is
ubiquitous in web browsers, so curl does the conversion by default to maintain
consistency. However, a server may require a POST to remain a POST after such
(Added in 7.17.1)
into GET requests when following a 302 redirection. The non-RFC behaviour is
ubiquitous in web browsers, so curl does the conversion by default to maintain
consistency. However, a server may require a POST to remain a POST after such
(Added in 7.19.1)
into GET requests when following a 303 redirection. The non-RFC behaviour is
ubiquitous in web browsers, so curl does the conversion by default to maintain
consistency. However, a server may require a POST to remain a POST after such
(Added in 7.26.0)
Tells curl to use the listed protocols for its initial retrieval. Protocols
are evaluated left to right, are comma separated, and are each a protocol
name or 'all', optionally prefixed by zero or more modifiers. Available
modifiers are:
Permit this protocol in addition to protocols already permitted (this is
the default if no modifier is used).
Deny this protocol, removing it from the list of protocols already permitted.
Permit only this protocol (ignoring the list already permitted), though
subject to later modification by subsequent entries in the comma separated
list.
For example:
uses the default protocols, but disables ftps
only enables http and https
also only enables http and https
Unknown protocols produce a warning. This allows scripts to safely rely on
being able to disable potentially dangerous protocols, without relying upon
support for that protocol being built into curl to avoid an error.

This option can be used multiple times, in which case the effect is the same
as concatenating the protocols into one instance of the option.

(Added in 7.20.2)
Tells curl to use the listed protocols after a redirect. See --proto for
how protocols are represented.

(Added in 7.20.2)
Tells curl to pick a suitable authentication method when communicating with
in 7.13.2)
Tells curl to use HTTP Basic authentication when communicating with the given
the default authentication method curl uses with proxies.
Tells curl to use HTTP Digest authentication when communicating with the given
Tells curl to use HTTP Negotiate (SPNEGO) authentication when communicating
with a remote host. (Added in 7.17.1)
Tells curl to use HTTP NTLM authentication when communicating with the given
This option allows you to change the service name for proxy negotiation.

Use the specified HTTP 1.0 proxy. If the port number is not specified, it is
assumed at port 1080.

is that attempts to use CONNECT through the proxy will specify an HTTP 1.0
protocol instead of the default HTTP 1.1.
(SSH) Public key file name. Allows you to provide your public key in this
separate file.

If this option is used several times, the last one will be used.

(As of 7.39.0, curl attempts to automatically extract the public key from the
private key file, so passing this option is generally not required. Note that
this public key extraction requires libcurl to be linked against a copy of
libssh2 1.2.8 or higher that is itself linked against OpenSSL.)
default config file search path.
commands are sent BEFORE the transfer takes place (just after the initial PWD
command in an FTP transfer, to be exact). To make commands take place after a
successful transfer, prefix them with a dash '-'.  To make commands be sent
after curl has changed the working directory, just before the transfer
command(s), prefix the command with a '+' (this is only supported for
FTP). You may specify any number of commands. If the server returns failure
for one of the commands, the entire operation will be aborted. You must send
syntactically correct FTP commands as RFC 959 defines to FTP servers, or one
of the commands listed below to SFTP servers.  This option can be used
multiple times. When speaking to an FTP server, prefix the command with an
asterisk (*) to make curl continue even if the command fails as by default
curl will stop at first failure.

SFTP is a binary protocol. Unlike for FTP, curl interprets SFTP quote commands
itself before sending them to the server.  File names may be quoted
shell-style to embed spaces or special characters.  Following is the list of
all supported SFTP quote commands:
The chgrp command sets the group ID of the file named by the file operand to
the group ID specified by the group operand. The group operand is a decimal
integer group ID.
The chmod command modifies the file mode bits of the specified file. The
mode operand is an octal integer mode number.
The chown command sets the owner of the file named by the file operand to the
user ID specified by the user operand. The user operand is a decimal
integer user ID.
The ln and symlink commands create a symbolic link at the target_file location
pointing to the source_file location.
The mkdir command creates the directory named by the directory_name operand.
The pwd command returns the absolute pathname of the current working directory.
The rename command renames the file or directory named by the source
operand to the destination path named by the target operand.
The rm command removes the file specified by the file operand.
The rmdir command removes the directory entry specified by the directory
operand, provided it is empty.
See ln.
in a number of ways.
specifies the first 500 bytes
specifies the second 500 bytes
specifies the last 500 bytes
specifies the bytes from offset 9500 and forward
specifies the first and last byte only(*)(H)
specifies 300 bytes from offset 500(H)
specifies two separate 100-byte ranges(*)(H)
(*) = NOTE that this will cause the server to reply with a multipart
response!

Only digit characters (0-9) are valid in the 'start' and 'stop' fields of the
the server's response will be unspecified, depending on the server's
configuration.

enabled, so that when you attempt to get a range, you'll instead get the whole
document.

FTP and SFTP range downloads only support the simple 'start-stop' syntax
(optionally with one of the numbers omitted). FTP use depends on the extended
FTP command SIZE.

If this option is used several times, the last one will be used.
When used, this will make curl attempt to figure out the timestamp of the
remote file, and if that is available make the local file get that same
timestamp.
(SSL) Specify the path name to file containing what will be considered as
random data. The data is used to seed the random engine for SSL connections.
(HTTP) When used, it disables all internal HTTP decoding of content or transfer
encodings and instead makes them passed on unaltered, raw. (Added in 7.16.2)
This option changes the default action for all given URLs to be dealt with as
Provide a custom address for a specific host and port pair. Using this, you
can make the curl requests(s) use a specified address and prevent the
otherwise normally resolved address to be used. Consider it a sort of
the number used for the specific protocol the host will be used for. It means
you need several entries if you want to provide address for the same host but
different ports.

This option can be used many times to add many host names to resolve.

(Added in 7.21.3)
If a transient error is returned when curl tries to perform a transfer, it
will retry this number of times before giving up. Setting the number to 0
makes curl do no retries (which is the default). Transient error means either:
a timeout, an FTP 4xx response code or an HTTP 5xx response code.

When curl is about to retry a transfer, it will first wait one second and then
for all forthcoming retries it will double the waiting time until it reaches
10 minutes which then will be the delay between the rest of the retries.  By
retries. (Added in 7.12.3)

If this option is used several times, the last one will be used.
Make curl sleep this amount of time before each retry when a transfer has
failed with a transient error (it changes the default backoff time algorithm
used. Setting this delay to zero will make curl use the default backoff time.
(Added in 7.12.3)

If this option is used several times, the last one will be used.
The retry timer is reset before the first transfer attempt. Retries will be
given limit. Notice that if the timer hasn't reached the limit, the request
will be made and while performing, it may take longer than this given time
Set this option to zero to not timeout retries. (Added in 7.12.3)

If this option is used several times, the last one will be used.
Silent or quiet mode. Don't show progress meter or error messages.  Makes Curl
mute. It will still output the data you ask for, potentially even to the
Enable initial response in SASL authentication.
(Added in 7.31.0)
This option allows you to change the service name for SPNEGO.

encryption required. (Added in 7.20.0)

option name can still be used but will be removed in a future version.

option name can still be used but will be removed in a future version.
(SSL) This option tells curl to not work around a security flaw in the SSL3
and TLS1.0 protocols known as BEAST.  If this option isn't used, the SSL layer
may use workarounds known to cause interoperability problems with some older
SSL implementations. WARNING: this option loosens the SSL security, and by
using this flag you ask for exactly that.  (Added in 7.25.0)
Use the specified SOCKS4 proxy. If the port number is not specified, it is
assumed at port 1080. (Added in 7.15.2)

mutually exclusive.

Since 7.21.7, this option is superfluous since you can specify a socks4 proxy

If this option is used several times, the last one will be used.
Use the specified SOCKS4a proxy. If the port number is not specified, it is
assumed at port 1080. (Added in 7.18.0)

mutually exclusive.

Since 7.21.7, this option is superfluous since you can specify a socks4a proxy

If this option is used several times, the last one will be used.
Use the specified SOCKS5 proxy (and let the proxy resolve the host name). If
the port number is not specified, it is assumed at port 1080. (Added in
7.18.0)

mutually exclusive.

Since 7.21.7, this option is superfluous since you can specify a socks5

If this option is used several times, the last one will be used. (This option
was previously wrongly documented and used as --socks without the number
appended.)
Use the specified SOCKS5 proxy - but resolve the host name locally. If the
port number is not specified, it is assumed at port 1080.

mutually exclusive.

Since 7.21.7, this option is superfluous since you can specify a socks5 proxy

If this option is used several times, the last one will be used. (This option
was previously wrongly documented and used as --socks without the number
appended.)

allows you to change it.

not match the principal name.  (Added in 7.19.4).
As part of the GSS-API negotiation a protection mode is negotiated. RFC 1961
unprotected exchange of the protection mode negotiation. (Added in 7.19.4).
Redirect all writes to stderr to the specified file instead. If the file name
is a plain '-', it is instead written to stdout.

If this option is used several times, the last one will be used.
Pass options to the telnet protocol. Supported options are:

TTYPE=<term> Sets the terminal type.

XDISPLOC=<X display> Sets the X display location.

NEW_ENV=<var,val> Sets an environment variable.
This transfers the specified local file to the remote URL. If there is no file
part in the specified URL, Curl will append the local file name. NOTE that you
is no file name or curl will think that your last directory name is the remote
file name to use. That will most likely cause the upload operation to fail. If
this is used on an HTTP(S) server, the PUT command will be used.

Use the file name "-" (a single dash) to use stdin instead of a given file.
Alternately, the file name "." (a single period) may be specified instead
of "-" to use stdin in non-blocking mode to allow reading server output
while stdin is being uploaded.

You can specify one -T for each URL on the command line. Each -T + URL pair
specifies what to upload and to where. curl also supports "globbing" of the -T
argument, meaning that you can upload multiple files to a single URL by using
the same URL globbing style supported in the URL, like this:


or even

details about this option. (Added in 7.11.2)
(TFTP) Set TFTP BLKSIZE option (must be >512). This is the block size that
curl will try to use when transferring data to or from a TFTP server. By
default 512 bytes will be used.

If this option is used several times, the last one will be used.

(Added in 7.20.0)
Set TLS authentication type. Currently, the only supported option is "SRP",
(Added in 7.21.4)
Set password for use with the TLS authentication method specified with
7.21.4)
Set username for use with the TLS authentication method specified with
7.21.4)
(SSL)
Forces curl to use TLS version 1.0 when negotiating with a remote TLS server.
(Added in 7.34.0)
(SSL)
Forces curl to use TLS version 1.1 when negotiating with a remote TLS server.
(Added in 7.34.0)
(SSL)
Forces curl to use TLS version 1.2 when negotiating with a remote TLS server.
(Added in 7.34.0)
(HTTP) Request a compressed Transfer-Encoding response using one of the
algorithms curl supports, and uncompress the data while receiving it.

(Added in 7.21.6)
Enables a full trace dump of all incoming and outgoing data, including
descriptive information, to the given output file. Use "-" as filename to have
the output sent to stdout.


If this option is used several times, the last one will be used.
Enables a full trace dump of all incoming and outgoing data, including
descriptive information, to the given output file. Use "-" as filename to have
the output sent to stdout.

shows the ASCII part of the dump. It makes smaller output that might be easier
to read for untrained humans.


If this option is used several times, the last one will be used.
Prepends a time stamp to each trace or verbose line that curl displays.
(Added in 7.14.0)
(HTTP) Connect through this Unix domain socket, instead of using the
network. (Added in 7.40.0)
Specify the user name and password to use for server authentication. Overrides

If you simply specify the user name, curl will prompt for a password.

The user name and passwords are split up on the first colon, which makes it
impossible to use a colon in the user name with this option. The password can,
still.

When using Kerberos V5 with a Windows based server you should include the
Windows domain name in the user name, in order for the server to successfully
obtain a Kerberos Ticket. If you don't then the initial authentication
handshake may fail.

When using NTLM, the user name can be specified simply as the user name,
without the domain, if there is a single domain and forest in your setup
for example.

To specify the domain name use either Down-Level Logon Name or UPN (User
respectively.

If you use a Windows SSPI-enabled curl binary and perform Kerberos V5,
Negotiate, NTLM or Digest authentication then you can tell curl to select
the user name and password from your environment by specifying a single colon
with this option: "-u :".

If this option is used several times, the last one will be used.
Specify the user name and password to use for proxy authentication.

If you use a Windows SSPI-enabled curl binary and do either Negotiate or NTLM
authentication then you can tell curl to select the user name and password
from your environment by specifying a single colon with this option: "-U :".

If this option is used several times, the last one will be used.
Specify a URL to fetch. This option is mostly handy when you want to specify
URL(s) in a config file.

This option may be used any number of times. To control where this URL is
seeing what's going on "under the hood". A line starting with '>' means
"header data" sent by curl, '<' means "header data" received by curl that is
hidden in normal cases, and a line starting with '*' means additional info
provided by curl.

might be the option you're looking for.

If you think this option still doesn't give you enough details, consider using


Make curl display information on stdout after a completed transfer. The format
is a string that may contain plain text mixed with any number of
variables. The format can be specified as a literal "string", or you can have
curl read the format from a file with "@filename" and to tell curl to read the
format from stdin you write "@-".

The variables present in the output format will be substituted by the value or
text that curl thinks fit, as described below. All variables are specified
as %{variable_name} and to output a normal % you just write them as

The %-symbol is a special symbol in the win32-environment, where all
occurrences of % must be doubled when using this option.

The variables available are:
The Content-Type of the requested document, if there was any.
The ultimate filename that curl writes out to. This is only meaningful if curl
option. (Added in 7.25.1)
The initial path curl ended up in when logging on to the remote FTP
server. (Added in 7.15.4)
The numerical response code that was found in the last retrieved HTTP(S) or
same info.
The numerical code that was found in the last response (from a proxy) to a
curl CONNECT request. (Added in 7.12.4)
The IP address of the local end of the most recently done connection - can be
either IPv4 or IPv6 (Added in 7.29.0)
The local port number of the most recently done connection (Added in 7.29.0)
Number of new connects made in the recent transfer. (Added in 7.12.3)
Number of redirects that were followed in the request. (Added in 7.12.3)
When an HTTP request was made without -L to follow redirects, this variable
The remote IP address of the most recently done connection - can be either
IPv4 or IPv6 (Added in 7.29.0)
The remote port number of the most recently done connection (Added in 7.29.0)
The total amount of bytes that were downloaded.
The total amount of bytes of the downloaded headers.
The total amount of bytes that were sent in the HTTP request.
The total amount of bytes that were uploaded.
The average download speed that curl measured for the complete download. Bytes
per second.
The average upload speed that curl measured for the complete upload. Bytes per
second.
The result of the SSL peer certificate verification that was requested. 0
means the verification was successful. (Added in 7.19.0)
The time, in seconds, it took from the start until the TCP connect to the
remote host (or proxy) was completed.
The time, in seconds, it took from the start until the name resolving was
completed.
The time, in seconds, it took from the start until the file transfer was just
about to begin. This includes all pre-transfer commands and negotiations that
are specific to the particular protocol(s) involved.
The time, in seconds, it took for all redirection steps include name lookup,
connect, pretransfer and transfer before the final transaction was
started. time_redirect shows the complete execution time for multiple
redirections. (Added in 7.12.3)
The time, in seconds, it took from the start until the first byte was just
about to be transferred. This includes time_pretransfer and also the time the
server needed to calculate the result.
The total time, in seconds, that the full operation lasted. The time will be
displayed with millisecond resolution.
The URL that was fetched last. This is most meaningful if you've told curl
to follow location: headers.
If this option is used several times, the last one will be used.
Use the specified proxy.

protocol support was added in curl 7.21.7)

If the port number is not specified in the proxy string, it is assumed to be
1080.

This option overrides existing environment variables that set the proxy to
use. If there's an environment variable setting a proxy, you can set proxy to

All operations that are performed over an HTTP proxy will transparently be
converted to HTTP. It means that certain protocol specific operations might
not be available. This is not the case if you can tunnel through the proxy, as

User and password that might be provided in the proxy string are URL decoded
by curl. This allows you to pass in special characters such as @ by using %40
or pass in a colon with %3a.

The proxy host can be specified the exact same way as the proxy environment
password.

If this option is used several times, the last one will be used.
(HTTP) Specifies a custom request method to use when communicating with the
HTTP server.  The specified request method will be used instead of the method
otherwise used (which defaults to GET). Read the HTTP 1.1 specification for
details and explanations. Common additional HTTP requests include PUT and
DELETE, but related technologies like WebDAV offers PROPFIND, COPY, MOVE and
more.

Normally you don't need this option. All sorts of GET, HEAD, POST and PUT
requests are rather invoked by using dedicated command line options.

This option only changes the actual word used in the HTTP request, it does not
alter the way curl behaves. So for example if you want to make a proper HEAD
option.

The method string you set with -X will be used for all requests, which if you
curl doesn't change request method according to the HTTP 30x response codes -
and similar.

(FTP)
Specifies a custom FTP command to use instead of LIST when doing file lists
with FTP.

(POP3)
Specifies a custom POP3 command to use instead of LIST or RETR. (Added in
7.26.0)

(IMAP)
Specifies a custom IMAP command to use instead of LIST. (Added in 7.30.0)

(SMTP)
Specifies a custom SMTP command to use instead of HELP or VRFY. (Added in 7.34.0)

If this option is used several times, the last one will be used.
When saving output to a file, this option tells curl to store certain file
metadata in extended file attributes. Currently, the URL is stored in the
xdg.origin.url attribute and, for HTTP, the content type is stored in
the mime_type attribute. If the file system does not support extended
attributes, a warning is issued.

If a download is slower than speed-limit bytes per second during a speed-time
period, the download gets aborted. If speed-time is used, the default

This option controls transfers and thus will not affect slow connects etc. If

If this option is used several times, the last one will be used.
If a download is slower than this given speed (in bytes per second) for
if not set.

If this option is used several times, the last one will be used.
date, or one that has been modified before that time. The <date expression>
can be all sorts of date strings or if it doesn't match any internal ones, it
is taken as a filename and tries to get the modification date (mtime) from
details.

Start the date expression with a dash (-) to make it request for a document

If this option is used several times, the last one will be used.
Usage help. This lists all current command line options with a short
description.
Manual. Display the huge help text.
Displays information about curl and the libcurl version it uses.

The first line includes the full version of curl, libcurl and other 3rd party
libraries linked with the executable.

The second line (starts with "Protocols:") shows all protocols that libcurl
reports to support.

The third line (starts with "Features:") shows specific features libcurl
reports to offer. Available features include:
You can use IPv6 with this.
Krb4 for FTP is supported.
SSL versions of various protocols are supported, such as HTTPS, FTPS, POP3S
and so on.
Automatic decompression of compressed files over HTTP is supported.
NTLM authentication is supported.
This curl uses a libcurl built with Debug. This enables more error-tracking
and memory debugging etc. For curl-developers only!
This curl uses asynchronous name resolves. Asynchronous name resolves can be
done using either the c-ares or the threaded resolver backends.
SPNEGO authentication is supported.
This curl supports transfers of large files, files larger than 2GB.
This curl supports IDN - international domain names.
GSS-API is supported.
SSPI is supported.
SRP (Secure Remote Password) authentication is supported for TLS.
This curl supports Metalink (both version 3 and 4 (RFC 5854)), which
describes mirrors and hashes.  curl will use mirrors for failover if
there are errors (such as the file or server not being available).
The environment variables can be specified in lower case or upper case. The
lower case version has precedence. http_proxy is an exception as it is only
available in lower case.

Using an environment variable to set the proxy has the same effect as using

Sets the proxy server to use for HTTP.
Sets the proxy server to use for HTTPS.
Sets the proxy server to use for [url-protocol], where the protocol is a
protocol that curl supports and as specified in a URL. FTP, FTPS, POP3, IMAP,
SMTP, LDAP etc.
Sets the proxy server to use if no protocol-specific proxy is set.
list of host names that shouldn't go through any proxy. If set to a asterisk
Since curl version 7.21.7, the proxy string may be specified with a

If no protocol is specified in the proxy string or if the string doesn't match
a supported one, the proxy will be treated as an HTTP proxy.

The supported proxy protocol prefixes are as follows:
There are a bunch of different error codes and their corresponding error
messages that may appear during bad conditions. At the time of this writing,
the exit codes are:
Unsupported protocol. This build of curl has no support for this protocol.
Failed to initialize.
URL malformed. The syntax was not correct.
A feature or option that was needed to perform the desired request was not
enabled or was explicitly disabled at build-time. To make curl able to do
this, you probably need another build of libcurl!
Couldn't resolve proxy. The given proxy host could not be resolved.
Couldn't resolve host. The given remote host was not resolved.
Failed to connect to host.
FTP weird server reply. The server sent data curl couldn't parse.
FTP access denied. The server denied login or denied access to the particular
resource or directory you wanted to reach. Most often you tried to change to a
directory that doesn't exist on the server.
FTP weird PASS reply. Curl couldn't parse the reply sent to the PASS request.
FTP weird PASV reply, Curl couldn't parse the reply sent to the PASV request.
FTP weird 227 format. Curl couldn't parse the 227-line the server sent.
FTP can't get host. Couldn't resolve the host IP we got in the 227-line.
FTP couldn't set binary. Couldn't change transfer method to binary.
Partial file. Only a part of the file was transferred.
failed.
FTP quote error. A quote command returned error from the server.
HTTP page not retrieved. The requested url was not found or returned another
error with the HTTP error code being 400 or above. This return code only
Write error. Curl couldn't write data to a local filesystem or similar.
FTP couldn't STOR file. The server denied the STOR operation, used for FTP
uploading.
Read error. Various reading problems.
Out of memory. A memory allocation request failed.
Operation timeout. The specified time-out period was reached according to the
conditions.
FTP PORT failed. The PORT command failed. Not all FTP servers support the PORT
command, try doing a transfer using PASV instead!
FTP couldn't use REST. The REST command failed. This command is used for
resumed FTP transfers.
HTTP range error. The range "command" didn't work.
HTTP post error. Internal post-request generation error.
SSL connect error. The SSL handshaking failed.
FTP bad download resume. Couldn't continue an earlier aborted download.
FILE couldn't read file. Failed to open the file. Permissions?
LDAP cannot bind. LDAP bind operation failed.
LDAP search failed.
Function not found. A required LDAP function was not found.
Aborted by callback. An application told curl to abort the operation.
Internal error. A function was called with a bad parameter.
Interface error. A specified outgoing interface could not be used.
Too many redirects. When following redirects, curl hit the maximum amount.
Unknown option specified to libcurl. This indicates that you passed a weird
option to curl that was passed on to libcurl and rejected. Read up in the
manual!
Malformed telnet option.
The peer's SSL certificate or SSH MD5 fingerprint was not OK.
The server didn't reply anything, which here is considered an error.
SSL crypto engine not found.
Cannot set SSL crypto engine as default.
Failed sending network data.
Failure in receiving network data.
Problem with the local certificate.
Couldn't use specified SSL cipher.
Peer certificate cannot be authenticated with known CA certificates.
Unrecognized transfer encoding.
Invalid LDAP URL.
Maximum file size exceeded.
Requested FTP SSL level failed.
Sending the data requires a rewind that failed.
Failed to initialise SSL Engine.
The user name, password, or similar was not accepted and curl failed to log in.
File not found on TFTP server.
Permission problem on TFTP server.
Out of disk space on TFTP server.
Illegal TFTP operation.
Unknown TFTP transfer ID.
File already exists (TFTP).
No such user (TFTP).
Character conversion failed.
Character conversion functions required.
Problem with reading the SSL CA cert (path? access rights?).
The resource referenced in the URL does not exist.
An unspecified error occurred during the SSH session.
Failed to shut down the SSL connection.
Could not load CRL file, missing or wrong format (added in 7.19.0).
Issuer check failed (added in 7.19.0).
The FTP PRET command failed
RTSP: mismatch of CSeq numbers
RTSP: mismatch of Session Identifiers
unable to parse FTP file list
FTP chunk callback reported error
No connection available, the session will be queued
SSL public key does not matched pinned public key
More error codes will appear here in future releases. The existing ones
are meant to never change.
Daniel Stenberg is the main author, but the whole list of contributors is
found in the separate THANKS file.
The
utility cuts out selected portions of each line (as specified by
from each
and writes them to the standard output.
If no
arguments are specified, or a file argument is a single dash
reads from the standard input.
The items specified by
can be in terms of column position or in terms of fields delimited
by a special character.
Column numbering starts from 1.
The
option argument
number ranges.
Number ranges consist of a number, a dash
and a second number
and select the fields or columns from the first number to the second,
inclusive.
Numbers or number ranges may be preceded by a dash, which selects all
fields or columns from 1 to the last number.
Numbers or number ranges may be followed by a dash, which selects all
fields or columns from the last number to the end of the line.
Numbers and number ranges may be repeated, overlapping, and in any order.
If a field or column is specified multiple times, it will appear only
once in the output.
It is not an error to select fields or columns not present in the
input line.
The options are as follows:
The
specifies byte positions.
The
specifies character positions.
Use
as the field delimiter character instead of the tab character.
The
specifies fields, separated in the input by the field delimiter character
(see the
option.)
Output fields are separated by a single occurrence of the field delimiter
character.
Do not split multi-byte characters.
Characters will only be output if at least one byte is selected, and,
after a prefix of zero or more unselected bytes, the rest of the bytes
that form the character are selected.
Suppress lines with no field delimiter characters.
Unless specified, lines with no delimiters are passed through unmodified.
The
and
environment variables affect the execution of
as described in
Extract users' login names and shells from the system
file as
pairs:
Show the names and login times of the currently logged in users:
The
utility conforms to
A
command appeared in
System III
Copyright (c) 2010 Apple Inc.  All rights reserved.
@APPLE_BSD_LICENSE_HEADER_START@
Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:
1.  Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.
2.  Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
3.  Neither the name of Apple Computer, Inc. ("Apple") nor the names of
    its contributors may be used to endorse or promote products derived
    from this software without specific prior written permission.
THIS SOFTWARE IS PROVIDED BY APPLE AND ITS CONTRIBUTORS "AS IS" AND ANY
EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL APPLE OR ITS CONTRIBUTORS BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
@APPLE_BSD_LICENSE_HEADER_END@
allows you to manage roots, or
archives, of files that replace parts of your system. This is useful
for installing a new version of a library or tool on your system while 
allowing you to uninstall the files and revert back to the originals 
safely and easily.
Do not run helpful automation. See HELPFUL AUTOMATION below.
Force. Some operations will fail gracefully due to potentially unsafe 
situations, such as a root that installs a file where a directory is.
In order to have darwinup continue through such a situation, you can
pass the -f option.
Dry run. Darwinup will go through an operation, including analyzing
be modified on your system and no records will be added to the depot.
This option implies -d.
Prefix path. Normally, darwinup will operate on the boot partition. You
can use the -p option to have darwinup work on another partition. You
can provide any arbitrary path, it does not need to be a mount point.
Restart. Gracefully restart after all operations are complete by telling
Finder to restart. 
Verbose. This option causes darwinup to print extra information. You can
pass 2 or 3 v's for even more information, but that is usually only needed
for development and debugging of darwinup itself.
Note that the
and
options listed below support globbing and multiple items. See the EXAMPLES 
section below for more details.
List the files and directories in the 
Install the root at 
List archives that are installed. You may optionally provide an
archive specification to limit which archives get listed. 
Rename an archive.
Uninstall the specified archive.
Find the last archive that was installed with the same name (basename of 
path), and replace it with the root at 
List all of the information about 
This includes status letters
detailing how the archive differs from whats on disk
Unknown state. Probably a bug.
Missing file during uninstall. Darwinup expected a file or directory to 
exist, but it did not. This could be a bug in darwinup, but most likely 
another tool or software update removed a file that darwinup had been 
tracking. It can also be caused by an installation failing due to an
object changing type (see FORCING OPERATIONS below), and the subsequent 
rollback finding the root only partially installed. Since these all 
happen during uninstall, they are typically safe to ignore, since darwinup 
was going to delete the object anyway.
Added. No previous file or directory existed so the file or directory was
added to your system.
External change. The file you are installing is different than the 
last file you installed, but it is identical to what was actually found
on disk. This probably means something manually installed a root or software
update without darwinup knowing about it. This is usually harmless. 
Mode change. Only changes to permission or ownership were needed to
uninstall the file or directory. 
Removed. No previous file or directory existed, so the uninstall process
removed the file. 
Updated. During installation, the file or directory replaces an existing 
object at the same path. During uninstallation, the previous version of
the file was restored.
Ignored. A file specified in the removal list was not removed. This usually
indicates that the file was a directory and the path in the removal list lacked
a trailing
character.
You can install archive files or directories by specifying a relative or 
absolute path. If the path is a directory, all files below it will be 
installed as a single root. If the path points to a file, it must be one of
the suported archive file types as described in the usage statement. 
like any other root.
archive file will be downloaded using curl to your machine and then
installed like any other archive file. You can not point darwinup at a
directory hosted via HTTP or HTTPS, only archive files such as tarballs.  
When running a subcommand which takes an 
argument, you can use one or more of the following items to specify which
archive to operate on. You can mix and match any of them as needed. 
You can use the list subcommand with these specifications to see what will 
match.
You can specify an archive with its serial number, which can be found using
the list subcommand.
You can specify an archive with its UUID, which can be found using the
list subcommand.
You can specify an archive with its name, which can be found using the
list subcommand.
The newest keyword will match the one archive which was most recently
installed. This should always be the first archive listed.
The oldest keyword will match the one archive which was installed the
longest time ago. This should always be the last archive listed. 
The superseded keyword will match zero or more archives. An archive is
superseded if every file it contains is contained in an archive that was
(and still is) installed after it. A file in an archive can also be superseded
by external changes, such as operating system updates. When uninstalling a
superseded archive, you should never see any status symbols, since being
superseded means there is a newer file on disk. 
The all keyword will match all archives. If you specify extra verbosity 
with -vv, then rollback archives will also be matched by the all keyword. This
means that 
will attempt to uninstall rollback archives, which will print a message
about not being able to uninstall rollback archives. This is normal and
not a problem. 
There are 2 cases where darwinup will require you to pass the force (-f)
option before proceeding with an operation.
If you install an archive which contains a file with the same path as a 
directory on your system, or vice versa, darwinup will give you a error
about not doing that unless you really want to force it. If you do force
the operation, darwinup will delete the existing object and replace it with
the object from the root. This can happen when a directory full of files
"type change", then it is probably safe to force the operation. 
Darwinup remembers the version (build) of the operating system when a root
is installed. The reason for this is darwinup saves the old (replaced)
files during the installation procedure. Those backups may have come from
the older operating system, and thus are not necessarily compatible with
the current build of the operating system. So if you try to uninstall an
archive that had been installed on a different version of the operating
system, darwinup will stop and provide a message asking you to force the
operation if you really want to. If the files you are uninstalling are all
superseded, then you should not get this error as the backup copies will
not be used anyway. 
Darwinup tries to detect common situations and run external tools that you
would otherwise have to remember to run yourself. The "dry run" (-n) and 
"disable automation" (-d) options prevent any of the following from 
happening.
If a root modifies any file, then darwinup will run 
update_dyld_shared_cache unless the -d option is specified.
kext cache is updated during the next boot. 
supports removing files from disk as part of installing a root. These files must
be enumerated in a list that is included in the root at the path
The list is a simple text file consisting of paths to remove, separated by new
lines. Directories may be present in this list. If a directory is to be removed,
be removed. When files are removed as part of root installation, they will be
restored when the root is uninstalled with the
command.
It is permissible for the root to contain files that are specified in its
removal list. This is primarily useful for replacing entire directory
hierarchies as singular entities.
Replacing a directory hierarchy can only be done safely is the root creator has
full knowledge of the contents of a given directory hierarchy and knows how to
completely populate it such that all dependencies will be satisfied. For
example, a project which installs content into
should
specify that path in its removal list since many other projects populate that
directory. The result of the removal operation in such a case would be the only
the contents of the root would exist in
after the installation completes.
cannot and does not protect against this scenario, so exercise extreme caution
when constructing roots with removal lists.
Neither the
directory nor its contents will be installed into the destination path.
$ darwinup install library-1.2.3.tar.gz
$ darwinup uninstall all
$ darwinup list superseded
$ darwinup uninstall superseded
$ darwinup uninstall 9 16 myroot oldest
When invoked without arguments, the
utility displays the current date and time.
Otherwise, depending on the options specified,
will set the date and time or print it in a user-defined way.
The
utility displays the date and time read from the kernel clock.
When used to set the date and time,
both the kernel clock and the hardware clock are updated.
Only the superuser may set the date,
and if the system securelevel (see
is greater than 1,
the time may not be changed by more than 1 second.
The options are as follows:
Set the kernel's value for daylight saving time.
If
is non-zero, future calls
to
will return a non-zero for
Use
as the format string to parse the
provided rather than using the default
format.
Parsing is done using
Do not try to set the date.
This allows you to use the
flag in addition to the
option to convert one date format to another.
By default, if the
daemon is running,
sets the time on all of the machines in the local group.
The
option suppresses this behavior and causes the time to be set only on the
current machine.
Print the date and time represented by
where
is the number of seconds since the Epoch
(00:00:00 UTC, January 1, 1970;
see
and can be specified in decimal, octal, or hex.
Set the system's value for minutes west of
specifies the number of minutes returned in
by future calls to
Display or set the date in
(Coordinated Universal) time.
Adjust (i.e., take the current date and display the result of the
adjustment; not actually set the date) the second, minute, hour, month
day, week day, month or year according to
If
is preceded with a plus or minus sign,
the date is adjusted forwards or backwards according to the remaining string,
otherwise the relevant part of the date is set.
The date can be adjusted as many times as required using these flags.
Flags are processed in the order given.
When setting values
(rather than adjusting them),
seconds are in the range 0-59, minutes are in the range 0-59, hours are
in the range 0-23, month days are in the range 1-31, week days are in the
range 0-6 (Sun-Sat),
months are in the range 1-12 (Jan-Dec)
and years are in the range 80-38 or 1980-2038.
If
is numeric, one of either
or
must be used to specify which part of the date is to be adjusted.
The week day or month may be specified using a name rather than a
number.
If a name is used with the plus
(or minus)
sign, the date will be put forwards
(or backwards)
to the next
(previous)
date that matches the given week day or month.
This will not adjust the date,
if the given week day or month is the same as the current one.
When a date is adjusted to a specific value or in units greater than hours,
daylight savings time considerations are ignored.
Adjustments in units of hours or less honor daylight saving time.
So, assuming the current date is March 26, 0:30 and that the DST adjustment
means that the clock goes forward at 01:00 to 02:00, using
will adjust the date to March 26, 2:30.
Likewise, if the date is October 29, 0:30 and the DST adjustment means that
the clock goes back at 02:00 to 01:00, using
will be necessary to reach October 29, 2:30.
When the date is adjusted to a specific value that does not actually exist
the date will be silently adjusted forwards in units of one hour until it
reaches a valid time.
When the date is adjusted to a specific value that occurs twice
(for example October 29, 1:30 2000),
the resulting timezone will be set so that the date matches the earlier of
the two times.
Adjusting the date by months is inherently ambiguous because
a month is a unit of variable length depending on the current date.
This kind of date adjustment is applied in the most intuitive way.
First of all,
tries to preserve the day of the month.
If it is impossible because the target month is shorter than the present one,
the last day of the target month will be the result.
For example, using
on May 31 will adjust the date to June 30, while using the same option
on January 30 will result in the date adjusted to the last day of February.
This approach is also believed to make the most sense for shell scripting.
Nevertheless, be aware that going forth and back by the same number of
months may take you to a different date.
Refer to the examples below for further details.
An operand with a leading plus
sign signals a user-defined format string
which specifies the format in which to display the date and time.
The format string may contain any of the conversion specifications
described in the
manual page, as well as any arbitrary text.
A newline
character is always output after the characters specified by
the format string.
The format string for the default display is
If an operand does not have a leading plus sign, it is interpreted as
a value for setting the system's notion of the current date and time.
The canonical representation for setting the date and time is:
Century
(either 19 or 20)
prepended to the abbreviated year.
Year in abbreviated form
(e.g., 89 for 1989, 06 for 2006).
Numeric month, a number from 1 to 12.
Day, a number from 1 to 31.
Hour, a number from 0 to 23.
Minutes, a number from 0 to 59.
Seconds, a number from 0 to 61
(59 plus a maximum of two leap seconds).
Everything but the minutes is optional.
Time changes for Daylight Saving Time, standard time, leap seconds,
and leap years are handled automatically.
The following environment variables affect the execution of
The timezone to use when displaying dates.
The normal format is a pathname relative to
For example, the command
displays the current time in California.
See
for more information.
record of the user setting the time
The
utility exits 0 on success, 1 if unable to set the date, and 2
if able to set the local date, but unable to set it globally.
The command:
will display:
DATE: 1987-11-21
TIME: 13:36:16
will display:
where it is currently
The command:
will display the last day of February in the year 2000:
So will do the command:
because there is no such date as the 30th of February.
The command:
will display the last Friday of the month:
where it is currently
The command:
sets the date to
may be used on one machine to print out the date
suitable for setting on another.
The command:
sets the time to
without modifying the date.
Finally the command:
can be used to parse the output from
and express it in Epoch time.
Occasionally, when
synchronizes the time on many hosts, the setting of a new time value may
require more than a few seconds.
On these occasions,
prints:
The message
occurs when the communication
between
and
fails.
As above, except for the second line, which is:
When invoked in legacy mode, the following exit values are returned:
The date was written successfully
Unable to set the date
Able to set the local date, but unable to set it globally
For more information about legacy mode, see
The
utility is expected to be compatible with
A
command appeared in
The
utility writes the pathnames of log files that are no longer in use (for example, no longer involved in active transactions), to the standard output, one pathname per line. These log files should be written to backup media to provide for recovery in the case of catastrophic failure (which also requires a snapshot of the database files), but they may then be deleted from the system to reclaim disk space.
The options are as follows:
Write all pathnames as absolute pathnames, instead of relative to the database home directories.
Remove log files that are no longer needed; no filenames are written. Automatic log file removal is likely to make catastrophic recovery impossible.
Specify a home directory for the database environment; by default, the current working directory is used.
Write out the pathnames of all the database log files, whether or not they are involved in active transactions.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
Write the pathnames of all the database files that need to be archived in order to recover the database from catastrophic failure. If any of the database files have not been accessed during the lifetime of the current log files, db_archive will not include them in this output.
It is possible that some of the files to which the log refers have since been deleted from the system. In this case, db_archive will ignore them. When db_recover is run, any files to which the log refers that are not present during recovery are assumed to have been deleted and will not be recovered.
Write the library version number to the standard output, and exit.
Run in verbose mode, listing the checkpoints in the log files as they are reviewed.
The db_archive utility uses a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, db_archive should always be given the chance to detach from the environment and exit gracefully. To cause db_archive to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
The
utility is a daemon process that monitors the database log, and periodically calls DB_ENV->txn_checkpoint to checkpoint it.
The options are as follows:
Checkpoint the log once, regardless of whether or not there has been activity since the last checkpoint and then exit.
Specify a home directory for the database environment; by default, the current working directory is used.
Checkpoint the database at least as often as every kbytes of log file are written.
Log the execution of the db_checkpoint utility to the specified file in the following format, where ### is the process ID, and the date is the time the utility was started.
This file will be removed if the db_checkpoint utility exits gracefully.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
Checkpoint the database at least every min minutes if there has been any activity since the last checkpoint.
Write the library version number to the standard output, and exit.
Write the time of each checkpoint attempt to the standard output.
At least one of the -1, -k, and -p options must be specified.
The db_checkpoint utility uses a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, db_checkpoint should always be given the chance to detach from the environment and exit gracefully. To cause db_checkpoint to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The db_checkpoint utility does not attempt to create the Berkeley DB shared memory regions if they do not already exist. The application that creates the region should be started first, and once the region is created, the db_checkpoint utility should be started.
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
The
utility traverses the database environment lock region, and aborts a lock request each time it detects a deadlock or a lock request that has timed out. By default, in the case of a deadlock, a random lock request is chosen to be aborted.
This utility should be run as a background daemon, or the underlying Berkeley DB deadlock detection interfaces should be called in some other way, whenever there are multiple threads or processes accessing a database and at least one of them is modifying it.
The options are as follows:
When a deadlock is detected, abort the locker:
with the greatest number of locks
with the fewest number of locks
with the oldest locker ID
with the fewest number of write locks
with the youngest locker ID
When lock or transaction timeouts have been specified:
abort any lock request that has timed out
Specify a home directory for the database environment; by default, the current working directory is used.
Log the execution of the db_deadlock utility to the specified file in the following format, where ### is the process ID, and the date is the time the utility was started.
This file will be removed if the db_deadlock utility exits gracefully.
Check the database environment every sec seconds plus usec microseconds to see if a process has been forced to wait for a lock; if one has, review the database environment lock structures.
Write the library version number to the standard output, and exit.
Run in verbose mode, generating messages each time the detector runs.
If the -t option is not specified, db_deadlock will run once and exit.
The db_deadlock utility uses a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, db_deadlock should always be given the chance to detach from the environment and exit gracefully. To cause db_deadlock to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The db_deadlock utility does not attempt to create the Berkeley DB shared memory regions if they do not already exist. The application which creates the region should be started first, and then, once the region is created, the db_deadlock utility should be started.
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
file
The
utility reads the database file file and writes it to the standard output using a portable flat-text format understood by the db_load utility. The file argument must be a file produced using the Berkeley DB library functions.
The options are as follows:
Dump the specified database in a format helpful for debugging the Berkeley DB library routines.
Display all information.
Display only page headers.
Do not display the free-list or pages on the free list. This mode is used by the recovery tests.
Write to the specified file instead of to the standard output.
Specify a home directory for the database environment; by default, the current working directory is used.
Dump record numbers from Queue and Recno databases as keys.
List the databases stored in the file.
Do not acquire shared region mutexes while running. Other problems, such as potentially fatal errors in Berkeley DB, will be ignored as well. This option is intended only for debugging errors, and should not be used under any other circumstances.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
If characters in either the key or data items are printing characters (as defined by isprint(3)), use printing characters in file to represent them. This option permits users to use standard text editors and tools to modify the contents of databases.
Note: different systems may have different notions about what characters are considered 
and databases dumped in this manner may be less portable to external systems.
Aggressively salvage data from a possibly corrupt file. The -R flag differs from the -r option in that it will return all possible data from the file at the risk of also returning already deleted or otherwise nonsensical items. Data dumped in this fashion will almost certainly have to be edited by hand or other means before the data is ready for reload into another database
Salvage data from a possibly corrupt file. When used on a uncorrupted database, this option should return equivalent data to a normal dump, but most likely in a different order.
Specify a single database to dump. If no database is specified, all databases in the database file are dumped.
Write the library version number to the standard output, and exit.
Dumping and reloading Hash databases that use user-defined hash functions will result in new databases that use the default hash function. Although using the default hash function may not be optimal for the new database, it will continue to work correctly.
Dumping and reloading Btree databases that use user-defined prefix or comparison functions will result in new databases that use the default prefix and comparison functions. 
The only available workaround for either case is to modify the sources for the db_load utility to load the database using the correct hash, prefix, and comparison functions.
The 
utility output format is documented in the Dump Output Formats section of the Berkeley DB Reference Guide.
The
utility may be used with a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, 
should always be given the chance to detach from the environment and exit gracefully. To cause
to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
Even when using a Berkeley DB database environment, the
utility does not use any kind of database locking if it is invoked with the -d, -R, or -r arguments. If used with one of these arguments, the
utility may only be safely run on databases that are not being modified by any other process; otherwise, the output may be corrupt.
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
file
The
utility reads from the standard input and loads it into the database file. The database file is created if it does not already exist.
The input to
must be in the output format specified by the db_dump utility, utilities, or as specified for the -T below.
The options are as follows:
Specify configuration options ignoring any value they may have based on the input. The command-line format is name=value. See the Supported Keywords section below for a list of keywords supported by the -c option.
Read from the specified input file instead of from the standard input.
Specify a home directory for the database environment.
If a home directory is specified, the database environment is opened using the Db.DB_INIT_LOCK, Db.DB_INIT_LOG, Db.DB_INIT_MPOOL, Db.DB_INIT_TXN, and Db.DB_USE_ENVIRON flags to DB_ENV->open. (This means that db_load can be used to load data into databases while they are in use by other processes.) If the DB_ENV->open call fails, or if no home directory is specified, the database is still updated, but the environment is ignored; for example, no locking is done.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
The -T option allows non-Berkeley DB applications to easily load text files into databases.
If the database to be created is of type Btree or Hash, or the keyword keys is specified as set, the input must be paired lines of text, where the first line of the pair is the key item, and the second line of the pair is its corresponding data item. If the database to be created is of type Queue or Recno and the keyword keys is not set, the input must be lines of text, where each line is a new data item for the database.
For this reason, any backslash or newline characters that naturally occur in the text input must be escaped to avoid misinterpretation by db_load.
If the -T option is specified, the underlying access method type must be specified using the -t option.
Specify the underlying access method. If no -t option is specified, the database will be loaded into a database of the same type as was dumped; for example, a Hash database will be created if a Hash database was dumped.
Btree and Hash databases may be converted from one to the other. Queue and Recno databases may be converted from one to the other. If the -k option was specified on the call to db_dump then Queue and Recno databases may be converted to Btree or Hash, with the key being the integer record number.
Write the library version number to the standard output, and exit.
The db_load utility may be used with a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, db_load should always be given the chance to detach from the environment and exit gracefully. To cause db_load to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The
Note that backslash characters naturally occurring in the text are escaped to avoid interpretation as escape characters by db_load.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
The following keywords are supported for the -c command-line option to the
utility. See DB->open for further discussion of these keywords and what values should be specified.
The parenthetical listing specifies how the value part of the name=value pair is interpreted. Items listed as (boolean) expect value to be 1 (set) or 0 (unset). Items listed as (number) convert value to a number. Items listed as (string) use the string value without modification.
The minimum number of keys per page.
Enable page checksums.
The database to load.
The byte order for integers in the stored database metadata.
The size of database pages, in bytes.
The value of the Db.DB_DUP flag.
The value of the Db.DB_DUPSORT flag.
The size of database extents, in pages, for Queue databases configured to use extents.
The density within the Hash database.
The size of the Hash database.
Specify whether keys are present for Queue or Recno databases.
Specify fixed-length records of the specified length.
Specify the fixed-length record pad character.
The value of the Db.DB_RECNUM flag.
The value of the Db.DB_RENUMBER flag.
The subdatabase to load.
The
utility is a debugging utility that dumps Berkeley DB log files in a human-readable format.
The options are as follows:
Specify a home directory for the database environment; by default, the current working directory is used.
Do not acquire shared region mutexes while running. Other problems, such as potentially fatal errors in Berkeley DB, will be ignored as well. This option is intended only for debugging errors, and should not be used under any other circumstances.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
Read the log files in reverse order.
Write the library version number to the standard output, and exit.
For more information on the
output and using it to debug applications, see Reviewing Berkeley DB log files.
The
utility uses a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment,
should always be given the chance to detach from the environment and exit gracefully. To cause
to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
The
utility must be run after an unexpected application, Berkeley DB, or system failure to restore the database to a consistent state. All committed transactions are guaranteed to appear after db_recover has run, and all uncommitted transactions will be completely undone.
The options are as follows:
Perform catastrophic recovery instead of normal recovery.
Retain the environment after running recovery. This option will rarely be used unless a DB_CONFIG file is present in the home directory. If a DB_CONFIG file is not present, then the regions will be created with default parameter values.
Specify a home directory for the database environment; by default, the current working directory is used.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
Recover to the time specified rather than to the most current possible date. The timestamp argument should be in the form [[CC]YY]MMDDhhmm[.SS] where each pair of letters represents the following:
The first two digits of the year (the century).
The second two digits of the year. If "YY" is specified, but "CC" is not, a value for "YY" between 69 and 99 results in a "YY" value of 19. Otherwise, a "YY" value of 20 is used.
The month of the year, from 1 to 12.
The day of the month, from 1 to 31.
The hour of the day, from 0 to 23.
The minute of the hour, from 0 to 59.
The second of the minute, from 0 to 61.
If the "CC" and "YY" letter pairs are not specified, the values default to the current year. If the "SS" letter pair is not specified, the value defaults to 0.
Write the library version number to the standard output, and exit.
Run in verbose mode.
In the case of catastrophic recovery, an archival copy -- or snapshot -- of all database files must be restored along with all of the log files written since the database file snapshot was made. (If disk space is a problem, log files may be referenced by symbolic links). For further information on creating a database snapshot, see Archival Procedures. For further information on performing recovery, see Recovery Procedures.
If the failure was not catastrophic, the files present on the system at the time of failure are sufficient to perform recovery.
If log files are missing, db_recover will identify the missing log file(s) and fail, in which case the missing log files need to be restored and recovery performed again.
The db_recover utility uses a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, db_recover should always be given the chance to detach from the environment and exit gracefully. To cause db_recover to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The db_recover utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
The
utility utility displays statistics for Berkeley DB environments.
The options are as follows:
Display internal information about the lock region. (The output from this option is often both voluminous and meaningless, and is intended only for debugging.)
Display all information.
Display lock conflict matrix.
Display lockers within hash chains.
Display region memory information.
Display objects within hash chains.
Display lock region parameters.
Display lock region statistics, as described in DB_ENV->lock_stat.
Display database statistics for the specified file, as described in DB->stat.
If the database contains multiple databases and the -s flag is not specified, the statistics are for the internal database that describes the other databases the file contains, and not for the file as a whole.
Display current environment statistics.
Display only those database statistics that can be acquired without traversing the database.
Specify a home directory for the database environment; by default, the current working directory is used.
Display log region statistics, as described in DB_ENV->log_stat.
Display internal information about the shared memory buffer pool. (The output from this option is often both voluminous and meaningless, and is intended only for debugging.)
Display all information.
Display buffers within hash chains.
Display region memory information.
Display shared memory buffer pool statistics, as described in DB_ENV->memp_stat.
Do not acquire shared region mutexes while running. Other problems, such as potentially fatal errors in Berkeley DB, will be ignored as well. This option is intended only for debugging errors, and should not be used under any other circumstances.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
Display replication statistics, as described in DB_ENV->rep_stat.
Display statistics for the specified database contained in the file specified with the -d flag.
Display transaction region statistics, as described in DB_ENV->txn_stat.
Write the library version number to the standard output, and exit.
Reset the statistics after reporting them; valid only with the -c, -e, -l, -m, and -t options.
Values normally displayed in quantities of bytes are displayed as a combination of gigabytes (GB), megabytes (MB), kilobytes (KB), and bytes (B). Otherwise, values smaller than 10 million are displayed without any special notation, and values larger than 10 million are displayed as a number followed by "M".
The
utility may be used with a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment,
should always be given the chance to detach from the environment and exit gracefully. To cause
to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
file ...
The
utility upgrades the Berkeley DB version of one or more files and the databases they contain to the current release version.
The options are as follows:
Specify a home directory for the database environment; by default, the current working directory is used.
Do not acquire shared region mutexes while running. Other problems, such as potentially fatal errors in Berkeley DB, will be ignored as well. This option is intended only for debugging errors, and should not be used under any other circumstances.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
This flag is only meaningful when upgrading databases from releases before the Berkeley DB 3.1 release.
As part of the upgrade from the Berkeley DB 3.0 release to the 3.1 release, the on-disk format of duplicate data items changed. To correctly upgrade the format requires that applications specify whether duplicate data items in the database are sorted or not. Specifying the -s flag means that the duplicates are sorted; otherwise, they are assumed to be unsorted. Incorrectly specifying the value of this flag may lead to database corruption.
Because the
utility upgrades a physical file (including all the databases it contains), it is not possible to use
to upgrade files where some of the databases it includes have sorted duplicate data items, and some of the databases it includes have unsorted duplicate data items. If the file does not have more than a single database, if the databases do not support duplicate data items, or if all the databases that support duplicate data items support the same style of duplicates (either sorted or unsorted),
will work correctly as long as the -s flag is correctly specified. Otherwise, the file cannot be upgraded using
and must be upgraded manually using the db_dump and db_load utilities.
Write the library version number to the standard output, and exit.
This means that if the system crashes during the upgrade procedure, or if the upgrade procedure runs out of disk space, the databases may be left in an inconsistent and unrecoverable state. See Upgrading databases for more information.
The
utility may be used with a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment,
should always be given the chance to detach from the environment and exit gracefully. To cause
to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
file ...
The
utility verifies the structure of one or more files and the databases they contain.
The options are as follows:
Specify a home directory for the database environment; by default, the current working directory is used.
Skip the database checks for btree and duplicate sort order and for hashing.
If the file being verified contains databases with non-default comparison or hashing configurations, calling the 
utility without the -o flag will usually return failure. The -o flag causes
to ignore database sort or hash ordering and allows
to be used on these files. To fully verify these files, verify them explicitly using the DB->verify method, after configuring the correct comparison or hashing functions.
Do not acquire shared region mutexes while running. Other problems, such as potentially fatal errors in Berkeley DB, will be ignored as well. This option is intended only for debugging errors, and should not be used under any other circumstances.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
Suppress the printing of any error descriptions, simply exit success or failure.
Write the library version number to the standard output, and exit.
utility does not perform any locking, even in Berkeley DB environments that are configured with a locking subsystem. As such, it should only be used on files that are not being modified by another thread of control.
The
utility may be used with a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, 
should always be given the chance to detach from the environment and exit gracefully. To cause 
to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
Create version diffs needs preversion
Upgrade the database to the current schema
Install the schema version tables to an existing database
Deploy the schema to the database
Select data from the schema
Insert data into the schema
Update data in the schema
Delete data from the schema
display this help
Supply the config file for parsing by Config::Any
The class of the schema to load
Where in the config to find the connection_info, supply in form MyApp::Model::DB
The resultset to operate on for data manipulation
The directory where sql diffs will be created
The RDBMs flavour you wish to use
Supply a version install
The previous version to diff against
Be forceful with some operations
Turn on DBIx::Class trace output
Be less verbose
You may distribute this code under the same terms as Perl itself
Create version diffs needs preversion
Upgrade the database to the current schema
Install the schema version tables to an existing database
Deploy the schema to the database
Select data from the schema
Insert data into the schema
Update data in the schema
Delete data from the schema
display this help
Supply the config file for parsing by Config::Any
The class of the schema to load
Where in the config to find the connection_info, supply in form MyApp::Model::DB
The resultset to operate on for data manipulation
The directory where sql diffs will be created
The RDBMs flavour you wish to use
Supply a version install
The previous version to diff against
Be forceful with some operations
Turn on DBIx::Class trace output
Be less verbose
You may distribute this code under the same terms as Perl itself
Create version diffs needs preversion
Upgrade the database to the current schema
Install the schema version tables to an existing database
Deploy the schema to the database
Select data from the schema
Insert data into the schema
Update data in the schema
Delete data from the schema
display this help
Supply the config file for parsing by Config::Any
The class of the schema to load
Where in the config to find the connection_info, supply in form MyApp::Model::DB
The resultset to operate on for data manipulation
The directory where sql diffs will be created
The RDBMs flavour you wish to use
Supply a version install
The previous version to diff against
Be forceful with some operations
Turn on DBIx::Class trace output
Be less verbose
You may distribute this code under the same terms as Perl itself
separate file for each run. Then compare using diff. (This example assumes
you're using a standard shell.)
will look like this:
separate file for each run. Then compare using diff. (This example assumes
you're using a standard shell.)
will look like this:
separate file for each run. Then compare using diff. (This example assumes
you're using a standard shell.)
will look like this:
See a report of the ten queries with the longest total runtime in the
See the top 10 most frequently run queries in the profile file
See the same report with 15 entries:
This tool is a command-line client for the DBI::ProfileData.  It
allows you to analyze the profile data file produced by
DBI::ProfileDumper and produce various useful reports.
This program accepts the following options:
Produce this many items in the report.  Defaults to 10.  If set to
Sort results by the given field. Sorting by multiple fields isn't currently
supported (patches welcome).  The available sort fields are:
Sorts by total time run time across all runs.  This is the default
sort.
Sorts by the longest single run.
Sorts by total number of runs.
Sorts by the time taken in the first run.
Sorts by the shortest single run.
Sorts by the value of the first element in the Path, which should be numeric.
Reverses the selected sort.  For example, to see a report of the
shortest overall time:
Consider only items where the specified key matches the given value.
Keys are numbered from 1.  For example, let's say you used a
DBI::Profile Path of:
And called dbiprof as in:
Your report would only show execute queries, leaving out prepares,
fetches, etc.
queries where key1 is the statement:
By default the match expression is matched case-insensitively, but
Remove items for where the specified key matches the given value.  For
example, to exclude all prepare entries where key2 is the method name:
By default the exclude expression is matched case-insensitively, but
case-sensitively.  Defaults to off.
files to be deleted after reading. See DBI::ProfileData for more details.
Print the list of nodes in the form of a perl data structure.
Print the dbiprof version number and exit.
Sam Tregar <sam@tregar.com>
Copyright (C) 2002 Sam Tregar
it under the same terms as Perl 5 itself.
DBI::ProfileDumper,
See a report of the ten queries with the longest total runtime in the
See the top 10 most frequently run queries in the profile file
See the same report with 15 entries:
This tool is a command-line client for the DBI::ProfileData.  It
allows you to analyze the profile data file produced by
DBI::ProfileDumper and produce various useful reports.
This program accepts the following options:
Produce this many items in the report.  Defaults to 10.  If set to
Sort results by the given field. Sorting by multiple fields isn't currently
supported (patches welcome).  The available sort fields are:
Sorts by total time run time across all runs.  This is the default
sort.
Sorts by the longest single run.
Sorts by total number of runs.
Sorts by the time taken in the first run.
Sorts by the shortest single run.
Sorts by the value of the first element in the Path, which should be numeric.
Reverses the selected sort.  For example, to see a report of the
shortest overall time:
Consider only items where the specified key matches the given value.
Keys are numbered from 1.  For example, let's say you used a
DBI::Profile Path of:
And called dbiprof as in:
Your report would only show execute queries, leaving out prepares,
fetches, etc.
queries where key1 is the statement:
By default the match expression is matched case-insensitively, but
Remove items for where the specified key matches the given value.  For
example, to exclude all prepare entries where key2 is the method name:
By default the exclude expression is matched case-insensitively, but
case-sensitively.  Defaults to off.
files to be deleted after reading. See DBI::ProfileData for more details.
Print the list of nodes in the form of a perl data structure.
Print the dbiprof version number and exit.
Sam Tregar <sam@tregar.com>
Copyright (C) 2002 Sam Tregar
it under the same terms as Perl 5 itself.
DBI::ProfileDumper,
See a report of the ten queries with the longest total runtime in the
See the top 10 most frequently run queries in the profile file
See the same report with 15 entries:
This tool is a command-line client for the DBI::ProfileData.  It
allows you to analyze the profile data file produced by
DBI::ProfileDumper and produce various useful reports.
This program accepts the following options:
Produce this many items in the report.  Defaults to 10.  If set to
Sort results by the given field. Sorting by multiple fields isn't currently
supported (patches welcome).  The available sort fields are:
Sorts by total time run time across all runs.  This is the default
sort.
Sorts by the longest single run.
Sorts by total number of runs.
Sorts by the time taken in the first run.
Sorts by the shortest single run.
Sorts by the value of the first element in the Path, which should be numeric.
Reverses the selected sort.  For example, to see a report of the
shortest overall time:
Consider only items where the specified key matches the given value.
Keys are numbered from 1.  For example, let's say you used a
DBI::Profile Path of:
And called dbiprof as in:
Your report would only show execute queries, leaving out prepares,
fetches, etc.
queries where key1 is the statement:
By default the match expression is matched case-insensitively, but
Remove items for where the specified key matches the given value.  For
example, to exclude all prepare entries where key2 is the method name:
By default the exclude expression is matched case-insensitively, but
case-sensitively.  Defaults to off.
files to be deleted after reading. See DBI::ProfileData for more details.
Print the list of nodes in the form of a perl data structure.
Print the dbiprof version number and exit.
Sam Tregar <sam@tregar.com>
Copyright (C) 2002 Sam Tregar
it under the same terms as Perl 5 itself.
DBI::ProfileDumper,
This tool is just a front end for the DBI::ProxyServer package. All it
does is picking options from the command line and calling
Available options include:
drivers in the config file or you have to create hard links to Unix
sockets, if your drivers are using them. For example, with MySQL, a
config file might contain the following lines:
Config files are assumed to return a single hash ref that overrides the
arguments of the new method. However, command line arguments in turn take
in the DBI::ProxyServer documentation for details on the config file.
Turn debugging mode on. Mainly this asserts that logging messages of
This is useful, if you want your server to bind to a privileged port
(<1024), but don't want the server to execute as root. See also
has. This attribute allows to restrict the server to the given
This attribute sets the port on which the daemon is listening. It
must be given somehow, as there's no default.
Be default logging messages will be written to the syslog (Unix) or
stderr. See Net::Daemon::Log for details.
The server can run in three different modes, depending on the environment.
If you are running Perl 5.005 and did compile it for threads, then the
server will create a new thread for each connection. The thread will
server will behave similar by creating a new process for each connection.
This mode will be used automatically in the absence of threads or if
Finally there's a single-connection mode: If the server has accepted a
for example on the Macintosh. For debugging purposes you can force this
given location. Default is to not create a pidfile.
This is useful, if you want your server to bind to a privileged port
(<1024), but don't want the server to execute as root. See also
Suppresses startup of the server; instead the version string will
be printed and the program exits immediately.
The DBI::ProxyServer module is free software; you can redistribute it
permission is granted to Tim Bunce for distributing this as a part of
This tool is just a front end for the DBI::ProxyServer package. All it
does is picking options from the command line and calling
Available options include:
drivers in the config file or you have to create hard links to Unix
sockets, if your drivers are using them. For example, with MySQL, a
config file might contain the following lines:
Config files are assumed to return a single hash ref that overrides the
arguments of the new method. However, command line arguments in turn take
in the DBI::ProxyServer documentation for details on the config file.
Turn debugging mode on. Mainly this asserts that logging messages of
This is useful, if you want your server to bind to a privileged port
(<1024), but don't want the server to execute as root. See also
has. This attribute allows to restrict the server to the given
This attribute sets the port on which the daemon is listening. It
must be given somehow, as there's no default.
Be default logging messages will be written to the syslog (Unix) or
stderr. See Net::Daemon::Log for details.
The server can run in three different modes, depending on the environment.
If you are running Perl 5.005 and did compile it for threads, then the
server will create a new thread for each connection. The thread will
server will behave similar by creating a new process for each connection.
This mode will be used automatically in the absence of threads or if
Finally there's a single-connection mode: If the server has accepted a
for example on the Macintosh. For debugging purposes you can force this
given location. Default is to not create a pidfile.
This is useful, if you want your server to bind to a privileged port
(<1024), but don't want the server to execute as root. See also
Supresses startup of the server; instead the version string will
be printed and the program exits immediately.
The DBI::ProxyServer module is free software; you can redistribute it
permission is granted to Tim Bunce for distributing this as a part of
This tool is just a front end for the DBI::ProxyServer package. All it
does is picking options from the command line and calling
Available options include:
drivers in the config file or you have to create hard links to Unix
sockets, if your drivers are using them. For example, with MySQL, a
config file might contain the following lines:
Config files are assumed to return a single hash ref that overrides the
arguments of the new method. However, command line arguments in turn take
in the DBI::ProxyServer documentation for details on the config file.
Turn debugging mode on. Mainly this asserts that logging messages of
This is useful, if you want your server to bind to a privileged port
(<1024), but don't want the server to execute as root. See also
has. This attribute allows to restrict the server to the given
This attribute sets the port on which the daemon is listening. It
must be given somehow, as there's no default.
Be default logging messages will be written to the syslog (Unix) or
stderr. See Net::Daemon::Log for details.
The server can run in three different modes, depending on the environment.
If you are running Perl 5.005 and did compile it for threads, then the
server will create a new thread for each connection. The thread will
server will behave similar by creating a new process for each connection.
This mode will be used automatically in the absence of threads or if
Finally there's a single-connection mode: If the server has accepted a
for example on the Macintosh. For debugging purposes you can force this
given location. Default is to not create a pidfile.
This is useful, if you want your server to bind to a privileged port
(<1024), but don't want the server to execute as root. See also
Suppresses startup of the server; instead the version string will
be printed and the program exits immediately.
The DBI::ProxyServer module is free software; you can redistribute it
permission is granted to Tim Bunce for distributing this as a part of


 
 
 
 

 
 
 
 

 
 
 
 
 
-d
crypt encryption (default, except on Win32, Netware)  
-m
MD5 encryption (default on Win32, Netware)  
-s
SHA1 encryption  
-p
  
 
 
add
adduser
check
delete
import
update
view
  
 
 
 
 
dc [-V] [--version] [-h] [--help]
   [-e scriptexpression] [--expression=scriptexpression]
   [-f scriptfile] [--file=scriptfile]
   [file ...]
unlimited precision arithmetic.
It also allows you to define and call macros.
if any command arguments are given to it, they are filenames,
from standard input.
All normal output is to standard output;
all error output is to standard error.
A reverse-polish calculator stores numbers on a stack.
Entering a number pushes it on the stack.
Arithmetic operations pop arguments off the stack and push the results.
To enter a number in
type the digits with an optional decimal point.
Exponential notation is not supported.
To enter a negative number,
begin the number with ``_''.
``-'' cannot be used for this,
as it is a binary operator for subtraction instead.
To enter two numbers in succession,
separate them with spaces or newlines.
These have no meaning as commands.
then exit.
Print a usage message briefly summarizing these command-line options
and the bug-reporting address,
then exit.
Add the commands in
to the set of commands to be run while processing the input.
Add the commands contained in the file
to the set of commands to be run while processing the input.
If any command-line parameters remain after processing the above,
these parameters are interpreted as the names of input files to
be processed.
A file name of
refers to the standard input stream.
The standard input will processed if no file names are specified.
Printing Commands
Prints the value on the top of the stack,
without altering the stack.
A newline is printed after the value.
Prints the value on the top of the stack, popping it off,
and does not print a newline after.
Pops off the value on top of the stack.
If it it a string, it is simply printed without a trailing newline.
Otherwise it is a number, and the integer portion of its absolute
value is printed out as a "base (UCHAR_MAX+1)" byte stream.
Assuming that (UCHAR_MAX+1) is 256
(as it is on most machines with 8-bit bytes),
could also accomplish this function,
except for the side-effect of clobbering the x register.
Prints the entire contents of the stack
and the contents of all of the registers,
without altering anything.
This is a good command to use if you are lost or want
to figure out what the effect of some command has been.
Arithmetic
Pops two values off the stack, adds them,
and pushes the result.
The precision of the result is determined only
by the values of the arguments,
and is enough to be exact.
Pops two values,
subtracts the first one popped from the second one popped,
and pushes the result.
Pops two values, multiplies them, and pushes the result.
The number of fraction digits in the result depends on
the current precision value and the number of fraction
digits in the two arguments.
Pops two values,
divides the second one popped from the first one popped,
and pushes the result.
The number of fraction digits is specified by the precision value.
Pops two values,
computes the remainder of the division that the
command would do,
and pushes that.
The value computed is the same as that computed by
Pops two values,
divides the second one popped from the first one popped.
The quotient is pushed first, and the remainder is pushed next.
The number of fraction digits used in the division
is specified by the precision value.
this function, with slightly different error checking.)
Pops two values and exponentiates,
using the first value popped as the exponent
and the second popped as the base.
The fraction part of the exponent is ignored.
The precision value specifies the number of fraction
digits in the result.
Pops three values and computes a modular exponentiation.
The first value popped is used as the reduction modulus;
this value must be a non-zero number,
and should be an integer.
The second popped is used as the exponent;
this value must be a non-negative number,
and any fractional part of this exponent will be ignored.
The third value popped is the base which gets exponentiated,
which should be an integer.
Pops one value,
computes its square root,
and pushes that.
The precision value specifies the number of fraction digits in the result.
Most arithmetic operations are affected by the ``precision value'',
which you can set with the
command.
The default precision value is zero,
which means that all arithmetic except for
addition and subtraction produces integer results.
Stack Control
Clears the stack, rendering it empty.
Duplicates the value on the top of the stack,
pushing another copy of it.
Thus, ``4d*p'' computes 4 squared and prints it.
Reverses the order of (swaps) the top two values on the stack.
Registers
each named by a single character.
You can store a number or a string in a register and retrieve it later.
Pop the value off the top of the stack and store
it into register
Copy the value in register
and push it onto the stack.
This does not alter the contents of
Each register also contains its own stack.
The current register value is the top of the register's stack.
Pop the value off the top of the (main) stack and
push it onto the stack of register
The previous value of the register becomes inaccessible.
Pop the value off the top of register
stack and push it onto the main stack.
The previous value
in register
stack, if any,
is now accessible via the
command.
The
command prints a list of all registers that have contents stored in them,
together with their contents.
Only the current contents of each register
(the top of its stack)
is printed.
Parameters
the precision, the input radix, and the output radix.
The precision specifies the number
of fraction digits to keep in the result of most arithmetic operations.
The input radix controls the interpretation of numbers typed in;
all numbers typed in use this radix.
The output radix is used for printing numbers.
The input and output radices are separate parameters;
you can make them unequal,
which can be useful or confusing.
The input radix must be between 2 and 16 inclusive.
The output radix must be at least 2.
The precision must be zero or greater.
The precision is always measured in decimal digits,
regardless of the current input or output radix.
Pops the value off the top of the stack
and uses it to set the input radix.
Pops the value off the top of the stack
and uses it to set the output radix.
Pops the value off the top of the stack
and uses it to set the precision.
Pushes the current input radix on the stack.
Pushes the current output radix on the stack.
Pushes the current precision on the stack.
Strings
The only things you can do with strings are
print them and execute them as macros
(which means that the contents of the string are processed as
All registers and the stack can hold strings,
Some commands such as arithmetic operations demand numbers
as arguments and print errors if given strings.
Other commands can accept either a number or a string;
for example, the
command can accept either and prints the object
according to its type.
Makes a string containing
(contained between balanced
and
characters),
and pushes it on the stack.
For example,
prints the characters
(with no newline).
The top-of-stack is popped.
If it was a number, then the low-order byte of this number
is converted into a string and pushed onto the stack.
Otherwise the top-of-stack was a string,
and the first character of that string is pushed back.
Pops a value off the stack and executes it as a macro.
Normally it should be a string;
if it is a number,
it is simply pushed back onto the stack.
For example,
executes the macro
which pushes
on the stack and prints
on a separate line.
Macros are most often stored in registers;
stores a macro to print
into register
and
invokes this macro.
Pops two values off the stack and compares them
assuming they are numbers,
executing the contents of register
as a macro if the original top-of-stack
is greater.
Thus,
will invoke register
contents and
will not.
Similar but invokes the macro if the original top-of-stack is
not greater than (less than or equal to) what was the second-to-top.
Similar but invokes the macro if the original top-of-stack is less.
Similar but invokes the macro if the original top-of-stack is
not less than (greater than or equal to) what was the second-to-top.
Similar but invokes the macro if the two numbers popped are equal.
Similar but invokes the macro if the two numbers popped are not equal.
This can also be validly used to compare two strings for equality.
Reads a line from the terminal and executes it.
This command allows a macro to request input from the user.
exits from a macro and also from the macro which invoked it.
If called from the top level,
or from a macro which was called directly from the top level,
the
Pops a value off the stack and uses it as a count
of levels of macro execution to be exited.
Thus,
exits three levels.
The
Status Inquiry
Pops a value off the stack,
calculates the number of digits it has
(or number of characters, if it is a string)
and pushes that number.
Pops a value off the stack,
calculates the number of fraction digits it has,
and pushes that number.
For a string,
the value pushed is
0.
Pushes the current stack depth:
the number of objects on the stack before the execution of the
command.
Miscellaneous
Will run the rest of the line as a system command.
Note that parsing of the !<, !=, and !> commands take precedence,
so if you want to run a command starting with <, =, or > you will
need to add a space after the !.
Will interpret the rest of the line as a comment.
Will pop the top two values off of the stack.
The old second-to-top value will be stored in the array
indexed by the old top-of-stack value.
Pops the top-of-stack and uses it as an index into
the array
The selected value is then pushed onto the stack.
Note that each stacked instance of a register has its own
array associated with it.
because the 2 was stored in an instance of 0:a that
was later popped.
BUGS
Email bug reports to
The
utility copies the standard input to the standard output.
Input data is read and written in 512-byte blocks.
If input reads are short, input from multiple reads are aggregated
to form the output block.
When finished,
displays the number of complete and partial input and output blocks
and truncated input records to the standard error output.
The following operands are available:
Set both input and output block size to
bytes, superseding the
and
operands.
If no conversion values other than
or
are specified, then each input block is copied to the output as a
single block without any aggregation of short blocks.
Set the conversion record size to
bytes.
The conversion record size is required by the record oriented conversion
values.
Copy only
input blocks.
Copy
input files before terminating.
This operand is only applicable when the input device is a tape.
Set the input block size to
bytes instead of the default 512.
Read input from
instead of the standard input.
Seek on the input file
blocks.
This is synonymous with
Set the output block size to
bytes instead of the default 512.
Write output to
instead of the standard output.
Any regular output file is truncated unless the
conversion value is specified.
If an initial portion of the output file is seeked past (see the
operand),
the output file is truncated at that point.
Seek on the output file
blocks.
This is synonymous with
Seek
blocks from the beginning of the output before copying.
On non-tape devices, an
operation is used.
Otherwise, existing blocks are read and the data discarded.
If the user does not have read permission for the tape, it is positioned
using the tape
function calls.
If the seek operation is past the end of file, space from the current
end of file to the specified offset is filled with blocks of
bytes.
Skip
blocks from the beginning of the input before copying.
On input which supports seeks, an
operation is used.
Otherwise, input data is read and discarded.
For pipes, the correct number of bytes is read.
For all other devices, the correct number of blocks is read without
distinguishing between a partial or complete block being read.
Where
is one of the symbols from the following list.
The same as the
value except that characters are translated from
to
before the
records are converted.
(These values imply
if the operand
is also specified.)
There are two conversion maps for
The value
specifies the recommended one which is compatible with
The value
specifies the one used in historic
and
systems.
Treats the input as a sequence of newline or end-of-file terminated variable
length records independent of input and output block boundaries.
Any trailing newline character is discarded.
Each input record is converted to a fixed length output record where the
length is specified by the
operand.
Input records shorter than the conversion record size are padded with spaces.
Input records longer than the conversion record size are truncated.
The number of truncated input records, if any, are reported to the standard
error output at the completion of the copy.
The same as the
value except that characters are translated from
to
after the
records are converted.
(These values imply
if the operand
is also specified.)
There are four conversion maps for
The value
specifies the recommended one which is compatible with
The value
is a slightly different mapping, which is compatible with the
value.
The values
and
are maps used in historic
and
systems.
Transform uppercase characters into lowercase characters.
Do not stop processing on an input error.
When an input error occurs, a diagnostic message followed by the current
input and output block counts will be written to the standard error output
in the same format as the standard completion message.
If the
conversion is also specified, any missing input data will be replaced
with
bytes (or with spaces if a block oriented conversion value was
specified) and processed as a normal input buffer.
If the
conversion is not specified, the input block is omitted from the output.
On input files which are not tapes or pipes, the file offset
will be positioned past the block in which the error occurred using
Do not truncate the output file.
This will preserve any blocks in the output file not explicitly written
by
The
value is not supported for tapes.
Pad the final output block to the full output block size.
If the input file is not a multiple of the output block size
after conversion, this conversion forces the final output block
to be the same size as preceding blocks for use on devices that require
regularly sized blocks to be written.
This option is incompatible with use of the
block size specification.
If one or more output blocks would consist solely of
bytes, try to seek the output file by the required space instead of
filling them with
resulting in a sparse file.
Swap every pair of input bytes.
If an input buffer has an odd number of bytes, the last byte will be
ignored during swapping.
Pad every input block to the input buffer size.
Spaces are used for pad bytes if a block oriented conversion value is
specified, otherwise
bytes are used.
Transform lowercase characters into uppercase characters.
Treats the input as a sequence of fixed length records independent of input
and output block boundaries.
The length of the input records is specified by the
operand.
Any trailing space characters are discarded and a newline character is
appended.
Where sizes are specified, a decimal, octal, or hexadecimal number of
bytes is expected.
If the number ends with a
or
the
number is multiplied by 512, 1024 (1K), 1048576 (1M), 1073741824 (1G)
or the number of bytes in an integer, respectively.
Two or more numbers may be separated by an
to indicate a product.
When finished,
displays the number of complete and partial input and output blocks,
truncated input records and odd-length byte-swapping blocks to the
standard error output.
A partial input block is one where less than the input block size
was read.
A partial output block is one where less than the output block size
was written.
Partial output blocks to tape devices are considered fatal errors.
Otherwise, the rest of the block will be written.
Partial output blocks to character devices will produce a warning message.
A truncated input block is one where a variable length record oriented
conversion value was specified and the input line was too long to
fit in the conversion record or was not newline terminated.
Normally, data resulting from input or conversion or both are aggregated
into output blocks of the specified size.
After the end of input is reached, any remaining output is written as
a block.
This means that the final output block may be shorter than the output
block size.
If
receives a
(see the
argument for
signal, the current input and output block counts will
be written to the standard error output
in the same format as the standard completion message.
If
receives a
signal, the current input and output block counts will
be written to the standard error output
in the same format as the standard completion message and
will exit.
The
utility is expected to be a superset of the
standard.
The
operand and the
and
values are extensions to the
standard.
Usage:
Where the options are:
Each file is expected to be a BinHex file.  By default, the output file is
given the name that the BinHex file dictates, regardless of the name of
the BinHex file.
Largely untested.
his grubby paws off anything...
SXren M. Andersen (somian), made it actually work under Perl 5.8.7 on MSWin32.
Usage:
Where the options are:
Each file is expected to be a BinHex file.  By default, the output file is
given the name that the BinHex file dictates, regardless of the name of
the BinHex file.
Largely untested.
his grubby paws off anything...
SXren M. Andersen (somian), made it actually work under Perl 5.8.7 on MSWin32.
read
read-type 
write
}
rename
delete 
| find
}
allows users to read, write, and delete Mac OS X user defaults from a command-line shell. Mac OS X applications and other programs use the defaults system to record user preferences and other information that must be maintained when the applications aren't running (such as default font for new documents, or the position of an Info panel). Much of this information is accessible through an application's Preferences panel, but some of it isn't, such as the position of the Info panel. You can access this information with
Since applications do access the defaults system while they're running, you shouldn't modify the defaults of a running application. If you change a default in a domain that belongs to a running application, the application won't see the change and might even overwrite the default.
User defaults belong to
Though all applications, system services, and other programs have their own domains, they also share a domain named
If a default isn't specified in the application's domain, but is specified in
then the application uses the value in that domain.
The commands are as follows:
Prints all of the user's defaults, for every domain, to standard output.
Prints all of the user's defaults for
to standard output.
Prints the value for the default of
identified by
Prints the plist type for the given
identified by
Writes
as the value for
in
must be a property list, and must be enclosed in single quotes.
For example:
defaults write com.companyname.appname "Default Color" '(255, 0, 0)'
sets the value for Default Color to an array containing the strings 255, 0, 0 (the red, green, and blue components). Note that the key is enclosed in quotation marks because it contains a space.
Overwrites the defaults information in
with that given as
must be a property list representation of a dictionary, and must be enclosed in single quotes.
For example: 
defaults write com.companyname.appname '{ "Default Color" = (255, 0, 0);
				"Default Font" = Helvetica; }';
erases any previous defaults for com.companyname.appname and writes the values for the two names into the defaults system.
Removes all default information for
Removes the default named
from
Prints the names of all domains in the user's defaults system.
Searches for
in the domain names, keys, and values of the user's defaults, and prints out a list of matches.
Prints a list of possible command formats.
Example:
defaults read com.apple.TextEdit
defaults read -app TextEdit
Domains may also be specified as a path to an arbitrary plist file, with or without the '.plist' extension. For example:
normally gives the same result as the two previous examples.
In the following example:
will write the key 'foo' with the value 'bar' into the plist file 'TestFile.plist' that is on the user's desktop. If the file does not exist, it will be created. If it does exist, the key-value pair will be added, overwriting the value of 'foo' if it already existed.
WARNING: The defaults command will be changed in an upcoming major release to only operate on preferences domains. General plist manipulation utilities will be folded into a different command-line program.
If no type flag is provided,
will assume the value is a string. For best results, use one of the type flags, listed below. 
Allows the user to specify a string as the value for the given preference key.
Allows the user to specify a bunch of raw data bytes as the value for the given preference key. 
The data must be provided in hexidecimal.
Allows the user to specify an integer as the value for the given preference key.
Allows the user to specify a floating point number as the value for the given preference key.
Allows the user to specify a boolean as the value for the given preference key.
Value must be TRUE, FALSE, YES, or NO.
Allows the user to specify a date as the value for the given preference key.
Allows the user to specify an array as the value for the given preference key:
defaults write somedomain preferenceKey -array element1 element2 element3
The specified array overwrites the value of the key if the key was present at the time of the write. If the key was not present, it is created with the new value.
Allows the user to add new elements to the end of an array for a key which has an array as its value. Usage is the same as -array above. If the key was not present, it is created with the specified array as its value.
Allows the user to add a dictionary to the defaults database for a domain.  Keys and values are specified in order:
defaults write somedomain preferenceKey -dict key1 value1 key2 value2
The specified dictionary overwrites the value of the key if the key was present at the time of the write. If the key was not present, it is created with the new value.
Operations on the defaults database normally apply to any host the user may log in on, but may be restricted to apply only to a specific host. 
If no host is provided, preferences operations will apply to any host the user may log in on.
Restricts preferences operations to the host the user is currently logged in on.
Defaults can be structured in very complex ways, making it difficult for the user to enter them with this command.
First appeared in NeXTStep.
The
utility
displays statistics about the amount of free disk space on the specified
or on the filesystem of which
is a part.
Values are displayed in 512-byte per block counts.
If neither a file or a filesystem operand is specified,
statistics for all mounted filesystems are displayed
(subject to the
option below).
The following options are available:
Show all mount points, including those that were mounted with the MNT_IGNORE
flag.
Use (the default) 512-byte blocks.
This is only useful as a way to override an
specification from the environment.
Use 1073741824-byte (1-Gbyte) blocks rather than the default.
Note that this overrides the
specification from the environment.
"Human-readable" output.  Use unit suffixes: Byte, Kilobyte, Megabyte,
Gigabyte, Terabyte and Petabyte in order to reduce the number of
digits to three or less using base 10 for sizes.
"Human-readable" output.  Use unit suffixes: Byte, Kilobyte, Megabyte,
Gigabyte, Terabyte and Petabyte in order to reduce the number of
digits to three or less using base 2 for sizes.
Include statistics on the number of free inodes. This option is now the default to conform to
Use
to suppress this output.
Use 1024-byte (1-Kbyte) blocks, rather than the default.
Note that this overrides the
specification from the environment.
Only display information about locally-mounted filesystems.
Use 1048576-byte (1-Mbyte) blocks rather than the default.  Note that
this overrides the
specification from the environment.
Print out the previously obtained statistics from the filesystems.
This option should be used if it is possible that one or more
filesystems are in a state such that they will not be able to provide
statistics without a long delay.
When this option is specified,
will not request new statistics from the filesystems, but will respond
with the possibly stale statistics that were previously obtained.
Use (the default) 512-byte blocks.
This is only useful as a way to override an
specification from the environment.
Only print out statistics for filesystems of the specified types.
More than one type may be specified in a comma separated list.
The list of filesystem types can be prefixed with
to specify the filesystem types for which action should
be taken.
For example, the
command:
df -T nonfs,mfs
lists all filesystems except those of type
and
The
command can be used to find out the types of filesystems
that are available on the system.
If used with no arguments,
this option is a no-op
(Mac OS X already prints the total allocated-space figures).
If used with an argument, it acts like
but this usage is deprecated and should not be relied upon.
If the environment variable
is set, the block counts will be displayed in units of that size block.
The
and
flags are ignored if a file or filesystem is specified.
The "capacity" percentage is normally rounded up to the next higher integer.
In legacy mode, it is rounded down to the next lower integer.
When the
option and the
option are used together,
sizes are reported in 1024-blocks.
In legacy mode, when the
option and
option are used together,
the last option specified dictates the reported block size.
The
option is normally a no-op
(Mac OS X already prints the total allocated-space figures).
In legacy mode, it is equivalent to
For more information about legacy mode, see
A
command appeared in
Compare files line by line.
Ignore case differences in file contents.
Ignore case when comparing file names.
Consider case when comparing file names.
Ignore changes due to tab expansion.
Ignore changes in the amount of white space.
Ignore all white space.
Ignore changes whose lines are all blank.
Ignore changes whose lines all match RE.
Strip trailing carriage return on input.
Treat all files as text.
Output NUM (default 3) lines of copied context.
Output NUM (default 3) lines of unified context.
Use LABEL instead of file name.
Show which C function each change is in.
Show the most recent line matching RE.
Output only whether files differ.
Output an ed script.
Output a normal diff.
Output an RCS format diff.
Output in two columns.
Output at most NUM (default 130) print columns.
Output only the left column of common lines.
Do not output common lines.
Output merged file to show `#ifdef NAME' diffs.
Similar, but format GTYPE input groups with GFMT.
Similar, but format all input lines with LFMT.
Similar, but format LTYPE input lines with LFMT.
LTYPE is `old', `new', or `unchanged'.
GTYPE is LTYPE or `changed'.
GFMT may contain:
%<
lines from FILE1
%>
lines from FILE2
%=
lines common to FILE1 and FILE2
%[-][WIDTH][.[PREC]]{doxX}LETTER
printf-style spec for LETTER
LETTERs are as follows for new group, lower case for old group:
F
first line number
L
last line number
N
number of lines = L-F+1
E
F-1
M
L+1
LFMT may contain:
%L
contents of line
%l
contents of line, excluding any trailing newline
%[-][WIDTH][.[PREC]]{doxX}n
printf-style spec for input line number
Either GFMT or LFMT may contain:
%%
%
%c'C'
the single character C
the character with octal code OOO
Pass the output through `pr' to paginate it.
Expand tabs to spaces in output.
Make tabs line up by prepending a tab.
Recursively compare any subdirectories found.
Treat absent files as empty.
Treat absent first files as empty.
Report when two files are the same.
Exclude files that match PAT.
Exclude files that match any pattern in FILE.
Start with FILE when comparing directories.
Compare FILE1 to all operands.  FILE1 can be a directory.
Compare all operands to FILE2.  FILE2 can be a directory.
Keep NUM lines of the common prefix and suffix.
Try hard to find a smaller set of changes.
Assume large files and many scattered small changes.
Output version info.
Output this help.
FILES are `FILE1 FILE2' or `DIR1 DIR2' or `DIR FILE...' or `FILE... DIR'.
If a FILE is `-', read standard input.
Written by Paul Eggert, Mike Haertel, David Hayes,
Richard Stallman, and Len Tower.
Report bugs to <bug-gnu-utils@gnu.org>.
This program comes with NO WARRANTY, to the extent permitted by law.
You may redistribute copies of this program
under the terms of the GNU General Public License.
For more information about these matters, see the file named COPYING.
The full documentation for
is maintained as a Texinfo manual.  If the
and
programs are properly installed at your site, the command
should give you access to the complete manual.
Compare three files line by line.
Output unmerged changes from OLDFILE to YOURFILE into MYFILE.
Output unmerged changes, bracketing conflicts.
Output all changes, bracketing conflicts.
Output overlapping changes.
Output overlapping changes, bracketing them.
Output unmerged nonoverlapping changes.
Use LABEL instead of file name.
Append `w' and `q' commands to ed scripts.
Treat all files as text.
Make tabs line up by prepending a tab.
Use PROGRAM to compare files.
Output version info.
Output this help.
If a FILE is `-', read standard input.
Written by Randy Smith.
Report bugs to <bug-gnu-utils@gnu.org>.
This program comes with NO WARRANTY, to the extent permitted by law.
You may redistribute copies of this program
under the terms of the GNU General Public License.
For more information about these matters, see the file named COPYING.
The full documentation for
is maintained as a Texinfo manual.  If the
and
programs are properly installed at your site, the command
should give you access to the complete manual.
of the insertions, deletions, and modifications per-file.
Diffstat is a program that is useful for reviewing large, complex patch files.
producing a histogram of the total lines changed for each file referenced.
If the input filename ends with .bz2, .gz, .lzma, .z or .Z,
diffstat will read the
uncompressed data via a pipe from the corresponding program.
It also can infer the compression type from files piped via the standard input.
Diffstat recognizes the most popular types of output from diff:
unified
context
best for readability, but not very compact.
default
not good for much, but simple to generate.
tell which files are compared, and then counts the markers in the
first column that denote the type of change (insertion, deletion
or modification).
If no filename is given on the command line,
ignore lines matching "Binary files XXX and YYY differ" in the diff
prefix each line of output with "#", making it a comment-line for shell
scripts.
add SGR color escape sequences to highlight the histogram.
specify a directory containing files which can be referred to as
the result of applying the differences.
to obtain the total number of lines in each file.
The remainder, after subtracting modified and deleted lines,
is shown as "unchanged lines".
specify the format of the histogram.
0
for concise, which shows only the value and a single histogram code for each of
insert (+),
modify (!)
1
for normal output,
2
to fill in the histogram with dots,
4
to print each value with the histogram.
Any nonzero value gives a histogram.
The dots and individual values can be combined,
prints the usage message and exits.
suppress the merging of filenames in the report.
lists only the filenames.
No histogram is generated.
approximate a count of the modified lines.
specify the minimum width used for filenames.
filename, after stripping common prefixes.
specify the maximum width used for filenames.
Names longer than this limit are truncated on the left.
suppress the "0 files changed" message for empty diffs.
provides optional rounding of the data shown in histogram,
rather than truncating with error adjustments.
0
is the default.
No rounding is performed,
but accumulated errors are added to following columns.
1
rounds the data
2
rounds the data and adjusts the histogram to ensure that
it displays something if there are any differences even if
those would normally be rounded to zero.
Assume patch was created with old and new files swapped.
show only the summary line, e.g., number of insertions and deletions.
the original files (before applying differences) can be found.
overrides the histogram,
generates output of comma separated values.
suppress the sorting of filenames in the report.
show progress,
e.g., if the output is redirected to a file,
write progress messages to the standard error.
prints the current version number and exits.
specify the maximum width of the histogram.
The histogram will never be shorter than 10 columns,
just in case the filenames get too large.
You can override the compiled-in paths of programs used for decompressing
input files by setting environment variables corresponding to their name:
DIFFSTAT_BZCAT_PATH
DIFFSTAT_BZIP2_PATH
DIFFSTAT_COMPRESS_PATH
DIFFSTAT_GZIP_PATH
DIFFSTAT_LZCAT_PATH
DIFFSTAT_PCAT_PATH
DIFFSTAT_UNCOMPRESS_PATH
DIFFSTAT_XZ_PATH
DIFFSTAT_ZCAT_PATH
There is no way to obtain a filename from the standard diff between
two files with no options.
Context diffs work,
as well as unified diffs.
There's no easy way to determine the degree of overlap between the
"before" and "after" displays of modified lines.
Thomas Dickey <dickey@invisible-island.net>.
(domain information groper) is a flexible tool for interrogating DNS name servers. It performs DNS lookups and displays the answers that are returned from the name server(s) that were queried. Most DNS administrators use
to troubleshoot DNS problems because of its flexibility, ease of use and clarity of output. Other lookup tools tend to have less functionality than
Although
option is given. Unlike earlier versions, the BIND 9 implementation of
allows multiple lookups to be issued from the command line.
Unless it is told to query a specific name server,
will try each of the servers listed in
When no command line arguments or options are given,
will perform an NS query for "." (the root).
via
The IN and CH class names overlap with the IN and CH top level domains names. Either use the
and
options to specify the type and class, use the
the specify the domain name, or use "IN." and "CH." when looking up these top level domains.
A typical invocation of
looks like:
 dig @server name type 
where:
argument is a hostname,
resolves that name before querying that name server. If no
argument is provided,
consults
and queries the name servers listed there. The reply from the name server that responds is displayed.
is the name of the resource record that is to be looked up.
can be any valid query type. If no
argument is supplied,
will perform a lookup for an A record.
The
option sets the source IP address of the query to
The default query class (IN for internet) is overridden by the
option.
is any valid class, such as HS for Hesiod records or CH for Chaosnet records.
The
option makes
operate in batch mode by reading a list of lookup requests to process from the file
The
option enables memory usage debugging.
option is used.
is the port number that
The
option forces
to only use IPv4 query transport. The
option forces
to only use IPv6 query transport.
The
option sets the query type to
option is supplied to indicate a reverse lookup. A zone transfer can be requested by specifying a type of AXFR. When an incremental zone transfer (IXFR) is required,
is set to
ixfr=N. The incremental zone transfer will contain the changes made to the zone since the serial number in the zone's SOA record was
The
option sets the query name to
from other arguments.
option.
and
arguments.
automatically performs a lookup for a name like
and sets the query type and class to PTR and IN respectively. By default, IPv6 addresses are looked up using nibble format under the IP6.ARPA domain. To use the older RFC1886 method using the IP6.INT domain specify the
option. Bit string labels (RFC2874) are now experimental and are not attempted.
To sign the DNS queries sent by
and their responses using transaction signatures (TSIG), specify a TSIG key file using the
option. You can also specify the TSIG key itself on the command line using the
option;
is the name of the TSIG key and
or in the shell's history file. When using TSIG authentication with
and
statements in
The
command does not use the host name and address resolution or the DNS query routing mechanisms used by other processes running on Mac OS X.
The results of name or address queries printed by
may differ from those found by other processes that use the Mac OS X native name and address resolution mechanisms.
The results of DNS queries may also differ from queries that use the Mac OS X DNS routing library.
provides a number of query options which affect the way in which lookups are made and the results displayed. Some of these set or reset flag bits in the query header, some determine which sections of the answer get printed, and others determine the timeout and retry strategies.
Each query option is identified by a keyword preceded by a plus sign (+). Some keywords set or reset an option. These may be preceded by the string
no
to negate the meaning of that keyword. Other keywords assign values to options like the timeout interval. They have the form
Use [do not use] TCP when querying name servers. The default behavior is to use UDP unless an AXFR or IXFR query is requested, in which case a TCP connection is used.
Use [do not use] TCP when querying name servers. This alternate syntax to
is provided for backwards compatibility. The "vc" stands for "virtual circuit".
Ignore truncation in UDP responses instead of retrying with TCP. By default, TCP retries are performed.
Set the search list to contain the single domain
directive in
option were given.
Use [do not use] the search list defined by the searchlist or domain directive in
(if any). The search list is not used by default.
Perform [do not perform] a search showing intermediate results.
Deprecated, treated as a synonym for
Sets the "aa" flag in the query.
A synonym for
Set [do not set] the CD (checking disabled) bit in the query. This requests the server to not perform DNSSEC validation of responses.
Display [do not display] the CLASS when printing the record.
Display [do not display] the TTL when printing the record.
Toggle the setting of the RD (recursion desired) bit in the query. This bit is set by default, which means
normally sends recursive queries. Recursion is automatically disabled when the
or
query options are used.
When this option is set,
attempts to find the authoritative name servers for the zone containing the name being looked up and display the SOA record that each name server has for the zone.
Toggle tracing of the delegation path from the root name servers for the name being looked up. Tracing is disabled by default. When tracing is enabled,
makes iterative queries to resolve the name being looked up. It will follow referrals from the root servers, showing the answer from each server that was used to resolve the lookup.
Toggles the printing of the initial comment in the output identifying the version of
and the query options that have been applied. This comment is printed by default.
Provide a terse answer. The default is to print the answer in a verbose form.
Show [or do not show] the IP address and port number that supplied the answer when the
option is enabled. If short form answers are requested, the default is not to show the source address and port number of the server that provided the answer.
Toggle the display of comment lines in the output. The default is to print comments.
This query option toggles the printing of statistics: when the query was made, the size of the reply and so on. The default behavior is to print the query statistics.
Print [do not print] the query as it is sent. By default, the query is not printed.
Print [do not print] the question section of a query when an answer is returned. The default is to print the question section as a comment.
Display [do not display] the answer section of a reply. The default is to display it.
Display [do not display] the authority section of a reply. The default is to display it.
Display [do not display] the additional section of a reply. The default is to display it.
Set or clear all display flags.
Sets the timeout for a query to
seconds. The default timeout is 5 seconds. An attempt to set
to less than 1 will result in a query timeout of 1 second being applied.
Sets the number of times to try UDP queries to server to
instead of the default, 3. If
is less than or equal to zero, the number of tries is silently rounded up to 1.
Sets the number of times to retry UDP queries to server to
instead of the default, 2. Unlike
Set the number of dots that have to appear in
to
for it to be considered absolute. The default value is that defined using the ndots statement in
or
directive in
Set the UDP message buffer size advertised using EDNS0 to
bytes. The maximum and minimum sizes of this buffer are 65535 and 0 respectively. Values outside this range are rounded up or down appropriately. Values other than zero will cause a EDNS query to be sent.
Specify the EDNS version to query with. Valid values are 0 to 255. Setting the EDNS version will cause a EDNS query to be sent.
clears the remembered EDNS version.
output.
Print only one (starting) SOA record when performing an AXFR. The default is to print both the starting and ending SOA records.
Do not try the next server if you receive a SERVFAIL. The default is to not try the next server which is the reverse of normal stub resolver behavior.
Attempt to display the contents of messages which are malformed. The default is to not display malformed answers.
Requests DNSSEC records be sent by setting the DNSSEC OK bit (DO) in the OPT record in the additional section of the query.
Specifies a file containing trusted keys to be used with
If not specified,
will look for
then
in the current directory.
Include an EDNS name server ID request when sending a query.
The BIND 9 implementation of
supports specifying multiple queries on the command line (in addition to supporting the
batch file option). Each of those queries can be supplied with its own set of flags, options and query options.
In this case, each
A global set of query options, which should be applied to all queries, can also be supplied. These global query options must precede the first tuple of name, class, type, options, flags, and query options supplied on the command line. Any global query options (except the
shows how
could be used from the command line to make three lookups: an ANY query for
www.isc.org, a reverse lookup of 127.0.0.1 and a query for the NS records of
isc.org. A global query option of
is applied, so that
shows the initial query it made for each lookup. The final query has a local query option of
which means that
will not print the initial query when it looks up the NS records for
isc.org.
If
appropriately converts character encoding of domain name before sending a request to DNS server or displaying a reply from the server. If you'd like to turn off the IDN support for some reason, defines the
environment variable. The IDN support is disabled if the variable is set when
runs.
RFC1035.
There are probably too many query options.


In its first form, 
copies one or more source files or directories to a destination
directory.  If the destination directory does not exist it will be
created before the first source is copied.  If the destination
directory already exists then the source directories are merged
with the previous contents of the destination.
In its second form, 
copies a file to the supplied 
pathname.
The next two forms reflect
ability to create and extract
archives.  These archives can be either CPIO format (preferred for unix 
content) or PKZip (for Windows compatibility).
(and
can be the single character '-', causing ditto to read (write) archive data
from stdin (or to stdout, respectively).
follows symbolic links provided as arguments but does not follow any links
as it traverses the source or destination hierarchies.
overwrites existing files, symbolic links, and devices in the destination
when these are copied from a source.  The resulting files, links, and
devices will have the same mode, access time, modification time, owner,
and group as the source items from which they are copied.  Pipes, sockets,
and files with names beginning with .nfs or .afpDeleted will be ignored.
does not modify the mode, owner, group, extended attributes, or ACLs of existing
directories in the
destination.  Files and symbolic links cannot overwrite directories or
vice-versa.
can be used to "thin" Universal Mach-O binaries during a copy. 
can also copy files selectively based on the contents of a BOM
("Bill of Materials") file.
preserves file hard links (but not directory hard links) present in the source directories and preserves
setuid and setgid modes when run as the superuser. 
will preserve resource forks and HFS meta-data information
when copying unless instructed otherwise using
Similarly,
will preserve extended attributes and Access Control Lists (ACLs) unless
or
is passed.
can be set in the environment as an alias to
on the command line.
Print full usage.
Print a line of output to stderr for each source directory copied.
Print a line of output to stderr for every file, symbolic link, and device copied.
When copying one or more source directories, do not descend into directories
that have a different device ID.
Create an archive at the destination path.  The default format is CPIO, unless
is given.
CPIO archives should be stored in files with names ending in .cpio.
Compressed CPIO archives should be stored in files with names ending in
Create compressed CPIO archives, using
compression.
Create compressed CPIO archives, using
compression.
Extract the archives given as source arguments. The format is assumed to
be CPIO, unless
is given.  Compressed CPIO is automatically handled.
Create or extract from a PKZip archive instead of the default CPIO.
PKZip archives should be stored in filenames ending in .zip.
When creating an archive, embed the parent directory name
in
Thin Universal binaries to the specified
architecture.  If multiple
options are specified then the resulting destination file will contain
each of the specified architectures (if they are present in the source
file).
should be specified as "i386", "x86_64", etc.
Copy only files, links, devices, and directories that are present in the
specified BOM.
Preserve resource forks and HFS meta-data.
will store this data in Carbon-compatible ._ AppleDouble files on
filesystems that do not natively support resource forks.  As of Mac OS X 10.4,
is default behavior.
Do not preserve resource forks and HFS meta-data.  If both
and
are passed, whichever is passed last will take precedence.  Both options
override
also implies
and
to match the behavior of Mac OS X 10.4.
Preserve extended attributes (requires
As of Mac OS X 10.5,
is the default.
Do not preserve extended attributes (requires 
Preserve quarantine information.
As of Mac OS X 10.5,
is the default.
Do not preserve quarantine information.
Preserve Access Control Lists (ACLs).
As of Mac OS X 10.5,
is the default.
Do not preserve ACLs.
Do not perform copies using the Mac OS X Unified Buffer Cache. Files read
and written will not be cached, although if the file is already present
in the cache, the cached information will be used.
When copying files or extracting content from an archive, if the destination 
is an HFS+ volume that supports compression, all the content will be compressed
if appropriate. This is only supported on Mac OS X 10.6 or later, and is only
intended to be used in installation and backup scenarios that involve system 
files. Since files using HFS+ compression are not readable on versions of 
Mac OS X earlier than 10.6, this flag should not be used when dealing with
non-system files or other user-generated content that will be used on a 
version of Mac OS X earlier than 10.6. 
Do not compress files with HFS+ compression when copying or extracting content
from an archive unless the content is already compressed with HFS+ compression. 
This flag is only supported on Mac OS X 10.6 or later. 
is the default.
When copying files to an HFS+ volume that supports compression, ditto will 
preserve the compression of any source files that were using HFS+ compression. 
This flag is only supported on Mac OS X 10.6 or later. 
is the default.
Do not preserve HFS+ compression when copying files that are already compressed with
HFS+ compression. This is only supported on Mac OS X 10.6 or later.
When creating a PKZip archive, preserve resource forks and HFS meta-data
in the subdirectory __MACOSX.  PKZip extraction will automatically find
these resources.
Sets the compression level to use when creating a PKZip archive. The compression
level can be set from 0 to 9, where 0 represents no compression, and 9 
represents optimal (slowest) compression. By default, ditto will use the default compression
level as defined by zlib.
When extracting a password-encrypted ZIP archive, you must specify --password to allow ditto 
to prompt for a password to use to extract the contents of the file. If this option is not 
provided, and a password-encrypted file is encountered, ditto will emit an error message.
The command:
copies the contents of src_directory into dst_directory, creating
dst_directory if it does not already exist.
The command:
dir and dst_directory if they don't already exist.
The command:
copies the contents of all of the src directories into dst_directory,
creating dst_directory if it does not already exist.
The command:
copies the contents of universal_file into thin_file, thinning executable
code to ppc-only on the fly.
The command:
copies Scripts, skipping any resources or meta-data, to rhost.
The command:
will list the files in the CPIO archive archive.cpio.
The command:
will list the files in the compressed CPIO archive archive.cpgz.
The command:
will create a PKZip archive similarly to the Finder's Compress functionality.
The command:
will list the files in the PKZip archive archive.zip.
returns 0 if everything is copied, otherwise non-zero.
almost never gives up, preferring to report errors along the way.
Diagnostic messages will be printed to standard error.
If the environment variable
is set,
will call
if it encounters a fatal error.
If
is set but
and
are not specified,
will not preserve those additional types of metadata.
doesn't copy directories into directories in the same way as
In particular,
will copy the contents of foo into bar, whereas 
copies foo itself into bar. Though this is not a bug, some may
consider this bug-like behavior.
for non-archive copies will eventually alleviate this problem.
The
command is a network diagnostic tool, much like
or
However, unlike those tools, most of its functionality is not implemented in the
executable itself, but in library code that is available to any application.
The library API that
uses is documented in
The
command replaces the older
mDNS
command.
The
command is primarily intended for interactive use.
Because its command-line arguments and output format are subject to change,
invoking it from a shell script will generally be fragile. Additionally,
the asynchronous nature of DNS Service Discovery does
not lend itself easily to script-oriented programming. For example,
calls like "browse" never complete; the action of performing a "browse"
sets in motion machinery to notify the client whenever instances of
that service type appear or disappear from the network. These
notifications continue to be delivered indefinitely, for minutes,
hours, or even days, as services come and go, until the client
explicitly terminates the call. This style of asynchronous interaction
works best with applications that are either multi-threaded, or use a
main event-handling loop to receive keystrokes, network data, and other
asynchronous event notifications as they happen.
If you wish to perform DNS Service Discovery operations from a
scripting language, then the best way to do this is not to execute the
command and then attempt to decipher the textual output, but instead to
directly call the DNS-SD APIs using a binding for your chosen language.
For example, if you are programming in Ruby, then you can
directly call DNS-SD APIs using the dnssd package documented at
Similar bindings for other languages are also in development.
return a list of domains recommended for registering(advertising) services.
return a list of domains recommended for browsing services.
Normally, on your home network, the only domain you are likely to see is "local". 
However if your network administrator has created Domain Enumeration records, 
then you may also see other recommended domains for registering and browsing.
register (advertise) a service in the specified
with the given
and
as listening (on the current machine) on
can be arbitrary unicode text, containing any legal unicode characters
(including dots, spaces, slashes, colons, etc. without restriction),
up to 63 UTF-8 bytes long.
must be of the form "_app-proto._tcp" or "_app-proto._udp", where
"app-proto" is an application protocol name registered at
is the domain in which to register the service.
In current implementations, only the local multicast domain "local" is
supported. In the future, registering will be supported in any arbitrary
domain that has a working DNS Update server [RFC 2136]. The
"." is a synonym for "pick a sensible default" which today
means "local".
is a number from 0 to 65535, and is the TCP or UDP port number upon
which the service is listening.
Additional attributes of the service may optionally be described by
record. Allowable keys and values are listed with the service
registration at
browse for instances of service
in
For valid 
see
as described above. Omitting the
or using "." means "pick a sensible default."
look up and display the information necessary to contact and use the
named service: the hostname of the machine where that service is
available, the port number on which the service is listening, and (if
present) TXT record attributes describing properties of the service.
Note that in a typical application, browsing may only happen rarely, while lookup
(or "resolving") happens every time the service is used. For example, a
user browses the network to pick a default printer fairly rarely, but once
a default printer has been picked, that named service is resolved to its
current IP address and port number every time the user presses Cmd-P to
print.
create a proxy advertisement for a service running on(offered by) some other machine.
The two new options are Host, a name for the device and IP, the address of it.
The service for which you create a proxy advertisement does not necessarily have to be on your local network. 
You can set up a local proxy for a website on the Internet.
look up any DNS name, resource record type, and resource record class, 
not necessarily DNS-SD names and record types.
If rrtype is not specified, it queries for the IPv4 address of the name, 
if rrclass is not specified, IN class is assumed. If the name is not a fully 
qualified domain name, then search domains may be appended.
browse for service instances and display output in zone file format.
look up the IP address information of the name.
If v4 is specified, the IPv4 address of the name is looked up, 
if v6 is specified the IPv6 address is looked up. If v4v6 is specified both the IPv4 and IPv6 
address is looked up. If the name is not a fully qualified domain name, 
then search domains may be appended.
To advertise the existence of LPR printing service on port 515 on this
machine, such that it will be discovered by the Mac OS X printing software
and other DNS-SD compatible printing clients, use:
For this registration to be useful, you need to actually have LPR service
available on port 515. Advertising a service that does not exist is not
very useful, and will be confusing and annoying to other people on the
network.
Similarly, to advertise a web page being served by an HTTP
server on port 80 on this machine, such that it will show up in the
Bonjour list in Safari and other DNS-SD compatible Web clients, use:
To find the advertised web pages on the local network (the same list that
Safari shows), use:
While that command is running, in another window, try the
example given above to advertise a web page, and you should see the
"Add" event reported to the
window. Now press Ctrl-C in the
window and you should see the "Remove" event reported to the
window.
In the example below, the www.apple.com web page is advertised as a service called "apple", 
running on a target host called apple.local, which resolves to 17.149.160.49.
The Bonjour menu in the Safari web browser will now show "apple".
The same IP address can be reached by entering apple.local in the web browser.
In either case, the request will be resolved to the IP address and browser will show
contents associated with www.apple.com.
If a client wants to be notified of changes in server state, it can
initiate a query for the service's particular record and leave it running.
For example, to monitor the status of an iChat user you can use:
Everytime status of that user(someone) changes, you will see a new TXT record result reported.
You can also query for a unicast name like www.apple.com and monitor its status.
bugs are tracked in Apple Radar component "mDNSResponder".
The
command first appeared in Mac OS X 10.4 (Tiger).
The
The super-user can
set the domain name by supplying an argument; this is usually done
at startup by specifying a domain name in the contents of the file
domain name does not necessarily have anything to do with the Domain
Name System domain name, although they are often set equal for administrative
convenience.
The
command appeared in
based on a similar command in
For each
,
recursively merges all ._* files with their corresponding native files according to the rules specified with the given arguments.  By default, if there is an attribute on the native file that is also present in the ._ file, the most recent attribute will be used.
If no operands are given, a usage message is output.
If more than one directory is given, directories are merged in the order in which they are specified.
Flat merge.  Do not recursively merge all directories in the given
This is off by default.
Help. Prints verbose usage message.
Always delete dot underbar files.
Delete dot underbar file if there is no matching native file.
Follow symbolic links.  This will follow symbolic dot underbar files when they are found.
Print verbose output.
The default option.  If an attribute is associated with a data fork, use that.  Otherwise, use information stored in the AppleDouble file.  Note that the native fork's data is preferred even if the data in the AppleDouble file is newer.
Always use information stored in the AppleDouble file, replacing any extended attributes associated with the native file.
Always use the information associated with the data fork, ignoring any AppleDouble files.
The following is how to do an
merge on the mounted volume test, always using the dot underbar information.
None known.
uses the DiscRecording framework to interact with attached 
burning devices.  Common verbs include
and
The rest of the verbs are:
and
Each verb is listed with its description and individual arguments.
Drive selection arguments must appear before individual arguments.
Drive selection and argument descriptions can be found after the verb
descriptions in the Drive Selection Criteria section.
Lets you specify a drive or drives, per the output of
for those verbs that can operate on one or more drives.
See the Drive Selection Criterion section for more info.
Display the usage information for the specified verb.
Starts bulk erase mode, in which the drive will continually
erase inserted -RW media, eject it, and prompt for another disc until
terminated.
Types of erase:
Performs a quick erase, doing the minimal amount of work to make the 
disc appear blank. This operation typically takes only a minute or two. 
Performs a complete erase, erasing every block on the disk. This 
operation is slow (on the order of 30 minutes) to complete.
Burns a valid directory or image file to disc. The default is to burn the
specified directory to a new filesystem. The 
option creates an
audio CD (redbook) in which any valid QuickTime audio file present in the path
is converted to a track (in alphabetical order). If a file is specified (valid 
are burned. Pre-burn and post-burn options, and filesystem exclusions can be
specificed for enhanced functionality. Last option takes precedence. Invalid commands are ignored.
A valid path to a directory or file.
Specify an arbitrary valid burn option(s):
Or specify a default burn option:
Reads and displays any CD-Text information reported by the drive. The drive
must contain an audio CD, and be capable of reading CD-Text.
Displays detailed information about present media.
From the MMC command of the same name.
Tool to inspect and interpret ISO-9660 and Joliet structures on the media.
Block number to dump (in decimal or 0x hex notation). Blocks are
assumed to be 2048-byte blocks.
How to interpret the block. If format is not specified, dumpiso will attempt to guess. 
If present, this argument should be one of the following:
Tool to inspect and interpret UDF structures on the media.
Block number to dump (in decimal or 0x hex notation). Blocks are
assumed to be 2048-byte blocks.
Synonym for
Erases -RW media in the drive(s) and ejects it.
Types of erase:
Performs a quick erase, doing the minimal amount of work to make the 
disc appear blank. This operation typically takes only a minute or two. 
Performs a complete erase, erasing every block on the disk. This 
operation is slow (on the order of 30 minutes) to complete.
Shows how the specified filename will be modified to comply with the
naming rules of the filesystems that DiscRecording generates.
Displays device feature and profile list.
Types of config information:
Displays current features and profiles for a drive.
Displays all supported features and profiles for a drive.
Displays various pieces of information for each drive,
including how it's connected to the computer and a summary
of capabilities.
Lists all burning devices connected to the machine.
Displays device and media notifications until terminated.
Estimates the size of a valid directory or image file (in blocks). The default is to estimate 
the size of the specified path as a hybrid filesystem. The 
option calculates the contents of the directory as an audio CD (redbook) (for applicable files). If a file
will be calculated. Filesystem exclusions can be specificed for enhanced functionality. Calculated size will
be compared against blank media that is found unless the 
argument is specified. Last option takes precedence. Invalid commands are ignored.
A valid path to a directory or file.
Specify an arbitrary valid burn option(s):
Or specify a default burn option:
Displays detailed media-specific information.
Displays information from the subchannels on CD media. This
prints the MCN (media catalog number) for the disc, and the
ISRC (international standard recording code) for all tracks.
This command only works when CD media is present.
From the MMC command of the same name.
Displays table of contents (TOC) of inserted media.
Displays detailed information about all tracks present
on the media.
From the MMC command of the same name.
do not have trays, and some have trays but may lack motorized
eject or inject capability.
Tray commands:
Opens a drive's tray, if no media is present and the
drive has a tray capable of motorized eject.
Closes a drive's tray, if the drive has a tray capable
of motorized inject.
Ejects media from the drive, if the drive has a tray capable
of motorized eject. If no media is present, this is equivalent
to
If media is present and can be unmounted, it will be unmounted
and then ejected.
If media is present but cannot be unmounted, the eject will fail.
Displays operating system and DiscRecording framework version numbers.
When specified (valid options only:
the output for the specified verb will be shown in xml format.
Some functions of
operate on a specific drive. Since any number of
drives may be available, and they may come and go at any time, the device
selection arguments provide a method for selecting among them.
The candidate list starts out as a list of all attached drives. One or more
arguments of the form
may be specified. Each argument has the
effect of narrowing the candidate list, depending on what
is. It may be:
A positive decimal number, assumed to be a 1-based index into the
candidate list. The candidate list is trimmed to just that device.
One of the following keywords:
The candidate list is trimmed to devices which match the specified 
candidate list is trimmed to devices whose vendor or product 
strings exactly match the argument. Case (but not whitespace) is 
ignored in this comparison.
Multiple
arguments may be specified; each argument narrows the
candidate list further. After all the
arguments have been processed, the candidate list is considered. If
it contains exactly one item, that drive is used. If it contains
zero items,
prints an error message and exits. If it contains more than one item,
the selected function is executed on all drives remaining in the list.
Simple verbs with no drive commands
        Displays help for the verb "status".
        Displays a list of attached devices.
		Displays miscellaneous information for all attached devices.
		Displays media-specific information for all attached devices.
        Burns the Documents directory to the internal drive without
        verifying, then ejects the disc.
        Creates a XML file containing info about internal drives.
Examples of drive selection
        Closes the tray of the first burning device seen, if possible.
        Lists drive specific information for all externally
        connected burning devices.
        Lists media specific information for media present in
        attached firewire burning devices.
        Opens the tray of all burning devices whose vendor id is 
        VENDOR, if possible.
        Lists supported features and profiles for attached devices
        whose product id is 'CD-RW CDW827ES'.
first appeared in MacOS X 10.3.
does various operations against the Directory Service cache including gathering statistics, initiating lookups, inspection, cache flush, etc.  This tool replaces most of the functionality of the lookupd tool previously available in the OS.  
A list of flags and their descriptions:
Lists the options for calling
Initiate a query using standard calls.  These calls will either return results from the cache or go fetch live data and place them in the cache.  By default if no specific query is requested via
then all results within that category will be returned.
Optional flag to 
for a specific key with a value.
Dumps an overview of the cache by default.  Additional flags will provide more detailed information.
Used in conjunction with
to also print hash bucket usage of the current cache.
Used in conjunction with
to dump detailed information about cache entries.  An optional category can be supplied to only see types of interest.  Dumping 'host' entries can only be done by administrative users.
Prints current configuration information, such as the search policy from Directory Service and cache parameters.
Flushes the entire cache.  This should only be used in extreme cases.  Validation information is used within the cache along with other techniques to ensure the OS has valid information available to it.
Prints statistics from the cache including an overview and detailed call statistics.  Some calls are not cached but are derived from other calls internally.  Cache hits and cache misses may not always be equal to external calls.  For example getaddrinfo is actually a combination of gethostbyname with other calls internally to the cache to maximize cache hit rate.
Available categories and associated keys:
name or gid
name or ip_address (used for both IPv6 and IPv4)
name
name or number
name or number
name or port
name or uid
options:
prompt for password
authenticate as user
authentication password
targeted local node database file path
don't strip off prefix from DirectoryService API constants
print out record(s) or attribute(s) in XML plist format
print record attribute values in URL-style encoding
quiet - no interactive prompt
commands:
available only in interactive mode:
is a general-purpose utility for operating on Directory Service directory nodes.  Its commands allow one to create, read, and manage Directory Service data.  If invoked without any commands,
runs in an interactive mode, reading commands from standard input.  Interactive processing is terminated by the
command.  Leading dashes ("-") are optional for all commands.
option and either the
of
options to specify an administrative user and password on the remote host to authenticate with to the remote host. The exception to this is if "localhost" is specified.  Passing passwords on the command line is inherently insecure and can cause password exposure.  For better security do not provide the password as part of the command and you will be securely prompted.
The datasource may also be specified as "localonly" in which case a separate DirectoryService daemon process is activated which contains only the Local plugin for use by dscl.  If no file path is provided then access goes only to the registered local nodes on the system. However, if the
There are two modes of operation when specifying paths to operate on. The two modes correspond to whether the datasource is a node or a host. In the case of specifying a node, the top level of paths will be record types. Example top level paths would be:
In the case of specifying a host as a data source, the top level of paths correspond to Open Directory plug-ins and Search Paths. One can specify the plug-in to traverse to a node name, after which the paths are equivalent to the former usage. The following might be the equivalent paths as the above paths:
All pathnames are case-sensitive.
The action of each command is described below.  Some commands have aliases.  For example, "cat" and "." are aliases for "read".  Command aliases are listed in parentheses.
Usage: read
Prints a directory.  The property key is followed by colon, then a space-separated list of the values for that property. If any value contains embedded spaces, the list will instead be displayed one entry per line, starting on the line after the key.
If The 
flag for raw output has been given, then
prints the full DirectoryService API constant for record and attribute types.
If the
flag has been specified then printed record path attribute values are encoded in the style of URLs. This is useful if a script or program is trying to process the output since values will not have any spaces or other control characters.
Usage: readall
prints all the records of a given type.  The output of readall is formatted in the same way as
with a "-" on a line as a delimeter between records.
Usage: readpl
Prints the contents of
The
is followed by a colon, then a whitespace, and then the value for the path.
If the
is the key for a dictionary or array, the contents of it are displayed in plist form after the
If
is the key for a string, number, bool, date, or data object, only the value is printed out after the
Usage: readpli
Prints the contents of
for the plist at
of the key.
The
is followed by a colon, then a whitespace, and then the value for the path.
If the
is the key for a dictionary or array, the contents of it are displayed in plist form after the
If
is the key for a string, number, bool, date, or data object, only the value is printed out after the
Usage: list
Lists the subdirectories of the given directory.  Subdirectories are listed one per line.  In the case of listing a search path, the names are preceded by an index number that can act as a shortcut and used in place of the name when specifying a path.
When used in interactive mode, the path is optional.  With no path given, the current directory will be used.
Searches for records that match a pattern.  The search is rooted at the given path.  The path may be a node path or a record type path.  Valid keys are Directory Service record attribute types.
Usage: create
Creates a record, property, or value.  If only a record path is given, the
command will create the record if it does not exist.  If a key is given, then a property with that key will be created.
WARNING - If a property with the given key already exists, it will be destroyed and a new property will be created in its place.  To add values to an existing property, use the
or 
commands.
If values are included in the command, these values will be set for the given key.
NOTE - Not all directory nodes support a property without a value. An error will be given if you attempt to create a property with no value in such a directory node.
Usage: createpl
Creates a string, or array of strings at
If you are creating a value at the root of a plist that is an array, simply use "0" as the
If only
is specified, a string will be created at
If
are specified, an array of strings will be created at
WARNING - If a value with the given
already exists, it will be destroyed and a new value will be created in its place.
Usage: createpli
Creates a string, or array of strings at
for the plist at
of the key.
If you are creating a value at the root of a plist that is an array, simply use "0" as the
If only
is specified, a string will be created at
If
are specified, an array of strings will be created at
WARNING - If a value with the given
already exists, it will be destroyed and a new value will be created in its place.
Usage: append
Appends one or more values to a property in a given record.  The property is created if it does not exist.
Usage: merge
Appends one or more values to a property in a given directory if the property does not already have those values.  The property is created if it does not exist.
Usage: change
Replaces the given old value in the list of values of the given key with the new value in the specified record.
Usage: changei
Replaces the value at the given index in the list of values of the given key with the new value in the specified record.  
is an integer value.  An index of 1 specifies the first value.  An index greater than the number of values in the list will result in an error.
Usage: diff
Compares the data from path1 and path2 looking at the specified keys (or all if no keys are specified).
Usage: delete
Delete a directory, property, or value.  If a directory path is given, the
command will delete the directory.  This can only be used on record type and record paths.  If a key is given, then a property with that key will be deleted.  If one or more values are given, those values will be removed from the property with the given key.
Usage: deletepl
Deletes a value in a plist.  If no values are given
deletes the
If one or more values are given,
deletes the values within
Usage: deletepli
Deletes a value for the plist at
of the key.  If no values are given
deletes the
If one or more values are given,
deletes the values within
Usage: passwd
Changes a password for a user. The user must be specified by full path, not just a username.  If you are authenticated to the node (either by specifying the
and
flags or by using the auth command when in interactive node) then you can simply specify a new password.  If you are not authenticated or if FileVault is enabled then the user's old password must be specified.  If passwords are not specified while in interactive mode, you will be prompted for them.  Passing these passwords on the command line is inherently insecure and can cause password exposure.  For better security do not provide the password as part of the command and you will be securely prompted.
Usage: cd dir
Sets the current directory.  Path names for other
commands may be relative to the current directory.
Usage: pushd path
Similar to the pushd command commonly found in Unix shells.  When a path is specified it sets the current directory while pushing the previous directory on to the directory stack.  If no path is specified it exchanges the top two elements of the directory stack.  It will also print the final directory stack.
Usage: popd
Pops the directory stack and returns to the new top directory.  It will also print the final directory stack.
Usage: auth
Authenticate as the named user, or as "root" if no user is specified.  If a password is supplied, then that password is used for authentication, otherwise the command prompts for a password.
If
is run in host mode, then when this command is run the current directory must be in the subdirectories of a node.
Usage: authonly
Used to verify the password of a named user, or of "root" if no user is specified.  If a password is supplied, then that password is used for authentication, otherwise the command prompts for a password.
If
is run in host mode, then when this command is run the current directory must be in the subdirectories of a node.
Usage: quit
Ends processing of interactive commands and terminates the program.
The up and down arrow keys will scan through the command history. 
When pathnames are being typed, pressing the tab key will result in a search to auto-complete the typed partial subdirectory name. It will also attempt to correct capitilization in the process.
will return -1 (255) on error.
options:
verbose logging to stdout
prompt for passwords as required
choose SSL connection
enforce secure authentication only
enforce packet signing security policy
enforce man-in-middle security policy
enforce encryption security policy
do not update search policies
do not prompt about adding certificates
display usage statement
add config of servername
remove config of servername
name given to LDAP server config
name used if binding to directory
privileged network username
privileged network user password
local admin username
local admin password
allows addition or removal of LDAP server configurations. Presented below is a discussion of possible parameters. Usage has three intents: add server config, remove server config, or display help.
Options list and their descriptions:
Bindings will be established or dropped in conjunction with the addition or removal of the LDAP server configuration.
This enables the logging to stdout of the details of the operations. This can be redirected to a file.
You will be prompted for a password to use in conjunction with a specified username.
This ensures that no clear text passwords will be sent to the LDAP server during authentication.  This will only be enabled if the server supports non-cleartext methods.
This ensures that if the server is capable of supporting encryption methods (i.e., SSL or Kerberos) that encryption will be enforced at all times via policy.
This ensures that man-in-the-middle capabilities will be enforced via Kerberos, if the server supports the capability.
This ensures that packet signing capabilities will be enforced via Kerberos, if the server supports the capability.
Connection to the LDAP server will only be made over SSL.
Will skip updating the search policies.
Will assume Yes for installing certificates
Display usage statement.
This is either the fully qualified domain name or correct IP address of the LDAP server to be added to the DirectoryService LDAPv3 configuration.
This is either the fully qualified domain name or correct IP address of the LDAP server to be removed from the DirectoryService LDAPv3 configuration.
This is the UI configuration label that is to be given the LDAP server configuration.
This is the name to be used for directory binding to the LDAP server. If none is given the first substring, before a period, of the hostname (the defined environment variable "HOST") is used.
Username of a privileged network user to be used in authenticated directory binding.
Password for the privileged network user.  This is a less secure method of providing a password, as it may be viewed via process list.  For stronger security leave the option off and you will be prompted for a password.
Username of a local administrator.
Password for the local administrator.  This is a less secure method of providing a password, as it may be viewed via process list.  For stronger security leave the option off and you will be prompted for a password.
-a ldap.company.com
The LDAP server config for the LDAP server myldap.company.com will be added. If authenticated directory binding is required by the LDAP server, then this call will fail. Otherwise, the following parameters configname, computerid, and local admin name will respectively pick up these defaults: ip address of the LDAP servername, substring up to first period of fully qualified hostname, and username of the user in the shell this tool was invoked.
-r ldap.company.com
The LDAP server config for the LDAP server myldap.company.com will be removed but not unbound since no network user credentials were supplied.  The local admin name will be the username of the user in the shell this tool was invoked.
opendirectoryd(8), odutil(1)
The
utility exports records from Open Directory.
The first argument is the path to the output file.
If the file already exists it will be overwritten.
The second argument is the path to the OpenDirectory node from which the records will be read.
The third argument is the type of record to export.
If the record type does not begin with
or
the
utility will determine if the node supports a standard attribute by the specified name;
otherwise,
will assume that the record type is native.
A warning will be printed if the record type is converted.
Standard record types can be listed using the following command:
The options are as follows:
Export all attributes, including native attributes.
By default,
only exports standard attributes.
Comma-separated list of records to export from the specified node.
The
option may be used multiple times to specify additional records to export.
If the
option is not specified,
will attempt to export all records.
Comma-separated list of attributes that should not be exported.
The
option may be used multiple times to specify additional attributes to exclude.
The following attributes are always excluded:
Address of the desired proxy machine.
Username to use for the proxy connection
Password to use for the proxy connection.
If the
option is not specified,
will interactively prompt for the password.
When using an LDAP node, please be aware that
can only export as many records as the LDAP server is willing to return.
If the LDAP server has several thousand users, you may want to raise the maximum number of search results that the server returns.
This can be done in Server Admin (my.server.com>OpenDirectory>Settings>Protocols tab).
By default this is set to 11000 results.
Export all user records from the local node to
Export the group records for
and
from the LDAPv3 node on a proxy machine
Export augmented users from the LDAPv3 node, including native attributes but excluding the PasswordPlus attribute:
is a tool for importing records into an Open Directory source.
is the path of the file to be imported.
is the path of the Open Directory node where the records should be imported.
overwrite of any existing records that have the same record name, UID or GID. All previous attribute values are deleted.
merge import data with existing records or create the record if it does not exist.
ignore the record if there is a conflicting name, UID or GID.
append the data to existing records, but do not create a record if it does not exist.
A list of options and their descriptions:
is used to signify that all user passwords are crypt-based. Entries in the import file can also be prefixed with {CRYPT} on a per record basis if not all users are crypt-based.  By default all passwords are assumed to be provided as listed in the import file.
forces a specific value for the named attribute for all records during the import. The new value will overwrite any value specified in the import file. This option may be specified multiple times for forcing more than one attribute.
is the GID used for any records that do not specify a primary GID.
designate a preset record to be applied to imported group records.
changes the amount of logging detail output to the log file.
Outputs a plist to the specified file with a list of changed users or groups and rejected records due to name conflicts.
Also includes a list of deleted records (overwrite mode), and lists of records that failed and succeeded during import.
The format of this file is likely to change in a future release of Mac OS X.
is the admin's password for import operations. Used to authenticate to the directory node during import. A secure prompt will be used for interactive input if not supplied via parameter.  Using the prompt method is the most secure method of providing password to 
passes in the delimiters and attributes and record type to specify the order and names of attributes in the file to be imported. An example record format string: 
0x0A 0x5C 0x3A 0x2C dsRecTypeStandard:Users 7 dsAttrTypeStandard:RecordName dsAttrTypeStandard:Password dsAttrTypeStandard:UniqueID dsAttrTypeStandard:PrimaryGroupID dsAttrTypeStandard:RealName dsAttrTypeStandard:NFSHomeDirectory dsAttrTypeStandard:UserShell
A special value of IGNORE can be used for values that should be ignored in the import file on a record-by-record basis.
Override the record type defined in the import file. For example, to import ComputerGroups as ComputerLists, use:
The opposite works for importing ComputerLists as ComputerGroups, and so on.
connects to a remote host at the network address specified.  Commonly used to import to a remote Mac OS X Server.
specifies user name to use for the remote connection.
specifies password to use for the remote connection. A secure prompt will be used to ask for the password if
is specified and
is not.  Using the prompt method is the most secure method of providing password to 
indicates the ID number to start with when the import tool generates user or group IDs for any import file that lacks an ID as part of the import data. 
is used for delimited import of files that lack field descriptions.
contains the following fields in the order: 
RecordName
Password
UniqueID
PrimaryGroupID
DistinguishedName
NFSHomeDirectory
UserShell 
contains the following fields in the order:
RecordName
Password
PrimaryGroupID
GroupMembership 
is the admin username to use when importing records. If this is not specified the current user is the default name.  Also, if used in conjunction with 
then this admin user will be used for the Open Directory node whereas the username provided in
will be used for the remote connection.  If this option is left off but
is provided, then the remote username will be used for both the connection and for importing records.
designate a preset record to be applied to imported user records.
To import a standard dsexport file into the Local database:
administrator
adminpassword
is a program that implements the membership API calls in a command line utility.  
A list of flags and their descriptions:
Lists the options for calling
Causes
to operate in verbose mode.
The action of each command is described below:
Takes any of the options and returns the associated UUID.
Takes any of the options and returns the associated UID or GID depending on option provided.
Takes any of the options and returns the associated SID.
Returns if a user or group with the associated option is a member of the group.
Flushes the current membership cache.
Legacy commands such as dumpstate and statistics are gone. See 
for show cache and statistics operations.
A list of options available. In some cases 
and
can be used synonymously due to nature of the value.
Using user with UID
Using user with name
Using user with SID
Using user with UUID
Using group with GID
Using group with name
Using group with SID
Using group with UUID
Users new to DTrace are encouraged to read:
Options to list the set of probes and providers currently published by DTrace
Options to enable probes directly using any of the probe description specifiers (provider, module, function, name)
Options to run the D compiler and compile one or more D program files or programs written directly on the command-line
Options to generate anonymous tracing programs
Options to generate program stability reports
Options to modify DTrace tracing and buffering behavior and enable additional D compiler features
have exited, reporting the exit status for each child process as it terminates. The process-ID of the first command is made available to any D programs specified 
Note that with successive invocations of dtrace with the -o option, dtrace does not overwrite, but rather appends to the output file.
exits when all commands have exited, reporting the exit status for each process as it terminates. The first process-ID is made available to any D programs spe
Show D compiler intermediate code.  The D compiler will produce a report of the intermediate code generated for each D program to stderr.
Allow destructive actions. D programs containing destructive actions will fail to compile unless this flag is specified.
Enable or modify a DTrace runtime option or D compiler option.  Boolean options are enabled by specifying their name.  Options with values are set by separating the option name and value with an equals sign (=).
The Objective C provider is similar to the pid provider, and allows instrumentation of Objective C classes and methods. Objective C probe specifiers use the following format:
The id number of the process.
The name of the Objective C class.
The name of the category within the Objective C class.
The name of the Objective C method.
Every instance method of class NSString in process 123.
Every method on every category of class NSString in process 123.
Every class method in NSString's foo category in process 123.
Every instance method in every class and category in process 123.
The dealloc method in the foo category of class NSString in process 123.
Name the provider and specify its probes, using the following form:
};
Process the provider description into a header file.
Add probe invocations to the application
For each probe defined in the provider, the provider.h file will contain two macros.The naming is as follows:
In the Example provider, the increment probe becomes:
Place a macro invocation in the code at each site to be traced. If the arguments passed to a probe are expensive to calculate, you may guard the probe placement like this:
if (EXAMPLE_INCREMENT_ENABLED()) {
};
The if test will only succeed when the increment probe is active.
Compile and link your program normally. No additional compiler or linker flags are required.
A small number of DTrace builtin variables have OS X specific changes:
A string giving the name that was passed to exec(2) to execute the current process.
The string consists of at most MAXCOMLEN-1 characters.
A uint64_t timestamp returning mach_absolute_time().
A uint64_t thread ID of the currently executing thread. The thread ID is guaranteed to be unique and non repeating. The tid value is not equivalent to pthread_self.
The pidresume(pid) action is a destructive action meant to be used in conjunction with the stop() action.  
While the stop() action will task_suspend the currently running process, the pidresume(pid) action will task_resume it.  
The pidresume(pid) action will only act on a process that has been stopped using the dtrace stop() action.
Passing a pid for a process that does not exist, or that was not stopped using dtrace stop() action, will result in an error.
The default behavior of the pid provider is to bail out when it detects a jump
table. This results in missing return probes. The nojtanalysis option disables
the jump table analysis. Please note that use of this option is discouraged,
inappropriately placed probes may cause data corruption or even crashes in the
target process.
A fatal error occurred.  For D program requests, the 1 exit status indicates that program compilation failed or that the specified request could not be satisfied.
Invalid command-line options or arguments were specified.

The
utility displays the file system block usage for each file argument
and for each directory in the file hierarchy rooted in each directory
argument.
If no file is specified, the block usage of the hierarchy rooted in
the current directory is displayed.
The options are as follows:
Display an entry for each file in a file hierarchy.
Display a grand total.
Display an entry for all files and directories
directories deep.
Symbolic links on the command line are followed, symbolic links in file
hierarchies are not followed.
"Human-readable" output.
Use unit suffixes: Byte, Kilobyte, Megabyte,
Gigabyte, Terabyte and Petabyte.
Ignore files and directories matching the specified
Display block counts in 1073741824-byte (1-Gbyte) blocks.
Display block counts in 1024-byte (1-Kbyte) blocks.
Symbolic links on the command line and in file hierarchies are followed.
Display block counts in 1048576-byte (1-Mbyte) blocks.
No symbolic links are followed.
This is the default.
Generate messages about directories that cannot be read, files
that cannot be opened, and so on.
This is the default case.
This option exists solely for conformance with
Display an entry for each specified file.
(Equivalent to
File system mount points are not traversed.
The
utility counts the storage used by symbolic links and not the files they
reference unless the
or
option is specified.
If either the
or
options are specified, storage used by any symbolic links which are
followed is not counted or displayed.
If more than one of the
and
options is specified, the last one given is used.
Files having multiple hard links are counted (and displayed) a single
time per
execution.
Directories having multiple hard links (typically Time Machine backups) are
counted a single time per
execution.
If the environment variable
is set, and the
option is not specified, the block counts will be displayed in units of that
size block.
If
is not set, and the
option is not specified, the block counts will be displayed in 512-byte blocks.
In legacy mode, only one of the
or
options may be specified.
The command will detect and report a SYMLOOP error
(loop involving symbolic links).
In legacy mode, this is not the case.
For more information about legacy mode, see
A
command appeared in
DYLD_FRAMEWORK_PATH
DYLD_FALLBACK_FRAMEWORK_PATH
DYLD_VERSIONED_FRAMEWORK_PATH
DYLD_LIBRARY_PATH
DYLD_FALLBACK_LIBRARY_PATH
DYLD_VERSIONED_LIBRARY_PATH
DYLD_PRINT_TO_FILE
DYLD_ROOT_PATH
DYLD_SHARED_REGION
DYLD_INSERT_LIBRARIES
DYLD_FORCE_FLAT_NAMESPACE
DYLD_IMAGE_SUFFIX
DYLD_PRINT_OPTS
DYLD_PRINT_ENV
DYLD_PRINT_LIBRARIES
DYLD_PRINT_LIBRARIES_POST_LAUNCH
DYLD_BIND_AT_LAUNCH
DYLD_DISABLE_DOFS
DYLD_PRINT_APIS
DYLD_PRINT_BINDINGS
DYLD_PRINT_INITIALIZERS
DYLD_PRINT_REBASINGS
DYLD_PRINT_SEGMENTS
DYLD_PRINT_STATISTICS
DYLD_PRINT_DOFS
DYLD_PRINT_RPATHS
DYLD_SHARED_CACHE_DIR
DYLD_SHARED_CACHE_DONT_VALIDATE
The dynamic linker uses the following environment variables.
They affect any program that uses the dynamic linker.
This is a colon separated list of directories that contain frameworks.
The dynamic linker searches these directories before it searches for the
framework by its install name.
It allows you to test new versions of existing
frameworks. (A framework is a library install name that ends in the form
name.)
For each framework that a program uses, the dynamic linker looks for the
framework in each directory in 
in turn. If it looks in all the directories and can't find the framework, it
searches the directories in  
in turn. If it still can't find the framework, it then searches 
and
in turn.
Use the
option to 
to discover the frameworks and shared libraries that the executable
is linked against.
This is a colon separated list of directories that contain frameworks.
It is used as the default location for frameworks not found in their install
path.

By default, it is set to
This is a colon separated list of directories that contain potential override frameworks. 
The dynamic linker searches these directories for frameworks.  For
each framework found dyld looks at its LC_ID_DYLIB and gets the current_version 
and install name.  Dyld then looks for the framework at the install name path.
Whichever has the larger current_version value will be used in the process whenever
a framework with that install name is required.  This is similar to DYLD_FRAMEWORK_PATH
except instead of always overriding, it only overrides is the supplied framework is newer.
Note: dyld does not check the framework's Info.plist to find its version.  Dyld only
checks the -currrent_version number supplied when the framework was created.
This is a colon separated list of directories that contain libraries. The
dynamic linker searches these directories before it searches the default
locations for libraries. It allows you to test new versions of existing
libraries. 
For each library that a program uses, the dynamic linker looks for it in each
directory in 
in turn. If it still can't find the library, it then searches 
and
in turn.
Use the
option to 
to discover the frameworks and shared libraries that the executable
is linked against.
This is a colon separated list of directories that contain libraries.
It is used as the default location for libraries not found in their install
path.
By default, it is set
This is a colon separated list of directories that contain potential override libraries. 
The dynamic linker searches these directories for dynamic libraries.  For
each library found dyld looks at its LC_ID_DYLIB and gets the current_version 
and install name.  Dyld then looks for the library at the install name path.
Whichever has the larger current_version value will be used in the process whenever
a dylib with that install name is required.  This is similar to DYLD_LIBRARY_PATH
except instead of always overriding, it only overrides is the supplied library is newer.
This is a path to a (writable) file. Normally, the dynamic linker writes all
logging output (triggered by DYLD_PRINT_* settings) to file descriptor 2 
(which is usually stderr).  But this setting causes the dynamic linker to
write logging output to the specified file.  
This is a colon separated list of directories.  The dynamic linker will prepend each of
this directory paths to every image access until a file is found.    
This can be "use" (the default), "avoid", or "private".  Setting it to 
"avoid" tells dyld to not use the shared cache.  All OS dylibs are loaded 
dynamically just like every other dylib.  Setting it to "private" tells
dyld to remove the shared region from the process address space and mmap()
back in a private copy of the dyld shared cache in the shared region address
range. This is only useful if the shared cache on disk has been updated 
and is different than the shared cache in use.
This is a colon separated list of dynamic libraries to load before the ones
specified in the program.  This lets you test new modules of existing dynamic
shared libraries that are used in flat-namespace images by loading a temporary
dynamic shared library with just the new modules.  Note that this has no
effect on images built a two-level namespace images using a dynamic shared
library unless
is also used.
Force all images in the program to be linked as flat-namespace images and ignore
any two-level namespace bindings.  This may cause programs to fail to execute
with a multiply defined symbol error if two-level namespace images are used to
allow the images to have multiply defined symbols.
This is set to a string of a suffix to try to be used for all shared libraries
used by the program.  For libraries ending in ".dylib" the suffix is applied
just before the ".dylib".  For all other libraries the suffix is appended to the
library name.  This is useful for using conventional "_profile" and "_debug"
libraries and frameworks.
When this is set, the dynamic linker writes to file descriptor 2 (normally
standard error) the command line options.
When this is set, the dynamic linker writes to file descriptor 2 (normally
standard error) the environment variables.
When this is set, the dynamic linker writes to file descriptor 2 (normally
standard error) the filenames of the libraries the program is using.
This is useful to make sure that the use of
is getting what you want.
This does the same as
but the printing starts after the program gets to its entry point.
When this is set, the dynamic linker binds all undefined symbols
the program needs at launch time. This includes function symbols that can are normally 
lazily bound at the time of their first call.
Right before the process's main() is called, dyld prints out information about how
dyld spent its time.  Useful for analyzing launch performance.
Causes dyld not register dtrace static probes with the kernel.
Causes dyld to print out a line when running each initializers in every image.  Initializers
run by dyld included constructors for C++ statically allocated objects, functions marked with
__attribute__((constructor)), and -init functions.
Causes dyld to print a line whenever a dyld API is called (e.g. NSAddImage()).
Causes dyld to print out a line containing the name and address range of each mach-o segment
that dyld maps.  In addition it prints information about if the image was from the dyld 
shared cache.
Causes dyld to print a line each time a symbolic name is bound.  
Causes dyld to print out information about dtrace static probes registered with the kernel. 
Cause dyld  to print a line each time it expands an @rpath variable and whether
that expansion was successful or not.
This is a directory containing dyld shared cache files.  This variable can be used in
conjunction with DYLD_SHARED_REGION=private and DYLD_SHARED_CACHE_DONT_VALIDATE
to run a process with an alternate shared cache.
Causes dyld to not check that the inode and mod-time of files in the shared cache match
the requested dylib on disk. Thus a program can be made to run with the dylib in the
shared cache even though the real dylib has been updated on disk.
Unlike many other operating systems, Darwin does not locate dependent dynamic libraries
But there are times when a full path is not appropriate; for instance, may want your
binaries to be installable in anywhere on the disk.
This variable is replaced with the path to the directory containing the main executable for 
the framework load path could be encoded as 
moved around in the file system and dyld will still be able to load the embedded framework.
This variable is replaced with the path to the directory containing the mach-o binary which
contains the load command using @loader_path. Thus, in every binary, @loader_path resolves to
a different path, whereas @executable_path always resolves to the same path. @loader_path is
system location of the plugin-in unknown (so absolute paths cannot be used) or if the plug-in 
is used by multiple applications (so @executable_path cannot be used). If the plug-in mach-o
the framework load path could be encoded as 
be moved around in the file system and dyld will still be able to load the embedded framework.
Dyld maintains a current stack of paths called the run path list.  When @rpath is encountered
it is substituted with each path in the run path list until a loadable dylib if found.  
The run path stack is built from the LC_RPATH load commands in the depencency chain
that lead to the current dylib load.
You can add an LC_RPATH load command to an image with the -rpath option to ld(1).  You can
on the run path stack that relative to the image containing the LC_RPATH.  
The use of @rpath is most useful when you have a complex directory structure of programs and
dylibs which can be installed anywhere, but keep their relative positions.  This scenario
could be implemented using @loader_path, but every client of a dylib could need a different 
load path because its relative position in the file system is different. The use of @rpath
introduces a level of indirection that simplies things.  You pick a location in your directory
structure as an anchor point.  Each dylib then gets an install path that starts with @rpath 
and is the path to the dylib relative to the anchor point. Each main executable is linked
At runtime dyld sets it run path to be the anchor point, then each dylib is found relative
to the anchor point.  
libtool(1), ld(1), otool(1)
The
utility writes any specified operands, separated by single blank
characters and followed by a newline
character, to the standard
output.
The following option is available:
Do not print the trailing newline character.
This may also be achieved by appending
to the end of the string, as is done
by iBCS2 compatible systems.
Note that this option as well as the effect of
are implementation-defined in
Applications aiming for maximum
portability are strongly encouraged to use
to suppress the newline character.
Some shells may provide a builtin
command which is similar or identical to this utility.
Most notably, the builtin
in
does not accept the
option.
Consult the
manual page.
The
utility conforms to
The
utility is a line-oriented text editor.
It is used to create, display, modify and otherwise manipulate text
files.
When invoked as
the editor runs in
mode, in which the only difference is that the editor restricts the
use of filenames which start with
(interpreted as shell commands by
or contain a
Note that editing outside of the current directory is only prohibited
if the user does not have write access to the current directory.
If a user has write access to the current directory, then symbolic
links can be created in the current directory, in which case
will not stop the user from editing the file that the symbolic link
points to.
If invoked with a
argument, then a copy of
is read into the editor's buffer.
Changes are made to this copy and not directly to
itself.
Upon quitting
any changes not explicitly saved with a
command are lost.
Editing is done in two distinct modes:
and
When first invoked,
is in command mode.
In this mode commands are read from the standard input and
executed to manipulate the contents of the editor buffer.
A typical command might look like:
which replaces all occurrences of the string
with
When an input command, such as
(append),
(insert) or
(change), is given,
enters input mode.
This is the primary means
of adding text to a file.
In this mode, no commands are available;
instead, the standard input is written
directly to the editor buffer.
Lines consist of text up to and
including a
character.
Input mode is terminated by
entering a single period
on a line.
All
commands operate on whole lines or ranges of lines; e.g.,
the
command deletes lines; the
command moves lines, and so on.
It is possible to modify only a portion of a line by means of replacement,
as in the example above.
However even here, the
command is applied to whole lines at a time.
In general,
commands consist of zero or more line addresses, followed by a single
character command and possibly additional parameters; i.e.,
commands have the structure:
The address(es) indicate the line or range of lines to be affected by the
command.
If fewer addresses are given than the command accepts, then
default addresses are supplied.
The following options are available:
Suppress diagnostics.
This should be used if
standard input is from a script.
Prompt for an encryption key to be used in subsequent reads and writes
(see the
command).
Unsupported on Mac OS X.
Specify a command prompt.
This may be toggled on and off with the
command.
Specify the name of a file to read.
If
is prefixed with a
bang (!), then it is interpreted as a shell command.
In this case,
what is read is
the standard output of
executed via
To read a file whose name begins with a bang, prefix the
The default filename is set to
only if it is not prefixed with a bang.
An address represents the number of a line in the buffer.
The
utility maintains a
which is
typically supplied to commands as the default address when none is specified.
When a file is first read, the current address is set to the last line
of the file.
In general, the current address is set to the last line
affected by a command.
A line address is
constructed from one of the bases in the list below, optionally followed
by a numeric offset.
The offset may include any combination
of digits, operators (i.e.,
and
and whitespace.
Addresses are read from left to right, and their values are computed
relative to the current address.
One exception to the rule that addresses represent line numbers is the
address
(zero).
This means "before the first line,"
and is legal wherever it makes sense.
An address range is two addresses separated either by a comma or
semi-colon.
The value of the first address in a range cannot exceed the
value of the second.
If only one address is given in a range, then
the second address is set to the given address.
If an
of addresses is given where
then the corresponding range is determined by the last two addresses in
the
If only one address is expected, then the last address is used.
Each address in a comma-delimited range is interpreted relative to the
current address.
In a semi-colon-delimited range, the first address is
used to set the current address, and the second address is interpreted
relative to the first.
The following address symbols are recognized:
The current line (address) in the buffer.
The last line in the buffer.
The
line in the buffer
where
is a number in the range
The previous line.
This is equivalent to
and may be repeated with cumulative effect.
The
previous line, where
is a non-negative number.
The next line.
This is equivalent to
and may be repeated with cumulative effect.
The
next line, where
is a non-negative number.
The first through last lines in the buffer.
This is equivalent to
the address range
The current through last lines in the buffer.
This is equivalent to
the address range
The next line containing the regular expression
The search wraps to the beginning of the buffer and continues down to the
current line, if necessary.
The
previous line containing the regular expression
The search wraps to the end of the buffer and continues up to the
current line, if necessary.
?? repeats the last search.
The
line previously marked by a
(mark) command, where
is a lower case letter.
Regular expressions are patterns used in selecting text.
For example, the command:
prints all lines containing
Regular expressions are also
used by the
command for selecting old text to be replaced with new.
In addition to a specifying string literals, regular expressions can
represent
classes of strings.
Strings thus represented are said to be matched
by the corresponding regular expression.
If it is possible for a regular expression
to match several strings in a line, then the left-most longest match is
the one selected.
The following symbols are used in constructing regular expressions:
Any character
not listed below, including
and
matches itself.
Any backslash-escaped character
except for
and
matches itself.
Match any single character.
Match any single character in
To include a
in
it must be the first character.
A range of characters may be specified by separating the end characters
of the range with a
e.g.,
specifies the lower case characters.
The following literal expressions can also be used in
to specify sets of characters:
If
appears as the first or last
character of
then it matches itself.
All other characters in
match themselves.
Patterns in
of the form:
or,
where
is a
are interpreted according to the current locale settings
(not currently supported).
See
and
for an explanation of these constructs.
Match any single character, other than newline, not in
is defined
as above.
If
is the first character of a regular expression, then it
anchors the regular expression to the beginning of a line.
Otherwise, it matches itself.
If
is the last character of a regular expression, it
anchors the regular expression to the end of a line.
Otherwise, it matches itself.
Anchor the single character regular expression or subexpression
immediately following it to the beginning of a word.
(This may not be available)
Anchor the single character regular expression or subexpression
immediately following it to the end of a word.
(This may not be available)
Define a subexpression
Subexpressions may be nested.
A subsequent backreference of the form
where
is a number in the range [1,9], expands to the text matched by the
subexpression.
For example, the regular expression
matches any string
consisting of identical adjacent substrings.
Subexpressions are ordered relative to
their left delimiter.
Match the single character regular expression or subexpression
immediately preceding it zero or more times.
If
is the first
character of a regular expression or subexpression, then it matches
itself.
The
operator sometimes yields unexpected results.
For example, the regular expression
matches the beginning of
the string
(as opposed to the substring
since a null match
is the only left-most match.
Match the single character regular expression or subexpression
immediately preceding it at least
and at most
times.
If
is omitted, then it matches at least
times.
If the comma is also omitted, then it matches exactly
times.
Additional regular expression operators may be defined depending on the
particular
implementation.
All
commands are single characters, though some require additional parameters.
If a command's parameters extend over several lines, then
each line except for the last
In general, at most one command is allowed per line.
However, most commands accept a print suffix, which is any of
(print),
(list),
or
(enumerate),
to print the last line affected by the command.
An interrupt (typically ^C) has the effect of aborting the current command
and returning the editor to command mode.
The
utility
recognizes the following commands.
The commands are shown together with
the default address or address range supplied if none is
specified (in parenthesis).
Append text to the buffer after the addressed line.
Text is entered in input mode.
The current address is set to last line entered.
Change lines in the buffer.
The addressed lines are deleted
from the buffer, and text is appended in their place.
Text is entered in input mode.
The current address is set to last line entered.
Delete the addressed lines from the buffer.
If there is a line after the deleted range, then the current address is set
to this line.
Otherwise the current address is set to the line
before the deleted range.
Edit
and sets the default filename.
If
is not specified, then the default filename is used.
Any lines in the buffer are deleted before
the new file is read.
The current address is set to the last line read.
Edit the standard output of
(see
below).
The default filename is unchanged.
Any lines in the buffer are deleted before the output of
is read.
The current address is set to the last line read.
Edit
unconditionally.
This is similar to the
command,
except that unwritten changes are discarded without warning.
The current address is set to the last line read.
Set the default filename to
If
is not specified, then the default unescaped filename is printed.
Apply
to each of the addressed lines matching a regular expression
The current address is set to the
line currently matched before
is executed.
At the end of the
command, the current address is set to the last line affected by
Each command in
must be on a separate line,
and every line except for the last must be terminated by a backslash
Any commands are allowed, except for
and
A newline alone in
is equivalent to a
command.
Interactively edit the addressed lines matching a regular expression
For each matching line,
the line is printed,
the current address is set,
and the user is prompted to enter a
At the end of the
command, the current address
is set to the last line affected by (the last)
The format of
is the same as that of the
command.
A newline alone acts as a null command list.
A single
repeats the last non-null command list.
Toggle the printing of error explanations.
By default, explanations are not printed.
It is recommended that ed scripts begin with this command to
aid in debugging.
Print an explanation of the last error.
Insert text in the buffer before the current line.
Text is entered in input mode.
The current address is set to the last line entered.
Join the addressed lines.
The addressed lines are
deleted from the buffer and replaced by a single
line containing their joined text.
The current address is set to the resultant line.
Mark a line with a lower case letter
The line can then be addressed as
(i.e., a single quote followed by
in subsequent commands.
The mark is not cleared until the line is
deleted or otherwise modified.
Print the addressed lines unambiguously.
If a single line fills for than one screen (as might be the case
when viewing a binary file, for instance), a
prompt is printed on the last line.
The
utility waits until the RETURN key is pressed
before displaying the next screen.
The current address is set to the last line
printed.
Move lines in the buffer.
The addressed lines are moved to after the
right-hand destination address, which may be the address
(zero).
The current address is set to the
last line moved.
Print the addressed lines along with
their line numbers.
The current address is set to the last line
printed.
Print the addressed lines.
The current address is set to the last line
printed.
Toggle the command prompt on and off.
Unless a prompt was specified by with command-line option
the command prompt is by default turned off.
Quit
Quit
unconditionally.
This is similar to the
command,
except that unwritten changes are discarded without warning.
Read
to after the addressed line.
If
is not specified, then the default
filename is used.
If there was no default filename prior to the command,
then the default filename is set to
Otherwise, the default filename is unchanged.
The current address is set to the last line read.
Read
to after the addressed line
the standard output of
(see the
below).
The default filename is unchanged.
The current address is set to the last line read.
Replace text in the addressed lines
matching a regular expression
with
By default, only the first match in each line is replaced.
If the
(global) suffix is given, then every match to be replaced.
The
suffix, where
is a positive number, causes only the
match to be replaced.
It is an error if no substitutions are performed on any of the addressed
lines.
The current address is set the last line affected.
and
may be delimited by any character other than space and newline
(see the
command below).
If one or two of the last delimiters is omitted, then the last line
affected is printed as though the print suffix
were specified.
An unescaped
in
is replaced by the currently matched text.
The character sequence
where
is a number in the range [1,9], is replaced by the
backreference expression of the matched text.
If
consists of a single
then
from the last substitution is used.
Newlines may be embedded in
Repeat the last substitution.
This form of the
command accepts a count suffix
or any combination of the characters
and
If a count suffix
is given, then only the
match is replaced.
The
suffix causes
the regular expression of the last search to be used instead of the
that of the last substitution.
The
suffix toggles the global suffix of the last substitution.
The
suffix toggles the print suffix of the last substitution
The current address is set to the last line affected.
Copy (i.e., transfer) the addressed lines to after the right-hand
destination address, which may be the address
(zero).
The current address is set to the last line
copied.
Undo the last command and restores the current address
to what it was before the command.
The global commands
and
are treated as a single command by undo.
is its own inverse.
Apply
to each of the addressed lines not matching a regular expression
This is similar to the
command.
Interactively edit the addressed lines not matching a regular expression
This is similar to the
command.
Write the addressed lines to
Any previous contents of
is lost without warning.
If there is no default filename, then the default filename is set to
otherwise it is unchanged.
If no filename is specified, then the default
filename is used.
The current address is unchanged.
Write the addressed lines to
and then executes a
command.
Write the addressed lines to the standard input of
(see the
below).
The default filename and current address are unchanged.
Append the addressed lines to the end of
This is similar to the
command, expect that the previous contents of file is not clobbered.
The current address is unchanged.
Prompt for an encryption key which is used in subsequent reads and
writes.
If a newline alone is entered as the key, then encryption is
turned off.
Otherwise, echoing is disabled while a key is read.
Unsupported on Mac OS X.
Scroll
lines at a time starting at addressed line.
If
is not specified, then the current window size is used.
The current address is set to the last line printed.
Execute
via
If the first character of
is
then it is replaced by text of the
previous
The
utility does not process
However, an unescaped
is replaced by the default filename.
When the shell returns from execution, a
is printed to the standard output.
The current line is unchanged.
Print the line number of the addressed line.
Print the addressed line, and sets the current address to
that line.
buffer file
the file to which
attempts to write the buffer if the terminal hangs up
When an error occurs,
prints a
and either returns to command mode
or exits if its input is from a script.
An explanation of the last error can be
printed with the
(help) command.
Since the
(global) command masks any errors from failed searches and substitutions,
it can be used to perform conditional operations in scripts; e.g.,
replaces any occurrences of
with
If the
(undo) command occurs in a global command list, then
the command list is executed only once.
If diagnostics are not disabled, attempting to quit
or edit another file before writing a modified buffer
results in an error.
If the command is entered a second time, it succeeds,
but any changes to the buffer are lost.
USD:12-13
The
utility processes
arguments for backslash escapes, i.e., in a filename,
interpreted literally.
If a text (non-binary) file is not terminated by a newline character,
then
In the case of a binary file,
per line overhead: 4 ints
An
command appeared in
Version 1 AT&T UNIX.
The
utility does not recognize multibyte characters.


[
]
[
]


default is "A".

set the local modem capabilities.  See the section on
Class 1 the default is 1,n,0,2,0,0,0,0 where n is the highest
speed supported by the modem.  For Class 2 the default is
determined by the modem.


is a built-in 8x16 font.  See the efix(1) -f option for the font
file format.

6 %d escapes which are replaced by the baud rate following the
getty(8).

put string `hdr' at the top of each page.  The first %d in `hdr'
is replaced by the page number and the second, if any, is
replaced by the number of pages being sent.

-i commands are sent before the modem is put into fax mode, -j
commands after the modem is in fax mode, and -k commands just
before efax exits.  The only default is a hang-up (ATH) command
that is sent before exiting only if no other -k options are
given.  Multiple options may be used.

be the local telephone number in international format (for
example "+1 800 555-1212").  This is passed to the remote fax
machine.  Some fax machines may not accept characters other than
numbers, space, and '+'.  

protocol.  See the MODEM REQUIREMENTS section below for more

    0
Force use of Class 2.0 fax modem commands.  The modem must
support Class 2.0.

    2
Force use of Class 2 fax modem commands.  The modem must support
Class 2.

    1 
Force use of Class 1 fax modem commands. The modem must support
Class 1.  By default efax queries the modem and uses the first of
the three above classes which is supported by the modem.

    a
use software adaptive answer method.  If the first attempt to
answer the call does not result in a data connection within 8
seconds the phone is hung up temporarily and answered again in
fax mode (see "Accepting both fax and data calls" below).

    e 
ignore errors in modem initialization commands.

    f
use "virtual flow control".  efax tries to estimate the number of
bytes in the modem's transmit buffer and pauses as necessary to
avoid filling it.  The modem's buffer is assumed to hold at least
96 bytes.  This feature does not work properly with Class 2
modems that add redundant padding to scan lines.  Use this option
only if you have problems configuring flow control.

    h 
control.  Many modems will stop responding if this option is
used.  See the section `Resolving Problems' before using this
option.

    l
halve the time between testing lock files when waiting for other
programs to complete.  By default this is 8 seconds. For example
-olll sets the interval to 1 second.

    n
ignore requests for pages to be retransmitted. Use this option if
you don't care about the quality of the received fax or if the
receiving machine is too fussy.  Otherwise each page may be
retransmitted up to 3 times.

    r
do not reverse bit order during data reception for Class 2
modems.  Only Multitech modems require this option. Not normally
required since efax detects these modems.

    x
send XON (DC1) instead of DC2 to start data reception.  Applies
to a very few Class 2 modems only.

    z
delay an additional 100 milliseconds before each modem
initialization or reset command.  The initial delay is 100
ms. For example, -ozzz produces a 400 ms delay.  Use with modems
that get confused when commands arrive too quickly.


errors.  Default is 10.

each received fax page is stored in a separate file.  The file
A page number of the form .001, .002, ...  is appended to the
default string of "%m%d%H%M%S" is used.


remove lock file(s) after initializing the modem.  This allows
outgoing calls to proceed when efax is waiting for an incoming
call.  If efax detects modem activity it will attempt to re-lock
the device.  If the modem has been locked by the other program
efax will exit and return 1 (``busy'').  Normally a new efax
process is then started by launchd(8). The new efax process will
then check periodically until the lock file disappears and
then re-initialize the modem.

may contain any dial modifiers that the modem supports such as a
T prefix for tone dialing or commas for delays.  If no file names
are given the remote fax machine will be polled. If no -t
argument is given efax will answer the phone and attempt to
receive a fax.


e - 
errors
w - 
warnings
i - 
session progress information
n - 
capability negotiation information
c - 
modem (AT) commands and responses
h - 
HDLC frame data (Class 1 only)
m - 
modem output
a - 
program arguments
r -
reception error details
t -
transmission details
f -
image file details 
x -
lock file processing

Up to two -v options may be used.  The first is for messages
printed to the standard error and the second is for messages to
the standard output. The default is "ewin" to the standard error
only.

wait for an OK or CONNECT prompt instead of issuing an answer
program has already answered the call.

before opening it.  If the device is locked, efax checks every 15
seconds until it is free.  Up to 16 -x options may be used if
there are several names for the same device.  A `#' prefix on the
file name creates an binary rather than text (HDB-style) lock
file.  This is the reverse of what was used by previous efax
versions.


text, T.4 (Group 3), PBM, single- and multi-page TIFF (G3 and
uncompressed).  efax automatically determines the type of file
from its contents.  TIFF files are recommended as they contain
information about the image size and resolution.

Each page to be sent should be converted to a separate TIFF
format file with Group 3 (G3) compression.  Received files are
also stored in this format.  The EXAMPLES section below shows how
efix and other programs can be used to create, view and print
these files.


The operating system must provide short response times to avoid
protocol timeouts.  For Class 2 and 2.0 modems the delay should
not exceed 1 or 2 seconds.

When using Class 1 modems the program must respond to certain
events within 55 milliseconds.  Longer delays may cause the fax
protocol to fail in certain places (between DCS and TCF or
between RTC and MPS).  Class 1 modems should therefore not be
used on systems that cannot guarantee that the program will
respond to incoming data in less than 55 milliseconds.  In
particular, some intelligent serial cards and terminal servers
may introduce enough delay to cause problems with Class 1
operation.

The operating system must also provide sufficient low-level
buffering to allow uninterrupted transfer of data between the
modem and a disk file at the selected baud rate, typically 9600
bps.  Since the fax protocol does not provide end-to-end flow
control the effectiveness of flow control while receiving is
limited by the size of the modem's buffer. This can be less than
100 bytes.  Efax does not use flow control during reception.


The "Group" is the protocol used to send faxes between fax
machines.  Efax supports the Group 3 protocol used over the
public telephone network.

The "Class" is the protocol used by computers to control fax
modems.  Efax supports Class 1, 2 and 2.0 fax modems.

type of flow control adds very little overhead for fax use. Many
-oh option must be used to add hardware flow control.

While some modems have serial buffers of about 1k bytes, many
inexpensive modems have buffers of about one hundred bytes and
are thus more likely to suffer overruns when sending faxes.

A few older modems may need a delay between commands of more than
the default value used by efax (100 milliseconds).  If the delay
is too short, commands may not echo properly, may time out, or
options to increase the delay between modem initialization
commands and use the E0 modem initialization command to disable
echoing of modem commands.

By default efax sends DC2 to start the data flow from the modem
when receiving faxes from Class 2 modems.  A few older modems
require XON instead.  Use of DC2 would cause the modem to give an
option should be used in this case.

A few older Class 2 modems (e.g. some Intel models) don't send
DC2 or XON to start the data flow to the modem when sending
faxes.  After waiting 2 seconds efax will print a warning and
start sending anyways.

A very few Class 2 modems do not reverse the bit order (MSB to
LSB) by default on receive.  This might cause errors when trying
be used in this case.

9600 bps and reception is limited to 4800 bps.

The following Class 1 modems have been reported to work with efax:
AT&T DataPort,
Cardinal Digital Fax Modem (14400),
Digicom Scout+,
Motorola Lifestyle 28.8,
Motorola Power 28.8,
QuickComm Spirit II,
Smartlink 9614AV-Modem,
Supra Faxmodem 144LC,
USR Courier V.32bis Terbo,
USR Sportster (V.32 and V.34),
Zoom AFC 2.400,
Zoom VFX14.4V.

The following Class 2 modems have been reported to work with efax:
askey modem type 1414VQE,
AT&T DataPort,
AT&T Paradyne PCMCIA,
Boca modem,
BOCA M1440E, 
Crosslink 9614FH faxmodem,
FuryCard DNE 5005,
GVC 14.4k internal,
Intel 14.4 fax modem,
Megahertz 14.4,
Microcom DeskPorte FAST ES 28.8,
Motorola UDS FasTalk II,
MultiTech 1432MU,
Practical Peripherals PM14400FXMT,
Supra V32bis,
Telebit Worldblazer,
TKR DM-24VF+,
Vobis Fax-Modem (BZT-approved),
Zoom VFX14.4V,
ZyXEL U-1496E[+], 
ZyXEL Elite 2864I.


The required modem initialization commands are generated by efax.
Additional commands may be supplied as command-line arguments.
The modem must be set up to issue verbose(text) result codes.
The following command does this and is sent by efax before trying
to initialize the modem.

respond to commands with verbose result codes

The following commands may be useful for special purposes:

don't wait for dial tone before dialing.  This may be used to
send a fax when the call has already been dialed manually.  In
this case use an empty string ("") as the first argument to the
result codes.

leave the monitor speaker turned on for the duration of the call


disable echoing of modem commands.  See the Resolving Problems
section below.

returns the modem to command mode when DTR is dropped.  The
program drops DTR at the start and end of the call if it can't
reset the modem when DTR is dropped.

wait up to two minutes (120 seconds) for carrier.  This may be
useful if the answering fax machine takes a long time to start
with a long announcement).


The capabilities of the local hardware and software can be set
using a string of 8 digits separated by commas:


where:

0 for 98 lines per inch
1 for 196 lpi

0 for 2400 bps
1 for 4800
2 for 7200
3 for 9600
4 for 12000 (V.17)
5 for 14400 (V.17)

0 for 8.5" (21.5 cm) page width
1 for 10" (25.5 cm)
2 for 12" (30.3 cm)

0 for 11" (A4: 29.7 cm) page length
1 for 14" (B4: 36.4 cm)
2 for unlimited page length

0 for 1-D coding
1 for 2-D coding (not supported)

0 for no error correction

0 for no binary file transfer

0 for zero delay per line
1 for 5 ms per line
3 for 10 ms per line
5 for 20 ms per line
7 for 40 ms per line


fields of the capability string should be set to the maximum
values that your display software supports.  The default is 196


If the receiving fax machine does not support high resolution
pairs of scan lines.  If the receiving fax machine does not
support the image's width then efax will truncate or pad as



efax adds blank scan lines at the top of each image when it is
sent.  This allows room for the page header but increases the
length of the image (by default about 0.1" or 2.5mm of blank
space is added).

The header placed in this area typically includes the date and
time, identifies the, and shows the page number and total pages.
Headers cannot be disabled but the header string can be set to a
blank line.

The default font for generating the headers is the built-in 8x16
pixel font scaled to 12x24 pixels (about 9 point size).

Note that both efax and efix have -f options to specify the font.
efIx uses the font to generate text when doing text-to-fax
conversions (during "fax make") while efAx uses the font to
generate the header (during "fax send").


A session log is written to the standard error stream.  This log
gives status and error messages from the program as selected by
minutes and seconds is printed before each message.  Times
printed along with modem responses also show milliseconds.


The program returns an error code as follows:

0
The fax was successfully sent or received.

1
The dialed number was busy or the modem device was in use.  Try
again later.

2
Something failed (e.g. file not found or disk full). Don't retry.
Check the session log for more details.

3 
Modem protocol error.  The program did not receive the expected
response from the modem.  The modem may not have been properly
report may be in order.  Check the session log for more details.

4
The modem is not responding.  Operator attention is required.
Check that the modem is turned on and connected to the correct
port.

5
The program was terminated by a signal.

6
The program was terminated due to a system power event (i.e. the computer is about to sleep).

7
The operator canceled the call.



The efix program can be used to convert text files to TIFF-G3
format.  For example, the following command will convert the text

efix -nletter.%03d letter

TIFF-G3 format from postscript files.  For example, the command:


will convert the Postscript file
into high-resolution

the fax standard only requires that fax machines print a central
portion of the image 196.6mm (7.7 inches) wide by 281.5mm (11.1
inches) high.

The efix program can also insert bitmaps in images to create
letterhead, signatures, etc.


On CUPS based systems you can use lpr(1) to print faxes. For example, to 

lpr reply.001

On lpd based systems you can use the efix program to print faxes on Postscript or
HP-PCL (LaserJet) printers.  For example, to print the received

efix -ops reply.001 | lpr


The following command will dial the number 222-2222 using tone
dialing and send a two-page fax from the TIFF-G3 files letter.001

     -t T222-2222 letter.001 letter.002


You can use efax to answer the phone immediately and start fax
reception.  Use this mode if you need to answer calls manually to
see if they are fax or voice.

For example, the following command will make the fax modem on
fax.  The received fax will be stored in the files
identify itself as "555-1212" and receive faxes at high or low

   -c 1,5 -r reply


available from the modem (indicating an incoming call) before
rings.  The example below will make the modem answer incoming
calls in fax mode on the fourth ring and save the received faxes
using files names corresponding to the reception date and time.



The modem device can be shared by programs that use the UUCP
device locking protocol.  This includes pppd, chat, minicom,
kermit, uucico, efax, cu, and many others others.  However,
locking will only work if all programs use the same lock file.

efax will lock the modem device before opening it if one or more
directory that is to be locked.

while waiting for incoming calls so other programs can use the
same device.

If efax detects another program using the modem while it is
waiting to receive a fax, efax exits with a termination code of
1.  A subsequent efax process using this device will wait until
the other program is finished before re-initializing the modem
and starting to wait for incoming calls again.

Programs that try to lock the modem device by using device
locking facilities other than UUCP lock files not be able to use
this arbitration mechanism because the device will still be open
to the efax process.  In this case you will need to kill the efax
process (e.g. "fax stop") before starting the other program.

When efax is waiting for a fax it leaves the modem ready to
receive in fax mode but removes the lock file.  When a slip or
PPP program takes over the modem port by setting up its own lock
file efax cannot send any more commands to the modem -- not even
to reset it.  Therefore the other program has to set the modem
back to data mode when it starts up.  To do this add a modem
reset command (send ATZ expect OK) to the beginning of your slip
or PPP chat script.


(for Class 2[.0]) initialization string.  The type of call (data
or fax) can then be deduced from the modem's responses.

Some modems have limited adaptive answer features (e.g. only
working properly at certain baud rates or only in Class 2) or
none at all.  In this case use the initialization string
option to then hang up and try again in fax mode if the first
answer attempt was not successful.  This method only works if
your telephone system waits a few seconds after you hang up
before disconnecting incoming calls.

run as a shell command when an incoming data call is detected.
should expect to find the modem already off-hook and a lock file
present so it should not try to hang up the line or create a lock
file.  Note that the modem should be set up to report the DCE-DTE
(modem-computer, e.g. CONNECT 38400) speed, not the DCE-DCE
(modem-modem, e.g. CONNECT 14400) speed.  For many modems the
initialization option -iW0 will set this.

The following command will make efax answer incoming calls on
using two different lock files but these lock files will be
process.  Received fax files will be stored using names like
directory and the log file will be appended to


Note that adaptive answer of either type will not work for all
callers.  For some data calls the duration of the initial
data-mode answer may be too short for data handshaking to
complete.  In other cases this duration may be so long that
incoming fax calls will time out before efax switches to fax
mode.  In addition, some calling fax modems mistake data-mode
answering tones for fax signaling tones and initiate fax
negotiation too soon.  If you use software adaptive answer you
can reduce the value of the initial data-mode answer (set by
TO_DATAF in efax.c) to get more reliable fax handshaking or
increase it for more reliable data handshaking.  However, if you
need to provide reliable fax and data service to all callers you
should use separate phone numbers for the two types of calls.

When a call is answered the modem goes on-line with the
computer-to-modem baud rate fixed at the speed used for the most
recent AT command.  When efax is waiting for a fax or data call
it sets the interface speed to 19200 bps since this is the speed
required for fax operation.  This prevents full use of 28.8kbps
modem capabilities.



efax can answer all incoming calls if you create a launchd.plist(5)
process will run a new copy of efax when the system boots up and
whenever the previous efax process terminates.  The configuration

For example, the following XML Property List keeps efax running 
continuously:

  <?xml version="1.0" encoding="UTF-8"?>
  <plist version="1.0">
  <dict>
	  <array>

You should protect the fax script and configuration files against
tampering since launchd will execute them as a privileged (root)
process.  If you will be allowing data calls via getty and login
you should ensure that your system is reasonably secure
(e.g. that all user id's have secure passwords).

If efax exec()'s getty properly but you get a garbled login
prompt then there is probably a baud rate mismatch between the
modem and the computer.  First, check the efax log file to make
sure the modem's CONNECT response reported the serial port speed
getty manually with the same arguments and verify the port
want to enable hardware flow control for data connections (-h for
agetty, CRTSCTS for getty_ps).

A few programs won't work properly when efax is set up to answer
calls because they don't create lock files.  You can put the
shell script ``wrapper'' below around such programs to make them
work properly.  Change BIN and LOCKF to suit.

if [ -f $LOCKF ]
then
        echo lock file $LOCKF exists
        exit 1
else
        $BIN $*
        rm $LOCKF
fi



The "fax answer" script described above can be configured to
e-mail the fax files received by the previous fax answer process
to a "fax manager" who can then forward the fax to the correct
recipient.  The received fax files are send as MIME attachments,
one file per page, using the ``base64'' text encoding and the

To view the fax images directly from your e-mail reader you will
have to configure it with an application that can display files
will cause the fax file attachments to be displayed using the
``fax view'' command.



You can configure a "fax" printer into the lpr print spooler that
will fax a document out using efax instead of printing it. To set up a
fax printer do the following:



You should now be able to send a fax using the lpr interface by
using a command such as:

lpr -P fax -ophone="555-1212" file.ps

You can use lpq(1) to check the fax queue, lprm(1) to remove fax
jobs and lpc(8) to control the spooler.  In each case use the
-Pfax option to specify the fax ``printer.'' A log file will be
mailed to the user when the fax is sent.

See the lpr(1) man page for information on the print spooler.


Double check the configuration setup in the first part of the fax
script, particularly the modem device name and the lock file
names.

If efax hangs when trying to open the modem device (typically
process (e.g. pppd) or it requires the carrier detect line to be
true before it can be opened.  Many systems define an alternate
device name for the same physical device (typically cuaX) that
can be opened even if carrier is not present or other programs
are already using it.

If responses to modem initialization commands are being lost or
generated at random, another processes (e.g. getty or an efax
auto-answer process) may be trying to use the modem at the same
time.  Try running efax while this other program is running.  If
the lock files names are not specified correctly.

Attempt to send a fax. Check that the modem starts making the
calling signal (CNG, a 0.5 second beep every 3 seconds) as soon
as it's finished dialing.  This shows the modem is in fax mode.
You may need to set the SPKR variable to -iM2L3 to monitor the
phone line to do this.

Listen for the answering fax machine and check that it sends the
answer signal (CED, a 3 second beep) followed by "warbling"
sounds (DIS frames) every 3 seconds.  If you hear a continuous
sound (tones or noise) instead, then you've connected to a data
modem instead.

Your modem should send back its own warble (DCS frame) in
response to DIS immediately followed by 1.5 seconds of noise (a
channel check).  If everything is OK, the receiving end will send
another warble (CFR frame) and your modem will start to send
data.  If you have an external modem, check its LEDs.  If flow
control is working properly the modem's send data (SD) LED will
turn off periodically while the fax data is sent.

Check the message showing the line count and the average bit rate
when the page transmission is done.  Low line counts (under 1000
for a letter size image) or the warning "fax output buffer
overflow" while sending indicate that the image data format is
incorrect. Check the file being sent using the "fax view"
command.

If you get the error message ``flow control did not work'' then
flow control was not active.  This usually results in a garbled
transmission and the receiving machine may reject the page, abort

The warning "characters received while sending" or an <XOFF>
character appearing after the transmission means that the
operating system ignored the modem's XOFF flow control character.
Ensure that you are not running other programs such as getty or
flow control.

If you cannot get flow control to work properly then enable

Check that the remote machine confirms reception with a +FPTS:1
response (Class 2) or an MCF frame (Class 1).

For Class 2 modems, the error message "abnormal call termination
hung up.

Many companies advertise services that will fax back information
on their products.  These can be useful for testing fax
reception.

The message "run length buffer overflow" when receiving indicates
an error with the image data format.  You may need to use the

If efax displays the message "can't happen (<details>)" please
send a bug report to the author.

Finally, don't play "option bingo," if you can't resolve the
problem send a verbose log of the failed session (the output from


A Web Page with pointers to the latest version, known bugs and
patches is available at:


For Linux Systems

Independent packages provide more user-friendly interfaces to
efax (xfax, tefax) and provide an e-mail-to-fax (Qfax) gateway
using efax. All are available by anonymous FTP from

For Amiga Systems

A port of an early version of efax for the Amiga is available as
a component of a shareware voice mail package, AVM, distributed
by Al Villarica (rvillari@cat.syr.edu).

Other Ports

efax is relatively easy to port.  All system-dependent code is in
Version 0.8a was ported to Win32 by Luigi Capriotti.  Contact the
author if you would like to integrate the Win32 code into the
current version.


Efax was written by Ed Casas.  Please send comments or bug
reports to edc@cce.com.


Bug reports should include the operating system, the type of the
modem and a copy of a verbose session log that demonstrates the
problem.  It's usually impossible to help without a verbose log.


efax is copyright 1993 -- 1999 Ed Casas.  It may be used, copied
and modified under the terms of the GNU Public License.


prevent it from working correctly on your system.  Some of these
errors may cause serious problems including loss of data and
interruptions to telephone service.


CCITT Recommendation T.30, "Procedures for Document Facsimile
Transmission in the General Switched Telephone Network". 1988

CCITT Recommendation T.4, "Standardization of Group 3 Facsimile
Apparatus for Document Transmission". 1988.

For documentation on Class 1 and Class 2 fax commands as
implemented by Connexant (formerly Rockwell) modems see

For the TIFF specification see

For information on Ghostscript see

The pbm utilities can be obtained by ftp from wuarchive.wustl.edu

PCX and many other file formats are described in: Gunter Born,
The File Formats Handbook, International Thomson Computer Press,
1995.

The "Fax Modem Source Book" by Andrew Margolis, published by John
Wiley & Sons in 1994 (ISBN 0471950726), is a book on writing fax
applications which includes source code.

Dennis Bodson et. al., "FAX: Digital Facsimile Technology and
Applications", Second Edition. Artech House, Boston. 1992.




Can't read TIFF files with more than 1 strip

Class 1 operation may fail if the program can't respond to
certain data received from the modem within 55 milliseconds.

May fail if multitasking delays cause the received data to
overflow the computer's serial device buffer or if an under-run
of transmit data exceeds 5 seconds.

Polling does not work.

Does not support 2-D coding, ECM, or BFT.

[
]



determine the input type from its contents.

   fax
fax ("Group3") 1-D coded image

   text
text.  Line feeds separate lines, form feeds cause page breaks
and tabs are expanded assuming tabs every 8 columns.

   pbm
raw PBM (portable bit map)

   tiffg3
TIFF format with Group 3 (fax) compression.

   tiffraw
TIFF format with no compression.


   fax
fax ("Group3") 1-D coded image

   pbm
raw PBM

   pgm
raw PGM (Portable Gray Map).  Gray-scale values are produced by
the size given by -p.  The resulting image has 17 discrete values
between 0 and 255.

   pcl
HP-PCL (e.g. HP LaserJet).

   ps
encapsulated Postscript (e.g. Apple Laserwriter).  The file is
compressed using differential coding vertically and run-length
coding horizontally.  There is no provision for positioning the
image within the page and so the image will appear at the lower
left corner of the page when printed.

   tiffg3
TIFF format with Group 3 (fax) compression.

   tiffraw
TIFF format with no compression.

name.  Up to three %d escapes will be replaced by the page number
starting with 1 (e.g. -n order.%03d will create file names
order.001, order.002, etc.)


e - 
errors
w - 
warnings
i - 
information messages
a - 
program arguments
f - 
file format details

The default is "ewi".

should be a bit map of an image of H rows and 256*W columns.
Each successive WxH cell contains the bit map for characters with
codes from 0 to 255.  The default is to use a built-in 8x16 font.

scale the input by a factor of X horizontally and Y vertically.
Scaling does not change the size of the output (use -p).  If Y is
not specified it is assumed to be the same as X.  Any floating
point value may be used for X and Y. The default is 1,1.

displace the output right by R and down by D (opposite if
negative). See below for units.  Default is 0,0.

truncate or pad the output to generate an image of width W and
height H.  This does not scale the input.  See below for units.
The default is the size of the input image if it can be
determined or A4 (215x297mm) if it can't.

assume an output device resolution of X by Y dots per inch.  If Y
is not specified it is assumed to be the same as X.  The default
is the input resolution if it can be determined or the fax
resolution of 204.1x195.6 dpi if it can't.

assume an input device resolution of X by Y dots per inch.  If Y
is not specified it is assumed to be the same as X.  The default
is the input resolution if it can be determined or the fax
resolution of 204.1x195.6 dpi if it can't.

place n lines per page during text input. Default is 66.

overlay (logical OR) the image from file f into the output.  Use
"-" for standard input (-O-).  Default is no overlay file.

ignore all other options and copy the standard input to the
standard output while applying base64 (MIME) encoding as
specified by RFC 1521.



If no -n options are given, output is written to the standard
output.


The units of the W, H, R, and D values above are in inches by
default.  Any floating point value may be used.  Units of inches,
centimetres, millimetres or points (72 per inch) can be used
instead by appending one of the strings `in', `cm', `mm', or `pt'
to the argument (e.g. -d2,4cm).


The -d and -p options allow efix to cut out images from received
faxes for use in other faxes or documents.  The -d option specifies
the top left portion of the desired image and the -p option gives
the size of the cut image.  For example, the command
	efix -d-5,-8 -p2,1 sample.001 >sig.001
would cut out part of the input with its top left corner 5 inches
from the left edge and 8 inches from top of the input image.  The
output image would be 2 inches wide and 1 inch high.

The -O option allows efix to superimpose two or more images.  The
overlay image must be in fax format and cannot be scaled,
truncated or shifted. However, multiple efix commands may be used
to transform images before combining them.  For example, the
commands
	efix -d4,8 signature >sig.fax
	efix -O sig.fax letterhead >letterhead.fax
	efix -O letterhead.fax letter.002 >letter.002.new
will shift the image in the file signature down 8 inches and
right 4 inches and combine (overlay) it with the images in the
files letterhead and letter.002.


Gunter Born, "The File Formats Handbook", International Thompson
Computer Press, 1995.


efix is copyright 1994 -- 1999 by Ed Casas.  It may be used,
copied and modified under the terms of the GNU Public License.


prevent it from working correctly on your system.  Some of these
errors may cause serious problems including loss of data.




Only reads two types of TIFF compression formats.

Does not write multi-page TIFF files (a feature).

The
utility searches any given input files,
selecting lines that match one or more patterns.
By default, a pattern matches an input line if the regular expression
(RE) in the pattern matches the input line
without its trailing newline.
An empty expression matches every line.
Each input line that matches at least one of the patterns is written
to the standard output.
is used for simple patterns and
basic regular expressions
can handle extended regular expressions
See
for more information on regular expressions.
is quicker than both
and
but can only handle fixed patterns
(i.e. it does not interpret regular expressions).
Patterns may consist of one or more lines,
allowing any of the pattern lines to match a portion of the input.
and
act like
and
respectively, but accept input files compressed with the
or
compression utilities.
The following options are available:
Print
lines of trailing context after each match.
See also the
and
options.
Treat all files as ASCII text.
Normally
will simply print
if files contain binary characters.
Use of this option forces
to output lines matching the specified pattern.
Print
lines of leading context before each match.
See also the
and
options.
The offset in bytes of a matched pattern is
displayed in front of the respective matched line.
Print
lines of leading and trailing context surrounding each match.
The default is 2 and is equivalent to
Note:
no whitespace may be given between the option and its argument.
Only a count of selected lines is written to standard output.
Mark up the matching text with the expression stored in
environment variable.
The possible values of when can be `never', `always' or `auto'.
Specify the demanded action for devices, FIFOs and sockets.
The default action is `read', which means, that they are read
as if they were normal files.
If the action is set to `skip', devices will be silently skipped.
Specify the demanded action for directories.
It is `read' by default, which means that the directories
are read in the same manner as normal files.
Other possible values are `skip' to silently ignore the
directories, and `recurse' to read them recursively, which
has the same effect as the
and
option.
Interpret
as an extended regular expression
(i.e. force
to behave as
Specify a pattern used during the search of the input:
an input line is selected if it matches any of the specified patterns.
This option is most useful when multiple
options are used to specify multiple patterns,
or when a pattern begins with a dash
If specified, it excludes files matching the given
filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all files are searched that are
not excluded.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, it excludes directories matching the
given filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all directories are searched that are
not excluded.
Interpret
as a set of fixed strings
(i.e. force
to behave as
Read one or more newline separated patterns from
Empty pattern lines match every input line.
Newlines are not considered part of a pattern.
If
is empty, nothing is matched.
Interpret
as a basic regular expression
(i.e. force
to behave as traditional
Always print filename headers with output lines.
Never print filename headers
with output lines.
Print a brief help message.
Ignore binary files.
This option is equivalent to
option.
Perform case insensitive matching.
By default,
is case sensitive.
If specified, only files matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, only directories matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Decompress the
compressed file before looking for the text.
Only the names of files not containing selected lines are written to
standard output.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Only the names of files containing selected lines are written to
standard output.
will only search a file until a match has been found,
making searches potentially less expensive.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Use
instead of
to read input, which can result in better performance under some
circumstances but can cause undefined behaviour.
Stop reading the file after
matches.
Each output line is preceded by its relative line number in the file,
starting at line 1.
The line number counter is reset for each file processed.
This option is ignored if
or
is
specified.
Prints a zero-byte after the file name.
If
is specified, follow symbolic links only if they were explicitly listed
on the command line.
The default is not to follow symbolic links.
Prints only the matching part of the lines.
If
is specified, no symbolic links are followed.
This is the default.
Quiet mode:
suppress normal output.
will only search a file until a match has been found,
making searches potentially less expensive.
Recursively search subdirectories listed.
If
is specified, all symbolic links are followed.
The default is not to follow symbolic links.
Silent mode.
Nonexistent and unreadable files are ignored
(i.e. their error messages are suppressed).
Search binary files, but do not attempt to print them.
Display version information and exit.
Selected lines are those
matching any of the specified patterns.
The expression is searched for as a word (as if surrounded by
and
see
Only input lines selected against an entire fixed string or regular
expression are considered to be matching lines.
Equivalent to
Obsoleted.
Force
to behave as
Controls searching and printing of binary files.
Options are
the default: search binary files but do not print them;
do not search binary files;
and
treat all files as text.
Print
lines of leading and trailing context.
The default is 2.
Force output to be line buffered.
By default, output is line buffered when standard output is a terminal
and block buffered otherwise.
If no file arguments are specified, the standard input is used.
May be used to specify default options that will be placed at the beginning
of the argument list.
Backslash-escaping is not supported, unlike the behavior in GNU grep.
The
utility exits with one of the following values:
One or more lines were selected.
No lines were selected.
An error occurred.
To find all occurrences of the word
in a file:
To find all occurrences of the pattern
at the beginning of a line:
The apostrophes ensure the entire expression is evaluated by
instead of by the user's shell.
The caret
matches the null string at the beginning of a line,
and the
escapes the
which would otherwise match any character.
To find all lines in a file which do not contain the words
or
A simple example of an extended regular expression:
Peruses the file
looking for either 19, 20, or 25.
The
utility is compliant with the
specification.
The flags
are extensions to that specification, and the behaviour of the
flag when used with an empty pattern file is left undefined.
All long options are provided for compatibility with
GNU versions of this utility.
Historic versions of the
utility also supported the flags
This implementation supports those options;
however, their use is strongly discouraged.
The
command first appeared in
The
utility does not normalize Unicode input, so a pattern containing composed
characters will not match decomposed input, and vice versa.
Not intended for end users.
[
] [
]
is a version of
written by the author of the original (PDP-10)
Richard Stallman.
The primary documentation of GNU Emacs is in the GNU Emacs Manual,
which you can read using Info, either from Emacs or as a standalone
program.  Please look there for complete and up-to-date documentation.
This man page is updated only when someone volunteers to do so; the
Emacs maintainers' priority goal is to minimize the amount of time
this man page takes away from other more useful projects.
The user functionality of GNU Emacs encompasses
everything other
editors do, and it is easily extensible since its
editing commands are written in Lisp.
has an extensive interactive help facility,
but the facility assumes that you know how to manipulate
windows and buffers.
CTRL-h or F1 enters the Help facility.  Help Tutorial (CTRL-h t)
starts an interactive tutorial which can teach beginners the fundamentals
of
in a few minutes.
Help Apropos (CTRL-h a) helps you
find a command given its functionality, Help Character (CTRL-h c)
describes a given character's effect, and Help Function (CTRL-h f)
describes a given Lisp function specified by name.
Undo can undo several steps of modification to your buffers, so it is
easy to recover from editing mistakes.
many special packages handle mail reading (RMail) and sending (Mail),
outline editing (Outline), compiling (Compile), running subshells
within
windows (Shell), running a Lisp read-eval-print loop
(Lisp-Interaction-Mode), automated psychotherapy (Doctor), and much more.
There is an extensive reference manual, but
users of other Emacses
should have little trouble adapting even
without a copy.  Users new to
will be able
to use basic features fairly rapidly by studying the tutorial and
using the self-documentation features.
The following options are of general interest:
Edit
Go to the line specified by
(do not insert a space between the "+" sign and
the number).  This applies only to the next file specified.
Go to the specified
and
Do not load an init file.
Do not load the site-wide startup file.
Enable
Lisp debugger during the processing of the user init file
This is useful for debugging problems in the init file.
Load
init file.
Use specified
This must be the first argument specified in the command line.
Display
version information and exit.
The following options are lisp-oriented
(these options are processed in the order encountered):
Execute the lisp function
Load the lisp code in the file
Evaluate the Lisp expression
The following options are useful when running
as a batch editor:
Edit in batch mode.  The editor will send messages to stderr.  This
options to specify files to execute and functions to call.
Exit
while in batch mode.
Add
to the list of directories
searches for Lisp files.
has been tailored to work well with the X window system.
If you run
from under X windows, it will create its own X window to
display in.  You will probably want to start the editor
as a background process
so that you can continue using your original window.
can be started with the following X switches:
Specifies the name which should be assigned to the initial
window.  This controls looking up X resources as well as the window title.
Specifies the title for the initial X window.
Display the
window in reverse video.
Set the
window's font to that specified by
You will find the various
fonts in the
directory.
Note that
will only accept fixed width fonts.
Under the X11 Release 4 font-naming conventions, any font with the
value "m" or "c" in the eleventh field of the font name is a fixed
width font.  Furthermore, fonts whose name are of the form
are generally fixed width, as is the font
See
for more information.

When you specify a font, be sure to put a space between the
switch and the font name.
Set the
window's border width to the number of pixels specified by
Defaults to one pixel on each side of the window.
Set the window's internal border width to the number of pixels specified
by
Defaults to one pixel of padding on each side of the window.
Set the
window's width, height, and position as specified.  The geometry
specification is in the standard X format; see
for more information.
The width and height are specified in characters; the default is 80 by
24.  See the Emacs manual, section "Options for Window Size and Position",
for information on how window sizes interact
with selecting or deselecting the tool bar and menu bar.
On color displays, sets the color of the text.

Use the command
for a list of valid
color names.
On color displays,
sets the color of the window's background.
On color displays,
sets the color of the window's border.
On color displays,
sets the color of the window's text cursor.
On color displays,
sets the color of the window's mouse cursor.
Create the
window on the display specified by
Must be the first option specified in the command line.
Tells
not to use its special interface to X.  If you use this
switch when invoking
from an
window, display is done in that window.
You can set
default values for your
windows in your
file (see
Use the following format:
emacs.keyword:value
where
specifies the default value of
lets you set default values for the following keywords:
Sets the window's text font.
If
value is set to
the window will be displayed in reverse video.
If
value is set to
the window will iconify into the "kitchen sink."
Sets the window's border width in pixels.
Sets the window's internal border width in pixels.
For color displays,
sets the window's text color.
For color displays,
sets the window's background color.
For color displays,
sets the color of the window's border.
For color displays,
sets the color of the window's text cursor.
For color displays,
sets the color of the window's mouse cursor.
Sets the geometry of the
window (as described above).
Sets the title of the
window.
Sets the icon name for the
window icon.
If you try to set color values while using a black and white display,
the window's characteristics will default as follows:
the foreground color will be set to black,
the background color will be set to white,
the border color will be set to grey,
and the text and mouse cursors will be set to black.
The following lists the mouse button bindings for the
window under X11.

l l.
MOUSE BUTTON	FUNCTION
left	Set point.
middle	Paste text.
right	Cut text into X cut buffer.
SHIFT-middle	Cut text into X cut buffer.
SHIFT-right	Paste text.
CTRL-middle	Cut text into X cut buffer and kill it.
CTRL-right	T{
Select this window, then split it into
two windows.  Same as typing CTRL-x 2.
T}
CTRL-SHIFT-left	T{
down, wait for menu to appear, select
buffer, and release.  Move mouse out of
menu and release to cancel.
T}
CTRL-SHIFT-right	T{
Select window with mouse, and delete all
other windows.  Same as typing CTRL-x 1.
T}
You can order printed copies of the GNU Emacs Manual from the Free
Software Foundation, which develops GNU software.  See the file ORDERS
for ordering information.
Your local Emacs maintainer might also have copies available.  As
with all software and publications from FSF, everyone is permitted to
make and distribute copies of the Emacs manual.  The TeX source to the
manual is also included in the Emacs source distribution.
The complete text of the Emacs reference manual is included in a
convenient tree structured form.  Also includes the Emacs Lisp
Reference Manual, useful to anyone wishing to write programs in the
Emacs Lisp extension language.

that define most editing commands.  Some are preloaded;
others are autoloaded from this directory when used.

used with GNU Emacs.


strings for the Lisp primitives and preloaded Lisp functions
of GNU Emacs.  They are stored here to reduce the size of
Emacs proper.

various services to assist users of GNU Emacs, including education,
troubleshooting, porting and customization.

There is a mailing list, bug-gnu-emacs@gnu.org, for reporting Emacs
bugs and fixes.  But before reporting something as a bug, please try
to be sure that it really is a bug, not a misunderstanding or a
deliberate feature.  We ask you to read the section ``Reporting Emacs
Bugs'' near the end of the reference manual (or Info system) for hints
on how and when to report bugs.  Also, include the version number of

Do not expect a personal answer to a bug report.  The purpose of reporting
bugs is to get them fixed for everyone in the next release, if possible.
For personal assistance, look in the SERVICE file (see above) for
a list of people who offer it.

Please do not send anything but bug reports to this mailing list.
For more information about Emacs mailing lists, see the
fixed if they can be isolated, so it is in your interest to report
them in such a way that they can be easily reproduced.
is free; anyone may redistribute copies of
to
anyone under the terms stated in the
General Public License,
a copy of which accompanies each copy of
and which also
appears in the reference manual.
Copies of
may sometimes be received packaged with distributions of Unix systems,
but it is never included in the scope of any license covering those
systems.  Such inclusion violates the terms on which distribution
is permitted.  In fact, the primary purpose of the General Public
License is to prohibit anyone from attaching any other restrictions
to redistribution of
Richard Stallman encourages you to improve and extend
and urges that
you contribute your extensions to the GNU library.  Eventually GNU
(Gnu's Not Unix) will be a complete replacement for Unix.
Everyone will be free to use, copy, study and change the GNU system.
emacsclient(1), etags(1), X(1), xlsfonts(1), xterm(1), xrdb(1)
was written by Richard Stallman and the Free Software Foundation.
Joachim Martillo and Robert Krawitz added the X features.
Copyright
1995, 1999, 2000, 2001, 2002, 2003, 2004, 2005,
      2006, 2007 Free Software Foundation, Inc.
Permission is granted to make and distribute verbatim copies of this
document provided the copyright notice and this permission notice are
preserved on all copies.
Permission is granted to copy and distribute modified versions of
this document under the conditions for verbatim copying, provided that
the entire resulting derived work is distributed under the terms of
a permission notice identical to this one.
Permission is granted to copy and distribute translations of this
document into another language, under the above conditions for
modified versions, except that this permission notice may be stated
in a translation approved by the Free Software Foundation.

This manual page documents briefly the
command.  Full documentation is available in the GNU Info format; see
below.
distribution, but is not specific to that system.
works in conjunction with the built-in Emacs server.
You can either call
directly or let other programs run it for you when necessary.  On
GNU and Unix systems many programs consult the environment
variable EDITOR (sometimes also VISUAL) to obtain the command used for
editing.  Thus, setting this environment variable to 'emacsclient'
will allow these programs to use an already running Emacs for editing.
Other operating systems might have their own methods for defining the
default editor.

For
to work, you need an already running Emacs with a server.  Within Emacs,
call the functions `server-start' or `server-mode'.  (Your `.emacs' file
can do this automatically if you add either `(server-start)' or
`(server-mode 1)' to it.)

When you've finished editing the buffer, type `C-x #'
(`server-edit').  This saves the file and sends a message back to the
`emacsclient' program telling it to exit.  The programs that use
`EDITOR' wait for the "editor" (actually, `emacsclient') to exit.  `C-x
#' also checks for other pending external requests to edit various
files, and selects the next such file.

If you set the variable `server-window' to a window or a frame, `C-x
#' displays the server buffer in that window or in that frame.

The programs follow the usual GNU command line syntax, with long
options starting with two dashes (`-').
returns
immediately without waiting for you to "finish" the buffer in Emacs.
do not visit files but instead evaluate the arguments as Emacs
Lisp expressions.
use socket named FILENAME for communication.
use TCP configuration file FILENAME for communication.
This can also be specified via the `EMACS_SERVER_FILE' environment variable.
if the Emacs server is not running, run the specified editor instead.
This can also be specified via the `ALTERNATE_EDITOR' environment variable.
tell the server to display the files on the given display.
print version information and exit
print this usage information message and exit
The program is documented fully in
available via the Info system.
This manual page was written by Stephane Bortzmeyer <bortzmeyer@debian.org>,
This manual page is in the public domain.

Unicode Character Mapping files (.ucm) or Tcl Encoding Files (.enc).
Besides being used internally during the build process of the Encode
If you want to know as little about Perl as possible but need to
add a new encoding, just read this chapter and forget the rest.
Have a .ucm file ready.  You can get it from somewhere or you can write
your own from scratch or you can grab one from the Encode distribution
example below, I'll call my theoretical encoding myascii, defined
Issue a command as follows;
Now take a look at your current directory.  It should look like this.
The following files were created.
If you want *.ucm installed together with the modules, do as follows;
intention to give it to someone else.  But it is a good idea to edit
the pod and to add more tests.
Now issue a command all Perl Mongers love:
Now all you have to do is make.
The time it takes varies depending on how fast your machine is and
how large your encoding is.  Unless you are working on something big
like euc-tw, it won't take too long.
If you want to add your encoding to Encode's demand-loading list
to update Encode::ConfigLocal, a module that controls local settings.
more flexible than Tcl's Encoding Map and far more user-friendly,
this is the recommended format for Encode now.
The header section continues until a line containing the word
pair per line.  Strings used as values must be quoted. Barewords are
substitution character, not subcharacter.  When you decode a Unicode
sequence to this encoding but no matching character is found, the byte
sequence defined here will be used.  For most cases, the value here is
follows:
The format is roughly the same as a header section except for the
fallback flag: | followed by 0..3.   The meaning of the possible
values is as follows:
Round trip safe.  A character decoded to Unicode encodes back to the
same byte sequence.  Most characters have this flag.
character for the encode map only.
Skip sub-char mapping should there be no code point.
character for the decode map only.
or an existing encoding which is close to yours, rather than write
your own from scratch.
icu:state is not used.  Because of that, you need to write a perl
module if you want to support algorithmical encodings, notably
Encode::KR::2022_KR, and Encode::TW::HZ.
how to make sure:
Sort your map in Unicode order.
When you have a duplicate entry, mark either one with '|1' or '|3'.
this;
down, here is what happens.
ICU:Conversion Data
Encode,
perlmod,
perlpod
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Unicode Character Mapping files (.ucm) or Tcl Encoding Files (.enc).
Besides being used internally during the build process of the Encode
If you want to know as little about Perl as possible but need to
add a new encoding, just read this chapter and forget the rest.
Have a .ucm file ready.  You can get it from somewhere or you can write
your own from scratch or you can grab one from the Encode distribution
example below, I'll call my theoretical encoding myascii, defined
Issue a command as follows;
Now take a look at your current directory.  It should look like this.
The following files were created.
If you want *.ucm installed together with the modules, do as follows;
intention to give it to someone else.  But it is a good idea to edit
the pod and to add more tests.
Now issue a command all Perl Mongers love:
Now all you have to do is make.
The time it takes varies depending on how fast your machine is and
how large your encoding is.  Unless you are working on something big
like euc-tw, it won't take too long.
If you want to add your encoding to Encode's demand-loading list
to update Encode::ConfigLocal, a module that controls local settings.
more flexible than Tcl's Encoding Map and far more user-friendly,
this is the recommended format for Encode now.
The header section continues until a line containing the word
pair per line.  Strings used as values must be quoted. Barewords are
substitution character, not subcharacter.  When you decode a Unicode
sequence to this encoding but no matching character is found, the byte
sequence defined here will be used.  For most cases, the value here is
follows:
The format is roughly the same as a header section except for the
fallback flag: | followed by 0..3.   The meaning of the possible
values is as follows:
Round trip safe.  A character decoded to Unicode encodes back to the
same byte sequence.  Most characters have this flag.
character for the encode map only.
Skip sub-char mapping should there be no code point.
character for the decode map only.
or an existing encoding which is close to yours, rather than write
your own from scratch.
icu:state is not used.  Because of that, you need to write a perl
module if you want to support algorithmical encodings, notably
Encode::KR::2022_KR, and Encode::TW::HZ.
how to make sure:
Sort your map in Unicode order.
When you have a duplicate entry, mark either one with '|1' or '|3'.
this;
down, here is what happens.
ICU:Conversion Data
Encode,
perlmod,
perlpod
Unicode Character Mapping files (.ucm) or Tcl Encoding Files (.enc).
Besides being used internally during the build process of the Encode
If you want to know as little about Perl as possible but need to
add a new encoding, just read this chapter and forget the rest.
Have a .ucm file ready.  You can get it from somewhere or you can write
your own from scratch or you can grab one from the Encode distribution
example below, I'll call my theoretical encoding myascii, defined
Issue a command as follows;
Now take a look at your current directory.  It should look like this.
The following files were created.
If you want *.ucm installed together with the modules, do as follows;
intention to give it to someone else.  But it is a good idea to edit
the pod and to add more tests.
Now issue a command all Perl Mongers love:
Now all you have to do is make.
The time it takes varies depending on how fast your machine is and
how large your encoding is.  Unless you are working on something big
like euc-tw, it won't take too long.
If you want to add your encoding to Encode's demand-loading list
to update Encode::ConfigLocal, a module that controls local settings.
more flexible than Tcl's Encoding Map and far more user-friendly,
this is the recommended format for Encode now.
The header section continues until a line containing the word
pair per line.  Strings used as values must be quoted. Barewords are
substitution character, not subcharacter.  When you decode a Unicode
sequence to this encoding but no matching character is found, the byte
sequence defined here will be used.  For most cases, the value here is
follows:
The format is roughly the same as a header section except for the
fallback flag: | followed by 0..3.   The meaning of the possible
values is as follows:
Round trip safe.  A character decoded to Unicode encodes back to the
same byte sequence.  Most characters have this flag.
character for the encode map only.
Skip sub-char mapping should there be no code point.
character for the decode map only.
or an existing encoding which is close to yours, rather than write
your own from scratch.
icu:state is not used.  Because of that, you need to write a perl
module if you want to support algorithmical encodings, notably
Encode::KR::2022_KR, and Encode::TW::HZ.
how to make sure:
Sort your map in Unicode order.
When you have a duplicate entry, mark either one with '|1' or '|3'.
this;
down, here is what happens.
ICU:Conversion Data
Encode,
perlmod,
perlpod
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
encode_keychange - produce the KeyChange string for SNMPv3
-t md5|sha1
produces a KeyChange string using the old and new passphrases 
as described in Section 5 of RFC 2274 "User-based Security Model (USM) for 
option is mandatory and specifies the hash transform type to use.

The transform is used to convert passphrase to master key for a given
user (Ku), convert master key to the localized key (Kul), and to hash the 
old Kul with the random bits. 

Passphrases are obtained by examining a number of sources until success
(in order listed):
command line options (see 
and
options below);
the file 
which should only contain two lines with old and new passphrase;

specified, it is constructed from the first IP address for the local
host.
Force passphrases to be read from standard input.
Display the help message.
Passphrase used to generate the new Ku.
Passphrase used to generate the old Ku.
Turn off the prompt for passphrases when getting data from standard input.
Be verbose.
Echo passphrases to terminal.
                
The localized key method is defined in RFC 2274, Sections 2.6 and A.2, and
originally documented in
U. Blumenthal, N. C. Hien, B. Wijnen,
"Key Derivation for Network Management Applications",
The
utility executes another
after modifying the environment as
specified on the command line.
Each
option specifies the setting of an environment variable,
with a value of
All such environment variables are set before the
is executed.
The options are as follows:
Execute the
with only those environment variables specified by
options.
The environment inherited
by
is ignored completely.
Search the set of directories as specified by
to locate the specified
program, instead of using the value of the
environment variable.
Split apart the given
into multiple strings, and process each of the resulting strings
as separate arguments to the
utility.
The
option recognizes some special character escape sequences and
also supports environment-variable substitution, as described
below.
If the environment variable
is in the environment, then remove it before processing the
remaining options.
This is similar to the
command in
The value for
must not include the
character.
Print verbose information for each step of processing done by the
utility.
Additional information will be printed if
is specified multiple times.
The above options are only recognized when they are specified
before any
options.
If no
is specified,
prints out the names and values
The processing of the
option will split the given
into separate arguments based on any space or <tab> characters found in the
Each of those new arguments will then be treated as if it had been
specified as a separate argument on the original
command.
Spaces and tabs may be embedded in one of those new arguments by using
single
or double
quotes, or backslashes
Single quotes will escape all non-single quote characters, up to
the matching single quote.
Double quotes will escape all non-double quote characters, up to
the matching double quote.
It is an error if the end of the
is reached before the matching quote character.
If
would create a new argument that starts with the
character, then that argument and the remainder of the
will be ignored.
The
sequence can be used when you want a new argument to start
with a
character, without causing the remainder of the
to be skipped.
While processing the
value,
processing will treat certain character combinations as escape
sequences which represent some action to take.
The character escape sequences are in backslash notation.
The characters and their meanings are as follows:
Ignore the remaining characters in the
This must not appear inside a double-quoted string.
Replace with a <form-feed> character.
Replace with a <new-line> character.
Replace with a <carriage return> character.
Replace with a <tab> character.
Replace with a <vertical tab> character.
Replace with a
character.
This would be useful when you need a
as the first character in one of the arguments created
by splitting apart the given
Replace with a
character.
If this is found inside of a double-quoted string, then replace it
with a single blank.
If this is found outside of a quoted string, then treat this as the
separator character between new arguments in the original
Replace with a <double quote> character.
Replace with a <single quote> character.
Replace with a backslash character.
The sequences for <single-quote> and backslash are the only sequences
which are recognized inside of a single-quoted string.
The other sequences have no special meaning inside a single-quoted
string.
All escape sequences are recognized inside of a double-quoted string.
It is an error if a single
character is followed by a character other than the ones listed above.
The processing of
also supports substitution of values from environment variables.
To do this, the name of the environment variable must be inside of
such as:
The common shell syntax of
is not supported.
All values substituted will be the values of the environment variables
as they were when the
utility was originally invoked.
Those values will not be checked for any of the escape sequences as
described above.
And any settings of
will not effect the values used for substitution in
processing.
Also,
processing can not reference the value of the special parameters
which are defined by most shells.
For instance,
can not recognize special parameters such as:
or
if they appear inside the given
The
utility is often used as the
on the first line of interpreted scripts, as
described in
Note that the way the kernel parses the
(first line) of an interpreted script has changed as of
Prior to that, the
kernel would split that first line into separate arguments based
on any whitespace (space or <tab> characters) found in the line.
So, if a script named
had a first line of:
then the
program would have been started with the arguments of:
arg[1] = '-n'
arg[2] = '-q'
arg[3] = '-dsafe_mode=0'
plus any arguments the user specified when executing
However, this processing of multiple options on the
line is not the way any other operating system parses the
first line of an interpreted script.
So after a change which was made for
release, that script will result in
being started with the arguments of:
arg[1] = '-n -q -dsafe_mode=0'
plus any arguments the user specified.
This caused a significant change in the behavior of a few scripts.
In the case of above script, to have it behave the same way under
as it did under earlier releases, the first line should be
changed to:
The
utility will be started with the entire line as a single
argument:
and then
processing will split that line into separate arguments before
executing
The
utility uses the
environment variable to locate the requested
if the name contains no
characters, unless the
option has been specified.
An exit status of 126 indicates that
was found, but could not be executed.
An exit status of 127 indicates that
could not be found.
Since the
utility is often used as part of the first line of an interpreted script,
the following examples show a number of ways that the
utility can be useful in scripts.
The kernel processing of an interpreted script does not allow a script
to directly reference some other script as its own interpreter.
As a way around this, the main difference between
and
is that the latter works even if
is itself an interpreted script.
Probably the most common use of
is to find the correct interpreter for a script, when the interpreter
may be in different directories on different systems.
The following example will find the
interpreter by searching through the directories specified by
One limitation of that example is that it assumes the user's value
for
is set to a value which will find the interpreter you want
to execute.
The
option can be used to make sure a specific list of directories is
used in the search for
Note that the
option is also required for this example to work correctly.
The above finds
only if it is in
or
That could be combined with the present value of
to provide more flexibility.
Note that spaces are not required between the
and
options:
The
utility accepts the
option as a synonym for
The
utility conforms to
The
and
options are non-standard extensions supported by
but which may not be available on other operating systems.
The
command appeared in
The
and
options were added in
The
utility does not handle values of
which have an equals sign
in their name, for obvious reasons.
The
utility does not take multibyte characters into account when
processing the
option, which may lead to incorrect results in some locales.
Copyright (C) 1989-2000, 2001, 2004, 2005 Free Software Foundation, Inc.

Permission is granted to make and distribute verbatim copies of
this manual provided the copyright notice and this permission notice
are preserved on all copies.

Permission is granted to copy and distribute modified versions of this
manual under the conditions for verbatim copying, provided that the
entire resulting derived work is distributed under the terms of a
permission notice identical to this one.

Permission is granted to copy and distribute translations of this
manual into another language, under the above conditions for modified
versions, except that this permission notice may be included in
translations approved by the Free Software Foundation instead of in
the original English.
It is possible to have whitespace between a command line option and its
parameter.
This manual page describes the GNU version of
which is part of the groff document formatting system.
compiles descriptions of equations embedded within
input files into commands that are understood by
Normally, it should be invoked using the
option of
The syntax is quite compatible with Unix eqn.
The output of GNU
cannot be processed with Unix troff;
it must be processed with GNU troff.
If no files are given on the command line, the standard input
will be read.
A filename of
will cause the standard input to be read.
searches for the file
in the directories given with the
option first, then in
and finally in the standard macro directory
If it exists,
will process it before the other input files.
The
option prevents this.
GNU
does not provide the functionality of neqn:
it does not support low-resolution, typewriter-like devices
(although it may work adequately for very simple input).
Specify delimiters
for the left and right end, respectively, of in-line equations.
Any
statements in the source file overrides this.
Recognize
and
even when followed by a character other than space or newline.
Don't allow newlines within delimiters.
This option allows
to recover better from missing closing delimiters.
Print the version number.
Only one size reduction.
will not reduce the size of subscripts or superscripts to
The output is for device
The only effect of this is to define a macro
Typically
will use this to provide definitions appropriate for the output device.
The default output device is
Search
for
before the default directories.
Don't load
This is equivalent to a
command.
This is equivalent to a
command.
This option is deprecated.
will normally set equations at whatever the current point size
is when the equation is encountered.
This says that subscripts and superscripts should be
points smaller than the surrounding text.
This option is deprecated. 
Normally
makes sets subscripts and superscripts at 70% 
of the size of the surrounding text.
Only the differences between GNU
and Unix eqn are described here.
Most of the new features of GNU
below;
gives each component of an equation a type, and adjusts the spacing
between components using that type.
Possible types are:
ordinary
operator
a large operator such as
binary
relation
a relation such as `=';
opening
a opening bracket such as `(';
closing
a closing bracket such as `)';
punctuation
a punctuation character such as `,';
inner
a subformula contained within brackets;
suppress
spacing that suppresses automatic spacing adjustment.
Components of an equation get a type in one of two ways.
where
is one of the types mentioned above.
For example,
is defined as
The name of the type doesn't have to be quoted, but quoting protects
from macro expansion.
Unquoted groups of characters are split up into individual characters,
and the type of each character is looked up;
this changes the type that is stored for each character;
it says that the characters in
For example,
chartype "punctuation" .,;:
would make the characters `.,;:' have type punctuation
whenever they subsequently appeared in an equation.
can also be
or
in these cases
changes the font type of the characters.
See the
subsection.
This is similar to
reduces the size of
and
it also puts less vertical space between
or
and the fraction bar.
The
primitive in display styles;
corresponds to
in non-display styles.
This vertically centers
about the math axis.
The math axis is the vertical position about which characters
used for the bar of fractions.
For example,
is defined as
This sets
as an accent over
is assumed to be at the correct height for a lowercase letter;
will be moved down according if
is taller or shorter than a lowercase letter.
For example,
is defined as
accent { "^" }
and
are also defined using the
primitive.
This sets
as an accent under
is assumed to be at the correct height for a character without a descender;
will be moved down if
has a descender.
is pre-defined using
as a tilde accent below the baseline.
This has the same effect as simply
but
is not subject to macro expansion because it is quoted;
will be split up and the spacing between individual characters
will be adjusted.
This has the same effect as
but because
is not quoted it will be subject to macro expansion;
will not be split up
and the spacing between individual characters will not be adjusted.
This is a variant of
It produces a different result from
in a case such as
with
(as is conventional in mathematical typesetting),
whereas with
will be a subscript to the prime character.
The precedence of
is the same as that of
and
which is higher than that of everything except
and
that is not the first character will be treated like
using a
macro named
When the macro is called,
the string
and the number registers
and
(The
of an object says how much a subscript on that object should be tucked in;
the
of an object says how far to the right of the center of the object an
accent over the object should be placed.)
The macro must modify
so that it will output the desired result with its origin at the current
point, and increase the current horizontal position by the width
of the object.
The number registers must also be modified so that they correspond to the
result.
For example, suppose you wanted a construct that `cancels' an expression
by drawing a diagonal line through it.
define cancel 'special Ca'
with
Here's a more complicated construct that draws a box round an expression:
define box 'special Bx'
(in hundredths of an em) sets the vertical spacing before the equation,
a negative value sets the spacing after the equation, replacing the
default values.
This primitive provides an interface to
escape (but with opposite sign).
This keyword has no effect if the equation is part of a
picture.
(in hundredths of an em) increases the vertical spacing between rows,
using
escape.
Negative values are possible but have no effect.
If there is more than a single value given in a matrix, the biggest one
is used.
The appearance of equations is controlled by a large number of parameters.
These can be set using
the
command.
is an integer.
For example,
set x_height 45
says that
Possible parameters are as follows.
Values are in units of hundredths of an em unless otherwise stated.
These descriptions are intended to be expository rather than
definitive.
will not set anything at a smaller point-size than this.
The value is in points.
The
primitive emboldens an equation
by overprinting two copies of the equation
horizontally offset by this amount.
A fraction bar will be longer by twice this amount than
the maximum of the widths of the numerator and denominator;
in other words, it will overhang the numerator and
denominator by at least this amount.
When
or
is applied to a single character,
the line will be this long.
Normally,
or
produces a line whose length is the width of the object to which it applies;
in the case of a single character,
this tends to produce a line that looks too long.
Extensible delimiters produced with the
and
primitives will have a combined height and depth of at least this many
thousandths of twice the maximum amount by which the sub-equation that
the delimiters enclose extends away from the axis.
Extensible delimiters produced with the
and
primitives will have a combined height and depth
not less than the difference of
twice the maximum amount by which the sub-equation that
the delimiters enclose extends away from the axis
and this amount.
This much horizontal space is inserted
on each side of a fraction.
The width of subscripts and superscripts is increased by this amount.
This amount of space is automatically inserted after punctuation
characters.
This amount of space is automatically inserted on either side
of binary operators.
This amount of space is automatically inserted on either side of
relations.
The height of lowercase letters without ascenders such as `x'.
The height above the baseline of the center of characters
It is important that this value is correct for the font
you are using.
This should set to the thickness of the
character, or the thickness of horizontal lines produced with the
escape sequence.
The
command will shift up the numerator by at least this amount.
The
command will shift up the numerator by at least this amount.
The
command will shift down the denominator by at least this amount.
The
command will shift down the denominator by at least this amount.
Normally superscripts will be shifted up by at least this amount.
Superscripts within superscripts or upper limits
or numerators of
fractions
will be shifted up by at least this amount.
This is usually less than sup1.
Superscripts within denominators or square roots
or subscripts or lower limits will be shifted up by at least
this amount.
This is usually less than sup2.
Subscripts will normally be shifted down by at least this amount.
When there is both a subscript and a superscript, the subscript
will be shifted down by at least this amount.
The baseline of a superscript will be no more
than this much amount below the top of the object on
which the superscript is set.
The baseline of a subscript will be at least this much below
the bottom of the object on which the subscript is set.
The baseline of an upper limit will be at least this
much above the top of the object on which the limit is set.
The baseline of a lower limit will be at least this
much below the bottom of the object on which the limit is set.
The bottom of an upper limit will be at least this much above the
top of the object on which the limit is set.
The top of a lower limit will be at least this much below
the bottom of the object on which the limit is set.
This much vertical space will be added above and below limits.
The baselines of the rows in a pile or matrix will normally be
this far apart.
In most cases this should be equal to the sum of
and
The midpoint between the top baseline and the bottom baseline
in a matrix or pile will be shifted down by this much from the axis.
In most cases this should be equal to
This much space will be added between columns in a matrix.
This much space will be added at each side of a matrix.
If this is non-zero, lines will be drawn using the
escape sequence, rather than with the
escape sequence and the
character.
The amount by which the height of the equation exceeds this
will be added as extra space before the line containing the equation
(using
The default value is 85.
The amount by which the depth of the equation exceeds this
will be added as extra space after the line containing the equation
(using
The default value is 35.
If this is non-zero,
then
will behave like
and
will be ignored,
otherwise
will behave like
and
will be ignored.
file for the
and
devices.)
A more precise description of the role of many of these
Macros can take arguments.
In a macro body,
where
will be replaced by the
argument if the macro is called with arguments;
if there are fewer than
arguments, it will be replaced by nothing.
A word containing a left parenthesis where the part of the word
before the left parenthesis has been defined using the
command
will be recognized as a macro call with arguments;
characters following the left parenthesis
up to a matching right parenthesis will be treated as comma-separated
arguments;
commas inside nested parentheses do not terminate an argument.
This is like the
command, but
will not be recognized if called with arguments.
Include the contents of
and
are synonyms).
Lines of
beginning with
or
will be ignored.
If
has been defined by
(or has been automatically defined because
is the output device)
process
otherwise ignore
can be any character not appearing in
Remove definition of
making it undefined.
Besides the macros mentioned above, the following definitions are available:
(this is the same as
(three dots on the base line),
and
normally uses at least two fonts to set an equation:
an italic font for letters,
and a roman font for everything else.
The existing
command
changes the font that is used as the italic font.
The font that is used as the roman font can be changed
using the new
command.
The
primitive uses the current italic font set by
the
primitive uses the current roman font set by
There is also a new
command, which changes the font used by the
primitive.
If you only use the
and
primitives to changes fonts within an equation,
you can change all the fonts used by your equations
just by using
and
commands.
You can control which characters are treated as letters
(and therefore set in italics) by using the
command described above.
A type of
will cause a character to be set in italic type.
A type of
will cause a character to be set in roman type.
Initialization file.
Inline equations will be set at the point size that is current at the
beginning of the input line.
[
]
[
]
Reads an EQN equation (one line) as input; produces an image
file (by default in Portable Network Graphics format) suitable for the
Web as output.
that normally precedes it within 
macros; nor do you need to have dollar-sign or other delimiters
around the equation.
The output image will be a black-on-white graphic clipped to the
smallest possible bounding box that contains all the black pixels.
By specifying command-line options to be passed to 
you can give it a border, set the background transparent, set the
image's pixel density, or perform other useful transformations.
This program uses 
and the ImageMagick 
program.
These programs must be installed on your system and accessible on your
Run 
in the `unsafe' mode enabling the PIC macro
to execute arbitrary commands.
The default is to forbid this.
Specify an output format; the default is PNG (Portable Network Graphics).
Any format that
can emit is supported.
Command-line switches and arguments not listed above are passed to
The 
initialization file.
The directory in which temporary files will be created.
If this is not set
searches the environment variables
and
(in that order).
Otherwise, temporary files will be created in
Eric S. Raymond <esr@thyrsus.com>.
is a command line front-end for
library, which is an implementation of eRuby.
ERB provides an easy to use but powerful templating system for Ruby.
Using ERB, actual Ruby code can be added to any plain text document for the
is a part of
Prints the version of
Specifies the default value(s) for external encodings and internal encoding. Values should be separated with colon (:).
You can omit the one for internal encodings, then the value
Evaluates lines starting with
as Ruby code and removes the tailing EOLs.
Specifies the safe level in which eRuby script will run.
Specifies trim mode (default 0).
can be one of
EOL remains after the embedded ruby script is evaluated.
EOL is removed if the line ends with
EOL is removed if the line starts with
and ends with
EOL is removed if the line ends with
And leading whitespaces are removed if the erb directive starts with
can be one of
Sets the default value for internal encodings
Turns on debug mode.
will be set to true.
Prints a summary of the options.
Used with
Prepends the line number to each line in the output.
Enables verbose mode.
will be set to true.
Converts the eRuby script into Ruby script and prints it without line numbers.
Here is an eRuby script
<?xml version="1.0" ?>
<% require 'prime' -%>
<erb-example>
Command
prints
<?xml version="1.0" ?>
<erb-example>
And see
documentation for
class.
Reported problems will be published after being fixed.
Do not report security vulnerabilities
via the system because it publishes the vulnerabilities immediately.
Written by Masatoshi SEKI.


understood by
format understood by
the syntax of C, Objective C, C++, Java, Fortran, Ada, Cobol, Erlang, HTML,
Python, Prolog, Scheme and
Both forms read the files specified on the command line, and write a tag
Files specified with relative file names will be recorded in the tag
table with file names relative to the directory where the tag table
relative to the working directory.  Files specified with absolute file
names will be recorded
the name of the source file.
The programs recognize the language used in an input file based on its
parsing of the file names following the switch according to the given
language, overriding guesses based on filename extensions.
by ctags;
The programs accept unambiguous abbreviations for long option names.
through files.
In C and derived languages, create tags for function declarations,
Create tag entries for C preprocessor constant definitions
and enum constants, too.  Since this is the default behavior of
Do not create tag entries for C preprocessor constant definitions
and enum constants.
This may make the tags file much smaller if many header files are tagged.
accepts this option.
Create tag entries for global variables in C, C++, Objective C, Java,
and Perl.
accepts this option.
Do not tag global variables.  Typically this reduces the file size by
Include a note in the tag file indicating that, when searching for a
Don't rely on indentation as much as we normally do.  Currently, this
means not to assume that a closing brace in the first column is the
final brace of a function or structure definition in C and C++.
Parse the following files according to the given language.  More than
to get a list of the available languages and their default filename
extensions.  The `auto' language can be used to restore automatic
detection of language based on the file name.  The `none'
language may be used to disable language parsing altogether; only
Create tag entries for variables that are members of structure-like
constructs in C++, Objective C, Java.  This is the default for etags.
Do not tag member variables.  This is the default for ctags.
Only tag packages in Ada files.
May be used (only once) in place of a file name on the command line.

Make tags based on regexp matching for the files following this option,
in addition to the tags made with the standard parsing based on
option.  The regexps are cumulative, i.e. each such option will add to
the previous ones.  The regexps are of one of the forms:

useless characters.  If the match is such that more characters than
the same as in emacs.  The following character escape sequences are
respectively stand for the ASCII characters BEL, BS, DEL, ESC, FF, NL,
CR, TAB, VT.
at once, rather than line by line, and the matching sequence can match
character is needed inside the regular expression, it must be quoted
should be
otherwise.  This is particularly useful when storing many predefined
regexps in a file.
one per line.  Lines beginning with a space or tab are assumed
to be comments, and ignored.

Here are some examples.  All the regexps are quoted to protect them
from shell interpretation.

Tag the DEFVAR macros in the emacs source files:

Tag VHDL files (this example is a single long line, broken here for
formatting reasons):


a list of the recognised languages.  This feature is particularly useful inside
and those lines beginning with space or tab are ignored.  Lines beginning
with @ are references to regex files whose name follows the @ sign.  Other
For example, the command
reads the regexes contained in the file regex.file.
Don't do any more regexp matching on the following files.  May be
Record typedefs in C code as tags.  Since this is the default behavior
Generate tag entries for typedefs, struct, enum, and union tags, and
C++ member functions.  Since this is the default behavior
tag entries for other files in place.  Currently, this is implemented
by deleting the existing entries for the given files and then
rewriting the new entries at the end of the tags file.  It is often
faster to simply rebuild the entire tag file than to use this.
Instead of generating a tag file, write a cross reference (in
prints detailed information about how tags are created for LANG.
Print the current version of the program (same as the version of the

Stallman.

Copyright
1999, 2001, 2002, 2003, 2004, 2005, 2006, 2007  Free Software Foundation, Inc.
Permission is granted to make and distribute verbatim copies of this
document provided the copyright notice and this permission notice are
preserved on all copies.
Permission is granted to copy and distribute modified versions of
this document under the conditions for verbatim copying, provided that
the entire resulting derived work is distributed under the terms of
a permission notice identical to this one.
Permission is granted to copy and distribute translations of this
document into another language, under the above conditions for
modified versions, except that this permission notice may be stated
in a translation approved by the Free Software Foundation.

[options] [file ..]
starts
and sets options to make it behave like a modeless editor.
This is still Vim but used as a point-and-click editor.
This feels a lot like using Notepad on MS-Windows.
will always run in the GUI, to enable the use of menus and toolbar.
Only to be used for people who really can't work with Vim in the normal way.
Editing will be much less efficient.
See vim(1) for details about Vim, options, etc.
The 'insertmode' option is set to be able to type text directly.
Mappings are setup to make Copy and Paste work with the MS-Windows keys.
CTRL-X cuts text, CTRL-C copies text and CTRL-V pastes text.
Use CTRL-Q to obtain the original meaning of CTRL-V.
See vim(1).
The script loaded to initialize eVim.
Also Known As "Vim for gumbies".
When using evim you are expected to take a handkerchief,
make a knot in each corner and wear it on your head.
vim(1)
Most of
was made by Bram Moolenaar, with a lot of help from others.
[options] [file ..]
is a text editor that is upwards compatible to Vi.
It can be used to edit all kinds of plain text.
It is especially useful for editing programs.
There are a lot of enhancements above Vi: multi level undo,
multi windows and buffers, syntax highlighting, command line
editing, filename completion, on-line help, visual selection, etc..
See ":help vi_diff.txt" for a summary of the differences between
and Vi.
While running
a lot of help can be obtained from the on-line help system, with the ":help"
command.
See the ON-LINE HELP section below.
Most often
is started to edit a single file with the command
	vim file
More generally
is started with:
	vim [options] [filelist]
If the filelist is missing, the editor will start with an empty buffer.
Otherwise exactly one out of the following four may be used to choose one or
more files to be edited.
file ..
A list of filenames.
The first one will be the current file and read into the buffer.
The cursor will be positioned on the first line of the buffer.
You can get to the other files with the ":next" command.
The file to edit is read from stdin.  Commands are read from stderr, which
should be a tty.
The file to edit and the initial cursor position depends on a "tag", a sort
of goto label.
{tag} is looked up in the tags file, the associated file becomes the current
file and the associated command is executed.
Mostly this is used for C programs, in which case {tag} could be a function
name.
The effect is that the file containing that function becomes the current file
and the cursor is positioned on the start of the function.
Start in quickFix mode.
The file [errorfile] is read and the first error is displayed.
If [errorfile] is omitted, the filename is obtained from the 'errorfile'
option (defaults to "AztecC.Err" for the Amiga, "errors.err" on other
systems).
Further errors can be jumped to with the ":cn" command.
See ":help quickfix".
behaves differently, depending on the name of the command (the executable may
still be the same file).
vim
The "normal" way, everything is default.
ex
Start in Ex mode.
Go to Normal mode with the ":vi" command.
view
Start in read-only mode.  You will be protected from writing the files.  Can
gvim gview
The GUI version.
Starts a new window.
evim eview
The GUI version in easy mode.
Starts a new window.
rvim rview rgvim rgview
Like the above, but with restrictions.  It will not be possible to start shell
commands, or suspend
The options may be given in any order, before or after filenames.
Options without an argument can be combined after a single dash.
+[num]
For the first file the cursor will be positioned on line "num".
If "num" is missing, the cursor will be positioned on the last line.
For the first file the cursor will be positioned on the
first occurrence of {pat}.
+{command}
{command} will be executed after the
first file has been read.
{command} is interpreted as an Ex command.
If the {command} contains spaces it must be enclosed in double quotes (this
depends on the shell that is used).
Example: Vim "+set si" main.c
{file} will be sourced after the first file has been read.
argument).
processing any vimrc file.
If
has been compiled with ARABIC support for editing right-to-left
oriented files and Arabic keyboard mapping, this option starts
in Arabic mode, i.e. 'arabic' is set.  Otherwise an error
message is given and
aborts.
Binary mode.
A few options will be set that makes it possible to edit a binary or
executable file.
Compatible.  Set the 'compatible' option.
This will make
behave mostly like Vi, even though a .vimrc file exists.
Start in diff mode.
There should be two, three or four file name arguments.
will open all the files and show differences between them.
Works like vimdiff(1).
Open {device} for use as a terminal.
Only on the Amiga.
Example:
Debugging.  Go to debugging mode when executing the first command from a
script.
Start
in Ex mode, just like the executable was called "ex".
Start
in improved Ex mode, just like the executable was called "exim".
Foreground.  For the GUI version,
will not fork and detach from the shell it was started in.
On the Amiga,
is not restarted to open a new window.
This option should be used when
is executed by a program that will wait for the edit
session to finish (e.g. mail).
On the Amiga the ":sh" and ":!" commands will not work.
Foreground.  For the GUI version,
will not fork and detach from the shell it was started in.
If
has been compiled with FKMAP support for editing right-to-left
oriented files and Farsi keyboard mapping, this option starts
in Farsi mode, i.e. 'fkmap' and 'rightleft' are set.
Otherwise an error message is given and
aborts.
If
has been compiled with GUI support, this option enables the GUI.
If no GUI support was compiled in, an error message is given and
aborts.
Give a bit of help about the command line arguments and options.
After this
exits.
If
has been compiled with RIGHTLEFT support for editing right-to-left
oriented files and Hebrew keyboard mapping, this option starts
in Hebrew mode, i.e. 'hkmap' and 'rightleft' are set.
Otherwise an error message is given and
aborts.
When using the viminfo file is enabled, this option sets the filename to use,
This can also be used to skip the use of the .viminfo file, by giving the name
"NONE".
Lisp mode.
Sets the 'lisp' and 'showmatch' options on.
Modifying files is disabled.
Resets the 'write' option.
You can still modify the buffer, but writing a file is not possible.
Modifications not allowed.  The 'modifiable' and 'write' options will be unset,
so that changes are not allowed and files can not be written.  Note that these
options can be set to enable making modifications.
No-compatible mode.  Reset the 'compatible' option.
This will make
behave a bit better, but less Vi compatible, even though a .vimrc file does
not exist.
No swap file will be used.
Recovery after a crash will be impossible.
Handy if you want to edit a file on a very slow medium (e.g. floppy).
Can also be done with ":set uc=0".
Can be undone with ":set uc=200".
Become an editor server for NetBeans.  See the docs for details.
Open N windows stacked.
When N is omitted, open one window for each file.
Open N windows side by side.
When N is omitted, open one window for each file.
Open N tab pages.
When N is omitted, open one tab page for each file.
Read-only mode.
The 'readonly' option will be set.
You can still edit the buffer, but will be prevented from accidently
overwriting a file.
If you do want to overwrite a file, add an exclamation mark to the Ex command,
as in ":w!".
The 'readonly' option can be reset with ":set noro".
See ":help 'readonly'".
List swap files, with information about using them for recovery.
Recovery mode.
The swap file is used to recover a crashed editing session.
The swap file is a file with the same filename as the text file with ".swp"
appended.
See ":help recovery".
The script file {scriptin} is read.
The characters in the file are interpreted as if you had typed them.
The same can be done with the command ":source! {scriptin}".
If the end of the file is reached before the editor exits, further characters
are read from the keyboard.
Tells
the name of the terminal you are using.
Only required when the automatic way doesn't work.
Should be a terminal known
to
(builtin) or defined in the termcap or terminfo file.
Use the commands in the file {vimrc} for initializations.
All the other initializations are skipped.
Use this to edit a special kind of files.
It can also be used to skip all initializations by giving the name "NONE".
See ":help initialization" within vim for more details.
Use the commands in the file {gvimrc} for GUI initializations.
All the other GUI initializations are skipped.
It can also be used to skip all GUI initializations by giving the name "NONE".
Verbose.  Give messages about which files are sourced and for reading and
writing a viminfo file.  The optional number N is the value for 'verbose'.
Default is 10.
Start
in Vi mode, just like the executable was called "vi".  This only has effect
when the executable is called "ex".
All the characters that you type are recorded in the file
{scriptout}, until you exit
":source!".
If the {scriptout} file exists, characters are appended.
Use encryption when writing files.  Will prompt for a crypt key.
Don't connect to the X server.  Shortens startup time in a terminal, but the
window title and clipboard will not be used.
Start
in easy mode, just like the executable was called "evim" or "eview".
Makes
behave like a click-and-type editor.
Restricted mode.  Works like the executable starts with "r".
Denotes the end of the options.
Arguments after this will be handled as a file name.
GTK GUI only: Echo the Window ID on stdout.
Take file name arguments literally, do not expand wildcards.  This has no
effect on Unix where the shell expands wildcards.
Connect to a Vim server and make it edit the files given in the rest of the
arguments.  If no server is found a warning is given and the files are edited
in the current Vim.
Connect to a Vim server, evaluate {expr} in it and print the result on stdout.
Connect to a Vim server and send {keys} to it.
List the names of all Vim servers that can be found.
Use {name} as the server name.  Used for the current Vim, unless used with a
GTK GUI only: Use the GtkPlug mechanism to run gvim in another window.
Print version information and exit.
Type ":help" in
to get started.
Type ":help subject" to get help on a specific subject.
For example: ":help ZZ" to get help for the "ZZ" command.
Tags are present to jump from one place to another (sort of hypertext links,
see ":help").
All documentation files can be viewed in this way, for example
":help syntax.txt".
The
documentation files.
The tags file used for finding information in the documentation files.
System wide syntax initializations.
Syntax files for various languages.
System wide
initializations.
Your personal
initializations.
System wide gvim initializations.
Your personal gvim initializations.
Script used for the ":options" command, a nice way to view and set options.
System wide menu initializations for gvim.
Script to generate a bug report.  See ":help bugs".
Script to detect the type of a file by its name.  See ":help 'filetype'".
Script to detect the type of a file by its contents.  See ":help 'filetype'".
Files used for PostScript printing.
For recent info read the VIM home page:
vimtutor(1)
Most of
was made by Bram Moolenaar, with a lot of help from others.
See ":help credits" in
is based on Stevie, worked on by: Tim Thompson,
Tony Andrews and G.R. (Fred) Walter.
Although hardly any of the original code remains.
Probably.
See ":help todo" for a list of known problems.
Note that a number of things that may be regarded as bugs by some, are in fact
caused by a too-faithful reproduction of Vi's behaviour.
And if you think other things are bugs "because Vi does it differently",
you should take a closer look at the vi_diff.txt file (or type :help
vi_diff.txt when in Vim).
Also have a look at the 'compatible' and 'cpoptions' options.
The
utility processes the named files or the standard input writing
the standard output with tabs changed into blanks.
Backspace characters are preserved into the output and decrement
the column count for tab calculations.
The
utility is useful for pre-processing character files
(before sorting, looking at specific columns, etc.) that
contain tabs.
The
utility puts tabs back into the data from the standard input or the named
files and writes the result on the standard output.
The following options are available:
only.)
By default, only leading blanks and tabs
are reconverted to maximal strings of tabs.
If the
option is given, then tabs are inserted whenever they would compress the
resultant file by replacing two or more characters.
Set tab stops at column positions
If only a single number is given, tab stops are set that number of
column positions apart instead of the default number of 8.
The
and
environment variables affect the execution of
and
as described in
The
and
utilities conform to
The
command appeared in
[
]
[
]
[
[
]
]
[
]
is a program that "talks" to other interactive programs according to a
script.  Following the script,
knows what can be expected from
a program and what the correct response should be.  An interpreted
language provides branching and high-level control structures to
direct the dialogue.  In addition, the user can take control
and interact directly when desired, afterward returning control to the
script.
is a mixture of
and
It behaves just like
and
can also be used directly in C or C++ (that is, without Tcl).
See libexpect(3).
The name "Expect" comes from the idea of
sequences popularized
by uucp, kermit and other modem control programs.
However unlike uucp,
is generalized so that it can be run as a user-level command
with any program and task in mind.
can actually talk to several programs at the same time.
For example, here are some things
can do:
Cause your computer to dial you back,
so that you can login without paying for the call.
Start a game (e.g., rogue) and if the optimal configuration doesn't appear,
restart it (again and again) until it does,
then hand over control to you.
Run fsck, and in response to its questions, answer "yes", "no" or give control back to you,
based on predetermined criteria.
Connect to another network or BBS (e.g., MCI Mail, CompuServe) and
automatically retrieve your mail so that it appears as if
it was originally sent to your local system.
Carry environment variables, current directory,
or any kind of information across rlogin, telnet, tip, su, chgrp, etc.
There are a variety of reasons why the shell cannot perform these tasks.
(Try, you'll see.)
All are possible with
In general,
is useful for running any program which requires
interaction between the program and the user.
All that is necessary is that the interaction can be characterized
programmatically.
can also give the user back control
(without halting the program being controlled) if desired.
Similarly, the user can return control to the script at any time.
reads
for a list of commands to execute.
may also be invoked implicitly on systems which support the #! notation
by marking the script executable, and making the first line in your script:


Of course, the path must accurately describe where

The
flag prefaces a command to be executed before any in the script.
The command should be quoted to prevent being broken up by the shell.
This option may be used multiple times.
Multiple commands may be
executed with a single
by separating them with semicolons.
Commands are executed in the order they appear.  
(When using Expectk, this option is specified as
The
flag enables some diagnostic output, which
primarily reports internal activity of commands such as 
and
This flag has the same effect as "exp_internal 1" at the beginning of an Expect
script, plus the version of
is printed.
(The
command is useful for tracing statements, and the
command is useful for tracing variable assignments.)
(When using Expectk, this option is specified as
The
flag enables an interactive debugger.  An integer value should follow.
The debugger will take control before the next Tcl procedure
if the value is non-zero
or if a ^C is pressed (or a breakpoint is hit, or other appropriate debugger
command appears in the script).  See the README file or SEE ALSO (below)
for more information on the debugger.
(When using Expectk, this option is specified as
The
flag prefaces a file from which to read commands from.
The flag itself is optional as it is only useful when using
the #! notation (see above),
so that other arguments may be supplied on the command line.
(When using Expectk, this option is specified as
By default, the command file is read into memory and executed in its entirety.
It is occasionally desirable to read files one line at a time.  For example,
stdin is read this way.  In order to force arbitrary files to be handled this
way, use the
flag.
(When using Expectk, this option is specified as
The
flag causes
to interactively prompt for commands instead of reading
them from a file.
Prompting is terminated via the
command or upon EOF.
See
(below) for more information.
is assumed if neither a command file nor
is used.
(When using Expectk, this option is specified as
may be used to delimit the end of the options.  This is useful if
you want to pass an option-like argument to your script without it being
interpreted by
This can usefully be placed in the #! line to prevent any flag-like
interpretation by Expect.  For example, the following will leave the
original arguments (including the script name) in the variable


Note that the usual getopt(3) and execve(2) conventions must be observed
when adding arguments to the #! line.
the
flag is used.  
(When using Expectk, this option is specified as
Immediately after this,
flag is used.  If the environment variable DOTDIR is defined,
it is treated as a directory and .expect.rc is read from there.
(When using Expectk, this option is specified as
This sourcing occurs only after executing any
flags.
causes Expect to print its version number and exit.  (The corresponding flag
Optional
are constructed into a list and stored in the variable named
is initialized to the length of argv.
is defined to be the name of the script (or binary if no script is used).
For example,
the following prints out the name of the script and the first three arguments:


uses
(Tool Command Language).
Tcl provides control flow (e.g., if, for, break),
expression evaluation and several other features such as recursion,
procedure definition, etc.
Commands used here but not defined (e.g.,
are Tcl commands (see tcl(3)).
supports additional commands, described below.
Unless otherwise specified, commands return the empty string.
Commands are listed alphabetically so that they can be quickly located.
However, new users may find it easier to start by reading the descriptions
of
and
in that order.

Note that the best introduction to the language (both Expect and Tcl)
is provided in the book "Exploring Expect" (see SEE ALSO below).
Examples are included in this man page but they are very limited since
this man page is meant primarily as reference material.

Note that in the text of this man page, "Expect" with an uppercase "E"
refers to the
program while "expect" with a lower-case "e" refers to the
command within the
program.)
closes the connection to the current process.
Most interactive programs will detect EOF on their stdin and exit;
thus
usually suffices to kill the process as well.
The
flag declares the process to close corresponding to the named spawn_id.

Both
and
will detect when the current process exits and implicitly do a
But if you kill the process by, say, "exec kill $pid",
you will need to explicitly call

The
flag determines whether the spawn id will be closed in any new spawned
processes or if the process is overlayed.  To leave a spawn id open,
use the value 0.  A non-zero integer value will force the spawn closed
(the default) in any new processes.

The 
flag closes the slave associated with the spawn id.  (See "spawn -pty".)
When the connection is closed, the slave is automatically closed as
well if still open.

No matter whether the connection is closed implicitly or explicitly,
you should call
to clear up the corresponding kernel process slot.
does not call
since there is no guarantee that closing a process connection will cause
it to exit.
See
below for more info.
controls a Tcl debugger allowing you to step through statements, set
breakpoints, etc.

With no arguments, a 1 is returned if the debugger is not running, otherwise
a 0 is returned.

With a 1 argument, the debugger is started.  With a 0 argument, the
debugger is stopped.  If a 1 argument is preceded by the
flag, the debugger is started immediately (i.e., in the middle of the
command itself).  Otherwise, the debugger is started with the next
Tcl statement.

The
command does not change any traps.  Compare this to starting Expect with the 
flag (see above).

See the README file or SEE ALSO (below)
for more information on the debugger.
disconnects a forked process from the terminal.  It continues running in the
background.  The process is given its own process group (if possible).
The following fragment uses
to continue running the script in the background.  

    if {[fork]!=0} exit
    disconnect
    . . .

The following script reads a password, and then runs a program
every hour that demands a password each time it is run.  The script supplies
the password so that you only have to type it once.
(See the
command which demonstrates how to turn off password echoing.)

    for {} 1 {} {
        if {[fork]!=0} {sleep 3600;continue}
        disconnect
        spawn priv_prog
        expect Password:
        . . .
        exit
    }

An advantage to using
over the shell asynchronous process feature (&) is that
can
save the terminal parameters prior to disconnection, and then later
apply them to new ptys.  With &,
does not have a chance
to read the terminal's parameters since the terminal is already
disconnected by the time
receives control.
causes
to exit or otherwise prepare to do so.

The
flag causes the next argument to be used as an exit handler.
Without an argument, the current exit handler is returned.

The
flag causes
to prepare to exit but stop short of actually returning control to the
operating system.  The user-defined exit handler is run as well as Expect's
own internal handlers.
No further Expect commands should be executed.
This is useful if you are running Expect with other Tcl extensions.
The current interpreter (and main window if in the Tk environment) remain
so that other Tcl extensions can clean up.  If Expect's
is called again (however this might occur), the handlers are not rerun.

Upon exiting, 
all connections to spawned processes are closed.  Closure will be detected
as an EOF by spawned processes.
takes no other actions beyond what the normal _exit(2) procedure does.
Thus, spawned processes that do not check for EOF may continue to run.
(A variety of conditions are important to determining, for example, what
signals a spawned process will be sent, but these are system-dependent,
typically documented under exit(3).)
Spawned processes that continue to run will be inherited by init.

(or 0 if not specified) is returned as the exit status of
is implicitly executed if the end of the script is reached.
The command
allows
itself to continue
executing rather than returning as it normally would. By
default
resets the timeout timer. The
flag prevents timer from being restarted. (See
for more information.)
causes further commands to send diagnostic information internal to
to stderr if
is non-zero.  This output is disabled if
is 0.  The diagnostic information includes every character received,
and every attempt made to match the current output against the patterns.
If the optional
is supplied, all normal and debugging output is written to that file
(regardless of the value of
Any previous diagnostic output file is closed.

The
flag causes exp_internal to return a description of the
most recent non-info arguments given.
returns a Tcl file identifier that corresponds to the original spawn id.
The file identifier can then be used as if it were opened by Tcl's
command.  (The spawn id should no longer be used.  A
should not be executed.

The
flag leaves the spawn id open for access through 
Expect commands.  A
must be executed on the spawn id.
returns the process id corresponding to the currently spawned process.
If the
flag is used, the pid returned corresponds to that of the given spawn id.
is an alias for
is an alias for
is an alias for
is an alias for
is an alias for
is useful for assuring that the script is compatible with the current
version of Expect.
With no arguments, the current version of
is returned.  This version
may then be encoded in your script.  If you actually know that you are not
using features of recent versions, you can specify an earlier version.
Versions consist of three numbers separated by dots.  First
is the major number.  Scripts written for versions of
with a
different major number will almost certainly not work.
returns an error if the major numbers do not match.
Second is the minor number.  Scripts written for a version with a
greater minor number than the current version
may depend upon some new feature and might not run.
returns an error if the major numbers match, but the script minor number
is greater than that of the running
Third is a number that plays no part in the version comparison.
However, it is incremented when the
software
distribution is changed in any way, such as by additional documentation
or optimization.  It is reset to 0 upon each new minor version.
With the
flag,
prints an error and exits if the version is out of date.
waits until one of the patterns matches the output of a spawned process,
a specified time period has passed, or an end-of-file is seen.
If the final body is empty, it may be omitted.
Patterns from the most recent
command are implicitly used before any other patterns.
Patterns from the most recent
command are implicitly used after any other patterns.
If the arguments to the entire
statement require more than one line,
all the arguments may be "braced" into one so as to avoid terminating each
line with a backslash.  In this one case, the usual Tcl substitutions will
occur despite the braces.
If a pattern is the keyword
the corresponding body is executed upon end-of-file.
If a pattern is the keyword
the corresponding body is executed upon timeout.  If no timeout keyword
is used, an implicit null action is executed upon timeout.
The default timeout period is 10 seconds but may be set, for example to 30,
by the command "set timeout 30".  An infinite timeout may be designated
If a pattern is the keyword
the corresponding body is executed upon either timeout or end-of-file.
If a pattern matches, then the corresponding body is executed.
returns the result of the body (or the empty string if no pattern matched).
In the event that multiple patterns match, the one appearing first is
used to select a body.
Each time new output arrives, it is compared to each pattern in the order
they are listed.  Thus, you may test for absence of a match by making
the last pattern something guaranteed to appear, such as a prompt.
In situations where there is no prompt, you must use
(just like you would if you were interacting manually).
Patterns are specified in three ways.  By default, 
patterns are specified as with Tcl's
command.  (Such patterns are also similar to C-shell regular expressions
usually referred to as "glob" patterns).  The
flag may may
be used to protect patterns that might otherwise match
flags from doing so.
Any pattern beginning with a "-" should be protected this way.  (All strings
starting with "-" are reserved for future options.)

For example, the following fragment looks for a successful login.
(Note that
is presumed to be a procedure defined elsewhere in the script.)

    expect {
        failed             abort
        "invalid password" abort
        timeout            abort
        connected
    }

Quotes are necessary on the fourth pattern since it contains a space, which
would otherwise separate the pattern from the action.
Patterns with the same action (such as the 3rd and 4th) require listing the
actions again.  This can be avoid by using regexp-style patterns (see below).
More information on forming glob-style patterns can be found in the Tcl manual.
Regexp-style patterns follow the syntax defined by Tcl's
(short for "regular expression") command.
regexp patterns are introduced with the flag
The previous example can be rewritten using a regexp as:

    expect {
        timeout    abort
        connected
    }

Both types of patterns are "unanchored".  This means that patterns
do not have to match the entire string, but can begin and end the
match anywhere in the string (as long as everything else matches).
Use ^ to match the beginning of a string, and $ to match the end.
Note that if you do not wait for the end of a string, your responses
can easily end up in the middle of the string as they are echoed from
the spawned process.  While still producing correct results, the output
can look unnatural.  Thus, use of $ is encouraged if you can exactly
describe the characters at the end of a string.

Note that in many editors, the ^ and $ match the beginning and end of
lines respectively. However, because expect is not line oriented,
these characters match the beginning and end of the data (as opposed
to lines) currently in the expect matching buffer.  (Also, see the
note below on "system indigestion.")

The
flag causes the pattern to be matched as an "exact" string.  No
interpretation of *, ^, etc is made (although the usual Tcl
conventions must still be observed).
Exact patterns are always unanchored.

The
flag causes uppercase characters of the output to compare as if they were
lowercase characters.  The pattern is not affected.
While reading output,
more than 2000 bytes can force earlier bytes to be "forgotten".
This may be changed with the function
(Note that excessively large values can slow down the pattern matcher.)
If
is
the corresponding body is executed if
bytes have been received and no other patterns have matched.
Whether or not the
keyword is used, the forgotten characters are written to
expect_out(buffer).

If
is the keyword
and nulls are allowed (via the
command), the corresponding body is executed if a single ASCII
0 is matched.
It is not possible to
match 0 bytes via glob or regexp patterns.

Upon matching a pattern (or eof or full_buffer),
any matching and previously unmatched output is saved in the variable
Up to 9 regexp substring matches are saved in the variables
through
If the
flag is used before a pattern,
the starting and ending indices (in a form suitable for
of the
10 strings are stored in the variables
and
where X is a digit, corresponds to the substring position in the buffer.
0 refers to strings which matched the entire pattern
and is generated for glob patterns as well as regexp patterns.

    expect "cd"

is as if the following statements had executed:

    set expect_out(0,string) cd
    set expect_out(buffer) abcd



is as if the following statements had executed:

    set expect_out(0,start) 1
    set expect_out(0,end) 10
    set expect_out(0,string) bbbcabkkkk
    set expect_out(1,start) 2
    set expect_out(1,end) 3
    set expect_out(1,string) bb
    set expect_out(2,start) 10
    set expect_out(2,end) 10
    set expect_out(2,string) k
    set expect_out(buffer) abbbcabkkkk

flush the output buffer without reading any more output from the
process.
Normally, the matched output is discarded from Expect's internal buffers.
This may be prevented by prefixing a pattern with the
flag.  This flag is especially useful in experimenting (and can be
abbreviated to "-not" for convenience while experimenting).

The spawn id associated with the matching output (or eof or
full_buffer) is stored in

The
flag causes the current expect command to use the following value
as a timeout instead of using the value of the timeout variable.

By default, 
patterns are matched against output from the current process, however the
flag declares the output from the named spawn_id list be matched against
any following patterns (up to the next
The spawn_id list should either be a whitespace separated list of spawn_ids
or a variable referring to such a list of spawn_ids.

For example, the following example waits for
"connected" from the current process, or "busy", "failed" or "invalid
password" from the spawn_id named by $proc2.

    expect {
        timeout abort
        connected
    }

The value of the global variable
may be used to match patterns to any spawn_ids that are named
with all other
flags in the current
command.
The spawn_id from a
flag with no associated pattern (i.e., followed immediately
by another
is made available to any other patterns
in the same
command associated with

The
flag may also name a global variable in which case the variable is read
for a list of spawn ids.  The variable is reread whenever it changes.
execution.  Spawn ids provided this way are called "indirect" spawn ids.

Actions such as
and
cause control structures (i.e.,
to behave in the usual way.
The command
allows
itself to continue
executing rather than returning as it normally would.
This is useful for avoiding explicit loops or repeated expect statements.
The following example is part of a fragment to automate rlogin.  The
avoids having to write a second
statement (to look for the prompt again) if the rlogin prompts for a password.

    expect {
        Password: {
            stty -echo
            send_user "password (for $user) on $host: "
            stty echo
            exp_continue
        } incorrect {
            exit
        } timeout {
            exit
        } eof {
                "connection to host failed: $expect_out(buffer)"
            exit
        } -re $prompt
    }

For example, the following fragment might help a user guide
an interaction that is already totally automated.  In this case, the terminal
is put into raw mode.  If the user presses "+", a variable is incremented.
If "p" is pressed, several returns are sent to the process,
perhaps to poke it in some way, and "i" lets the user interact with the
process, effectively stealing away control from the script.
In each case, the
allows the current
to continue pattern matching after executing the
current action.

    expect_after {
        "+" {incr foo; exp_continue}
        "i" {interact; exp_continue}
        "quit" exit
    }

By default,
resets the timeout timer.  The timer is not restarted, if
is called with the 
flag.
works identically to the
except that if patterns from both
and
can match, the
pattern is used.  See the
command for more information.
takes the same arguments as
however it returns immediately.
Patterns are tested whenever new input arrives.
The pattern
and
are meaningless to
and are silently discarded.
Otherwise, the
command uses
and
patterns just like
does.

When
actions are being evaluated, background processing for the same
spawn id is blocked.  Background processing is unblocked when
the action completes.  While background processing is blocked,
it is possible to do a (foreground)
on the same spawn id.

It is not possible to execute an
while an
is unblocked.
for a particular spawn id is deleted by
declaring a new expect_background with the same spawn id.  Declaring
with no pattern removes the given spawn id
from the ability to match patterns in the background.
takes the same arguments as
however it returns immediately.
Pattern-action pairs from the most recent
with the same spawn id are implicitly added to any following
commands.  If a pattern matches, it is treated as if it had been
specified in the
command itself, and the associated body is executed in the context
of the
command.
If patterns from both
and
can match, the
pattern is used.

If no pattern is specified, the spawn id is not checked for any patterns.

Unless overridden by a
flag,
patterns match against the spawn id defined at the time that the 
command was executed (not when its pattern is matched).

to return the current specifications of what patterns it will match.
By default, it reports on the current spawn id.  An optional spawn id specification may be given for information on that spawn id.  For example

    expect_before -info -i $proc

suppresses direct spawn ids that come only from indirect specifications.

Instead of a spawn id specification, the flag "-all" will cause
"-info" to report on all spawn ids.

is like
By default, reading is performed in cooked mode.
Thus, lines must end with a return in order for
to see them.
This may be changed via
(see the
command below).
is like
but it reads characters from stdin (i.e. keystrokes from the user).
By default, reading is performed in cooked mode.
Thus, lines must end with a return in order for
to see them.
This may be changed via
(see the
command below).
creates a new process.  The new process is an exact copy of the current
process.  On success,
returns 0 to the new (child) process and returns the process ID of the child
process to the parent process.
On failure (invariably due to lack of resources, e.g., swap space, memory),
Forked processes exit via the
command, just like the original process.
Forked processes are allowed to write to the log files.  If you do not
disable debugging or logging in most of the processes, the result can be
confusing.
Some pty implementations may be confused by multiple readers and writers,
even momentarily.  Thus, it is safest to
before spawning processes.
gives control of the current process to the user, so that
keystrokes are sent to the current process,
and the stdout and stderr of the current process are returned.
String-body pairs may be specified as arguments, in which case the
body is executed when the corresponding string is entered.  (By default, the
string is not sent to the current process.)   The
command is assumed, if the final body is missing.
If the arguments to the entire
statement require more than one line,
all the arguments may be "braced" into one so as to avoid terminating each
line with a backslash.  In this one case, the usual Tcl substitutions will
occur despite the braces.
For example, the following command runs interact with the following
string-body pairs defined:  When ^Z is pressed,
is suspended.
(The
flag restores the terminal modes.)
When ^A is pressed, the user sees "you typed a control-A" and the
process is sent a ^A.  When $ is pressed, the user sees the date.
When ^C is pressed,
exits.  If "foo" is entered, the user sees "bar".
When ~~ is pressed, the
interpreter runs interactively.

    interact {
               }
        $      {send_user "The date is [clock format [clock seconds]]."}
        foo    {send_user "bar"}
        ~~
    }

In string-body pairs, strings are matched in the order they are listed
as arguments.  Strings that partially match are not sent to the
current process in anticipation of the remainder coming.  If
characters are then entered such that there can no longer possibly be
a match, only the part of the string will be sent to the process that cannot
possibly begin another match.  Thus, strings that are substrings of
partial matches can match later, if the original strings that was attempting
to be match ultimately fails.
By default, string matching is exact with no wild cards.  (In contrast,
the
command uses glob-style patterns by default.)  The
flag may be used to protect patterns that might otherwise match
flags from doing so.
Any pattern beginning with a "-" should be protected this way.    (All strings
starting with "-" are reserved for future options.)

The
flag forces the string to be interpreted as a regexp-style pattern.  In this
case, matching substrings are stored in the variable
similarly to the way
stores its output in the variable
The
flag is similarly supported.

The pattern
introduces an action that is 
executed upon end-of-file.  A separate
pattern may also follow the
flag in which case it is matched if an eof is detected while writing output.
The default
action is "return", so that
simply returns upon any EOF.

The pattern
introduces a timeout (in seconds) and action that is executed
after no characters have been read for a given time.
The
pattern applies to the most recently specified process.
There is no default timeout.
The special variable "timeout" (used by the
command) has no affect on this timeout.

For example, the following statement could be used to autologout users who have
not typed anything for an hour but who still get frequent system
messages:

        $spawn_id 


If the pattern is the keyword
and nulls are allowed (via the
command), the corresponding body is executed if a single ASCII
0 is matched.
It is not possible to
match 0 bytes via glob or regexp patterns.

Prefacing a pattern with the flag
causes the variable
to be set to the spawn_id which matched the pattern
(or eof).

Actions such as
and
cause control structures (i.e.,
to behave in the usual way.
However
causes interact to return to its caller, while
causes
to cause a return in its caller.  For example, if "proc foo" called
which then executed the action
would return.  (This means that if
calls
interactively typing
will cause the interact to continue, while
will cause the interact to return to its caller.)
During
raw mode is used so that all characters may be passed to the current process.
If the current process does not catch job control signals,
it will stop if sent a stop signal (by default ^Z).
If you really want to send a SIGSTOP to such a process (by ^Z),
consider spawning csh first and then running your program.
On the other hand, if you want to send a SIGSTOP to
itself, first call interpreter (perhaps by using an escape character), and then press ^Z.
String-body pairs can be used as a shorthand for avoiding having
to enter the interpreter and execute commands interactively.  The previous
terminal mode is used while the body of a string-body pair is being executed.
For speed, actions execute in raw mode by default.  The
flag resets the terminal to the mode it had before
was executed (invariably, cooked mode).
Note that characters entered when the mode is being switched may be lost
(an unfortunate feature of the terminal driver on some systems).
The only reason to use
is if your action
depends on running in cooked mode.
The
flag sends characters that match the following pattern back to the process
that generated them as each character is read.  This may be useful
when the user needs to see feedback from partially typed patterns.
If a pattern is being echoed but eventually fails to match,
the characters are sent to the spawned process.  If the spawned
process then echoes them, the user will see the characters twice.
is probably only appropriate in situations where the user is
unlikely to not complete the pattern.  For example, the following
excerpt is from rftp, the recursive-ftp script, where the user is
prompted to enter ~g, ~p, or ~l, to get, put, or list the current
directory recursively.  These are so far away from the normal ftp
commands, that the user is unlikely to type ~ followed by anything
else, except mistakenly, in which case, they'll probably just ignore
the result anyway.

    interact {
        -echo ~g {getcurdirectory 1}
        -echo ~l {getcurdirectory 0}
        -echo ~p {putcurdirectory}
    }

The
flag sends characters that match the following pattern on to
the output process as characters are read.

This is useful when you wish to let a program echo back the pattern.
For example, the following might be used to monitor where a person is
dialing (a Hayes-style modem).  Each time "atd" is seen the script
logs the rest of the line.

    proc lognumber {} {
        puts $log "[clock format [clock seconds]]: dialed $interact_out(1,string)"
    }

    interact -nobuffer "atd" lognumber

During
previous use of
is ignored.  In particular,
will force its output to be logged (sent to the standard output)
since it is presumed the user doesn't wish to interact blindly.
The
flag causes any following key-body pairs to be applied to the output of
the current process.
This can be useful, for example, when dealing with hosts that
send unwanted characters during a telnet session.  
By default, 
expects the user to be writing stdin and reading stdout of the
process
itself.
The
flag (for "user") makes
look for the user as the process named by its argument
(which must be a spawned id).  
This allows two unrelated processes to be joined
together without using an explicit loop.  To aid in debugging, Expect
diagnostics always go to stderr (or stdout for certain logging and
debugging information).  For the same reason, the
command will read interactively from stdin.
For example, the following fragment creates a login process.
Then it dials the user (not shown), and finally connects the two together.
Of course, any process may be substituted for login.
A shell, for example, would allow the user to work without supplying an
account and password.

    spawn login
    set login $spawn_id
    spawn tip modem
    # dial back out to user
    # connect user to login

To send output to multiple processes, list each spawn id list prefaced by a
flag.  Input for a group of output spawn ids may be determined
by a spawn id list prefaced by a
flag.  (Both
and
may take lists in the same form as the
flag in the
command, except that any_spawn_id is not meaningful in
All following flags and
strings (or patterns) apply to this input until another -input flag appears.
If no
appears,
(Similarly, with patterns that do not have
If one
is specified, it overrides $user_spawn_id.  If a second
is specified,
it overrides $spawn_id.  Additional
flags may be specified.

The two implied input processes default to having their outputs specified as
$spawn_id and $user_spawn_id (in reverse).  
If a
flag appears
with no
flag, characters from that process are discarded.

The
flag introduces a replacement for the current spawn_id when no
other
or

It is possible to change the processes that are being interacted with
by using indirect spawn ids.  (Indirect spawn ids are described in the
section on the expect command.)  Indirect spawn ids may be specified
with the -i, -u, -input, or -output flags.
causes the user to be interactively prompted for
and Tcl commands.
The result of each command is printed.
Actions such as
and
cause control structures (i.e.,
to behave in the usual way.
However
causes interpreter to return to its caller, while
causes
to cause a return in its caller.  For example, if "proc foo" called
which then executed the action
would return.
Any other command causes
to continue prompting for new commands.
By default, the prompt contains two integers.
The first integer describes the depth of
the evaluation stack (i.e., how many times Tcl_Eval has been called).  The
second integer is the Tcl history identifier.  The prompt can be set by
defining a procedure called "prompt1" whose return value becomes the next
prompt.  If a statement has open quotes, parens, braces, or brackets, a
secondary prompt (by default "+> ") is issued upon newline.  The secondary
prompt may be set by defining a procedure called "prompt2".
During
cooked mode is used, even if the its caller was using raw mode.
If stdin is closed,
will return unless the
flag is used, in which case the subsequent argument is invoked.
If a filename is provided,
will record a transcript of the session (beginning at that point) in the file.
will stop recording if no argument is given.  Any previous log file is closed.

Instead of a filename, a Tcl file identifier may be provided by using the
or
flags.  This is similar to the
command.  (See
for more info.)

The
flag forces output to be logged that was suppressed by the
command.

By default, the
command
to old files rather than truncating them,
for the convenience of being able to turn logging off and on multiple
times in one session.
To truncate files, use the
flag.

The
flag causes log_file to return a description of the
most recent non-info arguments given.
(and a logfile if open).
The logging to stdout is disabled by the command "log_user 0"
and reenabled by "log_user 1".  Logging to the logfile is unchanged.

The
flag causes log_user to return a description of the
most recent non-info arguments given.
defines the size of the buffer (in bytes) used internally by
With no
argument, the current size is returned.
With the
flag, the default size is set.  (The initial default is 2000.)
With the
flag, the size is set for the named spawn id, otherwise it is set for
the current process.
executes
in place of the current
program, which terminates.
A bare hyphen argument forces a hyphen in front of the command name as if
it was a login shell.
All spawn_ids are closed except for those named as arguments.  These
are mapped onto the named file identifiers.
Spawn_ids are mapped to file identifiers for the new program to inherit.
For example, the following line runs chess and allows it to be


This is more efficient than
interaction since the
process is no longer in control.
Note that no controlling terminal is provided.  Thus, if you
disconnect or remap standard input, programs that do
job control (shells, login, etc) will not function properly.
defines whether parity should be retained or stripped from the output of
spawned processes.  If
is zero, parity is stripped, otherwise it is not stripped.
With no
argument, the current value is returned.
With the
flag, the default parity value is set.  (The initial default is 1, i.e., 
parity is not stripped.)
With the
flag, the parity value is set for the named spawn id, otherwise it is set for
the current process.
defines whether nulls are retained or removed from the output of
spawned processes before pattern matching
or storing in the variable
or
If
is 1, nulls are removed.  If
is 0, nulls are not removed.
With no
argument, the current value is returned.
With the
flag, the default value is set.  (The initial default is 1, i.e., 
nulls are removed.)
With the
flag, the value is set for the named spawn id, otherwise it is set for
the current process.

Whether or not nulls are removed,
will record null bytes to the log and stdout.
Sends
to the current process.
For example, the command


sends the characters, h e l l o <blank> w o r l d <return> to the 
current process.  
(Tcl includes a printf-like command (called
which can build arbitrarily complex strings.)
Characters are sent immediately although programs with line-buffered input
will not read the characters until a return character is sent.  A return

The
flag forces the next argument to be interpreted as a string rather than a flag.
like a flag.  This provides a reliable mechanism to specify variable strings
without being tripped up by those that accidentally look like flags.
(All strings starting with "-" are reserved for future options.)

The
flag declares that the string be sent to the named spawn_id.
If the spawn_id is
and the terminal is in raw mode, newlines in the string are translated
to return-newline
sequences so that they appear as if the terminal was in cooked mode.
The
flag disables this translation.

The
flag sends null characters (0 bytes).  By default, one null is sent.
An integer may follow the
to indicate how many nulls to send.

The
flag generates a break condition.  This only makes sense if the spawn
id refers to a tty device opened via "spawn -open".  If you have
spawned a process such as tip, you should use tip's convention for
generating a break.

The
flag forces output to be sent "slowly", thus avoid the common situation
where a computer outtypes an input buffer that was designed for a
human who would never outtype the same buffer.  This output is
controlled by the value of the variable "send_slow" which takes a two
element list.  The first element is an integer that describes the
number of bytes to send atomically.  The second element is a real
number that describes the number of seconds by which the atomic sends
must be separated.  For example, "set send_slow {10 .001}" would force
characters sent.

The
flag forces output to be sent (somewhat) like a human actually typing.
Human-like delays appear between the characters.  (The algorithm is
based upon a Weibull distribution, with modifications to suit this
particular application.)  This output is controlled by the value of
the variable "send_human" which takes a five element list.  The first
two elements are average interarrival time of characters in seconds.
The first is used by default.  The second is used at word endings, to
simulate the subtle pauses that occasionally occur at such
transitions.  The third parameter is a measure of variability where .1
is quite variable, 1 is reasonably variable, and 10 is quite
invariable.  The extremes are 0 to infinity.  The last two parameters
are, respectively, a minimum and maximum interarrival time.
The minimum and maximum are used last and "clip" the final time.
The ultimate average can be quite different from the given average
if the minimum and maximum clip enough values.

As an
example, the following command emulates a fast and
consistent typist:

    set send_human {.1 .3 1 .05 2}

while the following might be more suitable after a hangover:

    set send_human {.4 .4 .2 .5 100}

Note that errors are not simulated, although you can set up error
correction situations yourself by embedding mistakes and corrections
in a send argument.

The flags for sending null characters, for sending breaks, for forcing slow
output and for human-style output are mutually exclusive. Only the one
specified last will be used. Furthermore, no
argument can be specified with the flags for sending null characters or breaks.

It is a good idea to precede the first
to a process by an
will wait for the process to start, while
cannot.
In particular, if the first
completes before the process starts running,
you run the risk of having your data ignored.
In situations where interactive programs offer no initial prompt,
you can precede
by a delay as in:

    # To avoid giving hackers hints on how to break in,
    # this system does not prompt for an external password.
    # Wait for 5 seconds for exec to complete
    spawn telnet very.secure.gov
    sleep 5

is an alias for
If you are using Expectk or some other variant of Expect in the Tk environment,
is defined by Tk for an entirely different purpose.
is provided for compatibility between environments.
Similar aliases are provided for other Expect's other send commands.
is like
except that the output is sent to stderr rather than the current
process.
is like
except that the string is only sent to the log file (see
The arguments are ignored if no log file is open.
is like
process.
is like
except that the output is sent to stdout rather than the current
process.
causes the script to sleep for the given number of seconds.
Seconds may be a decimal number.  Interrupts (and Tk events if you
are using Expectk) are processed while Expect sleeps.
creates a new process running
Its stdin, stdout and stderr are connected to Expect,
so that they may be read and written by other
commands.
The connection is broken by
or if the process itself closes any of the file identifiers.
When a process is started by
the variable
is set to a descriptor referring to that process.
The process described by
is considered the
may be read or written, in effect providing job control.
is a global variable containing a descriptor which refers to the user.
For example, when
is set to this value,
behaves like

is a global variable containing a descriptor which refers to the standard
error.
For example, when
is set to this value,
behaves like
is not defined.  This may be tested as:

    if {[info vars tty_spawn_id]} {
    } else {
        # probably in cron, batch, or at script
    }

returns the UNIX process id.  If no process is spawned, 0 is returned.
The variable
is set to the name of the pty slave device.
By default,
echoes the command name and arguments.  The
flag stops
from doing this.
The
flag causes console output to be redirected to the spawned process.
This is not supported on all systems.

Internally,
uses a pty, initialized the same way as the user's tty.  This is further
initialized so that all settings are "sane" (according to stty(1)).
If the variable
is defined, it is interpreted in the style of stty arguments
as further configuration.
For example, "set stty_init raw" will cause further spawned processes's
terminals to start in raw mode.
skips the initialization based on the user's tty.
skips the "sane" initialization.
Normally,
takes little time to execute.  If you notice spawn taking a
significant amount of time, it is probably encountering ptys that are
wedged.  A number of tests are run on ptys to avoid entanglements with
errant processes.  (These take 10 seconds per wedged pty.)  Running
Expect with the
option will show if
is encountering many ptys in odd states.  If you cannot kill
the processes to which these ptys are attached, your only recourse may
be to reboot.

If
cannot be spawned successfully because exec(2) fails (e.g. when
doesn't exist), an error message will be returned by the next
or
command as if
had run and produced the error message as output.
This behavior is a natural consequence of the implementation of
Internally, spawn forks, after which the spawned process has no
way to communicate with the original
process except by communication
via the spawn_id.

The
flag causes the next argument to be interpreted as a Tcl file identifier
(i.e., returned by
The spawn id can then be used as if it were a spawned process.  (The file
identifier should no longer be used.)
This lets you treat raw devices, files, and
pipelines as spawned processes without using a pty.  0 is returned to
indicate there is no associated process.  When the connection to
the spawned process is closed, so is the Tcl file identifier.
The
flag is similar to
except that
causes the file identifier to be left open even after the spawn id is closed.

The
flag causes a pty to be opened but no process spawned.  0 is returned
to indicate there is no associated process.  Spawn_id is set as usual.

The variable
is set to a file identifier corresponding to the pty slave.
It can be closed using "close -slave".

The
flag names a signal to be ignored in the spawned process.
Otherwise, signals get the default behavior.
Signals are named as in the
command, except that each signal requires a separate flag.
causes following statements to be printed before being executed.
(Tcl's trace command traces variables.)
indicates how far down in the call stack to trace.
For example,
the following command runs
while tracing the first 4 levels of calls,
but none below that.



The
flag causes strace to return a description of the
most recent non-info arguments given.
changes terminal modes similarly to the external stty command.

By default, the controlling terminal is accessed.  Other terminals can
the arguments should not be grouped into a single argument.)

Requests for status return it as the result of the command.  If no status
is requested and the controlling terminal is accessed, the previous
status of the raw and echo attributes are returned in a form which can
later be used by the command.

For example, the arguments
or
put the terminal into raw mode.
The arguments
or
put the terminal into cooked mode.
The arguments
and
put the terminal into echo and noecho mode respectively.
The following example illustrates how to temporarily disable echoing.
This could be used in otherwise-automatic
scripts to avoid embedding passwords in them.
(See more discussion on this under EXPECT HINTS below.)

    send_user "Password: "
    set password $expect_out(1,string)
    stty echo

gives
to sh(1) as input,
just as if it had been typed as a command from a terminal.
waits until the shell terminates.
The return status from sh is handled the same way that
handles its return status.
In contrast to
which redirects stdin and stdout to the script,
performs no redirection
(other than that indicated by the string itself).
For the same reason, the results of
are not recorded in the log.
returns a timestamp.
With no arguments, the number of
seconds since the epoch is returned.

The
flag introduces a string which is returned but with 
substitutions made according to the
POSIX rules for strftime.  For example %a is replaced by an abbreviated
weekday name (i.e., Sat).  Others are:
    %a      abbreviated weekday name
    %A      full weekday name
    %b      abbreviated month name
    %B      full month name
    %c      date-time as in: Wed Oct  6 11:45:56 1993
    %d      day of the month (01-31)
    %H      hour (00-23)
    %I      hour (01-12)
    %j      day (001-366)
    %m      month (01-12)
    %M      minute (00-59)
    %p      am or pm
    %S      second (00-61)
    %u      day (1-7, Monday is first day of week)
    %U      week (00-53, first Sunday is first day of week one)
    %V      week (01-53, ISO 8601 style)
    %w      day (0-6)
    %W      week (00-53, first Monday is first day of week one)
    %x      date-time as in: Wed Oct  6 1993
    %X      time as in: 23:59:59
    %y      year (00-99)
    %Y      year as in: 1993
    %Z      timezone (or nothing if not determinable)
    %%      a bare percent sign

Other % specifications are undefined.  Other characters will be passed
through untouched.  Only the C locale is supported.

The
flag introduces a number of seconds since the epoch to be used as a source
from which to format.  Otherwise, the current time is used.

The
flag forces timestamp output to use the GMT timezone.  With no flag,
the local timezone is used.
causes the given 
to be executed upon future receipt of any of the given signals.
The command is executed in the global scope.
If
is absent, the signal action is returned.
If
is the string SIG_IGN, the signals are ignored.
If
is the string SIG_DFL, the signals are result to the system default.
is either a single signal or a list of signals.  Signals may be specified
numerically or symbolically as per signal(3).  The "SIG" prefix may be omitted.

returns the signal number of the trap command currently being executed.

The
flag uses the return code of the command in place of whatever code Tcl
was about to return when the command originally started running.

The
flag causes the command to be evaluated using the interpreter
active at the time the command started running
rather than when the trap was declared.

The
flag causes the
command to return the signal name of the trap command currently being executed.

The
flag causes the
command to return the largest signal number that can be set.

For example, the command "trap {send_user "Ouch!"} SIGINT" will print "Ouch!"
each time the user presses ^C.

By default, SIGINT (which can usually be generated by pressing ^C) and 
SIGTERM cause Expect to exit.  This is due to the following trap, created
by default when Expect starts.

    trap exit {SIGINT SIGTERM}

If you use the -D flag to start the debugger, SIGINT is redefined
to start the interactive debugger.  This is due to the following trap:

    trap {exp_debug 1} SIGINT

The debugger trap can be changed by setting the environment variable
EXPECT_DEBUG_INIT to a new trap command.  

You can, of course, override both of these just by adding trap
commands to your script.  In particular, if you have your own "trap
exit SIGINT", this will override the debugger trap.  This is useful
if you want to prevent users from getting to the debugger at all.

If you want to define your own trap on SIGINT but still trap to the
debugger when it is running, use:

    if {![exp_debug]} {trap mystuff SIGINT}

Alternatively, you can trap to the debugger using some other signal.

will not let you override the action for SIGALRM as this is used internally
to
The disconnect command sets SIGALRM to SIG_IGN (ignore).  You can reenable
this as long as you disable it during subsequent spawn commands.

See signal(3) for more info.
delays until a spawned process (or
the current process if none is named) terminates.
normally returns a list of four integers.
The first integer is the pid of the process that was waited upon.
The second integer is the corresponding spawn id.
The third integer is -1 if an operating system error occurred, or 0 otherwise.
If the third integer was 0, the fourth integer is the status returned by
the spawned process.  If the third integer was -1, the fourth integer is
the value of errno set by the operating system.  The global variable
errorCode is also set.

Additional elements may appear at the end of the return value from
An optional fifth element identifies a class of information.
Currently, the only possible value for this element is CHILDKILLED in
which case the next two values are the C-style signal name and a short
textual description.
The
flag declares the process to wait corresponding to the named spawn_id
(NOT the process id).
Inside a SIGCHLD handler,
it is possible to wait for any spawned process by using the spawn id -1.

The
flag causes the wait to return immediately with the indication of a
successful wait.  When the process exits (later), it will automatically
disappear without the need for an explicit wait.

The
command may also be used wait for a forked process using the arguments
"-i -1".  Unlike its use with spawned processes, this command can be
executed at any time.  There is no control over which process is
reaped.  However, the return value can be checked for the process id.

Expect automatically knows about two built-in libraries for Expect scripts.
These are defined by the directories named in the variables
exp_library and exp_exec_library.  Both are meant to contain utility
files that can be used by other scripts.

exp_library contains architecture-independent files.  exp_exec_library
contains architecture-dependent files.  Depending on your system, both
directories may be totally empty.  The existence of the file
by default.
A vgrind definition is available for pretty-printing
scripts.
Assuming the vgrind definition supplied with the
distribution is
correctly installed, you can use it as:


It many not be apparent how to put everything together that the man page
describes.  I encourage you to read and try out the examples in
the example directory of the
distribution.
Some of them are real programs.  Others are simply illustrative
of certain techniques, and of course, a couple are just quick hacks.
The INSTALL file has a quick overview of these programs.
The
papers (see SEE ALSO) are also useful.  While some papers
use syntax corresponding to earlier versions of Expect, the accompanying
rationales are still valid and go into a lot more detail than this
man page.
Extensions may collide with Expect's command names.  For example, 
is defined by Tk for an entirely different purpose.
For this reason, most of the
commands are also available as "exp_XXXX".
Commands and variables beginning with "exp", "inter", "spawn",
and "timeout" do not have aliases.
Use the extended command names if you need this compatibility between environments.

takes a rather liberal view of scoping.
In particular, variables read by commands specific to the
program will be sought first from the local scope, and if not found, in the
global scope.  For example, this
obviates the need to place "global timeout" in every
procedure you write that uses
On the other hand, variables written are always in the local scope (unless
a "global" command has been issued).  The most common problem this causes
is when spawn is executed in a procedure.  Outside the procedure, 
no longer exists, so the spawned process is no longer accessible
simply because of scoping.  Add a "global spawn_id" to such a procedure.

If you cannot enable the multispawning capability
(i.e., your system supports neither select (BSD *.*), poll (SVR>2),
nor something equivalent),
will only be able to control a single process at a time.
In this case, do not attempt to set
nor should you execute processes via exec while a spawned process
is running.  Furthermore, you will not be able to
from multiple processes (including the user as one) at the same time.

Terminal parameters can have a big effect on scripts.  For example, if
a script is written to look for echoing, it will misbehave if echoing
is turned off.  For this reason, Expect forces sane terminal
parameters by default.  Unfortunately, this can make things unpleasant
for other programs.  As an example, the emacs shell wants to change
the "usual" mappings: newlines get mapped to newlines instead of
carriage-return newlines, and echoing is disabled.  This allows one to
use emacs to edit the input line.  Unfortunately, Expect cannot
possibly guess this.

You can request that Expect not override its default setting of
terminal parameters, but you must then be very careful when writing
scripts for such environments.  In the case of emacs, avoid depending
upon things like echoing and end-of-line mappings.

The commands that accepted arguments braced into a single list (the
variants and
use a heuristic to decide if the list is actually one argument or
many.  The heuristic can fail only in the case when the list actually
with non-whitespace characters between them.  This seems sufficiently
single argument to be handled as a single argument.  This could
conceivably be used with machine-generated Expect code.  Similarly,

It was really tempting to name the program "sex" (for either "Smart EXec"
or "Send-EXpect"), but good sense (or perhaps just Puritanism) prevailed.

On some systems, when a shell is spawned, it complains about not being
able to access the tty but runs anyway.  This means your system has a
mechanism for gaining the controlling tty that
doesn't know about.  Please find out what it is, and send this information
back to me.

Ultrix 4.1 (at least the latest versions around here) considers
timeouts of above 1000000 to be equivalent to 0.

Digital UNIX 4.0A (and probably other versions) refuses to allocate
ptys if you define a SIGCHLD handler.  See grantpt page for more info.

IRIX 6.0 does not handle pty permissions correctly so that if Expect
attempts to allocate a pty previously used by someone else, it fails.
Upgrade to IRIX 6.1.

Telnet (verified only under SunOS 4.1.2) hangs if TERM is not set.
This is a problem under cron, at and in cgi scripts, which do not
define TERM.  Thus, you must set it explicitly - to what type is
usually irrelevant.  It just has to be set to something!  The
following probably suffices for most cases.

    set env(TERM) vt100


are not set.  This is a problem under cron, at and in cgi scripts,
which do not define these environment variables.  Thus, you must set
them explicitly - to what type is usually irrelevant.  It just has to
be set to something!  The following probably suffices for most cases.




Some implementations of ptys are designed so that the kernel throws
away any unread output after 10 to 15 seconds (actual number is
implementation-dependent) after the process has closed the file
descriptor.  Thus
programs such as

    spawn date
    sleep 20
    expect

will fail.  To avoid this, invoke non-interactive programs with
rather than
While such situations are conceivable, in practice I have never
encountered a situation in which the final output of a truly
interactive program would be lost due to this behavior.

On the other hand, Cray UNICOS ptys throw away any unread output
immediately after the process has closed the file descriptor.  I have
reported this to Cray and they are working on a fix.

Sometimes a delay is required between a prompt and a response, such as
when a tty interface is changing UART settings or matching baud rates
sleep for a second or two.  A more robust technique is to retry until
the hardware is ready to receive input.  The following example uses
both strategies:

    sleep 1
    expect {
        $prompt
    }


loop, such as sleep.  The problem is that in the event loop, Tcl
discards the return codes from async event handlers.  A workaround is
to set a flag in the trap code.  Then check the flag immediately after
the command (i.e., sleep).

The expect_background command ignores -timeout arguments and has no
concept of timeouts in general.

There are a couple of things about
that may be non-intuitive.
This section attempts to address some of these things with a couple of
suggestions.

A common expect problem is how to recognize shell prompts.  Since
these are customized differently by differently people and different
shells, portably automating rlogin can be difficult without knowing
the prompt.  A reasonable convention is to have users store a regular
expression describing their prompt (in particular, the end of it) in
the environment variable EXPECT_PROMPT.  Code like the following
can be used.  If EXPECT_PROMPT doesn't exist, the code still has a good chance of functioning correctly.

    catch {set prompt $env(EXPECT_PROMPT)}

    expect -re $prompt

I encourage you to write
patterns that include the end of whatever
you expect to see.  This avoids the possibility of answering a question
before seeing the entire thing.  In addition, while you may well be
able to answer questions before seeing them entirely, if you answer
early,  your answer may appear echoed back in the middle of the question.
In other words, the resulting dialogue will be correct but look scrambled.

Most prompts include a space character at the end.
For example, the prompt from ftp is 'f', 't', 'p', '>' and <blank>.
To match this prompt, you must account for each of these characters.
It is a common mistake not to include the blank.
Put the blank in explicitly.

If you use a pattern of the form X*, the * will match all the output
received from the end of X to the last thing received.
This sounds intuitive but can be somewhat confusing because the phrase
"last thing received" can vary depending upon the speed of the computer
In particular, humans tend to see program output arriving in huge chunks
(atomically) when in reality most programs produce output one
line at a time.  Assuming this is the case, the * in the pattern of the
previous paragraph may only match the end of the current line even though
there seems to be more, because at the time of the match that was all
the output that had been received.
has no way of knowing that further output is coming unless your
pattern specifically accounts for it.
Even depending on line-oriented buffering is unwise.  Not only do programs
rarely make promises about the type of buffering they do, but system
indigestion can break output lines up so that lines break at seemingly
random places.  Thus, if you can express the last few characters
of a prompt when writing patterns, it is wise to do so.

If you are waiting for a pattern in the last output of a program
and the program emits something else instead, you will not be able to
detect that with the
keyword.  The reason is that
indication.
Use that instead.  Even better, use both.  That way if that line
is ever moved around, you won't have to edit the line itself.

Newlines are usually converted to carriage return, linefeed sequences
when output by the terminal driver.  Thus, if you want a pattern that
A similar translation occurs when reading from the user, via
In this case, when you press return, it will be
translated to a newline.  If
then passes that to a program
which sets its terminal to raw mode (like telnet), there is going to
be a problem, as the program expects a true return.  (Some programs
are actually forgiving in that they will automatically translate
newlines to returns, but most don't.)  Unfortunately, there is no way to find
out that a program put its terminal into raw mode.
Rather than manually replacing newlines with returns, the solution is to
use the command "stty raw", which will stop the translation.
Note, however, that this means that you will no longer get the cooked
line-editing features.
implicitly sets your terminal to raw mode so this problem will not arise then.

It is often useful to store passwords (or other private information)
in
scripts.  This is not recommended since anything that is
stored on a computer is susceptible to being accessed by anyone.
Thus, interactively prompting for passwords from a script is a smarter
idea than embedding them literally.  Nonetheless, sometimes such embedding
is the only possibility.
Unfortunately, the UNIX file system has no direct way of creating
scripts which are executable but unreadable.  Systems which support
setgid shell scripts may indirectly simulate this as follows:
Create the
script (that contains the secret data) as usual.
i.e., a group which is allowed to read it.  If necessary, create a new
The result is a script which may be executed (and read) by anyone.
When invoked, it runs the
script.
"Exploring Expect: A Tcl-Based Toolkit for Automating Interactive Programs"
Proceedings of the Summer 1990 USENIX Conference,
Anaheim, California, June 11-15, 1990.
"Using
Proceedings of the 1990 USENIX Large Installation Systems Administration
Conference, Colorado Springs, Colorado, October 17-19, 1990.
Proceedings of the Winter 1990 USENIX Conference,
Washington, D.C., January 22-26, 1990.
Computing Systems, Vol. 4, No. 2, University of California Press Journals,
November 1991.
Libes, Proceedings of the Summer 1992 USENIX Conference, pp. 135-144,
San Antonio, TX, June 12-15, 1992.
Vol. 23, No. 5, May, 1993.
Don Libes, National Institute of Standards and Technology
Thanks to John Ousterhout for Tcl, and Scott Paisley for inspiration.
Thanks to Rob Savoye for Expect's autoconfiguration code.
The HISTORY file documents much of the evolution of
It makes interesting reading and might give you further insight to this
software.  Thanks to the people mentioned in it who sent me bug fixes
and gave other assistance.
Design and implementation of
was paid for in part by the U.S. government and is therefore in the public
domain.
However the author and NIST would like credit
if this program and documentation or portions of them are used.
The
utility evaluates
and writes the result on standard output.
All operators and operands must be passed as separate arguments.
Several of the operators have special meaning to command interpreters
and must therefore be quoted appropriately.
All integer operands are interpreted in base 10 and must consist of only
an optional leading minus sign followed by one or more digits.
Arithmetic operations are performed using signed integer math with a
range according to the C
data type (the largest signed integral type available).
All conversions and operations are checked for overflow.
Overflow results in program termination with an error message on stdout
and with an error status.
Operators are listed below in order of increasing precedence; all
are left-associative.
Operators with equal precedence are grouped within symbols
and
Return the evaluation of
if it is neither an empty string nor zero;
otherwise, returns the evaluation of
if it is not an empty string;
otherwise, returns zero.
Return the evaluation of
if neither expression evaluates to an empty string or zero;
otherwise, returns zero.
Return the results of integer comparison if both arguments are integers;
otherwise, returns the results of string comparison using the locale-specific
collation sequence.
The result of each comparison is 1 if the specified relation is true,
or 0 if the relation is false.
Return the results of addition or subtraction of integer-valued arguments.
Return the results of multiplication, integer division, or remainder of integer-valued arguments.
The
operator matches
against
which must be a basic regular expression.
The regular expression is anchored
to the beginning of the string with an implicit
If the match succeeds and the pattern contains at least one regular
expression subexpression
the string corresponding to
is returned;
otherwise the matching operator returns the number of characters matched.
If the match fails and the pattern contains a regular expression subexpression
the null string is returned;
otherwise 0.
Parentheses are used for grouping in the usual manner.
The
utility makes no lexical distinction between arguments which may be
operators and arguments which may be operands.
An operand which is lexically identical to an operator will be considered a
syntax error.
See the examples below for a work-around.
The syntax of the
command in general is historic and inconvenient.
New applications are advised to use shell arithmetic rather than
The
utility exits with one of the following values:
the expression is neither an empty string nor 0.
the expression is an empty string or 0.
the expression is invalid.
The following example (in
syntax) adds one to the variable
This will fail if the value of
is a negative number.
To protect negative values of
from being interpreted as options to the
command, one might rearrange the expression:
More generally, parenthesize possibly-negative values:
With shell arithmetic, no escaping is required:
This example prints the filename portion of a pathname stored
in variable
Since
might represent the path
it is necessary to prevent it from being interpreted as the division operator.
The
characters resolve this ambiguity.
With modern
syntax,
expands to the same value.
The following examples output the number of characters in variable
Again, if
might begin with a hyphen, it is necessary to prevent it from being
interpreted as an option to
and
might be interpreted as an operator.
To deal with all of this, a complicated command
is required:
With modern
syntax, this can be done much more easily:
expands to the required number.
The
utility conforms to
The extended arithmetic range and overflow checks do not conflict with
POSIX's requirement that arithmetic be done using signed longs, since
they only make a difference to the result in cases where using signed
longs would give undefined behavior.
According to the
standard, the use of string arguments
or
produces undefined results. In this version of
these arguments are treated just as their respective string values.
[ 
]  
[
] 
The 
utility checks a specified
file for title and
version conflicts with any extensions installed in the JDK
software.
Before installing an extension, you can use this utility
to see if the same or a more recent version of the extension is
already installed.
The 
utility compares the Specification-title and
Specification-version headers in the manifest of 
file against the corresponding headers in all Jar files currently
installed in the extension directory.
(The extension directory is
by default.) The 
utility compares version
numbers in the same way as the method
If no conflict is detected, the return code is 0. 
If the manifest of any jar file in the extensions 
directory has the same Specification-title and
the same or a newer Specification-version 
number, a non-zero error code is returned. A
non-zero error code is also returned if 
targetfile.jar does not have the Specification-title
or Specification-version attributes in its manifest. 
The following options are supported:
Lists
files in the extension directory as they are
checked.
Additionally, manifest attributes of the target 
file and any conflicting 
files are also reported.
Pass
to the Java virtual machine, where 
is one of the options described on the man page for the
java application launcher, 
For example,
sets the startup memory to 48 megabytes. 
The eyapp compiler is a front-end to the Parse::Eyapp module, which lets you compile
Finite Automaton) states and overall usage of the parser.
corresponding to the compacted tables.
Create a standalone module in which the parsing driver is included.
Parse::Eyapp::YATW)) and Parse::Eyapp::Base 
Note that if you have more than one parser module called from a program, 
to have it standalone, you need this option only for one of your grammars;
Disable source file line numbering embedded in your parser module.
I don't know why one should need it, but it's there.
Gives your parser module the package name (or name space or module name or
parts are displayed. Comments will be also stripped 
used as template for generating the parser output.  The default is to 
For how to write your own template and which substitutions are available,
generated parser is directly an executable script, you can specify one
The argument is mandatory, but if you specify an empty string, the value
as the very last line of the output file. The argument is mandatory.
action tables.
The input grammar file. If no suffix is given, and the file does not exists,
Display current version of Parse::Eyapp and gracefully exits.
Display the usage screen.
Notice that there is no need to write lexer and error report subroutines.
First, we compile the grammar:
We can now execute the resulting program:
When a non conformant input is given, it produces an accurate error message:
Casiano Rodriguez-Leon
(c) Copyright 2006 Casiano Rodriguez-Leon
it under the same terms as Perl itself, either Perl version 5.8.8 or,
at your option, any later version of Perl 5 you may have available.
Parse::Eyapp,
perldoc vgg,
(An Introduction to Compiler Construction in seven pages)> in
eyapp,
treereg,
Parse::yapp,
Jeffrey D. Ullman (Addison-Wesley 1986)
Parse::RecDescent.
The eyapp compiler is a front-end to the Parse::Eyapp module, which lets you compile
Finite Automaton) states and overall usage of the parser.
corresponding to the compacted tables.
Create a standalone module in which the parsing driver is included.
Parse::Eyapp::YATW)) and Parse::Eyapp::Base 
Note that if you have more than one parser module called from a program, 
to have it standalone, you need this option only for one of your grammars;
Disable source file line numbering embedded in your parser module.
I don't know why one should need it, but it's there.
Gives your parser module the package name (or name space or module name or
parts are displayed. Comments will be also stripped 
used as template for generating the parser output.  The default is to 
For how to write your own template and which substitutions are available,
generated parser is directly an executable script, you can specify one
The argument is mandatory, but if you specify an empty string, the value
as the very last line of the output file. The argument is mandatory.
action tables.
The input grammar file. If no suffix is given, and the file does not exists,
Display current version of Parse::Eyapp and gracefully exits.
Display the usage screen.
Notice that there is no need to write lexer and error report subroutines.
First, we compile the grammar:
We can now execute the resulting program:
When a non conformant input is given, it produces an accurate error message:
Casiano Rodriguez-Leon
(c) Copyright 2006 Casiano Rodriguez-Leon
it under the same terms as Perl itself, either Perl version 5.8.8 or,
at your option, any later version of Perl 5 you may have available.
Parse::Eyapp,
perldoc vgg,
(An Introduction to Compiler Construction in seven pages)> in
eyapp,
treereg,
Parse::yapp,
Jeffrey D. Ullman (Addison-Wesley 1986)
Parse::RecDescent.
The eyapp compiler is a front-end to the Parse::Eyapp module, which lets you compile
Finite Automaton) states and overall usage of the parser.
corresponding to the compacted tables.
Create a standalone module in which the parsing driver is included.
Parse::Eyapp::YATW)) and Parse::Eyapp::Base 
Note that if you have more than one parser module called from a program, 
to have it standalone, you need this option only for one of your grammars;
Disable source file line numbering embedded in your parser module.
I don't know why one should need it, but it's there.
Gives your parser module the package name (or name space or module name or
parts are displayed. Comments will be also stripped 
used as template for generating the parser output.  The default is to 
For how to write your own template and which substitutions are available,
generated parser is directly an executable script, you can specify one
The argument is mandatory, but if you specify an empty string, the value
as the very last line of the output file. The argument is mandatory.
action tables.
The input grammar file. If no suffix is given, and the file does not exists,
Display current version of Parse::Eyapp and gracefully exits.
Display the usage screen.
Notice that there is no need to write lexer and error report subroutines.
First, we compile the grammar:
We can now execute the resulting program:
When a non conformant input is given, it produces an accurate error message:
Casiano Rodriguez-Leon
(c) Copyright 2006 Casiano Rodriguez-Leon
it under the same terms as Perl itself, either Perl version 5.8.8 or,
at your option, any later version of Perl 5 you may have available.
Parse::Eyapp,
perldoc vgg,
(An Introduction to Compiler Construction in seven pages)> in
eyapp,
treereg,
Parse::yapp,
Jeffrey D. Ullman (Addison-Wesley 1986)
Parse::RecDescent.
The
utility always exits with a nonzero exit code.
The
utility conforms to 







{
|
} 

[
[
]
]

{
|
|
}




use low (96 line per inch) resolution
display verbose messages for debugging
the phone call has already been dialed manually


The commands make, send, receive, view and queue may be
abbreviated to their first characters (e.g. ``fax q'').

before the command name to temporarily change the values of most
fax script variables (e.g. ``fax PAGE=A4 print letter.001'')



efix(1) programs.  It allows you to send text or Postscript files
as faxes and receive, print or preview received faxes.  The

To send a fax, the original files need to be converted from ASCII
or Postscript into a particular bit-map format (TIFF with Group 3
conversion before sending the fax.  The conversion will create
one file per page.  These files will have the name of the
original file with the page number as an additional suffix.  For
file doc.ps would generate the files doc.ps.001 and doc.ps.002.

the phone number on the command line.  The names of the files to
be sent are given on the command line, usually by using
wildcards.  For example, to send a multi-page fax consisting of
the files doc.ps.001, doc.ps.002, and so on, you could use the
again.

a fax.  If a file name is specified the received fax will be
stored in files with the given file name plus an extension equal
to the page number.  If no options are given, the received fax
will be stored in files having a name given by the date and time
and an extension equal to the page number.  For example, a fax
received beginning on July 4 at 3:05:20 pm will generate files
0704150520.001, 0704150520.002, and so on.

are used to print, preview or remove received fax files.  As with
the send command the file names are usually given using
wildcards.

If efax has been installed for automatic fax reception you can
incoming spool directory.  The fax script can also be configured
to print received faxes or e-mail them as MIME attachments with
shows the status of the automatic receive process once, or every
daemon.

faxes.  It is normally placed in a launchd.plist(5) file and is
run automatically by launchd(8).

Other features of the fax script are documented within the
script:

a directory that lets you specify recipients by name instead of
number

up a text editor

bit-mapped font for use in headers or text


Faxes can be created at low (98 lines per inch) or high (196 lpi)
resolution.  Almost all fax machines will operate at either
resolution.  By default files are created at high resolution but
resolution.


The modem commands and responses together with status and error
messages are written to file.  If the fax is successfully sent or
received the log file is removed.  Otherwise a message is printed
showing the log file name.  Please send a copy of this file when
reporting problems with efax.


The fax script will `source' the optional shell scripts
processing command-line arguments.  These files can be used to
set script variables to custom values for a particular system,

The following files are created in the FAXDIR spool directory
when automatic fax reception is enabled (see the fax script).

the log file created by the fax answer daemon with process id
DEV.log
contains collected log files for device DEV.  Log files showing a
termination status of 1 (device busy) or 4 (no response from
modem) are not added to this file.
DEV.stop
created by the fax stop command to prevent the fax daemon from
starting up.


Fax was written by Ed Casas.  Please send comments or bug reports
to edc@cce.com.  Please describe the type of modem used and
include a copy of the log file.


Fax is copyright 1993 -- 1999 by Ed Casas.  It may be used,
copied and modified under the terms of the GNU Public License.


prevent it from working correctly on your system.  Some of these
errors may cause serious problems including loss of data and
interruptions to telephone service.




See efax(1).
The
utility searches any given input files,
selecting lines that match one or more patterns.
By default, a pattern matches an input line if the regular expression
(RE) in the pattern matches the input line
without its trailing newline.
An empty expression matches every line.
Each input line that matches at least one of the patterns is written
to the standard output.
is used for simple patterns and
basic regular expressions
can handle extended regular expressions
See
for more information on regular expressions.
is quicker than both
and
but can only handle fixed patterns
(i.e. it does not interpret regular expressions).
Patterns may consist of one or more lines,
allowing any of the pattern lines to match a portion of the input.
and
act like
and
respectively, but accept input files compressed with the
or
compression utilities.
The following options are available:
Print
lines of trailing context after each match.
See also the
and
options.
Treat all files as ASCII text.
Normally
will simply print
if files contain binary characters.
Use of this option forces
to output lines matching the specified pattern.
Print
lines of leading context before each match.
See also the
and
options.
The offset in bytes of a matched pattern is
displayed in front of the respective matched line.
Print
lines of leading and trailing context surrounding each match.
The default is 2 and is equivalent to
Note:
no whitespace may be given between the option and its argument.
Only a count of selected lines is written to standard output.
Mark up the matching text with the expression stored in
environment variable.
The possible values of when can be `never', `always' or `auto'.
Specify the demanded action for devices, FIFOs and sockets.
The default action is `read', which means, that they are read
as if they were normal files.
If the action is set to `skip', devices will be silently skipped.
Specify the demanded action for directories.
It is `read' by default, which means that the directories
are read in the same manner as normal files.
Other possible values are `skip' to silently ignore the
directories, and `recurse' to read them recursively, which
has the same effect as the
and
option.
Interpret
as an extended regular expression
(i.e. force
to behave as
Specify a pattern used during the search of the input:
an input line is selected if it matches any of the specified patterns.
This option is most useful when multiple
options are used to specify multiple patterns,
or when a pattern begins with a dash
If specified, it excludes files matching the given
filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all files are searched that are
not excluded.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, it excludes directories matching the
given filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all directories are searched that are
not excluded.
Interpret
as a set of fixed strings
(i.e. force
to behave as
Read one or more newline separated patterns from
Empty pattern lines match every input line.
Newlines are not considered part of a pattern.
If
is empty, nothing is matched.
Interpret
as a basic regular expression
(i.e. force
to behave as traditional
Always print filename headers with output lines.
Never print filename headers
with output lines.
Print a brief help message.
Ignore binary files.
This option is equivalent to
option.
Perform case insensitive matching.
By default,
is case sensitive.
If specified, only files matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, only directories matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Decompress the
compressed file before looking for the text.
Only the names of files not containing selected lines are written to
standard output.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Only the names of files containing selected lines are written to
standard output.
will only search a file until a match has been found,
making searches potentially less expensive.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Use
instead of
to read input, which can result in better performance under some
circumstances but can cause undefined behaviour.
Stop reading the file after
matches.
Each output line is preceded by its relative line number in the file,
starting at line 1.
The line number counter is reset for each file processed.
This option is ignored if
or
is
specified.
Prints a zero-byte after the file name.
If
is specified, follow symbolic links only if they were explicitly listed
on the command line.
The default is not to follow symbolic links.
Prints only the matching part of the lines.
If
is specified, no symbolic links are followed.
This is the default.
Quiet mode:
suppress normal output.
will only search a file until a match has been found,
making searches potentially less expensive.
Recursively search subdirectories listed.
If
is specified, all symbolic links are followed.
The default is not to follow symbolic links.
Silent mode.
Nonexistent and unreadable files are ignored
(i.e. their error messages are suppressed).
Search binary files, but do not attempt to print them.
Display version information and exit.
Selected lines are those
matching any of the specified patterns.
The expression is searched for as a word (as if surrounded by
and
see
Only input lines selected against an entire fixed string or regular
expression are considered to be matching lines.
Equivalent to
Obsoleted.
Force
to behave as
Controls searching and printing of binary files.
Options are
the default: search binary files but do not print them;
do not search binary files;
and
treat all files as text.
Print
lines of leading and trailing context.
The default is 2.
Force output to be line buffered.
By default, output is line buffered when standard output is a terminal
and block buffered otherwise.
If no file arguments are specified, the standard input is used.
May be used to specify default options that will be placed at the beginning
of the argument list.
Backslash-escaping is not supported, unlike the behavior in GNU grep.
The
utility exits with one of the following values:
One or more lines were selected.
No lines were selected.
An error occurred.
To find all occurrences of the word
in a file:
To find all occurrences of the pattern
at the beginning of a line:
The apostrophes ensure the entire expression is evaluated by
instead of by the user's shell.
The caret
matches the null string at the beginning of a line,
and the
escapes the
which would otherwise match any character.
To find all lines in a file which do not contain the words
or
A simple example of an extended regular expression:
Peruses the file
looking for either 19, 20, or 25.
The
utility is compliant with the
specification.
The flags
are extensions to that specification, and the behaviour of the
flag when used with an empty pattern file is left undefined.
All long options are provided for compatibility with
GNU versions of this utility.
Historic versions of the
utility also supported the flags
This implementation supports those options;
however, their use is strongly discouraged.
The
command first appeared in
The
utility does not normalize Unicode input, so a pattern containing composed
characters will not match decomposed input, and vice versa.
This manual page documents version 5.04 of the
command.
tests each argument in an attempt to classify it.
There are three sets of tests, performed in this order:
filesystem tests, magic tests, and language tests.
The
test that succeeds causes the file type to be printed.
The type printed will usually contain one of the words
(the file contains only
printing characters and a few common control
characters and is probably safe to read on an
terminal),
(the file contains the result of compiling a program
in a form understandable to some
kernel or another),
or
meaning anything else (data is usually
or non-printable).
Exceptions are well-known file formats (core files, tar archives)
that are known to contain binary data.
When modifying magic files or the program itself, make sure to
Users depend on knowing that all the readable files in a directory
have the word
printed.
Don't do as Berkeley did and change
to
The filesystem tests are based on examining the return from a
system call.
The program checks to see if the file is empty,
or if it's some sort of special file.
Any known file types appropriate to the system you are running on
(sockets, symbolic links, or named pipes (FIFOs) on those systems that
implement them)
are intuited if they are defined in
the system header file
The magic tests are used to check for files with data in
particular fixed formats.
The canonical example of this is a binary executable (compiled program)
file, whose format is defined in
and possibly
in the standard include directory.
These files have a
stored in a particular place
near the beginning of the file that tells the
that the file is a binary executable, and which of several types thereof.
The concept of a
has been applied by extension to data files.
Any file with some invariant identifier at a small fixed
offset into the file can usually be described in this way.
The information identifying these files is read from the compiled
magic file
or the files in the directory
if the compiled file does not exist.
If a file does not match any of the entries in the magic file,
it is examined to see if it seems to be a text file.
ASCII, ISO-8859-x, non-ISO 8-bit extended-ASCII character sets
(such as those used on Macintosh and IBM PC systems),
UTF-8-encoded Unicode, UTF-16-encoded Unicode, and EBCDIC
character sets can be distinguished by the different
ranges and sequences of bytes that constitute printable text
in each set.
If a file passes any of these tests, its character set is reported.
ASCII, ISO-8859-x, UTF-8, and extended-ASCII files are identified
as
because they will be mostly readable on nearly any terminal;
UTF-16 and EBCDIC are only
because, while
they contain text, it is text that will require translation
before it can be read.
In addition,
will attempt to determine other characteristics of text-type files.
If the lines of a file are terminated by CR, CRLF, or NEL, instead
of the Unix-standard LF, this will be reported.
Files that contain embedded escape sequences or overstriking
will also be identified.
Once
has determined the character set used in a text-type file,
it will
attempt to determine in what language the file is written.
The language tests look for particular strings (cf.
) that can appear anywhere in the first few blocks of a file.
For example, the keyword
indicates that the file is most likely a
input file, just as the keyword
indicates a C program.
These tests are less reliable than the previous
two groups, so they are performed last.
The language test routines also test for some miscellany
(such as
archives).
Any file that cannot be identified as having been written
in any of the character sets listed above is simply said to be
Do not prepend filenames to output lines (brief mode).
Write a
output file that contains a pre-parsed version of the magic file or directory.
Cause a checking printout of the parsed form of the magic file.
This is usually used in conjunction with the
flag to debug a new magic file before installing it.
Write a
output file that contains a pre-parsed version of the magic file or directory.
Apply the default system tests; this is the default behavior unless
is specified.
Print debugging messages.
Exclude the test named in
from the list of tests made to determine the file type. Valid test names
are:
application type (only on EMX).
Various types of text files (this test will try to guess the text encoding, irrespective of the setting of the
option).
Different text encodings for soft magic tests.
Looks for known tokens inside text files.
Prints details of Compound Document Files.
Checks for, and looks inside, compressed files.
Prints ELF file details.
Consults magic files.
Examines tar files.
Use the specified string as the separator between the filename and the
file result returned. Defaults to
Read the names of the files to be examined from
(one per line)
before the argument list.
Either
or at least one filename argument must be present;
to test the standard input, use
as a filename argument.
option causes symlinks not to be followed
(on systems that support symbolic links).
If the file is a regular file, do not classify its contents.
Causes the file command to output mime type strings rather than the more
traditional human readable ones. Thus it may say
rather than
In order for this option to work, file changes the way
it handles files recognized by the command itself (such as many of the
text file types, directories etc), and makes use of an alternative
file.
(See the FILES section, below).
Like
but print only the specified element(s).
Don't stop at the first match, keep going. Subsequent matches will be
have the string
prepended.
(If you want a newline, see the
option.)
option causes symlinks to be followed, as the like-named option in
(on systems that support symbolic links).
This is the default behavior.
Specify an alternate list of files and directories containing magic.
This can be a single item, or a colon-separated list.
If a compiled magic file is found alongside a file or directory, it will be used instead.
Like
except that the default rules are not applied unless
is specified.
Force stdout to be flushed after checking each file.
This is only useful if checking a list of files.
It is intended to be used by programs that want filetype output from a pipe.
On systems that support
or
attempt to preserve the access time of files analyzed, to pretend that
never read them.
No operation, included for historical compatibility.
Normally,
only attempts to read and determine the type of argument files which
reports are ordinary files.
This prevents problems, because reading special files may have peculiar
consequences.
Specifying the
option causes
to also read argument files which are block or character special files.
This is useful for determining the filesystem types of the data in raw
disk partitions, which are block special files.
This option also causes
to disregard the file size as reported by
since on some systems it reports a zero size for raw disk partitions.
Print the version of the program and exit.
Try to look inside compressed files.
Output a null character
after the end of the filename. Nice to
the output. This does not affect the separator which is still printed.
Print a help message and exit.
Default compiled list of magic.
Directory containing default magic files.
The environment variable
can be used to set the default magic file name.
adds
to the value of this variable as appropriate.
In legacy mode, the
and
options do not exist.
The
and
options behave differently.
The
option provides debugging information (same as
in conformance mode).
The
option displays mime type information (same as
in conformance mode).
The
option will disable the translation of unprintable characters (by
default, this translation is already disabled in conformance mode).
Furthermore, the
option becomes the default symlink behavior (don't follow symlinks)
unless
is set.
For more information about legacy mode, see
This program conforms to
Its behavior is mostly compatible with the System V program of the same name.
This version knows more magic, however, so it will produce
different (albeit more accurate) output in many cases.
The one significant difference
between this version and System V
is that this version treats any white space
as a delimiter, so that spaces in pattern strings must be escaped.
For example,
in an existing magic file would have to be changed to
In addition, in this version, if a pattern string contains a backslash,
it must be escaped.
For example
in an existing magic file would have to be changed to
SunOS releases 3.2 and later from Sun Microsystems include a
command derived from the System V one, but with some extensions.
My version differs from Sun's only in minor ways.
It includes the extension of the
operator, used as,
for example,
>16	long&0x7fffffff	>0		not stripped
The magic file entries have been collected from various sources,
mainly USENET, and contributed by various authors.
Christos Zoulas (address below) will collect additional
or corrected magic file entries.
A consolidation of magic file entries
will be distributed periodically.
The order of entries in the magic file is significant.
Depending on what system you are using, the order that
they are put together may be incorrect.
If your old
command uses a magic file,
keep the old magic file around for comparison purposes
(rename it to
file.c:   C program text
file:     ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV),
	  dynamically linked (uses shared libs), stripped




There has been a
command in every
(man page dated November, 1973).
The System V version introduced one significant major change:
the external list of magic types.
This slowed the program down slightly but made it a lot more flexible.
This program, based on the System V version,
was written by Ian Darwin <ian@darwinsys.com>
without looking at anybody else's source code.
John Gilmore revised the code extensively, making it better than
the first version.
Geoff Collyer found several inadequacies
and provided some magic file entries.
Contributions by the `&' operator by Rob McMahon, cudcv@warwick.ac.uk, 1989.
Guy Harris, guy@netapp.com, made many changes from 1993 to the present.
Primary development and maintenance from 1990 to the present by
Christos Zoulas (christos@astron.com).
Altered by Chris Lowth, chris@lowth.com, 2000:
Handle the
option to output mime type strings, using an alternative
magic file and internal logic.
Altered by Eric Fischer (enf@pobox.com), July, 2000,
to identify character codes and attempt to identify the languages
of non-ASCII files.
Altered by Reuben Thomas (rrt@sc3d.org), 2007 to 2008, to improve MIME
support and merge MIME and non-MIME magic, support directories as well
as files of magic, apply many bug fixes and improve the build system.
The list of contributors to the
directory (magic files)
is too long to include here.
You know who you are; thank you.
Many contributors are listed in the source files.
Copyright (c) Ian F. Darwin, Toronto, Canada, 1986-1999.
Covered by the standard Berkeley Software Distribution copyright; see the file
LEGAL.NOTICE in the source distribution.
The files
and
were written by John Gilmore from his public-domain
program, and are not covered by the above license.
There must be a better way to automate the construction of the Magic
file from all the glop in Magdir.
What is it?
uses several algorithms that favor speed over accuracy,
thus it can be misled about the contents of
text
files.
The support for text files (primarily for programming languages)
is simplistic, inefficient and requires recompilation to update.
The list of keywords in
probably belongs in the Magic file.
This could be done by using some keyword like
for the offset value.
Complain about conflicts in the magic file entries.
Make a rule that the magic entries sort based on file offset rather
than position within the magic file?
The program should provide a way to give an estimate
of
a guess is.
We end up removing guesses (e.g.
as first 5 chars of file) because
they are not as good as other guesses (e.g.
versus
).
Still, if the others don't pan out, it should be possible to use the
first guess.
This manual page, and particularly this section, is too long.
returns 0 on success, and non-zero on error.
You can obtain the original author's latest version by anonymous FTP
on
in the directory
reads a file containing a call tree, as generated by the
or 
commands, and filters or prunes it as specified by the options.
Print the call tree from hottest to coldest stack frame.
Remove branches of the call tree that have count less than
Remove branches of the call tree that have malloc size less than
such as 500K or 1.2M.
their cost to the caller.
Remove stack frames from
while still charging their cost to the caller.  This argument can be repeated
for multiple libraries.
When charging libraries to callers, keep the top call into excluded libraries.
The
utility recursively descends the directory tree for each
listed, evaluating an
(composed of the
and
listed below) in terms
of each file in the tree.
The options are as follows:
Interpret regular expressions followed by
and
primaries as extended (modern) regular expressions rather than basic
regular expressions (BRE's).
The
manual page fully describes both formats.
Cause the file information and file type (see
returned for each symbolic link specified on the command line to be
those of the file referenced by the link, not the link itself.
If the referenced file does not exist, the file information and type will
be for the link itself.
File information of all symbolic links not on
the command line is that of the link itself.
Cause the file information and file type (see
returned for each symbolic link to be those of the file referenced by the
link, not the link itself.
If the referenced file does not exist, the file information and type will
be for the link itself.
This option is equivalent to the deprecated
primary.
Cause the file information and file type (see
returned for each symbolic link to be those of the link itself.
This is the default.
Permit
to be safely used in conjunction with
If a file name contains any of the delimiting characters used by
a diagnostic message is displayed on standard error, and the file
is skipped.
The delimiting characters include single
and double
quotes, backslash
space, tab and newline characters.
However, you may wish to consider the
primary in conjunction with
as an effective alternative.
Cause
to perform a depth-first traversal, i.e., directories
are visited in post-order and all entries in a directory will be acted
on before the directory itself.
By default,
visits directories in pre-order, i.e., before their contents.
Note, the default is
a breadth-first traversal.
This option is equivalent to the
primary of
The
option
can be useful when
is used with
to process files that are contained in directories with unusual permissions.
It ensures that you have write permission while you are placing files in a
directory, then sets the directory's permissions as the last thing.
Specify a file hierarchy for
to traverse.
File hierarchies may also be specified as the operands immediately
following the options.
Cause
to traverse the file hierarchies in lexicographical order,
i.e., alphabetical order within each directory.
Note:
and
may give different results.
Prevent
from descending into directories that have a device number different
than that of the file from which the descent began.
This option is equivalent to the deprecated
primary.
All primaries which take a numeric argument allow the number to be
preceded by a plus sign
or a minus sign
A preceding plus sign means
a preceding minus sign means
and neither means
True if the difference between the time of a file's inode creation
and the time
was started, rounded up to the next full minute, is
minutes.
Same as
If no units are specified, this primary evaluates to
true if the difference between the time of a file's inode creation
and the time
was started, rounded up to the next full 24-hour period, is
24-hour periods.
If units are specified, this primary evaluates to
true if the difference between the time of a file's inode creation
and the time
was started is exactly
units.
Please refer to the
primary description for information on supported time units.
May be used in conjunction with other primaries to locate
files with extended ACLs.
See
for more information.
True if the difference between the file last access time and the time
was started, rounded up to the next full minute, is
minutes.
Same as
If no units are specified, this primary evaluates to
true if the difference between the file last access time and the time
was started, rounded up to the next full 24-hour period, is
24-hour periods.
If units are specified, this primary evaluates to
true if the difference between the file last access time and the time
was started is exactly
units.
Possible time units are as follows:
second
minute (60 seconds)
hour (60 minutes)
day (24 hours)
week (7 days)
Any number of units may be combined in one
argument, for example,
Units are probably only useful when used in conjunction with the
or
modifier.
True if the difference between the time of last change of file status
information and the time
was started, rounded up to the next full minute, is
minutes.
Same as
If no units are specified, this primary evaluates to
true if the difference between the time of last change of file status
information and the time
was started, rounded up to the next full 24-hour period, is
24-hour periods.
If units are specified, this primary evaluates to
true if the difference between the time of last change of file status
information and the time
was started is exactly
units.
Please refer to the
primary description for information on supported time units.
Same as 
GNU find implements this as a primary in mistaken emulation of
Always returns true.
This executes
from the current working directory as
recurses down the tree.
It will not attempt to delete a filename with a
character in its pathname relative to
for security reasons.
Depth-first traversal processing is implied by this option.
Following symlinks is incompatible with this option.
Always true;
same as the
option.
True if the depth of the file relative to the starting point of the traversal
is
True if the current file or directory is empty.
True if the program named
returns a zero value as its exit status.
Optional
may be passed to the utility.
The expression must be terminated by a semicolon
If you invoke
from a shell you may need to quote the semicolon if the shell would
otherwise treat it as a control operator.
If the string
appears anywhere in the utility name or the
arguments it is replaced by the pathname of the current file.
will be executed from the directory from which
was executed.
and
are not subject to the further expansion of shell patterns
and constructs.
Same as
except that
is replaced with as many pathnames as possible for each invocation of
This behaviour is similar to that of
The
primary is identical to the
primary with the exception that
will be executed from the directory that holds
the current file.
The filename substituted for
the string
is not qualified.
Same as
except that
is replaced with as many pathnames as possible for each invocation of
This behaviour is similar to that of
The flags are specified using symbolic names (see
Those with the
prefix (except
are said to be
Flags in
are checked to be set, and flags in
are checked to be not set.
Note that this is different from
which only allows the user to specify mode bits that are set.
If flags are preceded by a dash
this primary evaluates to true
if at least all of the bits in
and none of the bits in
are set in the file's flags bits.
If flags are preceded by a plus
this primary evaluates to true
if any of the bits in
is set in the file's flags bits,
or any of the bits in
is not set in the file's flags bits.
Otherwise,
this primary evaluates to true
if the bits in
exactly match the file's flags bits,
and none of the
bits match those of
True if the file is contained in a file system of type
The
command can be used to find out the types of file systems
that are available on the system.
In addition, there are two pseudo-types,
and
The former matches any file system physically mounted on the system where
the
is being executed and the latter matches any file system which is
mounted read-only.
The same thing as
for compatibility with GNU find.
GNU find imposes a restriction that
is numeric, while
does not.
True if the file belongs to the group
If
is numeric and there is no such group name, then
is treated as a group ID.
This option is for GNU find compatibility and is ignored.
Like
but the match is case insensitive.
This is a GNU find extension.
Like
but the match is case insensitive.
True if the file has inode number
Like
but the match is case insensitive.
Like
but the match is case insensitive.
The same thing as 
for GNU find compatibility.
True if the file has
links.
Like
but the contents of the symbolic link are matched instead of the file
name.
Note that this only matches broken symbolic links
if symbolic links are being followed.
This is a GNU find extension.
This primary always evaluates to true.
The following information for the current file is written to standard output:
its inode number, size in 512-byte blocks, file permissions, number of hard
links, owner, group, size in bytes, last modification time, and pathname.
If the file is a block or character special file, the device number
will be displayed instead of the size in bytes.
If the file is a symbolic link, the pathname of the linked-to file will be
displayed preceded by
The format is identical to that produced by
Always true; descend at most
directory levels below the command line arguments.
If any
primary is specified, it applies to the entire expression even if it would
not normally be evaluated.
limits the whole search to the command line arguments.
Always true; do not apply any tests or actions at levels less than
If any
primary is specified, it applies to the entire expression even if it would
not normally be evaluated.
processes all but the command line arguments.
True if the difference between the file last modification time and the time
was started, rounded up to the next full minute, is
minutes.
Same as
The same thing as 
for GNU find compatibility.
If no units are specified, this primary evaluates to
true if the difference between the file last modification time and the time
was started, rounded up to the next full 24-hour period, is
24-hour periods.
If units are specified, this primary evaluates to
true if the difference between the file last modification time and the time
was started is exactly
units.
Please refer to the
primary description for information on supported time units.
True if the last component of the pathname being examined matches
Special shell pattern matching characters
and
may be used as part of
These characters may be matched explicitly by escaping them with a
backslash
True if the current file has a more recent last modification time than
True if the current file has a more recent last access time
inode creation time
change time
or modification time
than the last access time
inode creation time
change time
or modification time
of
In addition, if
then
is instead interpreted as a direct date specification of the form
understood by
Note that
is equivalent to
True if the file belongs to an unknown group.
This option is for GNU find compatibility and is ignored.
This option is for GNU find compatibility.
In GNU find it disables an optimization not relevant to 
so it is ignored.
True if the file belongs to an unknown user.
The
primary is identical to the
primary with the exception that
requests user affirmation for the execution of the
by printing
a message to the terminal and reading a response.
If the response is not affirmative
in the
locale),
the command is not executed and the
value of the
expression is false.
The
primary is identical to the
primary with the same exception as described for the
primary.
True if the pathname being examined matches
Special shell pattern matching characters
and
may be used as part of
These characters may be matched explicitly by escaping them with a
backslash
Slashes
are treated as normal characters and do not have to be
matched explicitly.
The
may be either symbolic (see
or an octal number.
If the
is symbolic, a starting value of zero is assumed and the
sets or clears permissions without regard to the process' file mode
creation mask.
If the
is octal, only bits 07777
of the file's mode bits participate
in the comparison.
If the
is preceded by a dash
this primary evaluates to true
if at least all of the bits in the
are set in the file's mode bits.
If the
is preceded by a plus
this primary evaluates to true
if any of the bits in the
are set in the file's mode bits.
Otherwise, this primary evaluates to true if
the bits in the
exactly match the file's mode bits.
Note, the first character of a symbolic mode may not be a dash
This primary always evaluates to true.
It prints the pathname of the current file to standard output.
If none of
or
is specified, the given expression shall be effectively replaced by
This primary always evaluates to true.
It prints the pathname of the current file to standard output, followed by an
character (character code 0).
This primary always evaluates to true.
It causes
to not descend into the current file.
Note, the
primary has no effect if the
option was specified.
True if the whole path of the file matches
using regular expression.
To match a file named
you can use the regular expression
or
but not
or
True if the file is a hard link to
If the command option
is specified, it is also true if the file is a symbolic link and
points to 
True if the file's size, rounded up, in 512-byte blocks is
If
is followed by a
then the primary is true if the
file's size is
bytes (characters).
Similarly if
is followed by a scale indicator then the file's size is compared to
scaled as:
kilobytes (1024 bytes)
megabytes (1024 kilobytes)
gigabytes (1024 megabytes)
terabytes (1024 gigabytes)
petabytes (1024 terabytes)
True if the file is of the specified type.
Possible file types are as follows:
block special
character special
directory
regular file
symbolic link
FIFO
socket
The same thing as
for compatibility with GNU find.
GNU find imposes a restriction that
is numeric, while
does not.
True if the file belongs to the user
If
is numeric and there is no such user name, then
is treated as a user ID.
The same thing as 
for GNU find compatibility.
True if the file has any extended attributes.
True if the file has an extended attribute with the specified
The primaries may be combined using the following operators.
The operators are listed in order of decreasing precedence.
This evaluates to true if the parenthesized expression evaluates to
true.
This is the unary
operator.
It evaluates to true if the expression is false.
Always false.
Always true.
The
operator is the logical
operator.
As it is implied by the juxtaposition of two expressions it does not
have to be specified.
The expression evaluates to true if both expressions are true.
The second expression is not evaluated if the first expression is false.
The
operator is the logical
operator.
The expression evaluates to true if either the first or the second expression
is true.
The second expression is not evaluated if the first expression is true.
All operands and primaries must be separate arguments to
Primaries which themselves take arguments expect each argument
to be a separate argument to
The
and
environment variables affect the execution of the
utility as described in
The following examples are shown as given to the shell:
Print out a list of all the files whose names do not end in
Print out a list of all the files owned by user
that are newer
than the file
Print out a list of all the files which are not both newer than
and owned by
Print out a list of all the files that are either owned by
or that are newer than
Print out a list of all the files whose inode change time is more
recent than the current time minus one minute.
Use the
command to print out a list of all the files.
Delete all broken symbolic links in
Find files and directories that are at least seven levels deep
in the working directory
Is not equivalent to the previous example, since
is not evaluated below level seven.
The
primary is deprecated; the
option should be used instead.
See the
section below for details.
The
utility syntax is a superset of the syntax specified by the
standard.
All the single character options except
and
as well as
and all of the
birthtime related primaries are extensions to
Historically, the
and
options were implemented using the primaries
and
These primaries always evaluated to true.
As they were really global variables that took effect before the traversal
began, some legal expressions could have unexpected results.
An example is the expression
As
always evaluates to true, the standard order of evaluation
implies that
would never be evaluated.
This is not the case.
The operator
was implemented as
and the operator
was implemented as
Historic implementations of the
and
primaries did not replace the string
in the utility name or the
utility arguments if it had preceding or following non-whitespace characters.
This version replaces it no matter where in the utility name or arguments
it appears.
The
option was inspired by the equivalent
and
options.
A
command appeared in
The special characters used by
are also special characters to many shell programs.
In particular, the characters
and
may have to be escaped from the shell.
As there is no delimiter separating options and file names or file
names and the
it is difficult to specify files named
or
These problems are handled by the
option and the
construct.
The
primary does not interact well with other options that cause the file system
tree traversal options to be changed.
The
and
primaries are actually global options (as documented above).
They should
probably be replaced by options which look like options.
find2perl is a little translator to convert find command lines to
equivalent Perl code.  The resulting code is typically faster than
running find itself.
quoted from interpretation by the shell using a backslash (just as with
quoted from interpretation by the shell using a backslash (just as with
Follow (dereference) symlinks.  The checking of file attributes depends
file check option, this now applies to the symbolic link itself, i.e.
Change directory traversal algorithm from breadth-first to depth-first.
Do not descend into the directory currently matched.
Do not traverse mount points (prunes search at mount-point directories).
quoted to avoid interpretation by the shell (just as with using
is implemented).
True if file's owner is not in password database.
True if file's group is not in group database.
True if (hard) link count of file matches N (see below).
True if file's size matches N (see below) N is normally counted in
True if last-access time of file matches N (measured in days) (see
below).
True if last-changed time of file's inode matches N (measured in days,
see below).
True if last-modified time of file matches N (measured in days, see below).
True if last-modified time of file matches N.
implicitly.
quoted from interpretation by the shell using a backslash (just as with
quoted from interpretation by the shell using a backslash (just as with
Predicates which take a numeric argument N can come in three forms:
find, File::Find.
find2perl is a little translator to convert find command lines to
equivalent Perl code.  The resulting code is typically faster than
running find itself.
quoted from interpretation by the shell using a backslash (just as with
quoted from interpretation by the shell using a backslash (just as with
Follow (dereference) symlinks.  The checking of file attributes depends
file check option, this now applies to the symbolic link itself, i.e.
Change directory traversal algorithm from breadth-first to depth-first.
Do not descend into the directory currently matched.
Do not traverse mount points (prunes search at mount-point directories).
quoted to avoid interpretation by the shell (just as with using
is implemented).
True if file's owner is not in password database.
True if file's group is not in group database.
True if (hard) link count of file matches N (see below).
True if file's size matches N (see below) N is normally counted in
True if last-access time of file matches N (measured in days) (see
below).
True if last-changed time of file's inode matches N (measured in days,
see below).
True if last-modified time of file matches N (measured in days, see below).
True if last-modified time of file matches N.
implicitly.
quoted from interpretation by the shell using a backslash (just as with
quoted from interpretation by the shell using a backslash (just as with
Predicates which take a numeric argument N can come in three forms:
find, File::Find.
find2perl is a little translator to convert find command lines to
equivalent Perl code.  The resulting code is typically faster than
running find itself.
quoted from interpretation by the shell using a backslash (just as with
quoted from interpretation by the shell using a backslash (just as with
Follow (dereference) symlinks.  The checking of file attributes depends
file check option, this now applies to the symbolic link itself, i.e.
Change directory traversal algorithm from breadth-first to depth-first.
Do not descend into the directory currently matched.
Do not traverse mount points (prunes search at mount-point directories).
quoted to avoid interpretation by the shell (just as with using
is implemented).
True if file's owner is not in password database.
True if file's group is not in group database.
True if (hard) link count of file matches N (see below).
True if file's size matches N (see below) N is normally counted in
True if last-access time of file matches N (measured in days) (see
below).
True if last-changed time of file's inode matches N (measured in days,
see below).
True if last-modified time of file matches N (measured in days, see below).
True if last-modified time of file matches N.
implicitly.
quoted from interpretation by the shell using a backslash (just as with
quoted from interpretation by the shell using a backslash (just as with
Predicates which take a numeric argument N can come in three forms:
find, File::Find.
command-line interface onto the File::Find::Rule heirarchy of modules.
The syntax for expressions is the rule name, preceded by a dash,
followed by an optional argument.  If the argument is an opening
parenthesis it is taken as a list of arguments, terminated by a
closing parenthesis.
Some examples:
we'd have omitted the parenthesis it would have parsed as a call to
I'm very slack.  Please consult the File::Find::Rule manpage for now,
findrule automatically loads all of your installed File::Find::Rule::*
extension modules, so check the documentation to see what those would be.
Richard Clamp <richardc@unixbeard.net> from a suggestion by Tatsuhiko Miyagawa
Copyright (C) 2002 Richard Clamp.  All Rights Reserved.
under the same terms as Perl itself.
File::Find::Rule
command-line interface onto the File::Find::Rule heirarchy of modules.
The syntax for expressions is the rule name, preceded by a dash,
followed by an optional argument.  If the argument is an opening
parenthesis it is taken as a list of arguments, terminated by a
closing parenthesis.
Some examples:
we'd have omitted the parenthesis it would have parsed as a call to
I'm very slack.  Please consult the File::Find::Rule manpage for now,
findrule automatically loads all of your installed File::Find::Rule::*
extension modules, so check the documentation to see what those would be.
Richard Clamp <richardc@unixbeard.net> from a suggestion by Tatsuhiko Miyagawa
Copyright (C) 2002 Richard Clamp.  All Rights Reserved.
under the same terms as Perl itself.
File::Find::Rule
command-line interface onto the File::Find::Rule heirarchy of modules.
The syntax for expressions is the rule name, preceded by a dash,
followed by an optional argument.  If the argument is an opening
parenthesis it is taken as a list of arguments, terminated by a
closing parenthesis.
Some examples:
we'd have omitted the parenthesis it would have parsed as a call to
I'm very slack.  Please consult the File::Find::Rule manpage for now,
findrule automatically loads all of your installed File::Find::Rule::*
extension modules, so check the documentation to see what those would be.
Richard Clamp <richardc@unixbeard.net> from a suggestion by Tatsuhiko Miyagawa
Copyright (C) 2002 Richard Clamp.  All Rights Reserved.
under the same terms as Perl itself.
File::Find::Rule
The
utility displays information about the system users.
Options are:
Forces
to use IPv4 addresses only.
Forces
to use IPv6 addresses only.
This option restricts the gecos output to only the users' real
name.
It also has the side-effect of restricting the output
of the remote host when used in conjunction with the
option.
When used in conjunction with the
option, the name of the remote host is displayed instead of the office
location and office phone.
Disable all use of
Produce a multi-line format displaying all of the information
described for the
option as well as the user's home directory, home phone number, login
shell, mail status, and the contents of the files
and
from the user's home directory.
If idle time is at least a minute and less than a day, it is
presented in the form ``hh:mm''.
Idle times greater than a day are presented as ``d day[s]hh:mm''.
Phone numbers specified as eleven digits are printed as ``+N-NNN-NNN-NNNN''.
Numbers specified as ten or seven digits are printed as the appropriate
subset of that string.
Numbers specified as five digits are printed as ``xN-NNNN''.
Numbers specified as four digits are printed as ``xNNNN''.
If write permission is denied to the device, the phrase ``(messages off)''
is appended to the line containing the device name.
One entry per user is displayed with the
option; if a user is logged on multiple times, terminal information
is repeated once per login.
Mail status is shown as ``No Mail.'' if there is no mail at all, ``Mail
last read DDD MMM ## HH:MM YYYY (TZ)'' if the person has looked at their
mailbox since new mail arriving, or ``New mail received ...'', ``Unread
since ...'' if they have new mail.
Prevent matching of
names.
is usually a login name; however, matching will also be done on the
users' real names, unless the
option is supplied.
All name matching performed by
is case insensitive.
When used in conjunction with the
option, the office location and office phone information is displayed
instead of the name of the remote host.
Prevent
the
option of
from displaying the contents of the
and
files.
Display the user's login name, real name, terminal name and write
status (as a ``*'' before the terminal name if write permission is
denied), idle time, login time, and either office location and office
phone number, or the remote host.
If
is given, the office location and office phone number is printed
(the default).
If
is given, the remote host is printed instead.
Idle time is in minutes if it is a single integer, hours and minutes
if a ``:'' is present, or days if a ``d'' is present.
If it is an
the login time indicates the time of last login.
Login time is displayed as the day name if less than 6 days, else month, day;
hours and minutes, unless more than six months ago, in which case the year
is displayed rather than the hours and minutes.
Unknown devices as well as nonexistent idle and login times are
displayed as single asterisks.
If no options are specified,
defaults to the
style output if operands are provided, otherwise to the
style.
Note that some fields may be missing, in either format, if information
is not available for them.
If no arguments are specified,
will print an entry for each user currently logged into the system.
The
utility may be used to look up users on a remote machine.
The format is to specify a
as
or
where the default output
format for the former is the
style, and the default output format for the latter is the
style.
The
option is the only option that may be passed to a remote machine.
If the file
exists in the user's home directory,
and the program is not run with superuser privileges,
behaves as if the user in question does not exist.
The optional
configuration file can be used to specify aliases.
Since
is invoked by
aliases will work for both local and network queries.
The
utility utilizes the following environment variable, if it exists:
This variable may be set with favored options to
alias definition data base
last login data base
The
command appeared in
The current FINGER protocol RFC requires that the client keep the connection
fully open until the server closes.
This prevents the use of the optimal
(Servers which depend on this requirement are
bogus but have nonetheless been observed in the Internet at large.)
The
utility does not recognize multibyte characters.
fixproc - Fixes a process by performing the specified action.
Fixes a process named "proc" by performing the specified action.  The
actions can be check, kill, restart, exist, or fix.  The action is specified
on the command line or is read from a default database, which describes
the default action to take for each process.  The database format and
the meaning of each action are described below.
minimum number of processes that should be running, defaults to 1
maximum number of processes that should be running, defaults to 1
kill process, wait 5 seconds, kill -9 if still exist
kill process, wait 5 seconds, kill -9 if still exist, then start again
checks if proc exists in ps && (min <= num. of processes <= max)
action, if check fails.
The
utility is a simple text formatter which reads the concatenation of input
files (or standard input if none are given) and produces on standard
output a version of its input with lines as close to the
length
as possible without exceeding the
The
length defaults
to 65 and the
to 10 more than the
length.
Alternatively, a single
parameter can be specified either by prepending a hyphen to it or by using
For example,
and
all produce identical output.
The spacing at the beginning of the input lines is preserved in the output,
as are blank lines and interword spacing.
Lines are joined or split only at white space; that is, words are never
joined or hyphenated.
The options are as follows:
Center the text, line by line.
In this case, most of the other
options are ignored; no splitting or joining of lines is done.
Try to format mail header lines contained in the input sensibly.
Format lines beginning with a
(dot) character.
Normally,
does not fill these lines, for compatibility with
Allow indented paragraphs.
Without the
flag, any change in the amount of whitespace at the start of a line
results in a new paragraph being begun.
Collapse whitespace inside lines, so that multiple whitespace
characters are turned into a single space.
(Or, at the end of a
sentence, a double space.)
Treat the
(and no others) as sentence-ending characters.
By default the
sentence-ending characters are full stop
question mark
and exclamation mark
Remember that some characters may need to be
escaped to protect them from your shell.
Replace multiple spaces with tabs at the start of each output
line, if possible.
Each
spaces will be replaced with one tab.
The default is 8.
If
is 0, spaces are preserved.
Assume that the input files' tabs assume
spaces per tab stop.
The default is 8.
The
utility
is meant to format mail messages prior to sending, but may also be useful
for other simple tasks.
For instance,
within visual mode of the
editor (e.g.,
the command
will reformat a paragraph,
evening the lines.
The
and
environment variables affect the execution of
as described in
The
command appeared in
The version described herein is a complete rewrite and appeared in
(added
length concept)
operations, the standard text processors are likely to be more appropriate.
When the first line of an indented paragraph is very long (more than
about twice the goal length), the indentation in the output can be
wrong.
The
utility is not infallible in guessing what lines are mail headers and what
lines are not.
The
utility is a filter which folds the contents of the specified files,
or the standard input if no files are specified,
breaking the lines to have a maximum of 80 columns.
The options are as follows:
Count
in bytes rather than column positions.
Fold line after the last blank character within the first
column positions (or bytes).
Specify a line width to use instead of the default 80 columns.
should be a multiple of 8 if tabs are present, or the tabs should
be expanded using
before using
The
and
environment variables affect the execution of
as described in
The
utility conforms to
If underlining is present it may be messed up by folding.
[-j] [-t] [-s] [-v] ( -a | <process name | pid> [ ... ] )
The
utility gathers and displays memory consumption information for the specified processes.
will display all addressable memory used by the specified processes, but it emphasizes anonymous and wired memory.  If multiple processes are specified,
will de-duplicate multiply mapped objects and will display shared objects separately from private ones.
Because it is inspecting the address space of other processes,
must be run as root.
target all processes (will take much longer)
format output in JSON instead of structured text
in addition to the supplied processes, target their children, grandchildren, etc.
skip processes that are dirty tracked and have no outstanding XPC transactions (i.e., are "clean")
display vmmap-like output of address space layout
display help and exit
Mail WindowServer
The
utility prints
out the mail header lines from the invoker's mailbox.
The following options are available:
Just print a count of messages and exit.
The supplied file
is examined instead of the invoker's mailbox.
If the
option is used, the
argument should not be used.
Read from standard input if file name
is given.
Only mail from addresses containing
the
supplied string are printed.
If
is given, the
mailbox is examined instead of the invoker's own mailbox.
(Privileges are required.)
If set, the location of the invoker's mailbox.
Otherwise, the default in
is used.
The
command appeared in
real-time
The
utility presents an ongoing display of system call usage information
pertaining to filesystem activity.
It requires root privileges due to the kernel tracing facility it uses to
operate.
By default, the activity monitored includes all system processes except the
running
process, Terminal, telnetd, sshd, rlogind, tcsh, csh and sh.
These defaults can be overridden such that output is limited to include or
exclude a list of processes specified by the user.
The output presented by
is formatted according to the size of your window.
A narrow window will display fewer columns of data.
Use a wide window for maximum data display.
You may override the window formatting restrictions
by forcing a wide display with the
option.
In this case, the data displayed will wrap
when the window is not wide enough.
The options are as follows:
Specifying the
option generates output that excludes sampling
of the running fs_usage tool.
If a list of process IDs or commands is also given,
then those processes are also excluded from the sampled output.
Specifying the
option forces a wider, more detailed output,
regardless of the window size.
Specifying the
option turns on output filtering based on the
provided.
Multiple filtering options can be specified.
By default, no output filtering occurs.
The supported modes are:
Network-related events are displayed.
Filesystem-related events are displayed.
Pathname-related events are displayed.
Exec and spawn events are displayed.
In addition, show cache hits.
Specifying the
Specifies a run timeout in seconds.  
will run for no longer than the timeout specified.
Specifies a raw trace file to process.
If 
is selected, specifies the start time in microseconds to
begin processing entries from the raw trace file. Entries
with timestamps before the specified start time will be
skipped.
If 
is selected, specifies the ending time in microseconds to
stop processing entries from the raw trace file.  Entries
with timestamps beyond the specified ending time will be
skipped.
The sampled data can be limited to a list of process IDs or commands.
When a command name is given, all processes with that name will be sampled.
Using the
option has the opposite effect,
excluding sampled data relating to the given list
of process IDs or commands.
If you set the DYLD_IMAGE_SUFFIX environment variable to
then an application will use the debug version of all libraries,
including the Carbon FileManager.
See
When
is run against a Carbon Application launched in this environment,
then the high-level Carbon FileManager calls
will be displayed bracketing the system calls that they are built on.
The data columns displayed are as follows:
TOD when call occurred.
Wide mode will have microsecond granularity.
The name of the network or filesystem related call, page-in, page-out,
or physical disk access.
Of the form F=x, x is a file descriptor.
Depending on the type of system call,
this will be either an input value or a return value.
Of the form B=x, x is the number of bytes requested by the call.
On error, the errno is displayed in brackets.
Pathname of the file accessed (up to the last 28 bytes).
Of the form A=0xnnnnnnnn,
where 0xnnnnnnnn is the address being faulted.
Of the form D=0xnnnnnnnn,
where 0xnnnnnnnn is the block number
of the physical disk block being read or written.
Of the form O=0xnnnnnnnn, where 0xnnnnnnnn is a file offset.
Of the form S=x, x is the number of ready descriptors returned
by the select() system call.
If S=0, the time limit expired.
The elapsed time spent in the system call.
A 
after the elapsed time indicates the process was scheduled out
during this file activity.
In this case, the elapsed time includes the wait time.
The process that made the system call.  Wide mode will append the
thread id to the process name (i.e Mail.nnn).
fs_usage -w -f filesys Mail
will display file system related data
for all instances of processes named Mail.
Maximum data output will be displayed in the window.
Internet file transfer program
is the user interface to the Internet standard File Transfer Protocol.
The program allows a user to transfer files to and from a
remote network site.
The last five arguments will fetch a file using the
or
protocols, or by direct copying, into the current directory.
This is ideal for scripts.
Refer to
below for more information.
Options may be specified at the command line, or to the
command interpreter.
Forces
to only use IPv4 addresses.
Forces
to only use IPv6 addresses.
Force active mode ftp.
By default,
will try to use passive mode ftp and fall back to active mode
if passive is not supported by the server.
This option causes
to always use an active connection.
It is only useful for connecting to very old servers that do not
implement passive mode properly.
Causes
to bypass normal login procedure, and use an anonymous login instead.
Enables debugging.
Disables command line editing.
This is useful for Emacs ange-ftp mode.
Forces a cache reload for transfers that go through the
or
proxies.
Disables file name globbing.
Turns off interactive prompting during
multiple file transfers.
Restrains
from attempting
upon initial connection for non auto-fetch transfers.
If auto-login is enabled,
will check the
(see below) file in the user's home directory for an entry describing
an account on the remote machine.
If no entry exists,
will prompt for the remote machine login name (default is the user
identity on the local machine), and, if necessary, prompt for a password
and an account with which to login.
To override the auto-login for auto-fetch transfers, specify the
username (and optionally, password) as appropriate.
Use
instead of
Refer to
for more information.
When auto-fetching files, save the contents in
is parsed according to the
below.
If
is not
or doesn't start with
then only the first file specified will be retrieved into
all other files will be retrieved into the basename of their
remote name.
Enable passive mode operation for use behind connection filtering firewalls.
This option has been deprecated as
now tries to use passive mode by default, falling back to active mode
if the server does not support passive connections.
Sets the port number to
Quit if the connection has stalled for
seconds.
Retry the connection attempt if it failed, pausing for
seconds.
Restart all non-proxied auto-fetches.
Uses
as the local IP address for all connections.
Enables packet tracing.
Set the maximum transfer rate for
to
and if specified, the increment to
Refer to
for more information.
Upload files on the command line to
where
is one of the ftp URL types as supported by auto-fetch
(with an optional target filename for single file uploads), and
is one or more local files to be uploaded.
Enable
and
This is the default if output is to a terminal (and in the case of
is the foreground process).
Forces
to show all responses from the remote server, as well
as report on data transfer statistics.
Disable
and
overriding the default of enabled when output is to a terminal.
The client host with which
is to communicate may be specified on the command line.
If this is done,
will immediately attempt to establish a connection to an
server on that host; otherwise,
will enter its command interpreter and await instructions
from the user.
When
is awaiting commands from the user the prompt
is provided to the user.
The following commands are recognized
by
Invoke an interactive shell on the local machine.
If there are arguments, the first is taken to be a command to execute
directly, with the rest of the arguments as its arguments.
Execute the macro
that was defined with the
command.
Arguments are passed to the macro unglobbed.
Supply a supplemental password required by a remote system for access
to resources once a login has been successfully completed.
If no argument is included, the user will be prompted for an account
password in a non-echoing input mode.
Append a local file to a file on the remote machine.
If
is left unspecified, the local file name is used in naming the
remote file after being altered by any
or
setting.
File transfer uses the current settings for
and
Set the file transfer
to network
This is the default type.
Arrange that a bell be sounded after each file transfer
command is completed.
Set the file transfer
to support binary image transfer.
Terminate the
session with the remote server
and exit
An end of file will also terminate the session and exit.
Toggle remote computer file name case mapping during
and
commands.
When
is on (default is off), remote computer file names with all letters in
upper case are written in the local directory with the letters mapped
to lower case.
Change the working directory on the remote machine
to
Change the remote machine working directory to the parent of the
current remote machine working directory.
Change the permission modes of the file
on the remote
system to
Terminate the
session with the remote server, and
return to the command interpreter.
Any defined macros are erased.
Toggle carriage return stripping during
ascii type file retrieval.
during ascii type file transfer.
When
is on (the default), carriage returns are stripped from this
sequence to conform with the
single linefeed record
delimiter.
Records on
remote systems may contain single linefeeds;
when an ascii type transfer is made, these linefeeds may be
distinguished from a record delimiter only when
is off.
Toggle debugging mode.
If an optional
is specified it is used to set the debugging level.
When debugging is on,
prints each command sent to the remote machine, preceded
by the string
Delete the file
on the remote machine.
Print a listing of the contents of a
directory on the remote machine.
The listing includes any system-dependent information that the server
chooses to include; for example, most
systems will produce
output from the command
If
is left unspecified, the current working directory is used.
If interactive prompting is on,
will prompt the user to verify that the last argument is indeed the
target local file for receiving
output.
If no local file is specified, or if
is
the output is sent to the terminal.
A synonym for
Toggle command line editing, and context sensitive command and file
completion.
This is automatically enabled if input is from a terminal, and
disabled otherwise.
Toggle the use of the extended
and
commands on IPv4 connections; first try
and then
This is enabled by default.
If an extended command fails then this option will be temporarily
disabled for the duration of the current connection, or until
is executed again.
A synonym for
Display what features the remote server supports (using the
command).
Retrieve the files listed in
which has one line per filename.
Set the file transfer
to
The default (and only supported)
format is
A synonym for
Toggle gate-ftp mode, which used to connect through the
TIS FWTK and Gauntlet ftp proxies.
This will not be permitted if the gate-ftp server hasn't been set
(either explicitly by the user, or from the
environment variable).
If
is given,
then gate-ftp mode will be enabled, and the gate-ftp server will be set to
If
is also given, that will be used as the port to connect to on the
gate-ftp server.
Retrieve the
and store it on the local machine.
If the local
file name is not specified, it is given the same
name it has on the remote machine, subject to
alteration by the current
and
settings.
The current settings for
and
are used while transferring the file.
Toggle filename expansion for
and
If globbing is turned off with
the file name arguments
are taken literally and not expanded.
Globbing for
is done as in
For
and
each remote file name is expanded
separately on the remote machine and the lists are not merged.
Expansion of a directory name is likely to be
different from expansion of the name of an ordinary file:
the exact result depends on the foreign operating system and ftp server,
and can be previewed by doing
Note:
and
are not meant to transfer
entire directory subtrees of files.
That can be done by
transferring a
archive of the subtree (in binary mode).
Toggle hash-sign
printing for each data block transferred.
The size of a data block defaults to 1024 bytes.
This can be changed by specifying
in bytes.
Enabling
disables
Print an informative message about the meaning of
If no argument is given,
prints a list of the known commands.
Set the inactivity timer on the remote server to
seconds.
If
is omitted, the current inactivity timer is printed.
A synonym for
Change the working directory on the local machine.
If
no
is specified, the user's home directory is used.
A synonym for
Display
with the program specified by the
option.
Print the working directory on the local machine.
A synonym for
Define a macro.
Subsequent lines are stored as the macro
a null line (consecutive newline characters in a file or carriage
returns from the terminal) terminates macro input mode.
There is a limit of 16 macros and 4096 total characters in all
defined macros.
Macro names can be a maximum of 8 characters.
Macros are only applicable to the current session they are
defined within (or if defined outside a session, to the session
invoked with the next
command), and remain defined until a
command is executed.
To invoke a macro, use the
command (see above).
The macro processor interprets
and
as special characters.
A
followed by a number (or numbers) is replaced by the
corresponding argument on the macro invocation command line.
A
followed by an
signals the macro processor that the executing macro is to be
looped.
On the first pass
is replaced by the first argument on the macro invocation command
line, on the second pass it is replaced by the second argument,
and so on.
A
followed by any character is replaced by that character.
Use the
to prevent special treatment of the
Delete the
on the remote machine.
Like
except multiple remote files may be specified.
If interactive prompting is on,
will prompt the user to verify that the last argument is indeed the
target local file for receiving
output.
Expand the
on the remote machine
and do a
for each file name thus produced.
See
for details on the filename expansion.
Resulting file names will then be processed according to
and
settings.
Files are transferred into the local working directory,
which can be changed with
new local directories can be created with
Make a directory on the remote machine.
Like
except multiple remote files may be specified,
and the
must be specified.
If interactive prompting is on,
will prompt the user to verify that the last argument is indeed the
target local file for receiving
output.
Display the contents of
(which should default to the current directory if not given)
in a machine-parsable form, using
The format of display can be changed with
Display the details about
(which should default to the current directory if not given)
in a machine-parsable form, using
The format of display can be changed with
Set the file transfer
to
The default (and only supported)
mode is
Show the last modification time of the file on the remote machine, in
format.
A synonym for
Expand wild cards in the list of local files given as arguments
and do a
for each file in the resulting list.
See
for details of filename expansion.
Resulting file names will then be processed according to
and
settings.
As per
but performs a
instead of
A synonym for
Get the file only if the modification time of the remote file is more
recent that the file on the current system.
If the file does not
exist on the current system, the remote file is considered
Otherwise, this command is identical to
A synonym for
Set or unset the filename mapping mechanism.
If no arguments are specified, the filename mapping mechanism is unset.
If arguments are specified, remote filenames are mapped during
commands and
commands issued without a specified remote target filename.
If arguments are specified, local filenames are mapped during
commands and
commands issued without a specified local target filename.
This command is useful when connecting to a
remote computer
with different file naming conventions or practices.
The mapping follows the pattern set by
and
is a template for incoming filenames (which may have already been
processed according to the
and
settings).
Variable templating is accomplished by including the
sequences
in
Use
to prevent this special treatment of the
character.
All other characters are treated literally, and are used to determine the
variable values.
For example, given
$1.$2 and the remote file name "mydata.data", $1 would have the value
"mydata", and $2 would have the value "data".
The
determines the resulting mapped filename.
The sequences
are replaced by any value resulting from the
template.
The sequence
is replaced by the original filename.
Additionally, the sequence
is replaced by
if
is not a null string; otherwise it is replaced by
For example, the command
nmap $1.$2.$3 [$1,$2].[$2,file]
would yield
the output filename "myfile.data" for input filenames "myfile.data" and
"myfile.data.old", "myfile.file" for the input filename "myfile", and
"myfile.myfile" for the input filename ".myfile".
Spaces may be included in
as in the example:
Use the
character to prevent special treatment
of the
and
characters.
Set or unset the filename character translation mechanism.
If no arguments are specified, the filename character
translation mechanism is unset.
If arguments are specified, characters in
remote filenames are translated during
commands and
commands issued without a specified remote target filename.
If arguments are specified, characters in
local filenames are translated during
commands and
commands issued without a specified local target filename.
This command is useful when connecting to a
remote computer
with different file naming conventions or practices.
Characters in a filename matching a character in
are replaced with the corresponding character in
If the character's position in
is longer than the length of
the character is deleted from the file name.
Establish a connection to the specified
server.
An optional port number may be supplied,
in which case,
will attempt to contact an
server at that port.
If the
option is on (default),
will also attempt to automatically log the user in to
the
server (see below).
Retrieve
and display with the program specified by the
option.
Toggle passive mode (if no arguments are given).
If
is given, act as if
is set to
If passive mode is turned on (default),
will send a
command for all data connections instead of a
command.
The
command requests that the remote server open a port for the data connection
and return the address of that port.
The remote server listens on that port and the client connects to it.
When using the more traditional
command, the client listens on a port and sends that address to the remote
server, who connects back to it.
Passive mode is useful when using
through a gateway router or host that controls the directionality of
traffic.
(Note that though
servers are required to support the
command by
some do not.)
Perform
and display the result with the program specified by the
option.
Perform
and display the result with the program specified by the
option.
Perform
and display the result with the program specified by the
option.
Toggle preservation of modification times on retrieved files.
Toggle display of transfer progress bar.
The progress bar will be disabled for a transfer that has
as
or a command that starts with
Refer to
for more information.
Enabling
disables
Toggle interactive prompting.
Interactive prompting
occurs during multiple file transfers to allow the
user to selectively retrieve or store files.
If prompting is turned off (default is on), any
or
will transfer all files, and any
will delete all files.
When prompting is on, the following commands are available at a prompt:
Answer
to the current file, and automatically answer
to any remaining files for the current command.
Answer
and do not transfer the file.
Answer
to the current file, and turn off prompt mode
(as is
had been given).
Terminate the current operation.
Answer
and transfer the file.
Display a help message.
Any other response will answer
to the current file.
Execute an ftp command on a secondary control connection.
This command allows simultaneous connection to two remote
servers for transferring files between the two servers.
The first
command should be an
to establish the secondary control connection.
Enter the command "proxy ?" to see other
commands executable on the secondary connection.
The following commands behave differently when prefaced by
will not define new macros during the auto-login process,
will not erase existing macro definitions,
and
transfer files from the host on the primary control connection
to the host on the secondary control connection, and
and
transfer files from the host on the secondary control connection
to the host on the primary control connection.
Third party file transfers depend upon support of the
protocol
command by the server on the secondary control connection.
Store a local file on the remote machine.
If
is left unspecified, the local file name is used
after processing according to any
or
settings
in naming the remote file.
File transfer uses the
current settings for
and
Print the name of the current working directory on the remote
machine.
A synonym for
The arguments specified are sent, verbatim, to the remote
server.
Throttle the maximum transfer rate to
If
is 0, disable the throttle.
may be one of:
Both directions.
Incoming transfers.
Outgoing transfers.
can be modified on the fly by
bytes (default: 1024) each time a given signal is received:
Increment
by
bytes.
Decrement
by
bytes.
The result must be a positive number.
If
is not supplied, the current throttle rates are displayed.
Note:
is not yet implemented for ascii mode transfers.
Set the size of the socket receive buffer to
A synonym for
acts like
except that if
exists and is
smaller than
is presumed to be
a partially transferred copy of
and the transfer
is continued from the apparent point of failure.
This command
is useful when transferring very large files over networks that
are prone to dropping connections.
Set options on the remote
server for
to
(whose absence is handled on a command-specific basis).
Remote
commands known to support options include:
(used for
and
Rename the file
on the remote machine, to the file
Clear reply queue.
server.
Resynchronization may be necessary following a violation of the
protocol by the remote server.
Restart the immediately following
or
at the
indicated
On
systems, marker is usually a byte
offset into the file.
Request help from the remote
server.
If a
is specified it is supplied to the server as well.
Delete a directory on the remote machine.
With no arguments, show status of remote machine.
If
is specified, show status of
on remote machine.
Toggle storing of files on the local system with unique filenames.
If a file already exists with a name equal to the target
local filename for a
or
command, a ".1" is appended to the name.
If the resulting name matches another existing file,
a ".2" is appended to the original name.
If this process continues up to ".99", an error
message is printed, and the transfer does not take place.
The generated unique filename will be reported.
Note that
will not affect local files generated from a shell command
(see below).
The default value is off.
A synonym for
Toggle the use of
commands.
By default,
will attempt to use a
command when establishing
a connection for each data transfer.
The use of
commands can prevent delays
when performing multiple file transfers.
If the
command fails,
will use the default data port.
When the use of
commands is disabled, no attempt will be made to use
commands for each data transfer.
This is useful
for certain
implementations which do ignore
commands but, incorrectly, indicate they've been accepted.
Set
to
If
and
are not given, display all of the options and their values.
The currently supported options are:
Defaults to
Defaults to
Defaults to
Defaults to
Defaults to
Defaults to
Defaults to
The arguments specified are sent, verbatim, to the remote
server as a
command.
Return size of
on remote machine.
Set the size of the socket send buffer to
Show the current status of
Set the file transfer
to
The default (and only supported)
structure is
Toggle storing of files on remote machine under unique file names.
The remote
server must support
protocol
command for
successful completion.
The remote server will report unique name.
Default value is off.
Show the type of operating system running on the remote machine.
Set the file transfer type to that needed to
talk to
machines.
A synonym for
Toggle packet tracing.
Set the file transfer
to
If no type is specified, the current type
is printed.
The default type is network
Set the default umask on the remote server to
If
is omitted, the current umask is printed.
Unset
Refer to
for more information.
Print the usage message for
Identify yourself to the remote
server.
If the
is not specified and the server requires it,
will prompt the user for it (after disabling local echo).
If an
field is not specified, and the
server
requires it, the user will be prompted for it.
If an
field is specified, an account command will
be relayed to the remote server after the login sequence
is completed if the remote server did not require it
for logging in.
Unless
is invoked with
disabled, this process is done automatically on initial connection to the
server.
Toggle verbose mode.
In verbose mode, all responses from
the
server are displayed to the user.
In addition,
if verbose is on, when a file transfer completes, statistics
regarding the efficiency of the transfer are reported.
By default,
verbose is on.
Set the size of the socket send and receive buffers to
A synonym for
Command arguments which have embedded spaces may be quoted with
quote
marks.
Commands which toggle settings can take an explicit
or
argument to force the setting appropriately.
Commands which take a byte count as an argument
(e.g.,
and
support an optional suffix on the argument which changes the
interpretation of the argument.
Supported suffixes are:
Causes no modification.
(Optional)
Kilo; multiply the argument by 1024
Mega; multiply the argument by 1048576
Giga; multiply the argument by 1073741824
If
receives a
(see the
argument of
or
signal whilst a transfer is in progress, the current transfer rate
statistics will be written to the standard error output, in the
same format as the standard completion message.
In addition to standard commands, this version of
supports an auto-fetch feature.
on the command line.
The following formats are valid syntax for an auto-fetch element:
format.
If
contains a glob character and globbing is enabled,
(see
then the equivalent of
is performed.
If the directory component of
contains no globbing characters,
it is stored locally with the name basename (see
of
in the current directory.
Otherwise, the full remote name is used as the local name,
relative to the local root directory.
An
URL, retrieved using the
protocol if
isn't defined.
Otherwise, transfer the URL using
via the proxy defined in
If
isn't defined and
is given, login as
In this case, use
if supplied, otherwise prompt the user for one.
If a suffix of
or
is supplied, then the transfer type will take place as
ascii or binary (respectively).
The default transfer type is binary.
In order to be compliant with
interprets the
part of an
auto-fetch URL as follows:
The
immediately after the
is interpreted as a separator before the
and not as part of the
itself.
The
is interpreted as a
list of name components.
For all but the last such component,
performs the equivalent of a
command.
For the last path component,
performs the equivalent of a
command.
Empty name components,
which result from
within the
or from an extra
at the beginning of the
will cause the equivalent of a
command without a directory name.
This is unlikely to be useful.
Any
codes
(per
within the path components are decoded, with
representing a character code in hexadecimal.
This decoding takes place after the
has been split into components,
but before each component is used in the equivalent of a
or
command.
Some often-used codes are
(which represents
and
(which represents
The above interpretation has the following consequences:
The path is interpreted relative to the
default login directory of the specified user or of the
user.
If the
directory is required, use a leading path of
If a user's home directory is required (and the remote server supports
the syntax), use a leading path of
For example, to retrieve
from
as the user
with the password
use
The exact
and
commands can be controlled by careful choice of
where to use
and where to use
(or
For example, the following URLs correspond to the
equivalents of the indicated commands:
You must have appropriate access permission for each of the
intermediate directories that is used in the equivalent of a
command.
An
URL, retrieved using the
protocol.
If
is defined, it is used as a URL to an
proxy server.
If
authorization is required to retrieve
and
(and optionally
is in the URL, use them for the first attempt to authenticate.
A local URL, copied from
on the local host.
Display information regarding
no file is retrieved for this auto-fetched element.
Supported values include:
Information about
The version of
Useful to provide when reporting problems.
Unless noted otherwise above, and
is not given, the file is stored in the current directory as the
of
Note that if a
redirect is received, the fetch is retried using the new target URL
supplied by the server, with a corresponding new
Using an explicit
is recommended, to avoid writing to unexpected file names.
If a classic format or an
URL format has a trailing
or an empty
component, then
will connect to the site and
to the directory given as the path, and leave the user in interactive
mode ready for further input.
This will not work if
is being used.
Direct
transfers use HTTP 1.1.
Proxied
and
transfers use HTTP 1.0.
If
is given, all auto-fetches that don't go via the
or
proxies will be restarted.
For
this is implemented by using
instead of
For
this is implemented by using the
directive.
If WWW or proxy WWW authentication is required, you will be prompted
to enter a username and password to authenticate with.
When specifying IPv6 numeric addresses in a URL, you need to
surround the address in square brackets.
E.g.:
This is because colons are used in IPv6 numeric address as well as
being the separator for the port number.
To abort a file transfer, use the terminal interrupt key
(usually Ctrl-C).
Sending transfers will be immediately halted.
Receiving transfers will be halted by sending an
protocol
command to the remote server, and discarding any further data received.
The speed at which this is accomplished depends upon the remote
server's support for
processing.
If the remote server does not support the
command, the prompt will not appear until the remote server has completed
sending the requested file.
If the terminal interrupt key sequence is used whilst
is awaiting a reply from the remote server for the ABOR processing,
then the connection will be closed.
This is different from the traditional behaviour (which ignores the
terminal interrupt during this phase), but is considered more useful.
Files specified as arguments to
commands are processed according to the following rules.
If the file name
is specified, the
(for reading) or
(for writing) is used.
If the first character of the file name is
the
remainder of the argument is interpreted as a shell command.
then forks a shell, using
with the argument supplied, and reads (writes) from the stdout
(stdin).
If the shell command includes spaces, the argument
must be quoted; e.g.
A particularly
useful example of this mechanism is:
Failing the above checks, if
is enabled, local file names are expanded according to the rules
used in the
see the
command.
If the
command expects a single local file (e.g.
only the first filename generated by the "globbing" operation is used.
For
commands and
commands with unspecified local file names, the local filename is
the remote filename, which may be altered by a
or
setting.
The resulting filename may then be altered if
is on.
For
commands and
commands with unspecified remote file names, the remote filename is
the local filename, which may be altered by a
or
setting.
The resulting filename may then be altered by the remote server if
is on.
The
specification specifies many parameters which may affect a file transfer.
The
may be one of
(binary),
and
(for
and
mostly).
supports the ascii and image types of file transfer,
plus local byte size 8 for
mode transfers.
supports only the default values for the remaining
file transfer parameters:
and
The
file contains login and initialization information
used by the auto-login process.
It resides in the user's home directory,
unless overridden with the
option, or specified in the
environment variable.
The following tokens are recognized; they may be separated by spaces,
tabs, or new-lines:
Identify a remote machine
The auto-login process searches the
file for a
token that matches the remote machine specified on the
command line or as an
command argument.
Once a match is made, the subsequent
tokens are processed,
stopping when the end of file is reached or another
or a
token is encountered.
This is the same as
except that
matches any name.
There can be only one
token, and it must be after all
tokens.
This is normally used as:
thereby giving the user an automatic anonymous
login to
machines not specified in
This can be overridden
by using the
flag to disable auto-login.
Identify a user on the remote machine.
If this token is present, the auto-login process will initiate
a login using the specified
Supply a password.
If this token is present, the auto-login process will supply the
specified string if the remote server requires a password as part
of the login process.
Note that if this token is present in the
file for any user other
than
will abort the auto-login process if the
is readable by
anyone besides the user.
Supply an additional account password.
If this token is present, the auto-login process will supply the
specified string if the remote server requires an additional
account password, or the auto-login process will initiate an
command if it does not.
Define a macro.
This token functions like the
command functions.
A macro is defined with the specified name; its contents begin with the
next
line and continue until a blank line (consecutive new-line
characters) is encountered.
Like the other tokens in the
file, a
is applicable only to the
definition preceding it.
A
entry cannot be utilized by multiple
definitions; rather, it must be defined following each
it is intended to be used with.
If a macro named
is defined, it is automatically executed as the last step in the
auto-login process.
For example,
default
macdef init
epsv4 off
followed by a blank line.
supports interactive command line editing, via the
library.
It is enabled with the
command, and is enabled by default if input is from a tty.
Previous lines can be recalled and edited with the arrow keys,
and other GNU Emacs-style editing keys may be used as well.
The
library is configured with a
file - refer to
for more information.
An extra key binding is available to
to provide context sensitive command and filename completion
(including remote file completion).
To use this, bind a key to the
command
By default, this is bound to the TAB key.
By default,
displays a command line prompt of
to the user.
This can be changed with the
command.
A prompt can be displayed on the right side of the screen (after the
command input) with the
command.
The following formatting sequences are replaced by the given
information:
The current remote working directory.
The trailing component of the current remote working directory, or
trailing components if a digit
is given.
If
begins with
the number of skipped components precede the trailing component(s) in
the format
(for
or
(for
The remote host name.
The remote host name, up to the first
The remote user name.
A single
uses the following environment variables.
Password to send in an anonymous
transfer.
Defaults to
Overrides the default operation mode.
Support values are:
active mode
only
automatic determination of passive or active (this is the default)
gate-ftp mode
passive mode
only
Command-line prompt to use.
Defaults to
Refer to
for more information.
Command-line right side prompt to use.
Defaults to
Refer to
for more information.
Host to use as gate-ftp server when
is enabled.
Port to use when connecting to gate-ftp server when
is enabled.
Default is port returned by a
lookup of
The value to send for the
User-Agent
header.
For default location of a
file, if one exists.
An alternate location of the
file.
Used by various commands to display files.
Defaults to
if empty or not set.
For default shell.
URL of
proxy to use when making
URL requests
(if not defined, use the standard
protocol).
See
for further notes about proxy use.
URL of
proxy to use when making
URL requests.
If proxy authentication is required and there is a username and
password in this URL, they will automatically be used in the first
attempt to authenticate to the proxy.
If
URL characters are required in the username or password
(for example
or
encode them with
encoding.
Note that the use of a username and password in
and
may be incompatible with other programs that use it
(such as
this is not used for interactive sessions, only for command-line
fetches.
A space or comma separated list of hosts (or domains) for which
proxying is not to be used.
Each entry may have an optional trailing ":port", which restricts
the matching to connections to that port.
Some firewall configurations do not allow
to use extended passive mode.
If you find that even a simple
appears to hang after printing a message such as this:
then you will need to disable extended passive mode with
See the above section
for an example of how to make this automatic.
attempts to be compliant with:
The
command appeared in
Various features such as command line editing, context sensitive
command and file completion, dynamic progress bar, automatic
fetching of files and URLs, modification time preservation,
transfer rate throttling, configurable command line prompt,
and other enhancements over the standard
were implemented in
and later releases
by
(but may not be present in all non-NetBSD versions of this program, depending
if the operating system supports IPv6 in a similar manner to KAME).
Correct execution of many commands depends upon proper behavior
by the remote server.
An error in the treatment of carriage returns
in the
ascii-mode transfer code
has been corrected.
This correction may result in incorrect transfers of binary files
to and from
servers using the ascii type.
Avoid this problem by using the binary image type.
assumes that all IPv4 mapped addresses
IPv6 addresses with a form like
indicate IPv4 destinations which can be handled by
sockets.
However, in certain IPv6 network configurations, this assumption is not true.
In such an environment, IPv4 mapped addresses must be passed to
sockets directly.
For example, if your site uses a SIIT translator for IPv6-to-IPv4 translation,
is unable to support your configuration.
Optional password to be used if ZIP archive is encrypted.  Decryption
may not be supported at some sites.  See DESCRIPTION for more details.
Optional input archive file specification. See DESCRIPTION for details.
without a file argument acts as a filter; that is, it assumes that a
standard input, and it extracts the first member from the archive to stdout.
When stdin comes from a tty device,
assumes that this cannot be a stream of (binary) compressed data and
shows a short help text, instead.
If there is a file argument, then input is read from the specified file
instead of from stdin.
A password for encrypted zip files can be specified
on the command line (preceding the file name, if any) by prefixing the
password with a dash.  Note that this constitutes a security risk on many
systems; currently running processes are often visible via simple commands
If the first entry of the zip file is encrypted and
no password is specified on the command line, then the user is prompted for
a password and the password is not echoed on the console.
The following section includes an example illustrating this usage in the
case of disk backups to tape.
funzip test.zip | more
will be reported on standard error):
(where, for example, nrst0 is a SCSI tape drive).
to prompt for password, the terminal may sometimes be reset to a non-echo
mode.  This is apparently due to a race condition between the two programs;
There is presently no way to extract any member but the first from a ZIP
archive.  This would be useful in the case where a ZIP archive is included
within another archive.  In the case where the first member is a directory,
itself (future release).
The Info-ZIP home page is currently at
or
Mark Adler (Info-ZIP)
open
IDs of processes running on the local system that have one
or more named files open. For block special devices, all processes
using any file on that device are listed.
about the named files indicating how the file is
being used.
Any output for processes running on remote systems that have a named
file open is unspecified.
The following options shall be supported:
The file is treated as a mount point and the utility shall report
on any files open in the file system.
The report shall be only for the named files.
The user name, in parentheses, associated with each process ID written
to standard output shall be written to standard
error.
The following operand shall be supported:
A pathname on which the file or file system is to be reported.
Not used.
The user database.
The following environment variables shall affect the execution of
Provide a default value for the internationalization variables that
are unset or null. (See the Base Definitions volume of
for
the precedence of internationalization variables used to determine
the values of locale categories.)
If set to a non-empty string value, override the values of all the
other internationalization variables.
Determine the locale for the interpretation of sequences of bytes
of text data as characters (for example, single-byte as
opposed to multi-byte characters in arguments).
Determine the locale that should be used to affect the format and
contents of diagnostic messages written to standard
error.
Default.
using each file given as an operand to standard output in
the following format:

error.
error:
The pathname of each named file is written followed immediately by
a colon.
shall be written to standard error if the process is
shall be written to standard error if the process is using
the file as its root directory. Implementations may write other alphabetic
characters to indicate other uses of files.
of the file shall be followed immediately by the user
name, in parentheses, corresponding to the process' real user ID.
If the user name cannot be resolved from the process' real user
ID, the process' real user ID shall be written instead of the user
name.
When standard output and standard error are directed to the same file,
the output shall be interleaved so that the filename
appears at the start of each line, followed by the process ID and
option is specified, the user name or user ID for each process using
that file shall be written.
A <newline> shall be written to standard error after the last output
None.
None.
The following exit values shall be returned:
Successful completion.
>0
An error occurred.
Default.
None.
The command:

writes to standard output the process IDs of processes that are using
the current directory and writes to standard error an
indication of how those processes are using the directory and the
user names associated with the processes that are using the
current directory.
None.
None.
Portions of this text are reprinted and reproduced in electronic form
from IEEE Std 1003.1, 2003 Edition, Standard for Information Technology
-- Portable Operating System Interface (POSIX), The Open Group Base
Specifications Issue 6, Copyright (C) 2001-2003 by the Institute of
Electrical and Electronics Engineers, Inc and The Open Group. In the
event of any discrepancy between this version and the original IEEE and
The Open Group Standard, the original IEEE and The Open Group Standard
is the referee document. The original Standard can be obtained online at
Use fwkdp to act as a proxy for the kernel debugging KDP protocol over FireWire. It will also accept kernel core dump images transmitted over FireWire. Additionally, fwkdp can be used to set the boot-args necessary for a target machine which is to be debugged.
As a complete technology, FireWireKDP redirects the kernel debugging KDP protocol over FireWire. It enables live LLDB debugging of a trapped kernel over a FireWire cable, just as you would over Ethernet.  It provides the following advantages over remote Ethernet kernel debugging:
Available sooner in the kernel's startup.
Available until right when the cpu is powered down at sleep and almost as soon as the cpu is powered when waking.
No IP network configuration is required.
FireWireKDP also enables Remote Kernel Core Dumps over FireWire. This allows you to debug a static kernel at a later time without the need to be connected at the time of debug. To enable kernel core dumps, see section "CORE DUMPS". For more info on debugging with Kernel Core Dumps, please see: Technical Note TN2118: Debugging With Kernel Core Dumps.
FireWireKDP works in two parts: kernel software on the target side (machine to be debugged) and user-space software on the side of the host. Now, the target side software is integrated into the OS. This means that AppleFireWireKDP.kext is no longer necessary. See the installation instructions below.
Sets the nvram boot-args on the current machine to
is not passed, the tool will prompt the user as to which boot-args are to be set.
Use proxy mode only.
Use core dump receive mode only.
Verbose mode.
Sets the nvram boot-args on the current machine to "debug=0x146" which disables kprintf logging. This flag should only be used on the target machine (which is contrary to typical usage cases, when this tool is used on the host).
Deletes the boot-args variable from nvram. This flag should only be used on the target machine (which is contrary to typical usage cases, when this tool is used on the host).
Turns off interactive mode.
Automatically restarts the machine only after the nvram has been modified by this tool.
Displays usage info for fwkdp.
FireWireKDP doesn't interfere with the loading of the normal FireWire stack - it only touches the FireWire hardware when the kernel debugger is invoked, either by a panic, NMI, trap, or similar.
Furthermore, FireWireKDP is designed to work cooperatively with FireWireKPrintf. To use both you must use a combination of boot-args such as "debug=0x14e kdp_match_name=firewire".
To use FireWireKDP on a non-built-in FireWire interface (e.g. when using a Thunderbolt to FireWire adapter) add fwkdp=0x8000 to your boot-args.
Connect two Macs via FireWire and follow the steps below.
On the target (machine to be debugged):
Use fwkdp to set the kernel boot arguments to enable live debugging:
If using FireWireKDP with FireWireKPrintf try:
Reboot the target.
Break into debug mode as you would with Ethernet.  (NMI button, panic, debugger traps, etc.)
On the debugger machine:
Run fwkdp:
Run LLDB with the target operating system's symbol file.
See the Apple Development Kits webpage for the proper "Kernel Debug Kit" which will contain the proper "kernel.development" or "kernel.debug" "symbol file. See step 6 for more info.
Within LLDB, allow script loading to import the appropriate kernel macros (commonly found along with symbolic mach_kernel).
Within LLDB, attach using kdp-remote.
The connection should be established. Use lldb as you would over Ethernet.
To capture kernel core dumps, set the proper bits of the boot-args' debug variable and kdp_match_name equal to "firewire". In addition, an IP address for the receiving computer is also required, although it's meaningless over FireWire.
On the target machine, set the boot-args and restart.
Connect the machine to be debugged to a second Mac with a FireWire cable. Run "fwkdp" from a Terminal window on the second Mac; it will wait for the target to transmit it's core after it drops to the debugger (panic, NMI, etc.). For more info on the debugging with Kernel Core Dumps, please see Technical Note TN2118: Debugging With Kernel Core Dumps.
Post-Panic Hot-Plugs
64-bit Debugging
Other FireWire Devices
Second FireWire Interface
The available options are as follows:
Open log file with Console.app. Only valid with
Create a new log file, rather than append. Only valid with
Prefix logger machine's ID to each log.
Do not publish FireWire unit directory keys.
Use a single window even if multiple loggers are present.
Sets the host's psuedo address space queue buffer to
in bytes. Increasing this value may help avoid potential packet loss. The default buffer size is 204,800 bytes.
Sets the log file path, if in use, to
given as a path to a file. The tilde character is not allowed.
Sets the nvram boot-args on the current machine to
is not passed, the tool will prompt the user as to which boot-args are to be set.
Sets the nvram boot-args on the current machine to "debug=0x14e io=0x880". This flag should only be used on the target machine (which is contrary to typical usage cases, when this tool is used on the host).
Sets the nvram boot-args on the current machine to "debug=0x146" which disables kprintf logging. This flag should only be used on the target machine (which is contrary to typical usage cases, when this tool is used on the host).
Deletes the boot-args variable from nvram. This flag should only be used on the target machine (which is contrary to typical usage cases, when this tool is used on the host).
Turns off interactive mode.
Automatically restarts the machine only after the nvram has been modified by this tool.
Displays usage info for fwkpfv.
Unlike in the past, Mac OS X 10.5 has integrated FireWireKPrintf functionality, so it is not necessary to install a separate kext to enable kprintf logging over FireWire.
While the symbol for kprintf() is available at all times, the calls are essentially ignored unless activated with a boot argument (see below).
While the new FireWireKPrintf is integrated with the normal FireWire stack, once the machine begins logging kprintfs via FireWire, normal FireWire services will stop until the machine is restarted. Once in logging mode, all typical FireWire services (like FireWire hard disk access) will be unavailable. It is expected that any devices connected before logging will be forcefully removed.  If you need to log while also using the FireWire stack, please use FireLog (see the FireWireSDK).
The new integrated FireWireKPrintf cannot be used while the old AppleFireWireKPrintf.kext is installed. Remove it to use the integrated version.
The new viewer will be able to capture kprintf logs from the old-style AppleFireWireKPrintf.kext, however, the old-style viewer will not work with the integrated FireWireKPrintf services.
To use the FireWireKPrintf, two machines must be setup as such:
On the Target machine (to be debugged):
Boot the Mac from the partition you wish to use.
Set kernel boot arguments to enable kernel printfs:
Restart the target Mac.
Disconnect any FireWire device.
On the debugger machine with Mac OS X and Developer Tools installed, run from Terminal.app:
Connect the two machines together using a FireWire cable.
After 5 seconds, you should see output in the viewer and kprintf logging is flowing. Note: At this point, normal FireWire services will cease to exist on the target until the machine is restarted.
FireWireKPrintf implements a few options that can be set as a "boot-arg," much like the "debug" variable. The "fwkpf" variable specifies the timestamp format (calculated on the target, before transmission), timestamp padding, verbose kprintf printing, and synchronous mode. To set the "fwkpf" variable, choose a timestamp unit and add any of the "additive" options. The default timestamp is 0x4 (microseconds).
Timestamp Formats (not additive):
Converted FW Cycle Time Units (c) - Classic time format shown as "Seconds.Microseconds". The Second unit rolls over every 128 seconds. Driven by the FireWire clock.
Absolute Time Units (a) - "Absolute" time units derived directly from the kernel's uptime clock.
FireWire Time Units (w) - Shown as "Seconds:Cycles:Offset". Driven by the FireWire clock. Seconds rollover every 128 seconds. 8000 cycles per second. 3072 offset counts per cycle. Equivalent to FireBug's time format.
Nanoseconds Time Units (n) - The kernel's uptime clock converted to nanoseconds.
Microseconds Time Units (u) - The kernel's uptime clock converted to microseconds.
Milliseconds Time Units (m) - The kernel's uptime clock converted to milliseconds.
Seconds Time Units (s) - Shown as "Seconds:Milliseconds:Microseconds". Converted from kernel's uptime clock.
Day Time Units (d) - "Days:Hours:Minutes:Seconds:Milliseconds:Microseconds". Converted from kernel's uptime clock.
No Time Units (-) - No time units, displayed as "-".
Additive Options:
Open log file with Console.app. Only valid with "-o".
Create a new log file, rather than append. Only valid with "-o".
Prefix logger machine's ID to each log.
For example, if you wish to display microsecond time units with padding, synchronous mode enabled, and verbose printing disabled, the target's boot-args would be as follows: "debug=0x14e fwkpf=0x114". On the target, run the following in Terminal.app:
% sudo nvram boot-args="debug=0x14e fwkpf=0x114"
If not defined, the "fwkpf" variable defaults to "0x004."
Once the viewer is running, he target machine is logging, and both machines are connected with a FireWire cable, you will see output similar to the following:
signifies viewer tool start correctly. If multiple interfaces are present on the debugger machine, it will give an interface count.
signifies the AppleFireWireKPrintf kext has (re)initialized the FireWire hardware for use in a FireWIreKPrintf manner.
displays the time format declared in the target's boot-args. See the "Options" section of this document to select a different time format.
displays the time at which the kprintf call was logged. Prefixed with the letter that corresponds to the time formats listed above. The format of this time log is displayed upon start and can be changed in the target's boot-args. See above.
the const char * string from the kprintf() call; the log. (This is a normal log.)
If you are seeing the following symptoms:
There is no output from the fwkpfv tool on the second machine:
Make sure the two machines are connected with a good FireWire cable.
Run "nvram boot-args" and verify that the boot-args are set correctly.
Be sure you're using the new fwkpfv utility, version 2.1 or newer.
The machine hangs at boot:
Sometimes the console will hang at boot when there is a high volume of logging to screen. Try booting in non-verbose mode or limiting the volume of logging. Remove the "-v" from your machine's boot-args. Or remove "io=0x80".
To disable the FireWireKPrintf, delete the target machine's boot-args. Within Terminal.app run the following:
% sudo nvram -d boot-args
     OR set the boot-args variable to your previous setting.
Restart to target Mac.
FireWireKPrintf tries to catch kprintf calls as soon as its start() routine is called. All kprintf calls after this point will be saved until the FireWire hardware has been initialized completely (which is also early in the boot process), however, the timestamps for these very early logs will reference the time they were sent via FireWire, not when kprintf() was called. All timestamps can be assumed accurate after the log from FireWireKPrintf that reads something similar to:
Similar to very early boot logs, kprintf() calls by the kernel very early upon wake will be saved and sent after the FireWire hardware has had time to initialize. Likewise, the timestamps for these early logs may reflect a yet-to-be-initialized cpu time. These timestamps will be extremely large and clearly recognizable.
With exception to the two cases above (very early boot and very early sleep) when the FireWire hardware cannot be initialized without stopping kernel progression, all FireWireKPrintf logs are sent synchronously. This means that if the log is sent successfully, it is guaranteed to be on the wire before the call returns. If the log cannot be sent, an error will be written to system.log.
Some applications, such as the Startup Disk preference pane, set the boot-args themselves. Therefore, it is always best to boot to the partition you wish to debug, set the boot-args, and then restart.
When a viewer Mac is connected to a logging (target) Mac, all normal FireWire services stop, including FireWire disk access. It may take a few moments for the disk to disappear on the logging Mac, but once you have connected a viewer Mac, it will be impossible to use a FireWire hard disk without restarting.
The following log is often shown when you first connect:
It is a normal log from a different part of the system and should not be of any concern. 
FireWireKPrintf works on both Intel and PowerPC based Macs. The integrated FireWireKPrintf and fwkpfv is new for Leopard and is not included in any previous OS release.
To avoid conflicts it is best not to have other FireWire devices plugged into the host or target machines while using FireWireKPrintf. Having more than 2 nodes total (i.e. the two CPUs) may cause unexpected results.
FireWireKPrintf is compatible with FireWireKDP. To use both, it is recommended to set the boot-args using the following command:
% sudo nvram boot-args="debug=0x14e kdp_match_name=firewire"
Of course, you may modify or add boot-args to suit your needs (see note above).
Remember, you can clear the scrollback buffer of Terminal.app by selecting "Clear Scrollback" (or Cmd-K) from the "Scrollback" menu.
The "built-in" kprintf output is target machine specific. This is due to special casing of hardware and other states. It may also vary with operating system version and even kext versions. Remember, a developer can change their kprintf() calls at any time.
FireLog and FireWireKPrintf are different, both in theory and practice. FireLog is a high speed logging system which requires a framework. Most importantly, FireLog uses a buffering system (in a pull manner) to prevent the loss of logs during high logging volume or low processing time. Conversely, FireWireKPrintf employs a push method of sending each log onto the wire as soon as it is available. Furthermore, FireWireKPrintf is available sooner in the kernel's startup. FireLog is an excellent solution if you need high speed logging.
is installed as part of the Mac OS X Developer Tools.
Copyright (C) 2004, 2005 Free Software Foundation, Inc.

This file is part of the gdiffmk utility, which is part of groff.
Written by Mike Bianchi <MBianchi@Foveal.com <mailto:MBianchi@Foveal.com>>

Permission is granted to make and distribute verbatim copies of
this manual provided the copyright notice and this permission notice
are preserved on all copies.

Permission is granted to copy and distribute modified versions of this
manual under the conditions for verbatim copying, provided that the
entire resulting derived work is distributed under the terms of a
permission notice identical to this one.

Permission is granted to copy and distribute translations of this
manual into another language, under the above conditions for modified
versions, except that this permission notice may be included in
translations approved by the Free Software Foundation instead of in
the original English.
]
]
compares two
or
documents,
and
and creates an output which is
with added `margin character' (.mc) commands that indicate the differences.
If the
filename is present,
the output is written there.
If it is
or absent the output is written to the standard output.
If the
or
argument is
the standard input is read for that input.
Clearly both cannot be
Note that the output is not necessarily compatible with all macro packages
and all preprocessors.
See the
section below.
Use the
for source lines not in
but present in
Default:
By default, the deleted texts marked by the
option end
with an added troff break command,
to ensure that the deletions are marked properly.
This is the only way to guarantee that deletions and small
changes get flagged.
This option directs the program not to insert these breaks; it makes no
sense to use it without
Use the
for changed source lines.
Default:
Use the
for deleted source lines.
Default:
Show the deleted portions from changed and deleted text.
Default delimiting marks:
Change the delimiting marks for the
option.
It makes no sense to use this option without
Use the
command to perform the comparison of
and
In particular,
should accept the GNU
option.
Default:
All the following arguments are treated as file names,
even if they begin with
Print a usage message on standard error output and exit.
Print version information on the standard output and exit.
The output is not necessarily compatible with all macro packages
and all preprocessors.
A workaround that is often successful against preprocessor problems
is to run
on the output of all the preprocessors instead of the input source.
relies on the
option of GNU
to make a merged `#ifdef' output format.
It hasn't been tested whether other versions of
do support this option.
See also the
option.
Report bugs to bug-groff@gnu.org.
Include a complete, self-contained example that will allow the bug to
be reproduced, and say which version of
you are using.
This document was written and is maintained by
This document is distributed under the terms of the FDL (GNU Free
Documentation License) version 1.1 or later.
You should have received a copy of the FDL on your system, it is also
available on-line at the
is part of the
GNU free software project.
All parts of the
are protected by GNU copyleft licenses.
The software files are distributed under the terms of the GNU General
Public License (GPL), while the documentation files mostly use the GNU
Free Documentation License (FDL).
the terms of the GNU General Public License as published by the Free
Software Foundation; either version 2, or (at your option) any later
version.
is distributed in the hope that it will be useful, but WITHOUT ANY
WARRANTY; without even the implied warranty of MERCHANTABILITY or
FITNESS FOR A PARTICULAR PURPOSE.
See the GNU General Public License for more details.
You should have received a copy of the GNU General Public License along
with groff; see the file COPYING.
If not, write to the Free Software
Foundation, 51 Franklin St - Fifth Floor, Boston, MA 02110-1301, USA.
For more information about it, you can use its
is a tool that generates bridging metadata information for a given framework or set of headers. The Objective-C bridges supported in Mac OS X, such as MacRuby (Ruby) and PyObjC (Python), read this information at runtime.
As of Mac OS 10.7,
uses an improved parser, based on
This means the generated
files should be more correct and complete, and the true parsing allows the
automatic extraction of metadata from existing
information supported by the compiler.
File generation time should also be faster.
Metadata files describe the parts of an Objective-C framework that the bridges cannot automatically handle. These are primarily the ANSI C elements of the framework -- functions, constants, enumerations, and so on -- but also include special cases such as functions or methods that accept pointer-like arguments. These special cases must be manually specified in separate files called exceptions. The
tool can then read in the exceptions file when it generates the framework metadata.
Certain elements, such as inline functions, cannot be described in the metadata files. It is therefore required to generate a dynamic library in order to make the bridges use them. The gen_bridge_metadata tool can take care of that for you. 
You should install metadata files in one of three filesystem locations. For example, for a framework named MyFramework that is installed as
you can install the
and
files in one of the following possible locations, in order of priority:
The
tool accepts the following command-line options:
Generates metadata for the given
This argument can accept both the name of a framework of an absolute path to a framework. When passing a framework name, the program will try to locate the framework in one of the standard framework locations. 
Generates metadata based on the private headers of the given frameworks. This argument must be used with the 
argument.
Selects the metadata format that will be generated. Possible values are:
The final metadata format. This is the default value.
The dynamic library format. This is only required if you want to support inline functions. In order to use this format you need to pass a value for the
argument.
This will generate an exception template. Please consult 
for more details about the exception format. Once your exception file is finished you can pass it to the
argument in order to generate the final metadata.
Considers the given exception file when generating the final metadata format. The given exception file must conform to a certain format, described in
Exception files are manually written, but you can generate a template by passing 
to the generator.
(This option is included for backwards compatibility, as this is now the default behavior.)
Writes both 32 and 64-bit annotations to the final metadata format and compiles
the dylib both 32 and 64-bit (if a framework is specified and it only contains
either 32 or 64-bit architectures, then the final metadata format and dylib
will be created only for that architecture).
In order to use this option you need to run the generator on a 64-bit machine.
The generation will take a bit more than twice the time, as both 32 and 64-bit
will need to be processed and merged into one.
Do not write the 32-bit annotations to the final metadata format or compile
the dylib 32-bit.
May not be used with
Do not write the 64-bit annotations to the final metadata format or compile
the dylib 64-bit.
May not be used with
Provides custom flags that will be passed to the C compiler. The generator compiles and executes several C and Objective-C programs during the generation of the final metadata format. Some flags are determined by default, but you might want to provide your own flags according to the piece of code you want to generate metadata for (for example, a framework part of a umbrella framework). 
Provides custom flags that will be passed to the C compiler, when generating 64-bit annotations. By default the same flags are passed to the C compiler when generating both 32-bit and 64-bit annotations.
Writes the output to the given file. This argument is mandatory when generating the 
format. For other formats, by default the output is redirected to the standard output.
Prints a summary of the options.
Turns on debugging messages. You probably don't want to enable this option, unless you are going to debug the metadata generator.
Shows the version of the program. The version is also marked in generated metadata files, as the
attribute of the
top-level element.
This generates bridge support metadata for a custom framework:
If the custom framework has inline functions and you want to be able to call them, here is how you can generate a
file:
It is also possible to generate bridge support metadata for a standalone C library (here, libcurl):
The
utility merges the text NLS input files
into a formatted message catalog file
The file
will be created if it does not already exist.  If
does exist, its messages will be included in the new
If set and message numbers collide, the new message text defined in
will replace the old message text currently contained in
The format of a message text source file is defined below.  Note that
the fields of a message text source line are separated by a single space
character: any other space characters are considered to be part of the
field contents.
This line specifies the set identifier of the following messages until
the next
or end-of-file appears.  The argument
is the set identifier which is defined as a number in the range
[1, (NL_SETMAX)].  Set identifiers must occur in ascending order within
a single source file, but need not be contiguous.  Any string following
a space following the set identifier is treated as a comment.  If no
directive  is specified in a given source file, all messages will
be located in the default message set NL_SETD.
This line deletes messages from set
from a message catalog.  The
specifies a set number.  Any string following a space following the set
number is treated as a comment.
A line beginning with
followed by a space is treated as a comment.
A message line consists of a message identifier
in the range [1, (NL_MSGMAX)].  The
is stored in the message catalog with the set identifier specified by
the last
directive, and the message identifier
If the
is empty, and there is a space character following the message identifier,
an empty string is stored in the message catalog.  If the
is empty, and if there is no space character following the message
identifier, then the existing message in the current set with the
specified message identifier is deleted from the catalog.  Message
identifiers must be in ascending order within a single set, but
need not be contiguous.  The
length must be in the range [0, (NL_TEXTMAX)].
This line specifies an optional quote character
which can be used to surround
so that trailing space or empty messages are visible in message
source files.  By default, or if an empty
directive is specified, no quoting of
will be recognized.
Empty lines in message source files are ignored.  The effect of lines
beginning with any character other than those described above is
undefined.
Text strings can contain the following special characters and escape
sequences.  In addition, if a quote character is defined, it may be
escaped as well to embed a literal quote character.
line feed
horizontal tab
vertical tab
backspace
carriage return
form feed
backslash
octal number in the range [000, 377]
A backslash character immediately before the end of the line in a file
is used to continue the line onto the next line, e.g.:
If the character following the backslash is not one of those specified,
the backslash is ignored.
The
utility is compliant with the
standard.
This manual page was originally written by
and later revised by
A message catalog file created from a blank input file cannot be revised;
it must be deleted and recreated.
The
utility prints the value of a
or
path or system configuration variable to the standard output.
If the specified variable is undefined, the string
is output.
The first form of the command, with two mandatory
arguments, retrieves file- and file system-specific
configuration variables using
The second form, with a single argument, retrieves system
configuration variables using
and
depending on the type of variable.
As an extension, the second form can also be used to query static limits from
All
and
variables use the same name as the manifest constants defined in
the relevant standard C-language bindings, including any leading
underscore or prefix.
That is to say,
might be
or
as opposed to the
names
or
Variables retrieved from
have the leading
stripped off; thus,
is queried by a
of
The
option specifies a
programming environment under which the values are to be queried.
This option currently does nothing, but may in the future be used
to select between 32-bit and 64-bit execution environments on platforms
which support both.
Specifying an environment which is not supported on the current execution
platform gives undefined results.
The standard programming environments are as follows:
Exactly 32-bit integer, long, pointer, and file offset.
None.
Exactly 32-bit integer, long, and pointer; at least 64-bit file offset.
Exactly 32-bit integer; exactly 64-bit long, pointer, and file offset.
At least 32-bit integer; at least 64-bit long, pointer, and file offset.
None.
The command:
returns a newline-separated list of environments in which the width
of certain fundamental types is no greater than the width of the native
C type
At present, all programming environments supported by
have this property.
Several of the
variables provide information on the necessary compiler and linker flags
to use the standard programming environments described above.
Many of these values are also available through the
mechanism.
The command:
will display the system default setting for the
environment variable.
The command:
will display the maximum length of a filename in the
directory.
The command:
will display the maximum value of the C type
in the
programming environment,
if the system supports that environment.
Use of a
or
which is completely unrecognized is considered an error,
causing a diagnostic message to be written to standard error.
One
which is known but merely undefined does not result in an error
indication.
The
utility recognizes all of the variables defined for
including those which are not currently implemented.
The
utility is expected to be compliant with
The
utility first appeared in
The
utility is used to break up options in command lines for easy parsing by
shell procedures, and to check for legal options.
is a string of recognized option letters (see
if a letter is followed by a colon, the option
is expected to have an argument which may or may not be
separated from it by white space.
The special option
is used to delimit the end of the options.
The
utility will place
in the arguments at the end of the options,
or recognize it if used explicitly.
The shell arguments
preceded by a
and in its own shell argument;
each option argument is also in its own shell argument.
The following code fragment shows how one might process the arguments
for a command that can take the options
and
and the option
which requires an argument.
# the arguments differently from what the set command below does.
if [ $? != 0 ]
then
	echo 'Usage: ...'
	exit 2
fi
# You cannot use the set command with a backquoted getopt directly,
# since the exit code from getopt would be shadowed by those of set,
# which is zero by definition.
for i
do
	case "$i"
	in
			echo flag $i set; sflags="${i#-}$sflags";
			shift;;
			echo oarg is "'"$2"'"; oarg="$2"; shift;
			shift;;
			shift; break;;
	esac
done
echo single-char flags: "'"$sflags"'"
echo oarg is "'"$oarg"'"
This code will accept any of the following as equivalent:
The
utility prints an error message on the standard error output and exits with
status > 0 when it encounters an option letter not included in
Written by
working from a Bell Labs manual page.
Behavior believed identical to the Bell version.
Example changed in
version 3.2 and 4.0.
Whatever
has.
Arguments containing white space or embedded shell metacharacters
generally will not survive intact;  this looks easy to fix but
isn't. People trying to fix
or the example in this manpage should check the history of this file
in
The error message for an invalid option is identified as coming
from
rather than from the shell procedure containing the invocation
of
this again is hard to fix.
The precise best way to use the
command to set the arguments without disrupting the value(s) of
shell options varies from one shell version to another.
Each shellscript has to carry complex code to parse arguments halfway
correcty (like the example presented here). A better getopt-like tool
would move much of the complexity into the tool and keep the client
shell scripts simpler.
[-nw] [-display display] [-q] [-v] [-l library] [-batch] [-f function] [-eval form] 
[-h hostname] [-p port] [-r remote-pathname] [[+line] file] ...
form
Removed as of gnuserv 3.x

Depending on your environment, it can be an X frame or a TTY frame.
One typical use for this is with a dialup connection to a machine on
which an emacs process is currently running.
Its use is deprecated. Try to get used to calling gnuclient directly.
handle all incoming and outgoing requests. It is not usually invoked
package and evaluating the Lisp form (gnuserv-start).
makes sense in this context. In addition it adds a few of its own. 
Options with long names can also be specified using a double
hyphen instead of a single one.
can attach to the current TTY. emacs will then open a new TTY frame.
The effect is similar to having started a new emacs on this TTY with
the ``-nw'' option. It currently only works if emacs is running on
the same machine as gnuclient. This is the default if the `DISPLAY'
environment variable is not set.
If this option is given or the `DISPLAY' environment variable is set
then gnuclient will tell emacs to edit files in a frame on the
specified X device.
all of the files on the command line have been finished with (their
buffers killed) by the emacs process, and all the forms have been
evaluated.
specified files to be viewed instead of edited.
Tell Emacs to load the specified library.
Tell Emacs not to open any frames. Just load libraries and evaluate
lisp code.  If no files to execute, functions to call or forms to eval 
are given using the
or
options, then forms to eval are read from STDIN.
Make Emacs execute the lisp function.
Make Emacs execute the lisp form.
Used only with Internet-domain sockets, this option specifies the host
specified then the value of the environment variable GNU_HOST is used
if set. If no hostname is specified, and the GNU_HOST variable is not
authentication is used or the GNU_SECURE variable has been specified
and points at a file listing all trusted hosts. (See SECURITY below.)

Note that an internet address may be specified instead of a hostname
which can speed up connections to the server by quite a bit,
especially if the client machine is running YP.

the connection to the server should use a Unix-domain socket (if
supported) rather than an Internet-domain socket.
Used only with Internet-domain sockets, this option specifies the
service port used to communicate between server and clients.  If this
option is not specified, then the value of the environment variable
GNU_PORT is used, if set, otherwise a service called ``gnuserv'' is
looked up in the services database.  Finally, if no other value can be
found for the port, then a default port is used which is usually 21490
+ uid.
it will have to be specified via one of the alternative methods.
Used only with Internet-domain sockets, the pathname argument may be
needed to inform emacs how to reach the root directory of a remote
given.  For example, if you were trying to edit a file on a client
machine called otter, whose root directory was accessible from the
taken from the environment variable GNU_NODE, if set, or the empty
string otherwise.
This is the path of the file to be edited.  If the file is a directory, then
the directory browsers dired or monkey are usually invoked instead.
The cursor is put at line number 'n' if specified.

Therefore, you should be able to start the server simply by evaluating
the emacs lisp form (gnuserv-start), or equivalently by typing
`M-x gnuserv-start'.

The behavior of this suite of program is mostly controlled on the lisp 
side in Emacs and its behavior can be customized to a large extent.
Type `M-x customize-group RET gnuserv RET' for easy access. More
documentation can be found in the file `gnuserv.el'

gnuclient -q -f mh-smail

More examples and sample wrapper scripts are provided in the


gnuserv.h. This is incompatible with both Unix-domain and
Internet-domain socket communication as described below. A file called
will cause the communication between server and client to fail until
the server is restarted.
communication and if deleted will cause communication between server
and client to fail.  Only the user running gnuserv will be able to
connect to the socket.
Internet-domain sockets are used to communicate between
INTERNET_DOMAIN_SOCKETS is defined at the top of gnuserv.h. Both
Internet-domain and Unix-domain sockets can be used at the same
time. If a hostname is specified via -h or via the GNU_HOST
internet domain socket. If not, a local connection is attempted via
either a unix-domain socket or SYSV IPC.
Using Internet-domain sockets, a more robust form of security is
needed that wasn't necessary with either Unix-domain sockets or SysV
IPC. Currently, two authentication protocols are supported to provide
this: MIT-MAGIC-COOKIE-1 (based on the X11 xauth(1) program) and a
simple host-based access control mechanism, hereafter called
GNUSERV-1. The GNUSERV-1 protocol is always available, whereas support
for MIT-MAGIC-COOKIE-1 may or may not have been enabled (via a #define
at the top of gnuserv.h) at compile-time.
control at the machine level. By default no internet-domain socket is
environment, and it names a readable filename, then this file is
opened and assumed to be a list of hosts, one per line, from which the
server will allow requests. Connections from any other host will be
permitted to make connections via the internet socket unless its
hostname is explicitly specified in this file.  Note that a host may
be either a numeric IP address or a hostname, and that
user on an approved host may connect to your gnuserv and execute arbitrary
elisp (e.g., delete all your files).
If this file contains a lot of
hostnames then the server may take quite a time to start up.
When the MIT-MAGIC-COOKIE-1 protocol is enabled, an internet socket
any host, and will wait for a "magic cookie" (essentially, a password)
to be presented by the client. If the client doesn't present the
cookie, or if the cookie is wrong, the authentication of the client is
the GNUSERV-1 protocol; If the client is calling from a host listed in
the GNU_SECURE file, the connection will be accepted, otherwise it
will be rejected. 
defined for display 999 on the machine where it is running. If the
cookie is found, it will be stored for use as the authentication
cookie. These cookies are defined in an authorization file (usually
example, a machine "kali" which runs an emacs that invokes
up correctly.
kali% xauth list
GS65.SP.CS.CMU.EDU:0  MIT-MAGIC-COOKIE-1  11223344
KALI.FTM.CS.CMU.EDU:999  MIT-MAGIC-COOKIE-1  1234
In the above case, the authorization file defines two cookies. The
second one, defined for screen 999 on the server machine, is used for
gnuserv authentication. 
On the client machine's side, the authorization file must contain an
identical line, specifying the 
cookie. In other words, on a machine "foobar" which wishes to connect
to "kali,"  the `xauth list' output should contain the line:
KALI.FTM.CS.CMU.EDU:999  MIT-MAGIC-COOKIE-1  1234
For more information on authorization files, take a look at the
xauth(1X11) man page, or invoke xauth interactively (without any
arguments) and type "help" at the prompt. Remember that case in the
name of the authorization protocol (i.e.`MIT-MAGIC-COOKIE-1') 
significant!


Default X device to put edit frame.

(SYSV_IPC only)
(unix domain sockets only)
emacs customization file, see emacs(1).
xauth(1X11), Xsecurity(1X11), gnuserv.el
NULs occurring in result strings don't get passed back to gnudoit properly.
The
flag does not work, due to lack of necessary functionality in emacs.
Andy Norman (ange@hplb.hpl.hp.com), based heavily upon
18.52 distribution.  Various modifications from Bob Weiner (weiner@mot.com),
Darrell Kindred (dkindred@cmu.edu), Arup Mukherjee (arup@cmu.edu), Ben
Wing (ben@xemacs.org) and Hrvoje Niksic (hniksic@xemacs.org).
[-nw] [-display display] [-q] [-v] [-l library] [-batch] [-f function] [-eval form] 
[-h hostname] [-p port] [-r remote-pathname] [[+line] file] ...
form
Removed as of gnuserv 3.x

Depending on your environment, it can be an X frame or a TTY frame.
One typical use for this is with a dialup connection to a machine on
which an emacs process is currently running.
Its use is deprecated. Try to get used to calling gnuclient directly.
handle all incoming and outgoing requests. It is not usually invoked
package and evaluating the Lisp form (gnuserv-start).
makes sense in this context. In addition it adds a few of its own. 
Options with long names can also be specified using a double
hyphen instead of a single one.
can attach to the current TTY. emacs will then open a new TTY frame.
The effect is similar to having started a new emacs on this TTY with
the ``-nw'' option. It currently only works if emacs is running on
the same machine as gnuclient. This is the default if the `DISPLAY'
environment variable is not set.
If this option is given or the `DISPLAY' environment variable is set
then gnuclient will tell emacs to edit files in a frame on the
specified X device.
all of the files on the command line have been finished with (their
buffers killed) by the emacs process, and all the forms have been
evaluated.
specified files to be viewed instead of edited.
Tell Emacs to load the specified library.
Tell Emacs not to open any frames. Just load libraries and evaluate
lisp code.  If no files to execute, functions to call or forms to eval 
are given using the
or
options, then forms to eval are read from STDIN.
Make Emacs execute the lisp function.
Make Emacs execute the lisp form.
Used only with Internet-domain sockets, this option specifies the host
specified then the value of the environment variable GNU_HOST is used
if set. If no hostname is specified, and the GNU_HOST variable is not
authentication is used or the GNU_SECURE variable has been specified
and points at a file listing all trusted hosts. (See SECURITY below.)

Note that an internet address may be specified instead of a hostname
which can speed up connections to the server by quite a bit,
especially if the client machine is running YP.

the connection to the server should use a Unix-domain socket (if
supported) rather than an Internet-domain socket.
Used only with Internet-domain sockets, this option specifies the
service port used to communicate between server and clients.  If this
option is not specified, then the value of the environment variable
GNU_PORT is used, if set, otherwise a service called ``gnuserv'' is
looked up in the services database.  Finally, if no other value can be
found for the port, then a default port is used which is usually 21490
+ uid.
it will have to be specified via one of the alternative methods.
Used only with Internet-domain sockets, the pathname argument may be
needed to inform emacs how to reach the root directory of a remote
given.  For example, if you were trying to edit a file on a client
machine called otter, whose root directory was accessible from the
taken from the environment variable GNU_NODE, if set, or the empty
string otherwise.
This is the path of the file to be edited.  If the file is a directory, then
the directory browsers dired or monkey are usually invoked instead.
The cursor is put at line number 'n' if specified.

Therefore, you should be able to start the server simply by evaluating
the emacs lisp form (gnuserv-start), or equivalently by typing
`M-x gnuserv-start'.

The behavior of this suite of program is mostly controlled on the lisp 
side in Emacs and its behavior can be customized to a large extent.
Type `M-x customize-group RET gnuserv RET' for easy access. More
documentation can be found in the file `gnuserv.el'

gnuclient -q -f mh-smail

More examples and sample wrapper scripts are provided in the


gnuserv.h. This is incompatible with both Unix-domain and
Internet-domain socket communication as described below. A file called
will cause the communication between server and client to fail until
the server is restarted.
communication and if deleted will cause communication between server
and client to fail.  Only the user running gnuserv will be able to
connect to the socket.
Internet-domain sockets are used to communicate between
INTERNET_DOMAIN_SOCKETS is defined at the top of gnuserv.h. Both
Internet-domain and Unix-domain sockets can be used at the same
time. If a hostname is specified via -h or via the GNU_HOST
internet domain socket. If not, a local connection is attempted via
either a unix-domain socket or SYSV IPC.
Using Internet-domain sockets, a more robust form of security is
needed that wasn't necessary with either Unix-domain sockets or SysV
IPC. Currently, two authentication protocols are supported to provide
this: MIT-MAGIC-COOKIE-1 (based on the X11 xauth(1) program) and a
simple host-based access control mechanism, hereafter called
GNUSERV-1. The GNUSERV-1 protocol is always available, whereas support
for MIT-MAGIC-COOKIE-1 may or may not have been enabled (via a #define
at the top of gnuserv.h) at compile-time.
control at the machine level. By default no internet-domain socket is
environment, and it names a readable filename, then this file is
opened and assumed to be a list of hosts, one per line, from which the
server will allow requests. Connections from any other host will be
permitted to make connections via the internet socket unless its
hostname is explicitly specified in this file.  Note that a host may
be either a numeric IP address or a hostname, and that
user on an approved host may connect to your gnuserv and execute arbitrary
elisp (e.g., delete all your files).
If this file contains a lot of
hostnames then the server may take quite a time to start up.
When the MIT-MAGIC-COOKIE-1 protocol is enabled, an internet socket
any host, and will wait for a "magic cookie" (essentially, a password)
to be presented by the client. If the client doesn't present the
cookie, or if the cookie is wrong, the authentication of the client is
the GNUSERV-1 protocol; If the client is calling from a host listed in
the GNU_SECURE file, the connection will be accepted, otherwise it
will be rejected. 
defined for display 999 on the machine where it is running. If the
cookie is found, it will be stored for use as the authentication
cookie. These cookies are defined in an authorization file (usually
example, a machine "kali" which runs an emacs that invokes
up correctly.
kali% xauth list
GS65.SP.CS.CMU.EDU:0  MIT-MAGIC-COOKIE-1  11223344
KALI.FTM.CS.CMU.EDU:999  MIT-MAGIC-COOKIE-1  1234
In the above case, the authorization file defines two cookies. The
second one, defined for screen 999 on the server machine, is used for
gnuserv authentication. 
On the client machine's side, the authorization file must contain an
identical line, specifying the 
cookie. In other words, on a machine "foobar" which wishes to connect
to "kali,"  the `xauth list' output should contain the line:
KALI.FTM.CS.CMU.EDU:999  MIT-MAGIC-COOKIE-1  1234
For more information on authorization files, take a look at the
xauth(1X11) man page, or invoke xauth interactively (without any
arguments) and type "help" at the prompt. Remember that case in the
name of the authorization protocol (i.e.`MIT-MAGIC-COOKIE-1') 
significant!


Default X device to put edit frame.

(SYSV_IPC only)
(unix domain sockets only)
emacs customization file, see emacs(1).
xauth(1X11), Xsecurity(1X11), gnuserv.el
NULs occurring in result strings don't get passed back to gnudoit properly.
The
flag does not work, due to lack of necessary functionality in emacs.
Andy Norman (ange@hplb.hpl.hp.com), based heavily upon
18.52 distribution.  Various modifications from Bob Weiner (weiner@mot.com),
Darrell Kindred (dkindred@cmu.edu), Arup Mukherjee (arup@cmu.edu), Ben
Wing (ben@xemacs.org) and Hrvoje Niksic (hniksic@xemacs.org).
[-nw] [-display display] [-q] [-v] [-l library] [-batch] [-f function] [-eval form] 
[-h hostname] [-p port] [-r remote-pathname] [[+line] file] ...
form
Removed as of gnuserv 3.x

Depending on your environment, it can be an X frame or a TTY frame.
One typical use for this is with a dialup connection to a machine on
which an emacs process is currently running.
Its use is deprecated. Try to get used to calling gnuclient directly.
handle all incoming and outgoing requests. It is not usually invoked
package and evaluating the Lisp form (gnuserv-start).
makes sense in this context. In addition it adds a few of its own. 
Options with long names can also be specified using a double
hyphen instead of a single one.
can attach to the current TTY. emacs will then open a new TTY frame.
The effect is similar to having started a new emacs on this TTY with
the ``-nw'' option. It currently only works if emacs is running on
the same machine as gnuclient. This is the default if the `DISPLAY'
environment variable is not set.
If this option is given or the `DISPLAY' environment variable is set
then gnuclient will tell emacs to edit files in a frame on the
specified X device.
all of the files on the command line have been finished with (their
buffers killed) by the emacs process, and all the forms have been
evaluated.
specified files to be viewed instead of edited.
Tell Emacs to load the specified library.
Tell Emacs not to open any frames. Just load libraries and evaluate
lisp code.  If no files to execute, functions to call or forms to eval 
are given using the
or
options, then forms to eval are read from STDIN.
Make Emacs execute the lisp function.
Make Emacs execute the lisp form.
Used only with Internet-domain sockets, this option specifies the host
specified then the value of the environment variable GNU_HOST is used
if set. If no hostname is specified, and the GNU_HOST variable is not
authentication is used or the GNU_SECURE variable has been specified
and points at a file listing all trusted hosts. (See SECURITY below.)

Note that an internet address may be specified instead of a hostname
which can speed up connections to the server by quite a bit,
especially if the client machine is running YP.

the connection to the server should use a Unix-domain socket (if
supported) rather than an Internet-domain socket.
Used only with Internet-domain sockets, this option specifies the
service port used to communicate between server and clients.  If this
option is not specified, then the value of the environment variable
GNU_PORT is used, if set, otherwise a service called ``gnuserv'' is
looked up in the services database.  Finally, if no other value can be
found for the port, then a default port is used which is usually 21490
+ uid.
it will have to be specified via one of the alternative methods.
Used only with Internet-domain sockets, the pathname argument may be
needed to inform emacs how to reach the root directory of a remote
given.  For example, if you were trying to edit a file on a client
machine called otter, whose root directory was accessible from the
taken from the environment variable GNU_NODE, if set, or the empty
string otherwise.
This is the path of the file to be edited.  If the file is a directory, then
the directory browsers dired or monkey are usually invoked instead.
The cursor is put at line number 'n' if specified.

Therefore, you should be able to start the server simply by evaluating
the emacs lisp form (gnuserv-start), or equivalently by typing
`M-x gnuserv-start'.

The behavior of this suite of program is mostly controlled on the lisp 
side in Emacs and its behavior can be customized to a large extent.
Type `M-x customize-group RET gnuserv RET' for easy access. More
documentation can be found in the file `gnuserv.el'

gnuclient -q -f mh-smail

More examples and sample wrapper scripts are provided in the


gnuserv.h. This is incompatible with both Unix-domain and
Internet-domain socket communication as described below. A file called
will cause the communication between server and client to fail until
the server is restarted.
communication and if deleted will cause communication between server
and client to fail.  Only the user running gnuserv will be able to
connect to the socket.
Internet-domain sockets are used to communicate between
INTERNET_DOMAIN_SOCKETS is defined at the top of gnuserv.h. Both
Internet-domain and Unix-domain sockets can be used at the same
time. If a hostname is specified via -h or via the GNU_HOST
internet domain socket. If not, a local connection is attempted via
either a unix-domain socket or SYSV IPC.
Using Internet-domain sockets, a more robust form of security is
needed that wasn't necessary with either Unix-domain sockets or SysV
IPC. Currently, two authentication protocols are supported to provide
this: MIT-MAGIC-COOKIE-1 (based on the X11 xauth(1) program) and a
simple host-based access control mechanism, hereafter called
GNUSERV-1. The GNUSERV-1 protocol is always available, whereas support
for MIT-MAGIC-COOKIE-1 may or may not have been enabled (via a #define
at the top of gnuserv.h) at compile-time.
control at the machine level. By default no internet-domain socket is
environment, and it names a readable filename, then this file is
opened and assumed to be a list of hosts, one per line, from which the
server will allow requests. Connections from any other host will be
permitted to make connections via the internet socket unless its
hostname is explicitly specified in this file.  Note that a host may
be either a numeric IP address or a hostname, and that
user on an approved host may connect to your gnuserv and execute arbitrary
elisp (e.g., delete all your files).
If this file contains a lot of
hostnames then the server may take quite a time to start up.
When the MIT-MAGIC-COOKIE-1 protocol is enabled, an internet socket
any host, and will wait for a "magic cookie" (essentially, a password)
to be presented by the client. If the client doesn't present the
cookie, or if the cookie is wrong, the authentication of the client is
the GNUSERV-1 protocol; If the client is calling from a host listed in
the GNU_SECURE file, the connection will be accepted, otherwise it
will be rejected. 
defined for display 999 on the machine where it is running. If the
cookie is found, it will be stored for use as the authentication
cookie. These cookies are defined in an authorization file (usually
example, a machine "kali" which runs an emacs that invokes
up correctly.
kali% xauth list
GS65.SP.CS.CMU.EDU:0  MIT-MAGIC-COOKIE-1  11223344
KALI.FTM.CS.CMU.EDU:999  MIT-MAGIC-COOKIE-1  1234
In the above case, the authorization file defines two cookies. The
second one, defined for screen 999 on the server machine, is used for
gnuserv authentication. 
On the client machine's side, the authorization file must contain an
identical line, specifying the 
cookie. In other words, on a machine "foobar" which wishes to connect
to "kali,"  the `xauth list' output should contain the line:
KALI.FTM.CS.CMU.EDU:999  MIT-MAGIC-COOKIE-1  1234
For more information on authorization files, take a look at the
xauth(1X11) man page, or invoke xauth interactively (without any
arguments) and type "help" at the prompt. Remember that case in the
name of the authorization protocol (i.e.`MIT-MAGIC-COOKIE-1') 
significant!


Default X device to put edit frame.

(SYSV_IPC only)
(unix domain sockets only)
emacs customization file, see emacs(1).
xauth(1X11), Xsecurity(1X11), gnuserv.el
NULs occurring in result strings don't get passed back to gnudoit properly.
The
flag does not work, due to lack of necessary functionality in emacs.
Andy Norman (ange@hplb.hpl.hp.com), based heavily upon
18.52 distribution.  Various modifications from Bob Weiner (weiner@mot.com),
Darrell Kindred (dkindred@cmu.edu), Arup Mukherjee (arup@cmu.edu), Ben
Wing (ben@xemacs.org) and Hrvoje Niksic (hniksic@xemacs.org).
[-nw] [-display display] [-q] [-v] [-l library] [-batch] [-f function] [-eval form] 
[-h hostname] [-p port] [-r remote-pathname] [[+line] file] ...
form
Removed as of gnuserv 3.x

Depending on your environment, it can be an X frame or a TTY frame.
One typical use for this is with a dialup connection to a machine on
which an emacs process is currently running.
Its use is deprecated. Try to get used to calling gnuclient directly.
handle all incoming and outgoing requests. It is not usually invoked
package and evaluating the Lisp form (gnuserv-start).
makes sense in this context. In addition it adds a few of its own. 
Options with long names can also be specified using a double
hyphen instead of a single one.
can attach to the current TTY. emacs will then open a new TTY frame.
The effect is similar to having started a new emacs on this TTY with
the ``-nw'' option. It currently only works if emacs is running on
the same machine as gnuclient. This is the default if the `DISPLAY'
environment variable is not set.
If this option is given or the `DISPLAY' environment variable is set
then gnuclient will tell emacs to edit files in a frame on the
specified X device.
all of the files on the command line have been finished with (their
buffers killed) by the emacs process, and all the forms have been
evaluated.
specified files to be viewed instead of edited.
Tell Emacs to load the specified library.
Tell Emacs not to open any frames. Just load libraries and evaluate
lisp code.  If no files to execute, functions to call or forms to eval 
are given using the
or
options, then forms to eval are read from STDIN.
Make Emacs execute the lisp function.
Make Emacs execute the lisp form.
Used only with Internet-domain sockets, this option specifies the host
specified then the value of the environment variable GNU_HOST is used
if set. If no hostname is specified, and the GNU_HOST variable is not
authentication is used or the GNU_SECURE variable has been specified
and points at a file listing all trusted hosts. (See SECURITY below.)

Note that an internet address may be specified instead of a hostname
which can speed up connections to the server by quite a bit,
especially if the client machine is running YP.

the connection to the server should use a Unix-domain socket (if
supported) rather than an Internet-domain socket.
Used only with Internet-domain sockets, this option specifies the
service port used to communicate between server and clients.  If this
option is not specified, then the value of the environment variable
GNU_PORT is used, if set, otherwise a service called ``gnuserv'' is
looked up in the services database.  Finally, if no other value can be
found for the port, then a default port is used which is usually 21490
+ uid.
it will have to be specified via one of the alternative methods.
Used only with Internet-domain sockets, the pathname argument may be
needed to inform emacs how to reach the root directory of a remote
given.  For example, if you were trying to edit a file on a client
machine called otter, whose root directory was accessible from the
taken from the environment variable GNU_NODE, if set, or the empty
string otherwise.
This is the path of the file to be edited.  If the file is a directory, then
the directory browsers dired or monkey are usually invoked instead.
The cursor is put at line number 'n' if specified.

Therefore, you should be able to start the server simply by evaluating
the emacs lisp form (gnuserv-start), or equivalently by typing
`M-x gnuserv-start'.

The behavior of this suite of program is mostly controlled on the lisp 
side in Emacs and its behavior can be customized to a large extent.
Type `M-x customize-group RET gnuserv RET' for easy access. More
documentation can be found in the file `gnuserv.el'

gnuclient -q -f mh-smail

More examples and sample wrapper scripts are provided in the


gnuserv.h. This is incompatible with both Unix-domain and
Internet-domain socket communication as described below. A file called
will cause the communication between server and client to fail until
the server is restarted.
communication and if deleted will cause communication between server
and client to fail.  Only the user running gnuserv will be able to
connect to the socket.
Internet-domain sockets are used to communicate between
INTERNET_DOMAIN_SOCKETS is defined at the top of gnuserv.h. Both
Internet-domain and Unix-domain sockets can be used at the same
time. If a hostname is specified via -h or via the GNU_HOST
internet domain socket. If not, a local connection is attempted via
either a unix-domain socket or SYSV IPC.
Using Internet-domain sockets, a more robust form of security is
needed that wasn't necessary with either Unix-domain sockets or SysV
IPC. Currently, two authentication protocols are supported to provide
this: MIT-MAGIC-COOKIE-1 (based on the X11 xauth(1) program) and a
simple host-based access control mechanism, hereafter called
GNUSERV-1. The GNUSERV-1 protocol is always available, whereas support
for MIT-MAGIC-COOKIE-1 may or may not have been enabled (via a #define
at the top of gnuserv.h) at compile-time.
control at the machine level. By default no internet-domain socket is
environment, and it names a readable filename, then this file is
opened and assumed to be a list of hosts, one per line, from which the
server will allow requests. Connections from any other host will be
permitted to make connections via the internet socket unless its
hostname is explicitly specified in this file.  Note that a host may
be either a numeric IP address or a hostname, and that
user on an approved host may connect to your gnuserv and execute arbitrary
elisp (e.g., delete all your files).
If this file contains a lot of
hostnames then the server may take quite a time to start up.
When the MIT-MAGIC-COOKIE-1 protocol is enabled, an internet socket
any host, and will wait for a "magic cookie" (essentially, a password)
to be presented by the client. If the client doesn't present the
cookie, or if the cookie is wrong, the authentication of the client is
the GNUSERV-1 protocol; If the client is calling from a host listed in
the GNU_SECURE file, the connection will be accepted, otherwise it
will be rejected. 
defined for display 999 on the machine where it is running. If the
cookie is found, it will be stored for use as the authentication
cookie. These cookies are defined in an authorization file (usually
example, a machine "kali" which runs an emacs that invokes
up correctly.
kali% xauth list
GS65.SP.CS.CMU.EDU:0  MIT-MAGIC-COOKIE-1  11223344
KALI.FTM.CS.CMU.EDU:999  MIT-MAGIC-COOKIE-1  1234
In the above case, the authorization file defines two cookies. The
second one, defined for screen 999 on the server machine, is used for
gnuserv authentication. 
On the client machine's side, the authorization file must contain an
identical line, specifying the 
cookie. In other words, on a machine "foobar" which wishes to connect
to "kali,"  the `xauth list' output should contain the line:
KALI.FTM.CS.CMU.EDU:999  MIT-MAGIC-COOKIE-1  1234
For more information on authorization files, take a look at the
xauth(1X11) man page, or invoke xauth interactively (without any
arguments) and type "help" at the prompt. Remember that case in the
name of the authorization protocol (i.e.`MIT-MAGIC-COOKIE-1') 
significant!


Default X device to put edit frame.

(SYSV_IPC only)
(unix domain sockets only)
emacs customization file, see emacs(1).
xauth(1X11), Xsecurity(1X11), gnuserv.el
NULs occurring in result strings don't get passed back to gnudoit properly.
The
flag does not work, due to lack of necessary functionality in emacs.
Andy Norman (ange@hplb.hpl.hp.com), based heavily upon
18.52 distribution.  Various modifications from Bob Weiner (weiner@mot.com),
Darrell Kindred (dkindred@cmu.edu), Arup Mukherjee (arup@cmu.edu), Ben
Wing (ben@xemacs.org) and Hrvoje Niksic (hniksic@xemacs.org).
[
]
[
]
[
]
Reads a grap program as input; produces an image file (by default in
Portable Network Graphics format) suitable for the Web as output.
For a description of the grap language, see
macros.
The output image will be a black-on-white graphic clipped to the
smallest possible bounding box that contains all the black pixels.
By specifying command-line options to be passed to 
you can give it a border, set the background transparent, set the
image's pixel density, or perform other useful transformations.
This program uses 
and the ImageMagick 
program.
These programs must be installed on your system and accessible on your
Run 
and
in the `unsafe' mode enabling the PIC macro
to execute arbitrary commands.
The default is to forbid this.
Specify an output format; the default is PNG (Portable Network Graphics).
Any format that
can emit is supported.
Command-line switches and arguments not listed above are passed to
The directory in which temporary files will be created.
If this is not set
searches the environment variables
and
(in that order).
Otherwise, temporary files will be created in
Eric S. Raymond <esr@thyrsus.com>
is used by the Apple Mac OS X base system to initalize graphics contexts. It should not be called directly.
The
utility searches any given input files,
selecting lines that match one or more patterns.
By default, a pattern matches an input line if the regular expression
(RE) in the pattern matches the input line
without its trailing newline.
An empty expression matches every line.
Each input line that matches at least one of the patterns is written
to the standard output.
is used for simple patterns and
basic regular expressions
can handle extended regular expressions
See
for more information on regular expressions.
is quicker than both
and
but can only handle fixed patterns
(i.e. it does not interpret regular expressions).
Patterns may consist of one or more lines,
allowing any of the pattern lines to match a portion of the input.
and
act like
and
respectively, but accept input files compressed with the
or
compression utilities.
The following options are available:
Print
lines of trailing context after each match.
See also the
and
options.
Treat all files as ASCII text.
Normally
will simply print
if files contain binary characters.
Use of this option forces
to output lines matching the specified pattern.
Print
lines of leading context before each match.
See also the
and
options.
The offset in bytes of a matched pattern is
displayed in front of the respective matched line.
Print
lines of leading and trailing context surrounding each match.
The default is 2 and is equivalent to
Note:
no whitespace may be given between the option and its argument.
Only a count of selected lines is written to standard output.
Mark up the matching text with the expression stored in
environment variable.
The possible values of when can be `never', `always' or `auto'.
Specify the demanded action for devices, FIFOs and sockets.
The default action is `read', which means, that they are read
as if they were normal files.
If the action is set to `skip', devices will be silently skipped.
Specify the demanded action for directories.
It is `read' by default, which means that the directories
are read in the same manner as normal files.
Other possible values are `skip' to silently ignore the
directories, and `recurse' to read them recursively, which
has the same effect as the
and
option.
Interpret
as an extended regular expression
(i.e. force
to behave as
Specify a pattern used during the search of the input:
an input line is selected if it matches any of the specified patterns.
This option is most useful when multiple
options are used to specify multiple patterns,
or when a pattern begins with a dash
If specified, it excludes files matching the given
filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all files are searched that are
not excluded.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, it excludes directories matching the
given filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all directories are searched that are
not excluded.
Interpret
as a set of fixed strings
(i.e. force
to behave as
Read one or more newline separated patterns from
Empty pattern lines match every input line.
Newlines are not considered part of a pattern.
If
is empty, nothing is matched.
Interpret
as a basic regular expression
(i.e. force
to behave as traditional
Always print filename headers with output lines.
Never print filename headers
with output lines.
Print a brief help message.
Ignore binary files.
This option is equivalent to
option.
Perform case insensitive matching.
By default,
is case sensitive.
If specified, only files matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, only directories matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Decompress the
compressed file before looking for the text.
Only the names of files not containing selected lines are written to
standard output.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Only the names of files containing selected lines are written to
standard output.
will only search a file until a match has been found,
making searches potentially less expensive.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Use
instead of
to read input, which can result in better performance under some
circumstances but can cause undefined behaviour.
Stop reading the file after
matches.
Each output line is preceded by its relative line number in the file,
starting at line 1.
The line number counter is reset for each file processed.
This option is ignored if
or
is
specified.
Prints a zero-byte after the file name.
If
is specified, follow symbolic links only if they were explicitly listed
on the command line.
The default is not to follow symbolic links.
Prints only the matching part of the lines.
If
is specified, no symbolic links are followed.
This is the default.
Quiet mode:
suppress normal output.
will only search a file until a match has been found,
making searches potentially less expensive.
Recursively search subdirectories listed.
If
is specified, all symbolic links are followed.
The default is not to follow symbolic links.
Silent mode.
Nonexistent and unreadable files are ignored
(i.e. their error messages are suppressed).
Search binary files, but do not attempt to print them.
Display version information and exit.
Selected lines are those
matching any of the specified patterns.
The expression is searched for as a word (as if surrounded by
and
see
Only input lines selected against an entire fixed string or regular
expression are considered to be matching lines.
Equivalent to
Obsoleted.
Force
to behave as
Controls searching and printing of binary files.
Options are
the default: search binary files but do not print them;
do not search binary files;
and
treat all files as text.
Print
lines of leading and trailing context.
The default is 2.
Force output to be line buffered.
By default, output is line buffered when standard output is a terminal
and block buffered otherwise.
If no file arguments are specified, the standard input is used.
May be used to specify default options that will be placed at the beginning
of the argument list.
Backslash-escaping is not supported, unlike the behavior in GNU grep.
The
utility exits with one of the following values:
One or more lines were selected.
No lines were selected.
An error occurred.
To find all occurrences of the word
in a file:
To find all occurrences of the pattern
at the beginning of a line:
The apostrophes ensure the entire expression is evaluated by
instead of by the user's shell.
The caret
matches the null string at the beginning of a line,
and the
escapes the
which would otherwise match any character.
To find all lines in a file which do not contain the words
or
A simple example of an extended regular expression:
Peruses the file
looking for either 19, 20, or 25.
The
utility is compliant with the
specification.
The flags
are extensions to that specification, and the behaviour of the
flag when used with an empty pattern file is left undefined.
All long options are provided for compatibility with
GNU versions of this utility.
Historic versions of the
utility also supported the flags
This implementation supports those options;
however, their use is strongly discouraged.
The
command first appeared in
The
utility does not normalize Unicode input, so a pattern containing composed
characters will not match decomposed input, and vice versa.
Copyright (C) 2000, 2001, 2002, 2003, 2004 Free Software Foundation, Inc.

Permission is granted to make and distribute verbatim copies of
this manual provided the copyright notice and this permission notice
are preserved on all copies.

Permission is granted to copy and distribute modified versions of this
manual under the conditions for verbatim copying, provided that the
entire resulting derived work is distributed under the terms of a
permission notice identical to this one.

Permission is granted to copy and distribute translations of this
manual into another language, under the above conditions for modified
versions, except that this permission notice may be included in
translations approved by the Free Software Foundation instead of in
the original English.
[
]
[
]
[
]
[
]
[
]
It is possible to have whitespace between a command line option and its
parameter.
is a preprocessor for including
pictures in
input.
writes to standard output, processing only input lines between two that
start with
and
Those lines must contain
commands (see below).
These commands request a
file, and the picture in that file is
converted and placed in the
input stream.
The
request may be followed by a C, L, or R to center, left, or right
justify the whole
picture (default justification is center).
If no
is mentioned, the standard input is read.
At the end of the picture, the position on the page is the bottom of the
picture.
If the
entry is ended with
instead of
the position is left at the top of the picture.
and
The following command-line options are understood:
Prepare output for printer
The default device is
See
for acceptable devices.
Prepend
to the default search path for
files.
The default path is (in that order) the current directory, the home
directory,
and
Search
for subdirectories
is the name of the device) for the
file before the default font directories
and
Recognize
and
(and
even when followed by a character other than space or newline.
Print the version number.
Each input line between
and
may have one
command.
Commands consist of one or two strings separated by white space, the first
string being the command and the second its operand.
Commands may be upper or lower case and abbreviated down to one character.
Commands that affect a picture's environment (those listed before
see below) are only in effect for the current picture:
The environment is reinitialized to the defaults at the start of the next
picture.
The commands are as follows:
Set
text size number 1 (2, 3, or 4) to
points.
The default is 12 (16, 24, and 36, respectively).
Set the roman (italics, bold, or special) font to
font
(either a name or number).
The default is R (I, B, and S, respectively).
Set the stipple font to
stipple font
(name or number).
The command
may be abbreviated down as far as `st' (to avoid
confusion with
There is
default for stipples (unless one is set by the default command), and it is
invalid to include a
picture with polygons without specifying a
stipple font.
Magnify the picture (in addition to any default magnification) by
a floating point number larger than zero.
The command
may be abbreviated down to `sc'.
Set the thickness of
narrow (medium and thick, respectively) lines to
times 0.15pt (this value can be changed at compile time).
The default is 1.0 (3.0 and 5.0, respectively), which corresponds to 0.15pt
(0.45pt and 0.75pt, respectively).
A thickness value of zero selects the smallest available line thickness.
Negative values cause the line thickness to be proportional to the current
point size.
Scale text to match the picture.
Gremlin text is usually printed in the point size specified with the
commands
regardless of any scaling factors in the picture.
Setting
will cause the point sizes to scale with the picture (within
limitations, of course).
An operand of anything but
will turn text scaling on.
Reset the picture environment defaults to the settings in the current
picture.
This is meant to be used as a global parameter setting mechanism at the
beginning of the
input file, but can be used at any time to reset the
default settings.
Forces the picture to be
inches wide.
This overrides any scaling factors present in the same picture.
is ignored.
Forces picture to be
inches high, overriding other scaling factors.
If both `width' and `height' are specified the tighter constraint will
determine the scale of the picture.
and
commands are not saved with a
command.
They will, however, affect point size scaling if that option is set.
Get picture from
file
located the current directory (or in the library directory; see the
option above).
If two
commands are given, the second one overrides the first.
If
doesn't exist, an error message is reported and processing continues from
the
line.
Since
is a preprocessor, it doesn't know about current indents, point sizes,
margins, number registers, etc.
Consequently, no
input can be placed between the
and
requests.
However,
text is now processed by
so anything legal in a single line of
input is legal in a line of
text (barring `.' directives at the beginning of a line).
Thus, it is possible to have equations within a
figure by including in the
file
expressions enclosed by previously defined delimiters (e.g.
When using
along with other preprocessors, it is best to run
before
to avoid overworking
should always be run last.
A picture is considered an entity, but that doesn't stop
from trying to break it up if it falls off the end of a page.
placement.
uses
number registers
through
and sets registers
and
to the width and height of the
figure (in device units) before entering the
request (this is for those who want to rewrite these macros).
There exist two distinct 
file formats, the original format from the
graphic terminal version, and the
or
version.
An extension to the
version allowing reference points with negative coordinates is
compatible with the
version.
As long as a 
file does not contain negative coordinates, either format will be read
correctly by either version of
or
The other difference to the
format is the use of names for picture objects (e.g., POLYGON, CURVE)
instead of numbers.
Files representing the same picture are shown in Table 1 in each format.
center, tab(@);
l lw(0.1i) l.
sungremlinfile@@gremlinfile
0 240.00 128.00@@0 240.00 128.00
CENTCENT@@2
240.00 128.00@@240.00 128.00
185.00 120.00@@185.00 120.00
240.00 120.00@@240.00 120.00
296.00 120.00@@296.00 120.00
*@@-1.00 -1.00
2 3@@2 3
10 A Triangle@@10 A Triangle
POLYGON@@6
224.00 416.00@@224.00 416.00
96.00 160.00@@96.00 160.00
384.00 160.00@@384.00 160.00
*@@-1.00 -1.00
5 1@@5 1
0@@0
-1@@-1
css.
Table 1. File examples
The first line of each
file contains either the string
version) or
The second line of the file contains an orientation, and
and
values for a positioning point, separated by spaces.
The orientation, either
or
is ignored by the
version.
means that
will display things in horizontal format (drawing area wider than it is
tall, with menu across top).
means that
will display things in vertical format (drawing area taller than it is wide,
with menu on left side).
and
are floating point values giving a positioning point to be used when this
file is read into another file.
The stuff on this line really isn't all that important; a value of ``1 0.00
0.00'' is suggested.
The rest of the file consists of zero or more element specifications.
After the last element specification is a line containing the string ``-1''.
Lines longer than 127 characters are chopped to this limit.
The first line of each element contains a single decimal number giving the
type of the element
version) or its ASCII name
version).
See Table 2.
center, tab(@);
css
ccc
nll.
0@BOTLEFT@bottom-left-justified text
1@BOTRIGHT@bottom-right-justified text
2@CENTCENT@center-justified text
3@VECTOR@vector
4@ARC@arc
5@CURVE@curve
6@POLYGON@polygon
7@BSPLINE@b-spline
10@TOPLEFT@top-left-justified text
11@TOPCENT@top-center-justified text
12@TOPRIGHT@top-right-justified text
13@CENTLEFT@left-center-justified text
14@CENTRIGHT@right-center-justified text
15@BOTCENT@bottom-center-justified text
css.
Table 2.
After the object type comes a variable number of lines, each specifying a
point used to display the element.
Each line contains an x-coordinate and a y-coordinate in floating point
format, separated by spaces.
The list of points is terminated by a line containing the string ``-1.0
-1.0''
version) or a single asterisk, ``*''
version).
After the points comes a line containing two decimal values, giving the
brush and size for the element.
The brush determines the style in which things are drawn.
For vectors, arcs, and curves there are six legal brush values:
center, tab(@);
ncw(0.1i)l.
For polygons, one more value, 0, is legal.
It specifies a polygon with an invisible border.
For text, the brush selects a font as follows:
center, tab(@);
ncw(0.1i)l.
If you're using
to run your pictures through
the font is really just a starting font:
The text string can contain formatting sequences like
or
which may change the font (as well as do many other things).
For text, the size field is a decimal value between 1 and 4.
It selects the size of the font in which the text will be drawn.
For polygons, this size field is interpreted as a stipple number to fill the
polygon with.
The number is used to index into a stipple font at print time.
The last line of each element contains a decimal number and a string of
characters, separated by a single space.
The number is a count of the number of characters in the string.
This information is only used for text elements, and contains the text
string.
There can be spaces inside the text.
For arcs, curves, and vectors, this line of the element contains the string
``0''.
was designed for
and its coordinates reflect the
coordinate space.
For vertical pictures, x-values range 116 to 511, and y-values from 0 to
483.
For horizontal pictures, x-values range from 0 to 511 and y-values range
from 0 to 367.
Although you needn't absolutely stick to this range, you'll get best results
if you at least stay in this vicinity.
Also, point lists are terminated by a point of (-1, -1), so you shouldn't
ever use negative coordinates.
writes out coordinates using format ``%f1.2''; it's probably a good idea to
use the same format if you want to modify the
code.
There is no longer a restriction on the range of coordinates used to create
objects in the
version of
However, files with negative coordinates
cause problems if displayed on the
Device description file for device
David Slattengren and Barry Roitblat wrote the original Berkeley
Daniel Senderowicz and Werner Lemberg modified it for
Copyright (C) 1989-2000, 2001, 2002, 2003, 2004 Free Software Foundation, Inc.

Permission is granted to make and distribute verbatim copies of
this manual provided the copyright notice and this permission notice
are preserved on all copies.

Permission is granted to copy and distribute modified versions of this
manual under the conditions for verbatim copying, provided that the
entire resulting derived work is distributed under the terms of a
permission notice identical to this one.

Permission is granted to copy and distribute translations of this
manual into another language, under the above conditions for modified
versions, except that this permission notice may be included in
translations approved by the Free Software Foundation instead of in
the original English.
[
] [
] [
] [
] [
]
It is possible to have whitespace between a command line option and its
parameter.
is a driver for
Normally it should be run by
This will run
it will also input the macros in
The dvi file generated by
can be printed by any correctly-written dvi driver.
The troff drawing primitives are implemented
If the driver does not support these, the
commands will not produce any output.
There is an additional drawing command available:
Draw a rule (solid black rectangle), with one corner
at the current position, and the diagonally opposite corner
at the current position
Afterwards the current position will be at the opposite corner.
This produces a rule in the dvi file and so can be printed even with a
driver that does not support the tpic specials unlike the other
commands.
The groff command
is translated into the same command in the dvi file as would be
produced by
may not contain a newline.
For inclusion of EPS image files,
loads
automatically, providing the
macro.
Please check
for a detailed description.
Font files for
can be created from tfm files using
The font description file should contain the following
additional commands:
The name of the tfm file (without the
extension) is
The checksum in the tfm file is
The designsize in the tfm file is
These are automatically generated by
The default color for
and
is black.
Currently, the drawing color for
commands is always black, and fill color values are translated to gray.
In
the
escape sequence can be used to access characters by their position
in the corresponding tfm file;
all characters in the tfm file can be accessed this way.
By design, the DVI format doesn't care about physical dimensions of the
output medium.
Instead,
on the first page;
(and possibly other DVI drivers) then sets the page size accordingly.
If either the page width or length is not positive, no papersize special
is output.
Do not use tpic specials to implement drawing commands.
Horizontal and vertical lines will be implemented by rules.
Other drawing commands will be ignored.
Prepend directory
to the search path for font and device description files;
is the name of the device, usually
Specify landscape orientation.
Specify paper dimensions.
This overrides the
and
commands in the
file; it accepts the same arguments as the
command (see
for details).
Print the version number.
Set the default line thickness to
thousandths of an em.
There are styles called
and
The fonts are grouped into families
and
having members in each of these styles:
CM Roman (cmr10)
CM Text Italic (cmti10)
CM Bold Extended Roman (cmbx10)
CM Bold Extended Text Italic (cmbxti10)
CM Sans Serif (cmss10)
CM Slanted Sans Serif (cmssi10)
CM Sans Serif Bold Extended (cmssbx10)
CM Slanted Sans Serif Bold Extended (cmssbxo10)
There are also the following fonts which are not members of a family:
CM Typewriter Text (cmtt10)
CM Italic Typewriter Text (cmitt10)
Special fonts are
(cmmi10),
(cmsy10),
(cmex10),
(cmtex10, only for
and, perhaps surprisingly,
and
due to the different font encodings of text fonts.
For italic fonts,
is used instead of
Finally, the symbol fonts of the American Mathematical Society are available
as special fonts
(msam10) and
(msbm10).
These two fonts are not mounted by default.
Using the option
(which loads the file
provides the EC and TC fonts.
The design of the EC family is very similar to that of the CM fonts;
additionally, they give a much better coverage of groff symbols.
Note that
must be called before any language-specific files; it doesn't take care of
hcode values.
Device description file.
Font description file for font
Macros for use with
Macros to switch to EC fonts.
Dvi files produced by
use a different resolution (57816 units per inch) to those produced by
rather than using the resolution specified in the dvi file will not
work with
When using the
option with boxed tables,
vertical and horizontal lines can sometimes protrude by one pixel.
and widths of rules be rounded.
groff.man

Last update: 01 Jul 2005

Copyright (C) 1989, 2002, 2003, 2004, 2005 Free Software Foundation, Inc.
Rewritten in 2002 by Bernd Warken <bwarken@mayn.de>

under the terms of the GNU Free Documentation License, Version 1.1 or
any later version published by the Free Software Foundation; with the
Invariant Sections being this .ig-section and AUTHOR, with no
Front-Cover Texts, and with no Back-Cover Texts.

A copy of the Free Documentation License is included as a file called
FDL in the main directory of the groff source package.
|
|
The command line is parsed according to the usual GNU convention.
The whitespace between a command line option and its argument is
optional.
Options can be grouped behind a single
(minus character).
A filename of
(minus character) denotes the standard input.
This document describes the
program, the main front-end for the 
document formatting system.
The
program and macro suite is the implementation of a
system within the free software collection
The
system has all features of the classical
but adds many extensions.
The
program allows to control the whole
system by command line options.
This is a great simplification in comparison to the classical case (which
uses pipes only).
As
is a wrapper program for
both programs share a set of options.
But the
program has some additional, native options and gives a new meaning to
some
options.
On the other hand, not all
options can be fed into
The following options either do not exist for
or are differently interpreted by
Preprocess with
Preprocess with
Preprocess with
Print a help message.
This option may be used to specify a directory to search for
files (both those on the command line and those named in
and
requests, and
and
escapes).
The current directory is always searched first.
This option may be specified more than once;
the directories will be searched in the order specified.
No directory search is performed for files specified using an absolute path.
This option implies the
option.
Send the output to a spooler program for printing.
The command that should be used for this is specified by the
command in the device description file, see
If this command is not present, the output is piped into the
program by default.
See options
and
Pass
to the spooler program.
Several arguments should be passed with a separate
option each.
Note that
does not prepend
(a minus sign) to
before passing it to the spooler program.
Don't allow newlines within
delimiters.
This is the same as the
option in
Preprocess with
Pass
or
to the postprocessor.
The option must be specified with the necessary preceding minus
sign(s)
or
because groff does not prepend any dashes before passing it to the
postprocessor.
command
is equivalent to
Preprocess with
No mechanism is provided for passing arguments to 
because most
options have equivalent language elements that can be specified within
the document.
See
for more details.
Preprocess with
Safer mode.
Pass the
option to
and disable the following
requests:
and
For security reasons, safer mode is enabled by default.
Preprocess with
Set output device to
For this device,
generates the
see
Then
calls a postprocessor to convert
to its final format.
Real devices in
are
TeX DVI format (postprocessor is
HTML output (preprocessors are
and
postprocessor is
postprocessor is
HP LaserJet4 compatible (or other PCL5 compatible) printers (postprocessor
is
PostScript output (postprocessor is
For the following TTY output devices (postprocessor is always
selects the output encoding:
7bit ASCII.
The following arguments select
as the `postprocessor' (it is rather a viewing program):
75dpi resolution, 10pt document base font.
75dpi resolution, 12pt document base font.
100dpi resolution, 10pt document base font.
100dpi resolution, 12pt document base font.
The default device is
Unsafe mode.
Reverts to the (old) unsafe behaviour; see option
Output version information of
and of all programs that are run by it; that is, the given command line
is parsed in the usual way, passing
to all subprograms.
Output the pipeline that would be run by
(as a wrapper program) on the standard output, but do not execute it.
If given more than once,
the commands will be both printed on the standard error and run.
Use
instead of using the usual postprocessor to (pre)view a document.
The printing spooler behavior as outlined with options
and
is carried over to 
by determining an argument for the
option of
This sets the default
action and the corresponding menu entry to that value.
only produces good results with
and
The default resolution for previewing
option to
for example
Suppress output generated by
Only error messages will be printed.
Print the
to standard output; see
Normally
calls automatically a postprocessor.
With this option, the output of
for the device, the so-called
is issued without postprocessing.
The following options are transparently handed over to the formatter
program
that is called by groff subsequently.
These options are described in more detail in
ascii approximation of output.
backtrace on error or warning.
disable color output.
Please consult the
man page for more details.
enable compatibility mode.
define string.
disable
error messages.
set default font family.
set path for font DESC files.
process standard input after the specified input files.
path for macro files.
number the first page
output only pages in
set number register.
enable warning
disable warning
The
implements the infrastructure of classical roff; see
for a survey on how a roff system works in general.
Due to the front-end programs available within the groff system, using
is much easier than
This section gives an overview of the parts that constitute the groff
system.
It complements
with groff-specific features.
This section can be regarded as a guide to the documentation around
the groff system.
The
paper size used by
to format the input is controlled globally with the requests
and
See
for the `papersize' macro package which provides a convenient interface.
The
paper size, giving the actual dimensions of the paper sheets, is
controlled by output devices like
with the command line options
and
See
and the man pages of the output devices for more details.
uses the command line option
to pass options to output devices; for example, the following selects
A4 paper in landscape orientation for the PS device:
The
program is a wrapper around the
program.
It allows to specify the preprocessors by command line options and
automatically runs the postprocessor that is appropriate for the
selected device.
Doing so, the sometimes tedious piping mechanism of classical
can be avoided.
The
program can be used for guessing the correct groff command line to
format a file.
The
program is an allround-viewer for groff files and man pages.
The groff preprocessors are reimplementations of the classical
preprocessors with moderate extensions.
The preprocessors distributed with the
package are
for including
pictures,
for drawing diagrams,
for bibliographic references,
for including macro files from standard locations,
and
for tables.
Besides these, there are some internal preprocessors that are
automatically run with some devices.
These aren't visible to the user.
Macro packages can be included by option
The groff system implements and extends all classical macro packages
in a compatible way and adds some packages of its own.
Actually, the following macro packages come with
The traditional man page format; see
It can be specified on the command line as
or
The general package for man pages; it automatically recognizes
whether the documents uses the
or the
format and branches to the corresponding macro package.
It can be specified on the command line as
or
The BSD-style man page format; see
It can be specified on the command line as
or
The classical
document format; see
It can be specified on the command line as
or
The classical
document format; see
It can be specified on the command line as
or
The classical
document format; see
It can be specified on the command line as
or
HTML-like macros for inclusion in arbitrary groff documents; see
Details on the naming of macro files and their placement can be found
in
this man page also documents some other, minor auxiliary macro packages
not mentioned here.
General concepts common to all roff programming languages are
described in
The groff extensions to the classical troff language are documented in
The groff language as a whole is described in the (still incomplete)
a short (but complete) reference can be found in
The central roff formatter within the groff system is
It provides the features of both the classical troff and nroff, as
well as the groff extensions.
The command line option
switches
into
which tries to emulate classical roff as much as possible.
There is a shell script
that emulates the behavior of classical nroff.
It tries to automatically select the proper output encoding, according to
the current locale.
The formatter program generates
see
In roff, the output targets are called
A device can be a piece of hardware, e.g. a printer, or a software
file format.
A device is specified by the option
The groff devices are as follows.
Text output using the
character set.
TeX DVI format.
HTML output.
HP LaserJet4-compatible (or other PCL5-compatible) printers.
PostScript output; suitable for printers and previewers like
encoding; see
75dpi X Window System output suitable for the previewers
and
100dpi X Window System output suitable for the previewers
and
The postprocessor to be used for a device is specified by the
command in the device description file; see
This can be overridden with the
option.
The default device is
for some Canon printers,
for text output using various encodings, e.g. on text-oriented
terminals or line-printers.
Today, most printing or drawing hardware is handled by the operating
system, by device drivers, or by software interfaces, usually accepting
PostScript.
Consequently, there isn't an urgent need for more hardware device
postprocessors.
The groff software devices for conversion into other document file
formats are
for the DVI format,
for HTML format,
for PostScript.
Combined with the many existing free conversion tools this should
be sufficient to convert a troff document into virtually any existing
data format.
The following utility programs around groff are available.
Add information to troff font description files for use with groff.
Create font description files for PostScript device.
General viewer program for groff files and man pages.
The groff X viewer, the GNU version of xditview.
Create font description files for lj4 device.
Make inverted index for bibliographic databases.
Search bibliographic databases.
Interactively search bibliographic databases.
Translate a PostScript font in .pfb format to ASCII.
Create font description files for TeX DVI device.
roff viewer distributed with X window.
Normally, the path separator in the following environment variables is the
colon; this may vary depending on the operating system.
For example, DOS and Windows use a semicolon instead.
This search path, followed by
will be used for commands that are executed by
If it is not set then the directory where the groff binaries were
installed is prepended to
When there is a need to run different roff implementations at the same
time
provides the facility to prepend a prefix to most of its programs that
could provoke name clashings at run time (default is to have none).
Historically, this prefix was the character
but it can be anything.
For example,
stood for
for the
version of
By setting
to different values, the different roff installations can be
addressed.
More exactly, if it is set to prefix
then
as a wrapper program will internally call
instead of
This also applies to the preprocessors
and to the utilities
and
This feature does not apply to any programs different from the ones
above (most notably
itself) since they are unique to the groff package.
A list of directories in which to search for the
directory in addition to the default ones.
See
and
for more details.
A list of directories in which to search for macro files in addition to
the default directories.
See
and
for more details.
The directory in which temporary files will be created.
If this is not set but the environment variable
instead, temporary files will be created in the directory
and
(in that order) are searched also, after
and
Otherwise, temporary files will be created in
The
and
commands use temporary files.
Preset the default device.
If this is not set the
device is used as default.
This device name is overwritten by the option
There are some directories in which
installs all of its data files.
Due to different installation habits on different operating systems,
their locations are not absolutely fixed, but their function is
clearly defined and coincides on all systems.
This contains all information related to macro packages.
Note that more than a single directory is searched for those files
as documented in
For the groff installation corresponding to this document, it is
located at
The following files contained in the
have a special meaning:
Initialization file for troff.
This is interpreted by
before reading the macro sets and any input.
Final startup file for troff, it is parsed after all macro sets have
been read.
Macro file for macro package
This contains all information related to output devices.
Note that more than a single directory is searched for those files; see
For the groff installation corresponding to this document, it is
located at
The following files contained in the
have a special meaning:
Device description file for device
see
Font file for font
of device
The following example illustrates the power of the
program as a wrapper around
To process a roff file using the preprocessors
and
and the
macro set, classical troff had to be called by
Using
this pipe can be shortened to the equivalent command
An even easier way to call this is to use
to guess the preprocessor and macro options and execute the generated
command (by using backquotes to specify shell command substitution)
The simplest way is to view the contents in an automated way by
calling
and
aren't available.
Similarly, output for EBCDIC code page
is not available on ASCII based operating systems.
Report bugs to bug-groff@gnu.org.
Include a complete, self-contained example that will allow the bug to
be reproduced, and say which version of groff you are using.
Information on how to get groff and related information is available
at the
The most recent released version of groff is available for anonymous
ftp at the
     "groff development site" .
Three groff mailing lists are available:
for reporting bugs,
for general discussion of groff,
a read-only list showing logs of commitments to the CVS repository.
Details on CVS access and much more can be found in the file
at the top directory of the groff source package.
There is a free implementation of the
preprocessor, written by
The actual version can be found at the
     "grap website" .
This is the only grap version supported by groff.
This document is distributed under the terms of the FDL (GNU Free
Documentation License) version 1.1 or later.
You should have received a copy of the FDL on your system, it is also
available on-line at the
This document is based on the original groff man page written by
It was rewritten, enhanced, and put under the FDL license by
It is maintained by
is a GNU free software project.
All parts of the
are protected by GNU copyleft licenses.
The software files are distributed under the terms of the GNU General
Public License (GPL), while the documentation files mostly use the GNU
Free Documentation License (FDL).
The
contains all information on the groff system within a single document.
Beneath the detailed documentation of all aspects, it provides
examples and background information.
See
on how to read it.
Due to its complex structure, the groff system has many man pages.
They can be read with
or
Introduction, history and further readings:
Viewer for groff files:
Wrapper programs for formatters:
Roff preprocessors:
Roff language with the groff extensions:
Roff formatter programs:
The
language:
Postprocessors for the output devices:
Groff macro packages and macro-specific utilities:
The following utilities are available:
groffer.1 - man page for groffer (section 1).


Last update: 22 August 2005

This file was written by
Copyright (C) 2001,2002,2004,2005 Free Software Foundation, Inc.
This file is part of
which is part of
a free software project.
as published by the
either version 2, or (at your option) any later version.
directory of the
source package.
Or read the
You can also write to the
The
program is the easiest way to use
It can display arbitrary documents written in the
language, see
or other
languages, see
that are compatible to the original
language.
The
program also includes many of the features for finding and displaying
such that it can be used as a replacement for a
program.
Moreover, compressed files that can be handled by
or
are decompressed on-the-fly.
The normal usage is quite simple by supplying a file name or name of a
without further options.
But the option handling has many possibilities for creating special
behaviors.
This can be done either in configuration files, with the shell
environment variable
or on the command line.
The output can be generated and viewed in several different ways
available for
This includes the
each
or
display program, a web browser by generating
in
or several
in text terminals.
Most of the options that must be named when running
directly are determined automatically for
due to the internal usage of the
program.
But all parts can also be controlled manually by arguments.
Several file names can be specified on the command line arguments.
They are transformed into a single document in the normal way of
Options and file names can be mixed freely.
The option
closes the option handling, all following arguments are treated as
file names.
Long options can be abbreviated.
All further
short options are accepted.
are accepted as well.
No
parameters means standard input.
stands for standard input (can occur several times).
the path name of an existing file.
if
is a character in
if
is a character in
if
The
program can usually be run with very few options.
But for special purposes, it supports many options.
These can be classified in 5 option classes.
All short options of
are compatible with the short options of
All long options of
are compatible with the long options of
As soon as one of these options is found on the command line it is
executed, printed to standard output, and the running
is terminated thereafter.
All other arguments are ignored.
Print a helping information with a short explanation of option sto
standard output.
Print version information to standard output.
The display mode and the viewer programs are determined by these
options.
If none of these mode and viewer options is specified
tries to find a suitable display mode automatically.
The default modes are
with
with device
under
on a terminal.
There are two kinds of options for viewers.
chooses the normal viewer programs that run on their own in
chooses programs that run on the terminal (on tty).
so there aren't many opportunities to call the tty viewers.
But they give the chance to view the output source; for example,
shows the content of the
output with the pager
and
for them; with
the viewer program will not become independently, it just stays
coupled with
But the program will not run if you specify a terminal program with
because this viewer will stay in background without a chance to reach
it.
So you really need
for viewers that run on tty.
Equivalent to
Reset all configuration from previously processed command line options
to the default values.
This is useful to wipe out all former options of the configuration, in
and restart option processing using only the rest of the command line.
Set the sequence of modes for
to the comma separated list given in the argument.
See
for details on modes.  Display in the default manner; actually, this
means to try the modes
and
in this sequence.
Equivalent to
This can be a file name or a program to be searched in
viewers include
and
In each case, arguments can be provided additionally.
Choose a program running on the terminal for viewing the output of
This can be a file name or a program to be searched in
arguments can be provided additionally.
Equivalent to
Equivalent to
It can be the path name of an executable file or a program in
In each case, arguments can be provided additionally.
Choose a terminal program for viewing the output of
It can be the path name of an executable file or a program in
arguments can be provided additionally.
Set the display mode.
The following mode values are recognized:
Select the automatic determination of the display mode.
The sequence of modes that are tried can be set with the
option.
Useful for restoring the
when a different mode was specified before.
Display formatted input in a
viewer program.
By default, the formatted input is displayed with the
program.
After the file determination, switch
to process the input like
would do.
This disables the
viewing features.
Translate the input into html format and display the result in a web
browser program.
By default, the existence of a sequence of standard web browsers is
tested, starting with
and
The text html viewer is
Display formatted input in a
(Portable Document Format) viewer
program.
By default, the input is formatted by
using the Postscript device, then it is transformed into the PDF file
format using
and finally displayed either with the
or the
program.
PDF has a big advantage because the text is displayed graphically and
is searchable as well.
But as the transformation takes a considerable amount of time, this
mode is not suitable as a default device for the
Display formatted input in a Postscript viewer program.
By default, the formatted input is displayed with the
program.
Format in a
and write the result to standard output without a pager or viewer
program.
The text device,
by default, can be chosen with option
Format in a
and write the result to standard output using a text pager program,
Equivalent to
Display the formatted input in a native
viewer.
By default, the formatted input is displayed with the
program being distributed together with
can also be chosen with the option
The default resolution is
but
are also possible.
The default
device
for the resolution of
is
for
it is
The corresponding
for the actual device is generated and the result is displayed.
For a resolution of
the default width of the geometry of the display program is chosen to
Equivalent to
The following modes do not use the
viewing features.
They are only interesting for advanced applications.
Generate device output with plain
without using the special viewing features of
If no device was specified by option
the
default
is assumed.
Display the source code of the input without formatting; equivalent to
Equivalent to
This can be a file name or a program to be searched in
arguments can be provided additionally.
Choose a terminal viewer program for
This can be a file name or a program to be searched in
arguments can be provided additionally.
Equivalent to
This can be a file name or a program to be searched in
Common Postscript viewers inlude
and
In each case, arguments can be provided additionally.
Choose a terminal viewer program for
This can be a file name or a program to be searched in
arguments can be provided additionally.
Equivalent to
Equivalent to
Choose a text pager for mode
The standard pager is
This option is eqivalent to
option
The option argument can be a file name or a program to be searched in
arguments can be provided additionally.
This is equivalent to
because the programs for
mode run on a terminal anyway.
Equivalent to
Equivalent to
Equivalent to
Equivalent to
Suitable viewer programs are
which is the default and
The argument can be any executable file or a program in
arguments can be provided additionally.
Choose a terminal viewer program for
The argument can be any executable file or a program in
arguments can be provided additionally.
Signals the end of option processing; all remaining arguments are
interpreted as
parameters.
Besides these,
accepts all short options that are valid for the
program.
All
options are sent unmodified via
to
So postprocessors, macro packages, compatibility with
and much more can be manually specified.
Enable five debugging informations.
The temporary files are kept and not deleted, the name of the
temporary directory and the shell name for
are printed, the parameters are printed at several steps of
development, and a function stack is output with function
Neither the function call stack that is printed at each opening and
closing of a function call nor the landmark information that is
printed to determine how far the program is running are used.
This seems to be the most useful among all debugging options.
Enable all seven debugging informations including the function call
stack and the landmark information.
Enable two debugging information, the printing of the name of the
temporary directory and the keeping of the temporary files.
Enable one debugging information, the landmark information.
Enable one debugging information, the parameters at several steps.
Enable one debugging information, the shell name for
Enable one debugging information, the function call stack.
Enable one debugging information, the name of the temporary directory.
Enable one debugging information, the function stack with
This is like
but without the output; no viewer is started.
This makes only sense in development.
Just print the argument to standard error.
This is good for parameter check.
Specify the shell under which the
script should be run.
This option overwrites the automatic shell determination of the
program.
If the argument
is empty a former shell option and the automatic shell determination
is cancelled and the default shell is restored.
Some shells run considerably faster than the standard shell.
Output the roff source code of the input files without further
processing.
This is the equivalent
This is an advanced option for debugging only.
Instead of displaying the formatted input, a lot of
specific information is printed to standard output:
the output file name in the temporary directory,
the display mode of the actual
run,
the display program for viewing the output with its arguments,
the active parameters from the config files, the arguments in
and the arguments of the command line,
the pipeline that would be run by the
program, but without executing it.
Other useful debugging options are the
option
and
All short options of
are compatible with the short options of
The following of
options have either an additional special meaning within
or make sense for normal usage.
Because of the special outputting behavior of the
option
was designed to be switched into
the
viewing features are disabled there.
The other
options do not switch the mode, but allow to customize the formatting
process.
This generates an ascii approximation of output in the
That could be important when the text pager has problems with control
sequences in
Add
as a
macro file.
This is useful in case it cannot be recognized automatically.
Send the argument
as an option or option argument to the actual
postprocessor.
This option determines
output device.
The most important devices are the text output devices for referring
to the different character sets, such as
and others.
Each of these arguments switches
into a
using this device, to
if the actual mode is not a
The following
arguments are mapped to the corresponding
option:
and
All
arguments are mapped to
Each other
argument switches to
using this device.
is equivalent to
It displays the
with
As the quality is relatively bad this option is deprecated; use
instead because the
uses an
device for a better display.
Switch into
and format the input with the
without postprocessing; see
This is equivalent to option
of
which can be used as well.
All other
options are supported by
but they are just transparently transferred to
without any intervention.
The options that are not explicitly handled by
are transparently passed to
Therefore these transparent options are not documented here, but in
Due to the automatism in
none of these
options should be needed, except for advanced usage.
Start the
command or facility of
for searching the
arguments within all
descriptions.
Each
argument is taken for search as it is; section specific parts are not
handled, such that
searches for the two arguments
and
with a large result; for the
nothing will be found.
The display differs from the
program by the following concepts:
construct a
frame to the output of
each
argument is searched on its own.
the restriction by
is handled as well,
wildcard characters are allowed and handled without a further option.
Show only the
descriptions for data documents, these are the
sections 4, 5, and 7.
Direct section declarations are ignored, wildcards are accepted.
Show only the
descriptions for development documents, these are the
sections 2, 3, and 9.
Direct section declarations are ignored, wildcards are accepted.
Show only the
descriptions for documents on programs, these are the
sections 1, 6, and 8.
Direct section declarations are ignored, wildcards are accepted.
For each
argument search all
This differs from
output by the following concepts
each retrieved file name is added,
local files are handled as well,
the display is framed by a
output format,
wildcard characters are allowed without a further option.
The following two options were added to
for choosing whether the file name arguments are interpreted as names
for local files or as a search pattern for
The default is looking up for local files.
Check the non-option command line arguments
first on being
then whether they represent an existing file.
By default, a
is first tested whether it is an existing file.
Do not check for
is the corresponding
option.
Disable former calls of
and
The long options of
are recognized, but not all of these options are important to
so most of them are just ignored.
In the following, the
options that have a special meaning for
are documented.
program can be passed via the environment variable
see
installed.
In searching
retrieve all suitable documents instead of only one.
In
display ASCII translation of special characters for critical environment.
This is equivalent to
see
Eqivalent to
Restrict
search to file names that have
appended to their section element.
For example, in the file name
the
extension is
Set the language for
This has the same effect, but overwrites
Print the location of the retrieved files to standard error.
Do not display the location of retrieved files; this resets a former
call to
This was added by
Use the specified search path for retrieving
instead of the program defaults.
If the argument is set to the empty string "" the search for
is disabled.
Set the pager program in
default is
This is equivalent to
Restrict searching for
to the given
a colon-separated list.
Search for
for the given operating systems; the argument
is a comma-separated list.
Eqivalent to
The following long options were adapted from the corresponding
will pass them to the actual viewer program if it is an
Otherwise these options are ignored.
Unfortunately these options use the old style of a single minus for
long options.
For
that was changed to the standard with using a double minus for long
options, for example,
uses the option
See
for more details on these options and their arguments.
Set the background color of the viewer window.
Specifies the color of the border surrounding the viewer window.
This is equivalent to
Specifies the width in pixels of the border surrounding the viewer
window.
syntax of the argument.
Set the foreground color of the viewer window.
This is equivalent to
Set the font used by the viewer window.
This is equivalent to
Set the geometry of the display window, that means its size and its
starting position.
See
for the syntax of the argument.
viewer programs.
The only supported dpi values are
and
Actually, the default resolution for
is set to
The resolution also sets the default device in
Reverse foreground and background color of the viewer window.
Set the title for the viewer window.
A
parameter is an argument that is not an option or option argument.
It means an input source.
In
parameters are a file name or a template for searching
These input sources are collected and composed into a single output
file such as
does.
the first non-option argument as
arguments is ignored.
arguments is used througout.
But, as usual, the double minus argument
ends the option handling and interprets all following arguments as
For the following, it is necessary to know that on each system the
are sorted according to their content into several sections.
The
have a single-character name, either a digit from
to
or one of the characters
or
In the following, a stand-alone character
stands for a
The internal precedence of
for searching
with the same name within several sections goes according to the
classical single-character sequence.
On some systems, this single character can be extended by a following
string.
But the special
facility is based on the classical single character sections.
Each
parameter can have one of the following forms in decreasing sequence.
No
parameters means that
waits for standard input.
The minus option
stands for standard input, too; it can occur several times.
Next a
is tested whether it is the path name of an existing file.
Otherwise it is assumed to be a searching pattern for a
and
where
can be any string, but it must exist in the
system.
Next some patterns based on the
are checked.
and
if
is a
mentioned above.
Otherwise a
named
is searched in the lowest
Now
searches for a
in the lowest
that has a document called
The pattern
originates from a strange argument parsing of the
program.
If
is a
interpret it as a search for a
called
otherwise interpret both
and
as two independent
arguments.
We are left with the argument
which is not an existing file.
So this searches for the
called
in the lowest
that has a document for this name.
Wildcards in
arguments are only accepted for
and
for normal display, they are interpreted as characters.
Several file name arguments can be supplied.
They are mixed by
into a single document.
Note that the set of option arguments must fit to all of these file
arguments.
So they should have at least the same style of the
language.
By default, the
program collects all input into a single file, formats it with the
program for a certain device, and then chooses a suitable viewer
program.
The device and viewer process in
is called a
The mode and viewer of a running
program is selected automatically, but the user can also choose it
with options.
The modes are selected by option the arguments of
Additionally, each of this argument can be specified as an option of
its own, such as
Most of these modes have a viewer program, which can be chosen by an
option that is constructed like
Several different modes are offered, graphical modes for
and some direct
for debugging and development.
By default,
first tries whether
is possible, then
and finally
This mode testing sequence for
can be changed by specifying a comma separated list of modes with the
option
The searching for
and the decompression of the input are active in every mode.
environment (or similar implementations within other windowing
environments).
The environment variable
and the option
If this environment variable is empty
You can change this automatic behavior by the option
Known viewers for the graphical display modes and their standard
viewers such as
or
(in
in a Postscript viewer
in a dvi viewer program
in a PDF viewer
in a web browser
or
The
allows to search for text within the viewer; this can be a really
important feature.
Unfortunately, it takes some time to transform the input into the PDF
format, so it was not chosen as the major mode.
These graphical viewers can be customized by options of the
But the
options use a leading double minus instead of the single minus used by
There are two modes for text output,
for plain output without a pager and
for a text output on a text terminal using some pager program.
If the variable
is not set or empty,
assumes that it should use
In the actual implementation, the
output device
is chosen for
This can be changed by specifying option
or
The pager to be used can be specified by one of the options
and
or by the environment variable
If all of this is not used the
program with the option
for correctly displaying control sequences is used as the default
pager.
These modes use the
file determination and decompression.
This is combined into a single input file that is fed directly into
with different strategy without the
viewing facilities.
These modes are regarded as advanced, they are useful for debugging
and development purposes.
The
with option
and
just displays the decompressed input.
The
passes the input to
using only some suitable options provided to
This enables the user to save the generated output into a file or pipe
it into another program.
In
the option
disables post-processing, thus producing the
In this mode, the input is formatted, but not postprocessed; see
for details.
All
short options are supported by
The default behavior of
is to first test whether a file parameter represents a local file; if
it is not an existing file name, it is assumed to represent a name of
a
This behavior can be modified by the following options.
forces to interpret all file parameters as
for searching
disable the
searching; so only local files are displayed.
If neither a local file nor a
was retrieved for some file parameter a warning is issued on standard
error, but processing is continued.
The
program provides a search facility for
All long options, all environment variables, and most of the
program were implemented.
This inludes the extended file names of
for example, the
of
where
and the file extension
shows the compression of the file.
The
(preformatted
are intentionally excluded from the search because
is a
program that wants to format by its own.
With the excellent performance of the actual computers, the
preformatted
aren't necessary any longer.
The algorithm for retrieving
uses five search methods.
They are successively tried until a method works.
The search path can be manually specified by using the option
An empty argument disables the
searching.
This overwrites the other methods.
If this is not available the environment variable
is searched.
If this is empty, the program tries to read it from the environment
variable
If this does not work a reasonable default path from
is searched for
If this does not work, the
program for determining a path of
directories is tried.
After this, the path elements for the language (locale) and operating
system specific
are added to the
their sequence is determined automatically.
For example, both
and
for french linux
are found.
The language and operating system names are determined from both
environment variables and command line options.
that is from highest to lowest precedence:
The language locale is usually specified in the
but the two-letter code in
is sufficient for most purposes.
If no
for a complicated locale are found the country part consisting of the
If still not found the corresponding
in the default language is used instead.
The
in the default language are usually in English.
Several operating systems can be given by appending their names,
separated by a comma.
This is then specified by the environment variable
or by the command line option
The precedence is similar to the locale case above from highest to
lowest precedence:
Topic
When searching for
this
with the additional language and system specific directories is used.
The search can further be restricted by limiting it to certain
sections.
A single section can be specified within each
argument, several sections as a colon-separated list in command line
option
or environment variable
When no section was specified a set of standard sections is searched
until a suitable
was found.
Finally, the search can be restricted to a so-called
This is a postfix that acts like a subsection.
It can be specified by
or environment variable
For further details on
searching, see
The program has a decompression facility.
If standard input or a file that was retrieved from the command line
parameters is compressed with a format that is supported by either
or
it is decompressed on-the-fly.
and the traditional
compression.
The program displays the concatenation of all decompressed input in
the sequence that was specified on the command line.
The
program supports many system variables, most of them by courtesy of
other programs.
All environment variables of
and some standard system variables are honored.
Store options for a run of
The options specified in this variable are overridden by the options
given on the command line.
The content of this variable is run through the shell builtin `eval';
so arguments containing white-space or special shell characters should
be quoted.
Do not forget to export this variable, otherwise it does not exist
during the run of
The
program is a shell script that is run through
which can be internally linked to programs like
The corresponding system environment is automatically effective.
The following variables have a special meaning for
system is running.
Testing this variable decides on whether graphical or text output is
generated.
This variable should not be changed by the user carelessly, but it can
be used to start the graphical
For example, depending on your system,
can be started on the second monitor by the command
If one of these variables is set (in the above sequence), its content
is interpreted as the locale, the language to be used, especially when
retrieving
A locale name is typically of the form
where
is an ISO 639 language code,
is an ISO 3166 country code, and
is a character set or encoding identifier like ISO-8859-1 or UTF-8;
see
stand for the default, i.e. the
directories without a language prefix.
This variable can be used to set the pager for the tty output.
For example, to disable the use of a pager completely set this
variable to the
program
All programs within the
shell script are called without a fixed path.
Thus this environment variable determines the set of programs used
within the run of
The
program internally calls
so all environment variables documented in
are internally used within
as well.
The following variable has a direct meaning for the
program.
If the value of this variable is an existing, writable directory,
uses it for storing its temporary files, just as
does.
Parts of the functionality of the
program were implemented in
support for all environment variables documented in
was added to
but the meaning was slightly modified due to the different approach in
but the user interface is the same.
The
environment variables can be overwritten by options provided with
which in turn is overwritten by the command line.
Restrict the search for
to files having this extension.
This is overridden by option
see there for details.
This variable contains options as a preset for
As not all of these are relevant for
only the essential parts of its value are extracted.
The options specified in this variable overwrite the values of the
other environment variables that are specific to
All options specified in this variable are overridden by the options
given on the command line.
If set, this variable contains the directories in which the
trees are stored.
This is overridden by option
If this is a colon separated list of section names, the search for
is restricted to those manual sections in that order.
This is overridden by option
If this is set to a comma separated list of names these are interpreted
as
trees for different operating systems.
This variable can be overwritten by option
see there for details.
The environment variable
is ignored by
because the necessary preprocessors are determined automatically.
The
program can be preconfigured by two configuration files.
System-wide configuration file for
User-specific configuration file for
where
denotes the user's home directory.
This file is called after the system-wide configuration file to enable
overriding by the user.
The precedence of option delivery is given in the following.
The configuration file in
has the lowest precedence; it is overwritten by the configuration file
in the home directory; both configuration files are overwritten by the
environment variable
everything is overwritten by the command line.
In the configuration files, arbitrary spaces are allowed at the
beginning of each line, they are just ignored.
Apart from that, the lines of the configuration lines either start
with a minus character, all other lines are interpreted as shell
commands.
The lines with the beginning minus are interpreted as
options.
This easily allows to set general
options that should be used with any call of
Each line can represent a single short option, a short option cluster,
or a long option with two minus signs, eventually with an argument.
The argument can be appended either after a space character or an
equal sign
The argument can be surrounded by quotes, but this is not necessary.
The options from these lines are collected and prepended to the
existing value of
at the end of each configuration file.
After the transformation of the minus lines, the configuration files
have been transferred into a shell script that is called within
shell syntax.
It makes sense to use these configuration files for the following
tasks:
Preset command line options, such as choosing a
or a viewer.
These are written into lines starting with a single or double minus
sign, followed by the option name.
Preset environment variables recognized by
but do not forget to export them.
You can also write a shell function for calling, for example a viewer
program for some
Such a function can be fed into a corresponding
option.
Enter
to specify a shell for the run of
Some shells run much faster than the standard shell.
As an example, consider the following configuration file in
say.
# groffer configuration file
#
# groffer options that are used in each call of groffer
#
# some shell commands
if test "$DISPLAY" = ""; then
  export DISPLAY='localhost:0.0'
fi
The lines starting with
are command lines.
This configuration sets four
rest of the script).
This has the following effects:
Use
as the shell to run the
script; if it works it should be faster than the usual
Use a text color of
in all viewers that support this, such as
Use a resolution of
in all viewers that support this, such as
By this, the default device in
is set to
Force
as the
viewer using the geometry option for setting the width to
and the height to
This geometry is suitable for a resolution of
If the environment variable
is empty set it to
That allows to start
is called from a text console.
Just for fun, the date of each
start is written to the file
in the home directory.
The usage of
is very easy.
Usually, it is just called with a file name or
The following examples, however, show that
has much more fancy capabilities.
Decompress, format and display the compressed file
in the directory
using the standard viewer
If the file
exists use it as input.
Otherwise interpret the argument as a search for the
named
in the smallest possible
being section 1 in this case.
search for the
of
even when the file
exists.
search the
of
in
This section search works only for a digit or a single character from
a small set.
If the file
does not exist interpret this as a search for the
of
As the extension
is not a single character in classical section style the argument is
not split to a search for
The arguments that are not existing files are looked-up as the
following
and
The quotes around
are necessary because the paranthesis are special shell characters;
escaping them with a backslash character
and
would be possible, too.
The formatted files are concatenated and displayed in one piece.
Retrieve the German
(language
for the
program, decompress it, format it to
format
and view the result in the web browser
The option
guarantees that the
is retrieved, even when a local file
exists in the actual directory.
Get the
called
content, its source code.
Decompress the standard input, send this to
without post-processing
option
using macro package by
option
bold font, using color yellow on red background.
The
program consists of two shell scripts.
The starting script is the file
that is installed in a
directory.
It is generated from the source file
It is just a short starting script without any functions such that it
can run on very poor shells.
The main part of the
program is the file
that is installed in the
library directory.
This script can be run under a different shell by using the
option
Both scripts are compatible with both
available in the internet at
Only a restricted set of shell language elements and shell builtins is
used to achieve even compatibility with some Bourne shells that are
The
shell scripts were tested on many shells, including the following
Bourne shells:
and
So it should work on most actual free and commercial operating
systems.
The shell for the run of
can be chosen by the option
on the command line or the environment variable
If you want to add it to one of the
configuration files you must write a line starting with
The
program provides its own parser for command line arguments that is
It can handle option arguments and file names containing white space
and a large set of special characters.
The following standard types of options are supported.
The option consisiting of a single minus
refers to standard input.
A single minus followed by characters refers to a single character
option or a combination thereof; for example, the
short option combination
is equivalent to
Long options are options with names longer than one character; they
are always preceded by a double minus.
An option argument can either go to the next command line argument or
be appended with an equal sign to the argument; for example,
is equivalent to
An argument of
ends option parsing; all further command line arguments are
interpreted as
parameters, i.e. file names or constructs for searching
All command line arguments that are neither options nor option
arguments are interpreted as
parameters and stored until option parsing has finished.
For example, the command line
is equivalent to
The free mixing of options and
parameters follows the GNU principle.
that ends option processing as soon as the first non-option argument
has been reached.
The end of option processing can be forced by the option
anyway.
Report bugs to the
Include a complete, self-contained example that will allow the bug to
be reproduced, and say which version of
you are using.
You can also use the
but you must first subscribe to this list.
You can do that by visiting the
"groff mailing list web page" .
See
for information on availability.
Details on the options and environment variables available in
all of them can be used with
Documentation of the
language.
Internally,
tries to guess the
command line options from the input using this program.
Documentation on the
output).
Documentation on the
macro files.
The standard program to display
The information there is only useful if it is the
for GNU
Then it documents the options and environment variables that are
supported by
Bourne shells that were tested with
Viewers for
Viewers for
Viewers for
Viewers for
Web-browsers for
or
Standard pager program for the
The decompression programs supported by
Copyright (C) 1989-2000, 2001, 2002, 2003 Free Software Foundation, Inc.

Permission is granted to make and distribute verbatim copies of
this manual provided the copyright notice and this permission notice
are preserved on all copies.

How to run the AppleFileServer
The AppleFileServer is typically launched using the Sharing Preference. Launch System Preferences. Select Sharing. Select the Services tab. Select Personal File Sharing and click start.
Please refer to Server help
AppleFileServer [-d]
The -d option will prevent daemonization.
AppleFileServer -v
Use the .Nm macro to refer to your program throughout the man page like such:
Underlining is accomplished with the .Ar macro like this:
A list of items with descriptions:
Description of item a
Description of item b
A list of flags and their descriptions:
Description of -a flag
Description of -b flag
FILE_1 description
FILE_2 description
Use the .Nm macro to refer to your program throughout the man page like such:
Underlining is accomplished with the .Ar macro like this:
A list of items with descriptions:
Description of item a
Description of item b
A list of flags and their descriptions:
Description of -a flag
Description of -b flag
FILE_1 description
FILE_2 description
Use the .Nm macro to refer to your program throughout the man page like such:
Underlining is accomplished with the .Ar macro like this:
A list of items with descriptions:
Description of item a
Description of item b
A list of flags and their descriptions:
Description of -a flag
Description of -b flag
FILE_1 description
FILE_2 description
standard output.
Options include:
sets debugging flags.
switch.
specifies the names of the input fields if input does not have to be
split into an array.  If you were translating an awk script that
processes the password file, you might say:
Any delimiter can be used to separate the field names.
causes a2p to assume that input will always have that many fields.
tells a2p to use old awk behavior.  The only current differences are:
Old awk always has a line loop, even if there are no line
actions, whereas new awk does not.
In old awk, sprintf is extremely greedy about its arguments.
For example, given the statement
A2p cannot do as good a job translating as a human would, but it
usually does pretty well.  There are some areas where you may want to
examine the perl script produced and tweak it some.  Here are some of
them, in no particular order.
force numeric interpretation, even though the argument is always
integer anyway.  This is generally unneeded in perl, but a2p can't
tell if the argument is always going to be integer, so it leaves it
in.  You may wish to remove it.
Perl differentiates numeric comparison from string comparison.  Awk
has one operator for both that decides at run time which comparison to
do.  A2p does not try to do a complete job of awk emulation at this
point.  Instead it guesses which one you want.  It's almost always
right, but it can be spoofed.  All such guesses are marked with the
warn you if you use == where you should have used eq.
Perl does not attempt to emulate the behavior of awk in which
nonexistent array elements spring into existence simply by being
referenced.  If somehow you are relying on this mechanism to create
null entries for a subsequent for...in, they won't be there in perl.
If a2p makes a split line that assigns to a list of variables that
looks like (Fld1, Fld2, Fld3...) you may want to rerun a2p using the
throughout the script.  If it splits to an array instead, the script
is probably referring to the number of fields somewhere.
block to bypass the block under such circumstances can be simplified
from the perl script.
Perl has two kinds of array, numerically-indexed and associative.
translated to hashes, but if you happen to know that the index is
always going to be numeric you could change the {...} to [...].
over such an array.
assuming its equivalent, $#, to have the value %.20g.  You'll want to
Near the top of the line loop will be the split operation that is
implicit in the awk script.  There are times when you can move this
down past some conditionals that test the entire record so that the
split is not done as often.
For aesthetic reasons you may wish to change index variables from being
operations the variable is involved in to match.
are passed through unmodified.
Awk scripts are often embedded in a shell script that pipes stuff into
and out of awk.  Often the shell script wrapper can be incorporated
into the perl script, since perl can start up pipes into and out of
itself, and can do other things that awk can't do by itself.
often be simplified by referring to the variables $`, $& and $', as
long as they are within the scope of the pattern match that sets them.
The produced perl script may have subroutines defined to deal with
awk's semantics regarding getline and print.  Since a2p usually picks
correctness over efficiency.  it is almost always possible to rewrite
such code to be more efficient by discarding the semantic sugar.
For efficiency, you may wish to remove the keyword from any return
statement that is the last statement executed in a subroutine.  A2p
catches the most common case, but doesn't analyze embedded blocks for
subtler cases.
loop that tries to iterate over ARGV[0] won't find it.
A2p uses no environment variables.
It would be possible to emulate awk's behavior in selecting string
versus numeric operations at run time by inspection of the operands,
but it would be gross and inefficient.  Besides, a2p almost always
guesses right.
Storage for the awk syntax tree is currently static, and can run out.
standard output.
Options include:
sets debugging flags.
switch.
specifies the names of the input fields if input does not have to be
split into an array.  If you were translating an awk script that
processes the password file, you might say:
Any delimiter can be used to separate the field names.
causes a2p to assume that input will always have that many fields.
tells a2p to use old awk behavior.  The only current differences are:
Old awk always has a line loop, even if there are no line
actions, whereas new awk does not.
In old awk, sprintf is extremely greedy about its arguments.
For example, given the statement
A2p cannot do as good a job translating as a human would, but it
usually does pretty well.  There are some areas where you may want to
examine the perl script produced and tweak it some.  Here are some of
them, in no particular order.
force numeric interpretation, even though the argument is always
integer anyway.  This is generally unneeded in perl, but a2p can't
tell if the argument is always going to be integer, so it leaves it
in.  You may wish to remove it.
Perl differentiates numeric comparison from string comparison.  Awk
has one operator for both that decides at run time which comparison to
do.  A2p does not try to do a complete job of awk emulation at this
point.  Instead it guesses which one you want.  It's almost always
right, but it can be spoofed.  All such guesses are marked with the
warn you if you use == where you should have used eq.
Perl does not attempt to emulate the behavior of awk in which
nonexistent array elements spring into existence simply by being
referenced.  If somehow you are relying on this mechanism to create
null entries for a subsequent for...in, they won't be there in perl.
If a2p makes a split line that assigns to a list of variables that
looks like (Fld1, Fld2, Fld3...) you may want to rerun a2p using the
throughout the script.  If it splits to an array instead, the script
is probably referring to the number of fields somewhere.
block to bypass the block under such circumstances can be simplified
from the perl script.
Perl has two kinds of array, numerically-indexed and associative.
translated to hashes, but if you happen to know that the index is
always going to be numeric you could change the {...} to [...].
over such an array.
assuming its equivalent, $#, to have the value %.20g.  You'll want to
Near the top of the line loop will be the split operation that is
implicit in the awk script.  There are times when you can move this
down past some conditionals that test the entire record so that the
split is not done as often.
For aesthetic reasons you may wish to change index variables from being
operations the variable is involved in to match.
are passed through unmodified.
Awk scripts are often embedded in a shell script that pipes stuff into
and out of awk.  Often the shell script wrapper can be incorporated
into the perl script, since perl can start up pipes into and out of
itself, and can do other things that awk can't do by itself.
often be simplified by referring to the variables $`, $& and $', as
long as they are within the scope of the pattern match that sets them.
The produced perl script may have subroutines defined to deal with
awk's semantics regarding getline and print.  Since a2p usually picks
correctness over efficiency.  it is almost always possible to rewrite
such code to be more efficient by discarding the semantic sugar.
For efficiency, you may wish to remove the keyword from any return
statement that is the last statement executed in a subroutine.  A2p
catches the most common case, but doesn't analyze embedded blocks for
subtler cases.
loop that tries to iterate over ARGV[0] won't find it.
A2p uses no environment variables.
It would be possible to emulate awk's behavior in selecting string
versus numeric operations at run time by inspection of the operands,
but it would be gross and inefficient.  Besides, a2p almost always
guesses right.
Storage for the awk syntax tree is currently static, and can run out.
standard output.
Options include:
sets debugging flags.
switch.
specifies the names of the input fields if input does not have to be
split into an array.  If you were translating an awk script that
processes the password file, you might say:
Any delimiter can be used to separate the field names.
causes a2p to assume that input will always have that many fields.
tells a2p to use old awk behavior.  The only current differences are:
Old awk always has a line loop, even if there are no line
actions, whereas new awk does not.
In old awk, sprintf is extremely greedy about its arguments.
For example, given the statement
A2p cannot do as good a job translating as a human would, but it
usually does pretty well.  There are some areas where you may want to
examine the perl script produced and tweak it some.  Here are some of
them, in no particular order.
force numeric interpretation, even though the argument is always
integer anyway.  This is generally unneeded in perl, but a2p can't
tell if the argument is always going to be integer, so it leaves it
in.  You may wish to remove it.
Perl differentiates numeric comparison from string comparison.  Awk
has one operator for both that decides at run time which comparison to
do.  A2p does not try to do a complete job of awk emulation at this
point.  Instead it guesses which one you want.  It's almost always
right, but it can be spoofed.  All such guesses are marked with the
warn you if you use == where you should have used eq.
Perl does not attempt to emulate the behavior of awk in which
nonexistent array elements spring into existence simply by being
referenced.  If somehow you are relying on this mechanism to create
null entries for a subsequent for...in, they won't be there in perl.
If a2p makes a split line that assigns to a list of variables that
looks like (Fld1, Fld2, Fld3...) you may want to rerun a2p using the
throughout the script.  If it splits to an array instead, the script
is probably referring to the number of fields somewhere.
block to bypass the block under such circumstances can be simplified
from the perl script.
Perl has two kinds of array, numerically-indexed and associative.
translated to hashes, but if you happen to know that the index is
always going to be numeric you could change the {...} to [...].
over such an array.
assuming its equivalent, $#, to have the value %.20g.  You'll want to
Near the top of the line loop will be the split operation that is
implicit in the awk script.  There are times when you can move this
down past some conditionals that test the entire record so that the
split is not done as often.
For aesthetic reasons you may wish to change index variables from being
operations the variable is involved in to match.
are passed through unmodified.
Awk scripts are often embedded in a shell script that pipes stuff into
and out of awk.  Often the shell script wrapper can be incorporated
into the perl script, since perl can start up pipes into and out of
itself, and can do other things that awk can't do by itself.
often be simplified by referring to the variables $`, $& and $', as
long as they are within the scope of the pattern match that sets them.
The produced perl script may have subroutines defined to deal with
awk's semantics regarding getline and print.  Since a2p usually picks
correctness over efficiency.  it is almost always possible to rewrite
such code to be more efficient by discarding the semantic sugar.
For efficiency, you may wish to remove the keyword from any return
statement that is the last statement executed in a subroutine.  A2p
catches the most common case, but doesn't analyze embedded blocks for
subtler cases.
loop that tries to iterate over ARGV[0] won't find it.
A2p uses no environment variables.
It would be possible to emulate awk's behavior in selecting string
versus numeric operations at run time by inspection of the operands,
but it would be gross and inefficient.  Besides, a2p almost always
guesses right.
Storage for the awk syntax tree is currently static, and can run out.


 
 

 
 

 
 
-d
-h
-i
-k
-l
-q
-r
-S
-V
-w
 
 
The following list describes the values returned by ab:
 
 
Server Software
Server Hostname
The DNS or IP address given on the command line  
Server Port
Document Path
Document Length
Concurrency Level
The number of concurrent clients used during the test  
Time taken for tests
This is the time taken from the moment the first socket connection is created to the moment the last response is received  
Complete requests
The number of successful responses received  
Failed requests
Write errors
Non-2xx responses
Keep-Alive requests
The number of connections that resulted in Keep-Alive requests  
Total body sent
Total transferred
HTML transferred
Requests per second
Time per request
Transfer rate
 
 
 
 
CLI interface to the accessibility API.
There are no configuration options.
Copyright (C) 1989-2000, 2001 Free Software Foundation, Inc.

Permission is granted to make and distribute verbatim copies of
this manual provided the copyright notice and this permission notice
are preserved on all copies.

Permission is granted to copy and distribute modified versions of this
manual under the conditions for verbatim copying, provided that the
entire resulting derived work is distributed under the terms of a
permission notice identical to this one.

Permission is granted to copy and distribute translations of this
manual into another language, under the above conditions for modified
versions, except that this permission notice may be included in
translations approved by the Free Software Foundation instead of in
the original English.
[
]
[
]
reads a troff font file
and adds some additional font-metric information
that is used by the groff system.
The font file with the information added is written on the
standard output.
The information added is guessed using 
some parametric information about the font
and assumptions
about the traditional troff names for characters.
The main information added is the heights and depths of characters.
The
and
arguments should be the same as the corresponding parameters
in the DESC file;
is the name of the file describing the font;
if
ends with
the font will be assumed to be italic.
prints the version number.
All other options changes one of the parameters that is used
to derive the heights and depths.
Like the existing quantities in the font
file, each
is in
for a font whose point size is
must be one of:
The height of lowercase letters without ascenders such as x.
The height of figures (digits).
The height of characters with ascenders, such as b, d or l.
The height of characters such as parentheses.
The height of uppercase letters such as A.
The depth of a comma.
The depth of characters with descenders, such as p,q, or y.
The depth of characters such as parentheses.
makes no attempt to use the specified parameters to guess
the unspecified parameters.
If a parameter is not specified the default will be used.
The defaults are chosen to have the reasonable values for
a Times font.
Audio File Convert will convert a source audio file to a new audio file with the specified file and data types
print help text
Audio File Hash writes an SHA-1 hash to an audio file or prints (to stdout) the hash contained in an audio file
print help text
write hash code to audio file
print hash code from audio file (if present)
compare hash codes from two audio files
afida compares a reference audio file with a distorted version and estimates the perceivable spatial image distortions in terms of image shift and width.
print help text
Audio File Info prints out information about an audio file to stdout
Copyright (C) 1989-2000, 2001, 2002, 2003, 2005 Free Software Foundation, Inc.

Permission is granted to make and distribute verbatim copies of
this manual provided the copyright notice and this permission notice
are preserved on all copies.

Permission is granted to copy and distribute modified versions of this
manual under the conditions for verbatim copying, provided that the
entire resulting derived work is distributed under the terms of a
permission notice identical to this one.

Permission is granted to copy and distribute translations of this
manual into another language, under the above conditions for modified
versions, except that this permission notice may be included in
translations approved by the Free Software Foundation instead of in
the original English.
The whitespace between an command line option and its argument is optional.
creates a font file for use with groff and
is written in perl;
you must have perl version 5.004 or newer installed in order to run
is the AFM (Adobe Font Metric) file for the font.
is a file that says which groff character names map onto
each PostScript character name;
this file should contain a sequence of lines of the form
ps_char groff_char
where
is the PostScript name of the character
and
is the groff name of the character (as used in the groff font file).
The same
can occur multiple times in the file;
each
must occur at most once.
Lines starting with
and blank lines are ignored.
If the file isn't found in the current directory, it is searched in
If a PostScript character is not named as
are four uppercase hexadecimal digits), and is not mentioned in
and a generic groff glyph name can't be deduced using the
Adobe Glyph List (AGL, built into
then
puts the PostScript character into the groff font file as an unnamed
character which can only be accessed by the
escape sequence in
If option
is not specified, the encoding defined in the AFM file (i.e., entries
with non-negative character codes) is used.
Please refer to section `Using Symbols' in the groff info file which
describes how groff glyph names are constructed.
the character code) are still available in groff; they get glyph index
values greater than 255 (or greater than the biggest character code used
in the AFM file in the unlikely case that it is greater than 255) in the
groff font file.
Glyph indices of unencoded characters don't have a specific order; it
is best to access them with glyph names only.
The groff font file will be output to a file called
If there is a downloadable font file for the font, it may be listed in
the file
see
If the
option is used,
will automatically generate an italic correction,
a left italic correction and a subscript correction
for each character
(the significance of these parameters is explained in
these parameters may be specified for individual characters by
adding to the
lines of the form:
where
is the PostScript name of the character,
and
is the desired value of the corresponding parameter in thousandths of an em.
These parameters are normally needed only for italic (or oblique) fonts.
Use
as the slant parameter in the font file;
this is used by groff in the positioning of accents.
By default
uses the negative of the ItalicAngle specified in the afm file;
with true italic fonts it is sometimes desirable to use
a slant that is less than this.
If you find that characters from an italic font have accents
placed too far to the right over them,
then use the
option to give the font a smaller slant.
The device description file is
rather than the default
If not found in the current directory, the `devps' subdirectory of the
default font directory is searched (this is true for both the default
device description file and a file given with option
The PostScript font should be reencoded to use the encoding described
in enc_file.
The format of
is described in
If not found in the current directory, the `devps' subdirectory of the
default font directory is searched.
Generate an italic correction for each character so that 
the character's width plus the character's italic correction
is equal to
thousandths of an em
plus the amount by which the right edge of the character's bounding box
is to the right of the character's origin.
If this would result in a negative italic correction, use a zero
italic correction instead.
Also generate a subscript correction equal to the 
product of the tangent of the slant of the font and
four fifths of the x-height of the font.
If this would result in a subscript correction greater than the italic
correction, use a subscript correction equal to the italic correction
instead.
Also generate a left italic correction for each character
equal to
thousandths of an em
plus the amount by which the left edge of the character's bounding box
is to the left of the character's origin.
The left italic correction may be negative unless option
is given.
This option is normally needed only with italic (or oblique) fonts.
The font files distributed with groff were created using an option of
for italic fonts.
Prevent negative left italic correction values.
Roman font files distributed with groff were created with
to improve spacing with
Don't output a
command for this font.
Use this with constant-width fonts.
The font is special.
The effect of this option is to add the
command to the font file.
Print version.
Don't use the built-in Adobe Glyph List.
Device description file.
Font description file for font
List of downloadable fonts.
Encoding used for text fonts.
Standard mapping.
The groff info file, section `Using Symbols'.
Audio File Play plays an audio file to the default audio output
print help text
path
The
command is used to decompress files compressed with HFS+ compression.
Paths specified are recursively traversed (while remaining on the starting filesystem) and all encountered files are decompressed. If the
option is specified, the encountered files will not be decompressed, but their contents will be printed to standard output.
first appeared in Mac OS X 10.6..TH AGENTXTRAP 1 "20 Dec 2009" V5.6 "Net-SNMP"
agentxtrap - send an AgentX NotifyPDU to an AgentX master agent
issues an AgentX NotifyPDU to a master agent. One or more object
identifiers (OIDs) can be given as arguments on the command line.
A type and a value must accompany each object identifier.
Each variable name is given in the format specified in
if the
option is present then the notification is sent in the nondefault name context.
if the
option is present then that value, parsed as centiseconds, is taken to be the
sysUpTime field of the application.
if the
option is present then contact the AgentX master at ADDRESS and not the default
one.
Additionally all the options described in
under the
headers as well as the
options are supported.
In
the parsing of the
field is controlled by the
field. The possible values for the
field is one of the following characters:
Let
decide how
should be interpreted
INTEGER
Unsigned
Counter32
OCTET STRING of chaacters
OCTET STRING, entered as a sequence of optionally space separated hexadecimal
digit pairs
OCTET STRING, entered as a sequence of space separated decimal digits in the
range 0 - 255
NULL
OBJECT IDENTIFIER
TimeTicks
IpAddress
BITS
which are handled in the same way as the
command.
To send a generic linkUp trap to the manager for interface 1 the following
command can be used:
agentxtrap netSnmp.0.3 ifindex.1 i 1
snmpcmd(1), snmpset(1), variables(5), RFC 2741
probe
encode
encode
encode
are implemented as a single tool with multiple names.  All invocations
support the three verbs
and
If multiple files are passed to
the exit status will be non-zero only if
files contain data in the specified encoding.
perform the operation even if the output file already exists
display version and usage, then quit
be verbose
display version, then quit
For
read encoded data from the standand input.  For
write encoded data to the standard output.  Currently, "plain" data must
be written to and from specified filenames (see also
create output files in
Use
for output, overriding any stored or default name.  For
the appropriate suffix will be added to
implies only one file to be encoded or decoded.
override the default suffix for the given encoding
don't use BinHex runlength compression when encoding
Specify MacBinary encoding type.  Type 1 is undesirable because it has
neither a checksum nor a signature and is thus difficult to recognize.
In general, the tool returns a non-zero exit status if it fails.
The
command connects to the documents or
resources designated by
and displays each applet
referenced by that document in its own window. 
Note: if the documents referred to by
do not reference any
applets with the
tag,
does nothing.
For details on the HTML tags that appletviewer supports,
The following options are supported:
Starts the applet viewer in the Java debugger,
thus allowing you to debug applets in the document.
(See
Specifies the input
file encoding name.
Passes the string
through as a single argument to 
the Java interpreter
which runs
the appletviewer.
The argument should not contain spaces.
Multiple argument words must all begin with the prefix
which is stripped.
This is useful for adjusting the compiler's execution
environment or compiler memory usage.
The
utility runs the named
on each
argument
in turn.
Character sequences of the form
in
where
is a digit from 1 to 9, are replaced by the
following unused
In this case, the largest digit number of arguments are discarded for
each execution of
The options are as follows:
Normally arguments are taken singly; the optional number
specifies the number of arguments to be passed to
If the number is zero,
is run, without arguments, once for each
If any sequences of
occur in
the
option is ignored.
The use of the character
as a magic character may be changed with the
option.
Display the commands that would have been executed, but do not actually
execute them.
The following environment variable affects the execution of
Pathname of shell to use.
If this variable is not defined, the Bourne shell is used.
is similar to
compares the `a' files to the `b' files;
runs
5 times; and
links all files in the current directory to the directory
default shell
Shell metacharacters in
may have bizarre effects; it is best to enclose complicated
commands in single quotes
The
command appeared in
keyword ...
apropos searches a set of database files containing short descriptions
of system commands for keywords and displays the result on the
standard output.
John W. Eaton was the original author of 
Zeyd M. Ben-Halim released man 1.2, and Andries Brouwer followed up with versions 1.3 thru 1.5p. 
Federico Lucifredi <flucifredi@acm.org> is the current maintainer.
whatis(1), man(1).
[
]
[
]
[
]
[
]
[
]
[
]
[
]
[
]
[
[
[
]
]
]
[
]
[
]
The tool apt, annotation processing tool, includes a set of 
new reflective APIs and supporting infrastructure to
process program annotations. The apt reflective APIs 
provide a build-time, source-based, read-only view of
program structure. These reflective APIs are designed 
to cleanly model the JavaTM programming language's
type system after the addition of generics. First, 
apt runs annotation processors that can produce new source
code and other files. Next, apt can cause compilation of 
both original and generated source files, easing
development. The reflective APIs and other APIs used 
to interact with the tool are subpackages of com.sun.mirror. 
A fuller discussion of how the tool operates as well as  
instructions for developing with apt are in Getting
Started with apt at 
Options may be in any order. For a discussion of parameters 
which apply to a specific option, see OPTIONS below.
Zero or more source files to be processed.
One or more files that list source files or other options.
Specify the directory root under which processor-generated 
source files will be placed; files are placed
in subdirectories based on package namespace. 
Do not compile sources files to class files.
Print out textual representation of specified types; 
perform no annotation processing or compilation. 
Options to pass to annotation processors -- these are 
not interpreted by apt directly, but are made
available for use by individual processors 
Specify where to find annotation processor factories; if 
this option is used, the classpath is not searched
for factories. 
Name of annotation processor factory to use; 
bypasses default discovery process 
Specify where to place processor and javac generated class files 
or
Specify where to find user class files and annotation processor 
factories. If
is given, the
classpath is not searched for factories. 
Consult the 
man page for information on 
options. 
The apt tool and its associated APIs may be changed or 
superseded in future j2se releases. 


 
 
 
 
 
 

 
 
 

      $ httpd -l
    
 
 

      $ apachectl restart
      $ _
    
 
 
 

 
 
 
  
 
 
-q
  
 
 
  
 
 
-g
  
 
 
-c
-p
  
  
 
-i
-a
-A
-e
  
 
 

      $ _
    
 
 

      $ _
    
 
This way a line named
 

    
 
 

    
 
For a quick test of the apxs mechanism you can create a sample Apache module template plus a corresponding Makefile via:
 

      $ apxs -g -n foo
      Creating [DIR]  foo
      $ _
    
 
Then you can immediately compile this sample module into a shared object and load it into the Apache server:
 

      $ cd foo
      $ make all reload
      apachectl restart
      $ _
    
 

The
command with no arguments, displays the machine's architecture type.
The other use of the
command it to run a selected architecture of a universal binary.
A universal binary contains code that can run on different architectures.
By default, the operating system will select the architecture that most closely
matches the processor type.
This means that an intel architecture is selected on intel processors and a
powerpc architecture is selected on powerpc processors.
A 64-bit architecture is preferred over a 32-bit architecture on a 64-bit
processor, while only 32-bit architectures can run on a 32-bit processor.
When the most natural architecture is unavailable, the operating system will
try to pick another architecture.
On 64-bit processors, a 32-bit architecture is tried.
If this is also unavailable, the operating system on an intel processor will
try running a 32-bit powerpc architecture.
Otherwise, no architecture is run, and an error results.
The
command can be used to alter the operating system's normal selection order.
The most common use is to select the 32-bit architecture on a 64-bit processor,
even if a 64-bit architecture is available.
The
argument must be one of the currently supported architectures:
32-bit intel
64-bit intel
Either prefix the architecture with a hyphen, or (for compatibility with
other commands), use
followed by the architecture.
If more than one architecture is specified, the operating system will try each
one in order, skipping an architecture that is not supported on the current
processor, or is unavailable in the universal binary.
The other options are:
Add the native 32-bit architecture to the list of architectures.
Add the native 64-bit architecture to the list of architectures.
Clears the environment that will be passed to the command to be run.
Deletes the named environment variable from the environment that will be passed
to the command to be run.
Assigns the given value to the named environment variable in the environment
that will be passed to the command to be run.
Any existing environment variable with the same name will be replaced.
Prints a usage message and exits.
The
argument is the command to run, followed by any arguments to pass to the
command.
It can be a full or partial path, while a lone name will be looked up in the user's
command search path.
If no architectures are specified on the command line, the
command takes the basename of the
argument and searches for the first property list file with that basename and
the
suffix, in the
sub-directory in each of the standard domains, in the following order:
User settings
Local settings
Network settings
System settings
This property list contains the architecture order preferences, as well
as the full path to the real executable.
For examples of the property list format, look at the files in
On an intel processor:
1234
shows the intel little endian byte order.
When a link is made to
command with a different name, that name is used to find
the corresponding property list file.
Thus, other commands can be wrapped so that they have custom architecture
selection order.
Because of some internal logic in the code, hard links to the
command may not work quite right.
It is best to avoid using hard links, and only use symbolic links to the
command.
The environment variable
can be used to provide architecture order preferences.
It is checked before looking for the corresponding property list file.
The value of the environment variable
is composed of one or more specifiers, separated by semicolons.
A specifier is made up of one, two or three fields, separated by colons.
Architectures specified in order, are separated by commas and make up the last
(mandatory) field.
The first field, if specified, is a name of a program, which selects this
specifier if that name matches the program name in question.
If the name field is empty or there is no name field, the specifier matches
any program name.
Thus, ordering of specifiers is important, and the one with no name should
be last.
When the
command is called directly, the
name provides the path information to the executable (possibly via the command
search path).
When a name is specified in a
specifier, the path information can alternately be specified as a second
field following the name.
When the
command is called indirectly via a link, this path information must be
specified.
If not specified as a second field in a specifier, the executable path will
be looked up in the corresponding property list file.
A specifier that matches any name.
A specifier that matches the program named
(the full executable path is in the
file).
A specifier with all fields specified.
A specifier for
and a second specifier that would match any other name.
Running the
command on an interpreter script may not work if the interpreter is a link
to the arch command, especially if a 64-bit architecture is specified (since the
command is 2-way universal, 32-bit only).
is a facility for manipulating the filesystem container for an applications using App Sandbox.
A container is a per-application filesytem hierarchy rooted in
Prints a summary of commands and their behaviours.
Determines with the given application is signed with App Sandbox entitlements.
In addition, if the application is specified by pid using the --pid syntax,
prints out whether the application is actually running with App Sandbox enabled,
a traditional sandbox, or no sandbox at all.
The following commands manage filesystem containers for sandboxed apps.
Print the path to the application's container.
Create and initialize the application's container.
Containers are normally created automatically when sandboxed applications
are run.
This command creates the container for an application without running the
application.
Upgrade the application's container to the current container schema.
Existing containers are normally automatically upgraded to the latest
container schema when their associated applications are run.
This command upgrades an existing container without running the associated
application.
Repair a container's structure by re-creating missing files and symlinks,
repairing file permissions so that files are owned by and accessible to the current user, and
rebuilding the application's sandbox information.
This operation may require authorization by the user.
Each container has an access control list comprised of code requirements.
A sandboxed application must satify one or more of the code requirements on
their container in order to run.
The following commands manipulate the container's access control list:
Update the access control list for the application's container to
include the application's designated code requirement.
Update the access control list for the application's container to
include the specified code requirement.
Update the access control list for the application's container such
that it consists of only the application's designated code requirement.
Any other code requirements will be removed from the ACL.
Print list of code requirements in the access control list for the
given application's container.
Validate the application against each of the code requirements in its
container's access control list.
Each code requirement in the ACL is labeled with one of the following:
application does not validate against code requirement.
application validates against code requirement.
application validates against code requirement and code requirement is
the same as the application's designated code requirement.
Synonym for acl validate.
App Sandbox will follow any symlinks in the paths to users' home directories.
In addition, it has a whitelist of other locations where it will acknowledge
and honor symbolic links.
Any symlinks not in this whitelist will not be followed and, as a result,
App Sandboxed applications will not have access to the paths that the symlinks
refer to.
The following command displays the whitelist of paths where App Sandbox will
acknowledge symlinks at:
Display the list of paths that App Sandbox searches for symlinks and, for
any paths that are symlinks, display where the symlinks currently resolve to. 
Collect diagnostic information related to Application Sandboxing and containers.
The information is collected into a single file that can be sent to Apple to aid in diagnosing 
problems when an application runs inside of a sandbox.
Should you choose to send the diagnostic information to Apple, then you must agree to this disclaimer:
This diagnostic tool generates files that allow Apple to investigate issues with your computer 
and help Apple to improve its products. The generated files may contain some of your personal 
information, which may include, but not be limited to, the serial number or similar unique number
for your device, your user name, your file names or your computer name. The information is used by Apple in
By enabling this diagnostic tool and sending a copy of the generated files to Apple, you are
consenting to Apple's use of the content of such files.
Additional information concerning a specific application can be gathered via the app subcommand.
This command must be run as 'root'.
The following command collects diagnostic information:
Collection diagnostic information. Outputs the path to the folder or file containing the information. 
Optional arguments:
Do not compress the folder containing the dianostic files into a Zip file.
Do not show the disclaimer. Use of this option constitutes acceptance of the disclaimer.
Do not reveal the resulting diagnostic file in Finder.
Do not show verbose output while running the diagnostic.
Optional subcommand:
Specify an application for which additional information will be gathered.
By default,
displays paths relative to the user's home directory.
This flag causes any paths in the output to be displayed as absolute paths
instead.
Write internal logging information to a temporary file.
Many commands require an application specification as one of their arguments.
Applications can be specified any of the following ways:
The application name as it appears in the Applications folder, with or
For example, "TextEdit".
The path to the application binary or bundle.
For example, 
Explicitly indicate the following argument is to be interpreted as the path
to the application binary or bundle.
The --file flag removes ambiguity when an argument can be interpreted as either
an application name or a valid path to an application.
For example, 
Interpret the following argument as the bunder identifier of the application.
For example, 
Interpret the following argument as the process identifier of a running
application.
For example, 
Interpret the following argument as a path to an existing container and determine the application for that container .
For example, 
The user's containers folder.
The
command first appeared in Mac OS X Version 10.7.
inspects or processes a .car file generated from an asset catalog, removing
requested scale factors, device idioms, subtypes, graphics feature set classes and
memory classes. 
A list of flags and their descriptions:
version information for 
Produce a JSON description of the asset catalog object with the given name to
--output directory if given or to stdout if no output path given. If no name is provided,
report on the contents of the entire car file.
Keep all assets that have idiom that is given on the command
line.
Keep all assets that have scale factor that is given on the command
line, present scale factors will not be removed if there is no fallback available.
Keep all assets that have memory class that is given on the command
line, present memory class will not be removed if there is no fallback available.
Keep all assets that have graphics class that is given on the command
line. The present graphics class will not be removed if there is no fallback available.
process the hosted idioms list, this is a list of the idioms that must
always be preserved in the car file. This list cannot contain
universal, and the different idioms should be given in a comma separated list.
Subtype to keep integer
Output file name, if no output file is given then input file is overwritten.
The
and
utilities
read commands from standard input or a specified file.
The commands are executed at a later time, using
executes commands at a specified time;
lists the user's pending jobs, unless the user is the superuser; in that
case, everybody's jobs are listed;
deletes jobs;
executes commands when system load levels permit; in other words, when the load average
drops below _LOADAVG_MX (1.5), or the value specified in the invocation of
The
utility allows some moderately complex
specifications.
It accepts times of the form
or
to run a job at a specific time of day.
(If that time is already past, the next day is assumed.)
As an alternative, the following keywords may be specified:
or
(4pm)
and time-of-day may be suffixed with
or
for running in the morning or the evening.
The day on which the job is to be run may also be specified
by giving a date in the form
with an optional
or giving a date of the forms
The specification of a date must follow the specification of
the time of day.
Time can also be specified as:
where the time-units can be
or
and
may be told to run the job today by suffixing the time with
and to run the job tomorrow by suffixing the time with
The shortcut
can be used instead of
For example, to run a job at 4pm three days from now, use
to run a job at 10:00am on July 31, use
and to run a job at 1am tomorrow, use
The
utility also supports the
time format (see
option).
For both
and
commands are read from standard input or the file specified
with the
option.
The working directory, the environment (except for the variables
and
and the
are retained from the time of invocation.
An
or
command invoked from a
shell will retain the current userid.
The user will be mailed standard error and standard output from his
commands, if any.
Mail will be sent using the command
If
is executed from a
shell, the owner of the login shell will receive the mail.
The superuser may use these commands in any case.
For other users, permission to use
is determined by the files
and
If the file
exists, only usernames mentioned in it are allowed to use
In these two files,
a user is considered to be listed
only if the user name has no blank or other characters
before it on its line and a newline character immediately after the name,
even at the end of the file.
Other lines are ignored and may be used for comments.
If
does not exist,
is checked, every username not mentioned in it is then allowed
to use
If neither exists, only the superuser is allowed use of
Note that
is implemented through the
daemon periodically invoking
which is disabled by default.
See 
for information about enabling
Is an alias for
Cat the jobs listed on the command line to standard output.
Is an alias for
(this option is deprecated; use
instead).
Read the job from
rather than standard input.
With no arguments, list all jobs for the invoking user.
If one or more
job numbers are given, list only those jobs.
Send mail to the user when the job has completed even if there was no
output.
Use the specified queue.
A queue designation consists of a single letter; valid queue designations
range from
to
and
to
The
queue (a) is the default for
and the
queue (b) is the default for
Queues with higher letters run with increased niceness.
If a job is submitted to a queue designated with an uppercase letter, it
is treated as if it had been submitted to batch at that time.
If
is given a specific queue, it will only show jobs pending in that queue.
Remove the specified jobs.
The argument should be in the form
where each pair of letters represents the following:
The first two digits of the year (the century).
The second two digits of the year.
The month of the year, from 1 to 12.
the day of the month, from 1 to 31.
The hour of the day, from 0 to 23.
The minute of the hour, from 0 to 59.
The second of the minute, from 0 to 61.
If the
and
letter pairs are not specified, the values default to the current
year.
If the
letter pair is not specified, the value defaults to 0.
For
shows completed but not yet deleted jobs in the queue; otherwise
shows the time the job will be executed.
directory containing job files
job-creation lock file
directory containing output spool files
allow permission control
deny permission control
login records
If the file
is not available or corrupted,
or if the user is not logged on at the time
is invoked, the mail is sent to the userid found
in the environment variable
If that is undefined or empty, the current userid is assumed.
The
and
utilities
as presently implemented are not suitable when users are competing for
resources.
If this is the case, another batch system such as
may be more suitable.
Specifying a date past 2038 may not work on some systems.
At was mostly written by
The time parsing routines are by
with minor enhancements by
The
command converts numeric addresses to their symbolic equivalents.  If full debug symbol information is available,
for example in a .app.dSYM sitting beside a .app, then the output of atos will include file name and source line
number information.
The input addresses may be given in one of three ways:
A list of addresses at the end of the argument list.
Using the
argument to specify the path of an input file containing whitespace-separated numeric addresses.
If no addresses were directly specified, 
enters an interactive mode, reading addresses from stdin.
The symbols are found in either a binary image file or in a currently executing process, as specified by:
The path to a binary image file in which to look up symbols.
The process ID or the partial name of a currently executing process in which to look up symbols.
Multiple process IDs or paths can be specified if necessary, and the two can be mixed in any order.
When working with a Mach-O binary image file, 
considers only addresses and symbols defined in that binary image file, at their default locations (unless the -l or -s option is given). 
When working with a running process, 
considers addresses and symbols defined in all binary images currently loaded by that process, at their loaded locations.
The following additional options are available.
The particular architecure of a binary image file in which to look up symbols.
The load address of the binary image.  This value is always assumed to be in hex, even without a "0x" prefix.  The input addresses are assumed to be in a binary image with that load address.  Load addresses for binary
images can be found in the Binary Images: section at the bottom of crash, sample, leaks, and malloc_history reports.
The slide value of the binary image -- this is the difference between the load address of a binary image, and the address at which the binary image was built.  
This slide value is subtracted from the input addresses.  
It is usually easier to directly specify the load address with the
argument than to manually calculate a slide value.
If a process was specified, the first line of atos output should be a header of the form "Looking up symbols in process <pid> named:  <process-name>".
This is primarily used when
is invoked as part of a stackshot(1) run, for verification of the process ID and name.
Full debug symbol information is available in Sketch.app.dSYM, which sits alongside Sketch.app.  When Sketch.app was run,
the Sketch binary (which was built at 0x100000000) was loaded at 0x10acde000.  Running 'sample Sketch' showed 3 addresses that
we want to get symbol information for -- 0x10acea1d3, 0x10ace4bea, and 0x10ace4b7a.
First notice that the .dSYM is next to the .app:
Sketch.app
Sketch.app.dSYM
Now, to symbolicate, we run atos with the
flag specifying the path to the actual Sketch executable (not the .app wrapper), the
flag, and the
flag to specify the load address.
-[SKTGraphicView drawRect:] (in Sketch) (SKTGraphicView.m:445)
-[SKTGraphic drawHandlesInView:] (in Sketch) (NSGeometry.h:110)
-[SKTGraphic drawHandleInView:atPoint:] (in Sketch) (SKTGraphic.m:490)
It is possible to get symbols for addresses from a different machine architecture than the system on which
is running.  For example, when running
on an Intel-based system, one may wish to get the symbol for an address that came from a backtrace of a process running on an ARM device.  To do so, use the
flag to specify the desired architecture (such as i386 or arm) and pass in a corresponding symbol-rich Mach-O binary image file with a binary image of the corresponding architecture (such as a Universal Binary).
The
utility selects records from the audit trail files based on the specified
criteria.
Matching audit records are printed to the standard output in
their raw binary form.
If no
argument is specified, the standard input is used
by default.
Use the
utility to print the selected audit records in human-readable form.
The options are as follows:
Select all records.
Select records that occurred after or on the given datetime.
Select records that occurred before the given datetime.
Select records matching the given audit classes specified as a comma
separated list of audit flags.
See
for a description of audit flags.
Select records that occurred on a given date.
This option cannot be used with
or
Select records with the given effective user ID or name.
Select records with the given effective group ID or name.
Select records with the given real group ID or name.
Select records having a subject token with matching ID.
Select records with the given event name or number. This option can
be used more then once to select records of multiple event types.
See
for a description of audit event names and numbers.
Select records containing path tokens, where the pathname matches
one of the comma delimited extended regular expression contained in
given specification.
Regular expressions which are prefixed with a tilde
are excluded
from the search results.
These extended regular expressions are processed from left to right,
and a path will either be selected or deslected based on the first match.
Since commas are used to delimit the regular expressions, a backslash
character should be used to escape the comma if it is a part of the search
pattern.
Select records containing the given message queue ID.
Select records containing the given process ID.
Select records containing the given semaphore ID.
Select records containing the given shared memory ID.
Select records with the given real user ID or name.
Select records with the given audit ID.
Invert sense of matching, to select records that do not match.
To select all records associated with effective user ID root from the audit
log
To select all
events from that log:
Output from the above command lines will typically be piped to a new trail
file, or via standard output to the
command.
Select all records containing a path token where the pathname contains
Select all records containing path tokens, where the pathname is a TTY
device:
Select all records containing path tokens, where the pathname is a TTY
except for
The OpenBSM implementation was created by McAfee Research, the security
It was subsequently adopted by the TrustedBSD Project as the foundation for
the OpenBSM distribution.
This software was created by McAfee Research, the security research division
of McAfee, Inc., under contract to Apple Computer Inc.
Additional authors include
and SPARTA Inc.
The Basic Security Module (BSM) interface to audit records and audit event
stream format were defined by Sun Microsystems.
provides authorization-based file opening services.  In its simplest form,
verifies that it is allowed to open
(using an appropriate
authorization right) and then writes the file to stdout.  If
is specified,
will read from
and write to the file.
is designed to be used both from the command line and programmatically.
The
flag allows a parent process to receive an open file descriptor pointing to
the file in question.
Before opening
will make an authorization request for a right of the form:
rights only allow for read-only file descriptors.
The
option can be used to provide an AuthorizationRef constructed by
the client.  This generally prevents
from presenting an authorization dialog containing its own name.
specifies that STDOUT_FILENO has been dup2()'d onto a pipe to a
parent process and that an open file descriptor to
should be sent back across it using the SCM_RIGHTS extension to
rather than
having the file itself written to or read from
specifies that
should read one AuthorizationExternalForm structure from
convert it to an AuthorizationRef, and attempt to use it to authorize
the
operation.  The authorization should refer to the 
right corresponding to the requested operation.  The authorization
data will be read before any additional data supplied on
and will not be included in data written with 
instructs
to open
has not been specified,
will then copy
to
until
is closed.
append to
rather than truncating it (truncating is the default).
create the file if it doesn't exist.
requires
specify the mode bits if a file is created.
numerically specify the flags that should be passed to
require that the file being created not exist.
or better can be obtained):
will fail if an appropriate
or
right cannot be obtained or if the named path does not exist.
should support prefix path authentication such that the right
should use
appeared in Mac OS X 10.1 to assist with the manipulation of disk devices.
runs the specified workflow.  To create or edit a workflow, use the Automator application.
The following options are available:
Set variable
to
for this run of 
Set 
as the input to 
If 
Run in verbose mode.
AUValidation tests a specified AudioUnit for API and behavioural conformance.
returns: OK: 0, malformed execution: 1, unit not conformant: -1
must be specified first. can specify either: -ppc to run using Rosetta on Intel machine, or -32 to run as 32 bit. If neither specified runs as 64 bit native architecture
print help text
lists all available AudioUnits of any type
lists all available AudioUnits of type 'TYPE'
opens the AudioUnit specified by the TYPE SUBT MANU component ID's and tests that unit.
iterates through all of the AU's of specified TYPE and MANU
execution is terminated when first error is encountered
execution is terminated when first warning is encountered
continue validating when an error occurs in batch mode. 
quiet - does no printing except for errors or warnings
doesn't print parameter or Factory Presets information
only runs a basic open and initialize test. good for debugging basic functionality
wait after finished - good for profiling memory usage see 'man leaks'
The version is printed to stdout.
The version is printed to stdout in hexadecimal.
Each line in the file should contain one complete command.
AUValidation tests a specified AudioUnit for API and behavioural conformance.
returns: OK: 0, malformed execution: 1, unit not conformant: -1
print help text
lists all available AudioUnits of any type
lists all available AudioUnits of type 'TYPE'
opens the AudioUnit specified by the TYPE SUBT MANU component ID's and tests that unit.
iterates through all of the AU's of specified TYPE and MANU
execution is terminated when first error is encountered
execution is terminated when first warning is encountered
continue validating when an error occurs in batch mode. 
quiet - does no printing except for errors or warnings
doesn't print parameter or Factory Presets information
only runs a basic open and initialize test. good for debugging basic functionality
wait after finished - good for profiling memory usage see 'man leaks'
The version is printed to stdout.
The version is printed to stdout in hexadecimal.
Each line in the file should contain one complete command.
The
executable is used for the managment of persistent AVB entities which are advertised by the Mac.
is launched automatically by launched as needed on demand and should not be launched manually.
configured Entities
allocated Entity IDs
The 
tool is used to capture a snapshot of the current AVB system state and help diagnose 
common issues with AVB.
looks for the system to determine that it actually has AVB capable interfaces and that at 
least one of these has been enabled.
will produce a number of warnings which may not be errors depending on the setup of the system.
Things such as missing local or remote attributes for MSRP will be flagged as a warning but is
not an error if the Mac is not sourcing or sinking streams as appropriate for the warning.
report may be the result of a network device. Please use your best judgement before filing the bug report.
The following options are available:
Disable the reading of the AVDECC AEM from the device and archiving it in the result.
Disable dumping of the state of the AVB audio driver device tree.
Enabled reading of and dumping the ACMP state of the entities.
Enable sending of the AVDECC AECP AEM GET_STREAM_INFO command to each of the possible stream sources and sinks and including in the info dump.
Enable sending of the AVDECC AECP AEM GET_COUNTER command to each of the possible stream sources and sinks and including in the info dump.
output The information gathered by
including the command line output, an ioreg dump and the current system.log and kernel.log files.
The
executable is used for the managment AVB features and settings.
The following options are available:
Enable or disable the virtual audio entity on the specified interface, or list the set of interfaces with a virtual audio entity enabled.
An interface must be present and enabled for AVB use to enable the virtual audio entity on that interface. A virtual audio entity can always be removed from an interface regardless of if the interface is present or not.
can be used to compress video media to different types for sharing on the web or loading onto devices.
prints usage information and available presets
sets the console output to verbose
sets the console output to quiet
shows progress during the export (default with -v)
converts the source media to an output file using the specified preset. Use --listPresets to get the full list. Common presets are:
is the source media file
is the output movie file
lists all of the presets avconvert supports
Optional flags to configure the audio export settings
a limit value for the data rate for the audio track in bits per second
sets the format of the audio output using a fourCC eg. aac
configures the sample rate of the output in Hertz. eg. 44100
is the channel count of the output eg. 1 (for mono) 2 (stereo) 4 (quad)
Optional flags to configure the video export settings
a limit value for the video data rate in bits per second
sets the height of the output video in pixels
sets the width of the output video in pixels
sets the format of the video output using a fourCC eg. avc1
sets the frame rate of the output video in frames per second
specifies how often keyframes appear in the output video
sets whether or not to enable frame reordering (b-frames)
Optional flags configuring track and metadata output
omits the listed track type from the exported movie Allowable track types are:
sets the file from which the metadata for the export is found if that is different from the source movie
	avconvert --listPresets
Lists the available presets that can be used for export
	avconvert --preset AppleM4ViPod --source sample_movie.mov --output ipod_movie.m4v
Exports the source movie "sample_movie.mov" to "ipod_movie.m4v" using the iPod encoding preset
	avconvert --preset AppleM4VAppleTV --source sample_movie.mov --output appletv_movie.m4v -adr 128000 -sr 441000
Overrides the AppleTV defaults for audio data rate and sample rate in the output movie
	avconvert --preset AppleM4VAppleTV --source sample_movie.mov --output appletv_movie.m4v -ot audioTrack
Omits the audio track from the output file "appletv_movie.m4v"
command first appeared in Mac OS X 10.7..de EX
awk
[
]
[
]
[
|
]
[
]
scans each input
for lines that match any of a set of patterns specified literally in
or in one or more files
specified as
With each pattern
there can be an associated action that will be performed
when a line of a
matches the pattern.
Each line is matched against the
pattern portion of every pattern-action statement;
the associated action is performed for each matched pattern.
The file name 
means the standard input.
Any
of the form
is treated as an assignment, not a filename,
and is executed at the time it would have been opened if it were a filename.
The option
followed by
is an assignment to be done before
is executed;
any number of
options may be present.
The
option defines the input field separator to be the regular expression
An input line is normally made up of fields separated by white space,
or by regular expression
The fields are denoted
refers to the entire line.
If
is null, the input line is split into one field per character.
A pattern-action statement has the form
A missing 
means print the line;
a missing pattern always matches.
Pattern-action statements are separated by newlines or semicolons.
An action is a sequence of statements.
A statement can be one of the following:
break
continue
Statements are terminated by
semicolons, newlines or right braces.
An empty
stands for
with the usual C escapes recognized within.
Expressions take on string or numeric values as appropriate,
and are built using the operators
(exponentiation), and concatenation (indicated by white space).
The operators
are also available in expressions.
Variables may be scalars, array elements
(denoted
or fields.
Variables are initialized to the null string.
Array subscripts may be any string,
not necessarily numeric;
this allows for a form of associative memory.
Multiple subscripts such as
are permitted; the constituents are concatenated,
separated by the value of
The
statement prints its arguments on the standard output
(or on a file if
or
is present or on a pipe if
is present), separated by the current output field separator,
and terminated by the output record separator.
and
may be literal names or parenthesized expressions;
identical string values in different statements denote
the same open file.
The
statement formats its expression list according to the format
(see
The built-in function
closes the file or pipe
The built-in function
flushes any buffered output for the file or pipe
The mathematical functions
and
are built in.
Other built-in functions:
the length of its argument
taken as a string,
or of
if no argument.
random number on (0,1)
sets seed for
and returns the previous seed.
truncates to an integer value
the
substring of
that begins at position
counted from 1.
the position in
where the string
occurs, or 0 if it does not.
the position in
where the regular expression
occurs, or 0 if it does not.
The variables
and
are set to the position and length of the matched string.
splits the string
into array elements
and returns
The separation is done with the regular expression
or with the field separator
if
is not given.
An empty string as field separator splits the string
into one array element per character.
substitutes
for the first occurrence of the regular expression
in the string
If
is not given,
is used.
same as
except that all occurrences of the regular expression
are replaced;
and
return the number of replacements.
the string resulting from formatting
according to the
format
executes
and returns its exit status
returns a copy of
with all upper-case characters translated to their
corresponding lower-case equivalents.
returns a copy of
with all lower-case characters translated to their
corresponding upper-case equivalents.
The ``function''
sets
to the next input record from the current input file;
sets
to the next record from
sets variable
instead.
Finally,
pipes the output of
into
each call of
returns the next line of output from
In all cases,
returns 1 for a successful input,
Patterns are arbitrary Boolean combinations
(with
of regular expressions and
relational expressions.
Regular expressions are as defined in
Isolated regular expressions
in a pattern apply to the entire line.
Regular expressions may also occur in
relational expressions, using the operators
and
is a constant regular expression;
any string (constant or variable) may be used
as a regular expression, except in the position of an isolated regular expression
in a pattern.
A pattern may consist of two patterns separated by a comma;
in this case, the action is performed for all lines
from an occurrence of the first pattern
though an occurrence of the second.
A relational expression is one of the following:
where a relop is any of the six relational operators in C,
and a matchop is either
(matches)
or
(does not match).
A conditional is an arithmetic expression,
a relational expression,
or a Boolean combination
of these.
The special patterns
and
may be used to capture control before the first input line is read
and after the last.
and
do not combine with other patterns.
Variable names with special meanings:
conversion format used when converting numbers
(default
regular expression used to separate fields; also settable
by option
number of fields in the current record
ordinal number of the current record
ordinal number of the current record in the current file
the name of the current input file
input record separator (default newline)
output field separator (default blank)
output record separator (default newline)
output format for numbers (default
separates multiple subscripts (default 034)
argument count, assignable
argument array, assignable;
non-null members are taken as filenames
array of environment variables; subscripts are names.
Functions may be defined (at the position of a pattern-action statement) thus:
function foo(a, b, c) { ...; return x }
Parameters are passed by value if scalar and by reference if array name;
functions may be called recursively.
Parameters are local to the function; all other variables are global.
Thus local variables may be created by providing excess parameters in
the function definition.
length($0) > 72
Print lines longer than 72 characters.
{ print $2, $1 }
Print first two fields in opposite order.
      { print $2, $1 }
	{ s += $1 }
Add up first column, print sum and average.
BEGIN	{	# Simulate echo(1)
	for (i = 1; i < ARGC; i++) printf "%s ", ARGV[i]
	exit }
A. V. Aho, B. W. Kernighan, P. J. Weinberger,
The AWK Programming Language,
Addison-Wesley, 1988.  ISBN 0-201-07981-X
There are no explicit conversions between numbers and strings.
To force an expression to be treated as a number add 0 to it;
to force it to be treated as a string concatenate
The scope rules for variables in functions are a botch;
the syntax is worse.
encodes and decodes Base64 data, as specified in RFC 4648. With no options,
reads raw data from stdin and writes encoded data as a continuous block to
stdout.
The following options are available:
Insert line breaks every
characters. Default is 0, which generates an unbroken stream.
Decode incoming Base64 stream into binary data.
Print usage summary and exit.
Read input from
Default is stdin; passing
also represents stdin.
Write output to
Default is stdout; passing
also represents stdout.
The
utility deletes any prefix ending with the last slash
character present in
(after first stripping trailing slashes),
and a
if given.
The
is not stripped if it is identical to the remaining characters in
The resulting filename is written to the standard output.
A non-existent suffix is ignored.
If
is specified, then every argument is treated as a
as if
were invoked with just one argument.
If
is specified, then the
is taken as its argument, and all other arguments are treated as a
The
utility deletes the filename portion, beginning
with the last slash
character to the end of
(after first stripping trailing slashes),
and writes the result to the standard output.
The following line sets the shell variable
to
The
and
utilities are expected to be
compatible.
[options]
[file]
executes commands read from the standard input or from a file.
is intended to be a conformant implementation of the
Shell and Utilities portion of the IEEE POSIX specification
(IEEE Standard 1003.1).
can be configured to be POSIX-conformant by default.
In addition to the single-character shell options documented in the
interprets the following options when it is invoked:
If the
option is present, then commands are read from
If there are arguments after the
they are assigned to the positional parameters, starting with
If the
option is present, the shell is
Make
act as if it had been invoked as a login shell (see
below).
If the
option is present, the shell becomes
(see
below).
If the
option is present, or if no arguments remain after option
processing, then commands are read from the standard input.
This option allows the positional parameters to be set
when invoking an interactive shell.
is printed on the standard output.
These are the strings that
are subject to language translation when the current locale
below).
that may be reused as input.
A
signals the end of options and disables further option processing.
Any arguments after the
are treated as filenames and arguments.  An argument of
also interprets a number of multi-character options.
These options must appear on the command line before the
single-character options to be recognized.
Arrange for the debugger profile to be executed before the shell
starts.
Turns on extended debugging mode (see the description of the
option to the
builtin below)
and shell function tracing (see the description of the
builtin below).
Display a usage message on standard output and exit successfully.
Execute commands from
instead of the standard personal initialization file
if the shell is interactive (see
below).
Do not use the GNU
library to read command lines when the shell is interactive.
Do not read either the system-wide startup file
or any of the personal initialization files
or
By default,
reads these files when it is invoked as a login shell (see
below).
Do not read and execute the personal initialization file
if the shell is interactive.
This option is on by default if the shell is invoked as
The shell becomes restricted (see
below).
Show version information for this instance of
on the standard output and exit successfully.
If arguments remain after option processing, and neither the
nor the
option has been supplied, the first argument is assumed to
be the name of a file containing shell commands.
If
is invoked in this fashion, 
is set to the name of the file, and the positional parameters
are set to the remaining arguments.
reads and executes commands from this file, then exits.
executed in the script.
If no commands are executed, the exit status is 0.
An attempt is first made to open the file in the current directory, and,
if no file is found, then the shell searches the directories in
for the script.
or one started with the 
option.
and without the
option
whose standard input and error are
both connected to terminals (as determined by
or one started with the
option.
is set and
includes
if
is interactive,
allowing a shell script or a startup file to test this state.
The following paragraphs describe how
executes its startup files.
If any of the files exist but cannot be read,
reports an error.
Tildes are expanded in file names as described below under
in the
section.
When
is invoked as an interactive login shell, or as a non-interactive shell
file exists.
and executes commands from the first one that exists and is readable.
The
option may be used when the shell is started to inhibit this behavior.
When a login shell exits,
exists.
When an interactive shell that is not a login shell is started,
This may be inhibited by using the
option.
When
is started non-interactively, to run a shell script, for example, it
looks for the variable
in the environment, expands its value if it appears there, and uses the
expanded value as the name of a file to read and execute.
behaves as if the following command were executed:
but the value of the
variable is not used to search for the file name.
If
is invoked with the name
it tries to mimic the startup behavior of historical versions of
as closely as possible,
while conforming to the POSIX standard as well.
When invoked as an interactive login shell, or a non-interactive
read and execute commands from
and
in that order.
The
option may be used to inhibit this behavior.
When invoked as an interactive shell with the name
looks for the variable
expands its value if it is defined, and uses the
expanded value as the name of a file to read and execute.
Since a shell invoked as
does not attempt to read and execute commands from any other startup
files, the
option has no effect.
A non-interactive shell invoked with the name
does not attempt to read any other startup files. 
When invoked as
enters
mode after the startup files are read.
When
is started in
mode, as with the
command line option, it follows the POSIX standard for startup files.
In this mode, interactive shells expand the
variable and commands are read and executed from the file
whose name is the expanded value.
No other startup files are read.
attempts to determine when it is being run by the remote shell
If
The
option may be used to inhibit this behavior, and the
option may be used to force another file to be read, but
or allow them to be specified.
If the shell is started with the effective user (group) id not equal to the
files are read, shell functions are not inherited from the environment, the
variable, if it appears in the environment, is ignored,
and the effective user id is set to the real user id.
the same, but the effective user id is not reset.
The following definitions are used throughout the rest of this
document.
A space or tab.
A sequence of characters considered as a single unit by the shell.
Also known as a
A 
consisting only of alphanumeric characters and underscores, and
beginning with an alphabetic character or an underscore.  Also
referred to as an
A character that, when unquoted, separates words.  One of the following:
symbols:
The following words are recognized as reserved when unquoted and either
the first word of a simple command (see
below) or the third word of a 
or
command:
specifies the command to be executed, and is passed as argument zero.
The remaining words are passed as arguments to the invoked command.
the character
The format for a pipeline is:
The standard output of
is connected via a pipe to the standard input of
This connection is performed before any redirections specified by the
command (see
below).
The return status of a pipeline is the exit status of the last
value of the last (rightmost) command to exit with a non-zero status,
or zero if all commands exit successfully.
If the reserved word
precedes a pipeline, the exit status of that pipeline is the logical
negation of the exit status as described above.
The shell waits for all commands in the pipeline to
terminate before returning a value.
If the
reserved word precedes a pipeline, the elapsed as well as user and
system time consumed by its execution are reported when the pipeline
terminates.
The
variable may be set to a format string that specifies how the timing
information should be displayed; see the description of
under
below.
Each command in a pipeline is executed as a separate process (i.e., in a
subshell).
of the operators
or
and optionally terminated by one of
or
Of these list operators,
and
have equal precedence, followed by
and
which have equal precedence.
of a semicolon to delimit commands.
If a command is terminated by the control operator
in a subshell.  The shell does not wait for the command to
finish, and the return status is 0.  Commands separated by a
are executed sequentially; the shell waits for each
command to terminate in turn.  The return status is the
exit status of the last command executed.
The control operators
and
denote AND lists and OR lists, respectively.
An AND list has the form
is executed if, and only if,
returns an exit status of zero.
An OR list has the form
is executed if and only if
returns a non-zero exit status.  The return status of
AND and OR lists is the exit status of the last command
executed in the list.
below).
Variable assignments and builtin
commands that affect the shell's environment do not remain in effect
after the command completes.  The return status is the exit status of
The return status is the exit status of
word is permitted to be recognized.  Since they do not cause a word
below under
If the value of the expression is non-zero, the return status is 0;
otherwise the return status is 1.  This is exactly equivalent to
Return a status of 0 or 1 depending on the evaluation of
Expressions are composed of the primaries described below under
Word splitting and pathname expansion are not performed on the words
variable expansion, arithmetic expansion, command substitution, process
substitution, and quote removal are performed.
as primaries.
right of the operator is considered a pattern and matched according
If the shell option
is enabled, the match is performed without regard to the case
of alphabetic characters.
Any part of the pattern may be quoted to force it to be matched as a
string.
When it is used, the string to the right of the operator is considered
The return value is 0 if the string matches
the pattern, and 1 otherwise.
If the regular expression is syntactically incorrect, the conditional
expression's return value is 2.
If the shell option
is enabled, the match is performed without regard to the case
of alphabetic characters.
Substrings matched by parenthesized subexpressions within the regular
matching the entire regular expression.
Expressions may be combined using the following operators, listed
in decreasing order of precedence:
This may be used to override the normal precedence of operators.
True if
is false.
True if both
and
are true.
True if either
or
is true.
the entire conditional expression.
of items.
below).
The return status is the exit status of the last command that executes.
list, no commands are executed, and the return status is 0.
to the rules described below under
until it evaluates to zero.
If any expression is omitted, it behaves as if it evaluates to 1.
that is executed, or false if any of the expressions is invalid.
of items.  The set of expanded words is printed on the standard
below).  The
prompt is then displayed and a line read from the standard input.
If the line consists of a number corresponding to one of
the displayed words, then the value of
is set to that word.  If the line is empty, the words and prompt
are displayed again.  If EOF is read, the command completes.  Any
other value read causes
to be set to null.  The line read is saved in the variable
The
is executed after each selection until a
command is executed.
The exit status of
is the exit status of the last command executed in
or zero if no commands were executed.
as for pathname expansion (see
below).
expansion, parameter and variable expansion, arithmetic substitution,
command substitution, process substitution and quote removal.
expansion, parameter and variable expansion, arithmetic substitution,
command substitution, and process substitution.
If the shell option
is enabled, the match is performed without regard to the case
of alphabetic characters.
When a match is found, the
subsequent matches are attempted.  The exit status is zero if no
pattern matches.  Otherwise, it is the exit status of the
The
is executed.  If its exit status is zero, the
executed, if present.  The exit status is the exit status of the
last command executed, or zero if no condition tested true.
the
is executed as long as the last command in
returns a non-zero exit status.
is the exit status
none was executed.
A shell function is an object that is called like a simple command and
executes a compound command with a new set of positional parameters.
Shell functions are declared as follows:
name of a simple command.
Any redirections (see
below) specified when a function is defined are performed
when the function is executed.
The exit status of a function definition is zero unless a syntax error
occurs or a readonly function with the same name already exists.
When executed, the exit status of a function is the exit status of the
last command executed in the body.  (See
below.)
In a non-interactive shell, or an interactive shell in which the
option to the
builtin is enabled (see
below), a word beginning with
causes that word and all remaining characters on that line to
be ignored.  An interactive shell without the
option enabled does not allow comments.  The
option is on by default in interactive shells.
characters or words to the shell.  Quoting can be used to 
disable special treatment for special characters, to prevent
reserved words from being recognized as such, and to prevent
parameter expansion.
has special meaning to the shell and must be quoted if it is to
represent itself.
When the command history expansion facilities are being used
(see
below), the
to prevent history expansion.
There are three quoting mechanisms: the
single quotes, and double quotes.
It preserves the literal value of the next character that follows,
is treated as a line continuation (that is, it is removed from the
input stream and effectively ignored).
Enclosing characters in single quotes preserves the literal value
of each character within the quotes.  A single quote may not occur
between single quotes, even when preceded by a backslash.
Enclosing characters in double quotes preserves the literal value
of all characters within the quotes, with the exception of
and, when history expansion is enabled,
The characters
and
retain their special meaning within double quotes.  The backslash
retains its special meaning only when followed by one of the following
characters:
or
A double quote may be quoted within double quotes by preceding it with
a backslash.
If enabled, history expansion will be performed unless an
appearing in double quotes is escaped using a backslash.
The backslash preceding the
is not removed.
The special parameters
and
have special meaning when in double
quotes (see
below).
as specified by the ANSI C standard.  Backslash escape sequences, if
present, are decoded as follows:
alert (bell)
backspace
an escape character
form feed
new line
carriage return
horizontal tab
vertical tab
backslash
single quote
(one to three digits)
(one or two hex digits)
The expanded result is single-quoted, as if the dollar sign had
not been present.
the string to be translated according to the current locale.
is ignored.
If the string is translated and replaced, the replacement is
double-quoted.
A
is an entity that stores values.
It can be a
a number, or one of the special characters listed below under
A
is a parameter denoted by a
Attributes are assigned using the
builtin command (see
below in
A parameter is set if it has been assigned a value.  The null string is
a valid value.  Once a variable is set, it may be unset only by using
the
builtin command (see
below).
A
may be assigned to by a statement of the form
If
is not given, the variable is assigned the null string.  All
undergo tilde expansion, parameter and variable expansion,
command substitution, arithmetic expansion, and quote
removal (see
below).  If the variable has its
attribute set, then
is evaluated as an arithmetic expression even if the $((...)) expansion is
not used (see
below).
Word splitting is not performed, with the exception
Pathname expansion is not performed.
Assignment statements may also appear as arguments to the
and
builtin commands.
In the context where an assignment statement is assigning a value
to a shell variable or array index, the += operator can be used to
append to or add to the variable's previous value.
When += is applied to a variable for which the integer attribute has been
variable's current value, which is also evaluated.
When += is applied to an array variable using compound assignment (see
below), the
variable's value is not unset (as it is when using =), and new values are
appended to the array beginning at one greater than the array's maximum index.
appended to the variable's value.
A
is a parameter denoted by one or more
digits, other than the single digit 0.  Positional parameters are
assigned from the shell's arguments when it is invoked,
and may be reassigned using the
builtin command.  Positional parameters may not be assigned to
with assignment statements.  The positional parameters are
temporarily replaced when a shell function is executed (see
below).
When a positional parameter consisting of more than a single
digit is expanded, it must be enclosed in braces (see
below).
The shell treats several parameters specially.  These parameters may
only be referenced; assignment to them is not allowed.
Expands to the positional parameters, starting from one.  When the
expansion occurs within double quotes, it expands to a single word
with the value of each parameter separated by the first character
of the 
is the first character of the value of the
variable.  If
is unset, the parameters are separated by spaces.
If
is null, the parameters are joined without intervening separators.
Expands to the positional parameters, starting from one.  When the
expansion occurs within double quotes, each parameter expands to a
If the double-quoted expansion occurs within a word, the expansion of
the first parameter is joined with the beginning part of the original
word, and the expansion of the last parameter is joined with the last
part of the original word.
expand to nothing (i.e., they are removed).
Expands to the number of positional parameters in decimal.
Expands to the status of the most recently executed foreground
pipeline.
Expands to the current option flags as specified upon invocation, 
by the
builtin command, or those set by the shell itself
(such as the
option).
Expands to the process ID of the shell.  In a () subshell, it
expands to the process ID of the current shell, not the
subshell.
Expands to the process ID of the most recently executed background
(asynchronous) command.
Expands to the name of the shell or shell script.  This is set at
shell initialization.  If
is invoked with a file of commands,
is set to the name of that file.  If
is started with the
option, then
is set to the first argument after the string to be
executed, if one is present.  Otherwise, it is set
to the file name used to invoke
as given by argument zero.
At shell startup, set to the absolute pathname used to invoke the
shell or shell script being executed as passed in the environment
or argument list.
Subsequently, expands to the last argument to the previous command,
after expansion.
Also set to the full pathname used to invoke each command executed
and placed in the environment exported to that command.
When checking mail, this parameter holds the name of the mail file
currently being checked.
The following variables are set by the shell:
Expands to the full file name used to invoke this instance of
An array variable whose values are the number of parameters in each
frame of the current bash execution call stack.
The number of
parameters to the current subroutine (shell function or script executed
When a subroutine is executed, the number of parameters passed is pushed onto
(see the description of the
option to the
builtin below)
An array variable containing all of the parameters in the current bash
execution call stack.  The final parameter of the last subroutine call
is at the top of the stack; the first parameter of the initial call is
at the bottom.  When a subroutine is executed, the parameters supplied
(see the description of the
option to the
builtin below)
The command currently being executed or about to be executed, unless the
shell is executing a command as the result of a trap,
in which case it is the command executing at the time of the trap.
An array variable whose members are the line numbers in source files
The element with index 0 is the portion of the string
matching the entire regular expression.
This variable is read-only.
An array variable whose members are the source filenames corresponding
Incremented by one each time a subshell or subshell environment is spawned.
The initial value is 0.
A readonly array variable whose members hold version information for
this instance of
The values assigned to the array members are as follows:
The patch level.
The build version.
Expands to a string describing the version of this instance of
cursor position.
This variable is available only in shell functions invoked by the
below).
The current command line.
This variable is available only in shell functions and external
commands invoked by the
below).
The index of the current cursor position relative to the beginning of
the current command.
If the current cursor position is at the end of the current command,
This variable is available only in shell functions and external
commands invoked by the
below).
The set of characters that the Readline library treats as word
separators when performing word completion.
If
is unset, it loses its special properties, even if it is
subsequently reset.
words in the current command line.
The words are split on shell metacharacters as the shell parser would
separate them.
This variable is available only in shell functions invoked by the
below).
An array variable (see
below) containing the current contents of the directory stack.
Directories appear in the stack in the order they are displayed by the
builtin.
Assigning to members of this array variable may be used to modify
directories already in the stack, but the
and
builtins must be used to add and remove directories.
Assignment to this variable will not change the current directory.
If
is unset, it loses its special properties, even if it is
subsequently reset.
Expands to the effective user ID of the current user, initialized at
shell startup.  This variable is readonly.
An array variable containing the names of all shell functions
currently in the execution call stack.
The element with index 0 is the name of any currently-executing
shell function.
The bottom-most element is "main".
This variable exists only when a shell function is executing.
Assignments to
have no effect and return an error status.
If
is unset, it loses its special properties, even if it is
subsequently reset.
An array variable containing the list of groups of which the current
user is a member.
Assignments to    
have no effect and return an error status.
If
is unset, it loses its special properties, even if it is
subsequently reset.
The history number, or index in the history list, of the current
command.
If
is unset, it loses its special properties, even if it is
subsequently reset.
Automatically set to the name of the current host.
Automatically set to a string that uniquely
describes the type of machine on which
is executing.
The default is system-dependent.
Each time this parameter is referenced, the shell substitutes
a decimal number representing the current sequential line number
(starting with 1) within a script or function.  When not in a
script or function, the value substituted is not guaranteed to
be meaningful.
If
is unset, it loses its special properties, even if it is
subsequently reset.
Automatically set to a string that fully describes the system
type on which
The default is system-dependent.
The previous working directory as set by the
command.
The value of the last option argument processed by the
builtin command (see
below).
The index of the next argument to be processed by the
builtin command (see
below).
Automatically set to a string that
describes the operating system on which
is executing.
The default is system-dependent.
An array variable (see
below) containing a list of exit status values from the processes
in the most-recently-executed foreground pipeline (which may
contain only a single command).
The process ID of the shell's parent.  This variable is readonly.
The current working directory as set by the
command.
Each time this parameter is referenced, a random integer between
0 and 32767 is
generated.  The sequence of random numbers may be initialized by assigning
a value to
If
is unset, it loses its special properties, even if it is
subsequently reset.
Set to the line of input read by the
builtin command when no arguments are supplied.
Each time this parameter is
referenced, the number of seconds since shell invocation is returned.  If a
value is assigned to 
the value returned upon subsequent
references is
the number of seconds since the assignment plus the value assigned.
If
is unset, it loses its special properties, even if it is
subsequently reset.
A colon-separated list of enabled shell options.  Each word in
the list is a valid argument for the
option to the
builtin command (see
below).  The options appearing in
are those reported as
If this variable is in the environment when
starts up, each shell option in the list will be enabled before
reading any startup files.
This variable is read-only.
Incremented by one each time an instance of
is started.
Expands to the user ID of the current user, initialized at shell startup.
This variable is readonly.
The following variables are used by the shell.  In some cases,
assigns a default value to a variable; these cases are noted
below.
its value is interpreted as a filename containing commands to
initialize the shell, as in
The value of
is subjected to parameter expansion, command substitution, and arithmetic
expansion before being interpreted as a file name.
is not used to search for the resultant file name.
The search path for the
command.
This is a colon-separated list of directories in which the shell looks
for destination directories specified by the
command.
A sample value is
when printing selection lists.  Automatically set upon receipt of a SIGWINCH.
generated by a shell function invoked by the programmable completion
with value
it assumes that the shell is running in an emacs shell buffer and disables
line editing.
The default editor for the
builtin command.
A colon-separated list of suffixes to ignore when performing
filename completion (see
below).
A filename whose suffix matches one of the entries in 
is excluded from the list of matched filenames.
A sample value is
A colon-separated list of patterns defining the set of filenames to
be ignored by pathname expansion.
If a filename matched by a pathname expansion pattern also matches one
of the patterns in
it is removed from the list of matches.
A colon-separated list of values controlling how commands are saved on
the history list.
If the list of values includes
lines which begin with a
character are not saved in the history list.
A value of 
causes lines matching the previous history entry to not be saved.
A value of
A value of
causes all previous lines matching the current line to be removed from
the history list before that line is saved.
Any value not in the above list is ignored.
all lines read by the shell parser are saved on the history list,
subject to the value of
The second and subsequent lines of a multi-line compound command are
not tested, and are added to the history regardless of the value of
The name of the file in which command history is saved (see
command history is not saved when an interactive shell exits.
The maximum number of lines contained in the history file.  When this
variable is assigned a value, the history file is truncated, if
necessary, by removing the oldest entries,
to contain no more than that number of lines.  The default
value is 500.  The history file is also truncated to this size after
writing it when an interactive shell exits.
A colon-separated list of patterns used to decide which command lines
should be saved on the history list.  Each pattern is anchored at the
beginning of the line and must match the complete line (no implicit
after the checks specified by
are applied.
backslash; the backslash is removed before attempting a match.
The second and subsequent lines of a multi-line compound command are
not tested, and are added to the history regardless of the value of
The number of commands to remember in the command history (see
below).  The default value is 500.
If this variable is set and not null, its value is used as a format string
If this variable is set, time stamps are written to the history file so
they may be preserved across shell sessions.
The home directory of the current user; the default argument for the
The value of this variable is also used when performing tilde expansion.
Contains the name of a file in the same format as
that should be read when the shell needs to complete a
hostname.
The list of possible hostname completions may be changed while the
shell is running;
the next time hostname completion is attempted after the
value is changed,
adds the contents of the new file to the existing list.
If
to obtain the list of possible hostname completions.
When
is unset, the hostname list is cleared.
The
that is used
for word splitting after expansion and to
split lines into words with the
builtin command.  The default value is
``<space><tab><newline>''.
Controls the
action of an interactive shell on receipt of an
character as the sole input.  If set, the value is the number of
consecutive
characters which must be
typed as the first characters on an input line before
exits.  If the variable exists but does not have a numeric value, or
has no value, the default value is 10.  If it does not exist,
signifies the end of input to the shell.
The filename for the
startup file, overriding the default of
(see
below).
Used to determine the locale category for any category not specifically
This variable determines the collation order used when sorting the
results of pathname expansion, and determines the behavior of range
expressions, equivalence classes, and collating sequences within
pathname expansion and pattern matching.
This variable determines the interpretation of characters and the
behavior of character classes within pathname expansion and pattern
matching.
This variable determines the locale used to translate double-quoted
This variable determines the locale category used for number formatting.
for printing selection lists.  Automatically set upon receipt of a SIGWINCH.
If this parameter is set to a file name and the
variable is not set,
informs the user of the arrival of mail in the specified file.
Specifies how
often (in seconds)
checks for mail.  The default is 60 seconds.  When it is time to check
for mail, the shell does so before displaying the primary prompt.
If this variable is unset, or set to a value that is not a number
greater than or equal to zero, the shell disables mail checking.
A colon-separated list of file names to be checked for mail. 
The message to be printed when mail arrives in a particular file
may be specified by separating the file name from the message with a `?'.
the current mailfile. 
Example:
supplies a default value for this variable, but the location of the user
If set to the value 1,
displays error messages generated by the
builtin command (see
below).
is initialized to 1 each time the shell is invoked or a shell
script is executed.
The search path for commands.  It
is a colon-separated list of directories in which
the shell looks for commands (see
below).
current directory.
A null directory name may appear as two adjacent colons, or as an initial
or trailing colon.
The default path is system-dependent,
and is set by the administrator who installs
A common value is
invocation option had been supplied.  If it is set while the shell is
had been executed.
If set, the value is executed as a command prior to issuing each primary
prompt.
The value of this parameter is expanded (see
below) and used as the primary prompt string.  The default value is
The value of this parameter is expanded as with
and used as the secondary prompt string.  The default is
The value of this parameter is used as the prompt for the
command (see
above).
The value of this parameter is expanded as with
and the value is printed before each command
displays during an execution trace.  The first character of
is replicated multiple times, as necessary, to indicate multiple
The full pathname to the shell is kept in this environment variable.
If it is not set when the shell starts,
assigns to it the full pathname of the current user's login shell.
The value of this parameter is used as a format string specifying
how the timing information for pipelines prefixed with the
reserved word should be displayed.
expanded to a time value or other information.
The escape sequences and their meanings are as follows; the
braces denote optional portions.
The elapsed time in seconds.
The number of CPU seconds spent in user mode.
The number of CPU seconds spent in system mode.
the number of fractional digits after a decimal point.
A value of 0 causes no decimal point or fraction to be output.
At most three places after the decimal point may be specified;
included.
If the value is null, no timing information is displayed.
A trailing newline is added when the format string is displayed.
In an interactive shell, the value is interpreted as the
number of seconds to wait for input after issuing the primary prompt.
terminates after waiting for that number of seconds if input does
not arrive.
This variable controls how the shell interacts with the user and
job control.  If this variable is set, single word simple
commands without redirections are treated as candidates for resumption
of an existing stopped job.  There is no ambiguity allowed; if there is
more than one job beginning with the string typed, the job most recently
accessed is selected.  The
of a stopped job, in this context, is the command line used to
start it.
If set to the value
the string supplied must match the name of a stopped job exactly;
if set to
the string supplied needs to match a substring of the name of a
stopped job.  The
value provides functionality analogous to the
job identifier (see
below).  If set to any other value, the supplied string must
be a prefix of a stopped job's name; this provides functionality
The two or three characters which control history expansion
and tokenization (see
the character which signals the start of a history
character, which is used as shorthand for re-running the previous
command entered, substituting one string for another in the command.
The optional third character is the character
which indicates that the remainder of the line is a comment when found
comment character causes history substitution to be skipped for the
remaining words on the line.  It does not necessarily cause the shell
parser to treat the rest of the line as a comment.
provides one-dimensional array variables.  Any variable may be used as
an array; the
builtin will explicitly declare an array.  There is no maximum
limit on the size of an array, nor any requirement that members
be indexed or assigned contiguously.  Arrays are indexed using
integers and are zero-based.
An array is created automatically if any variable is assigned to using
is treated as an arithmetic expression that must evaluate to a number
greater than or equal to zero.  To explicitly declare an array, use
(see
below).
specified for an array variable using the
and
builtins.  Each attribute applies to all members of an array.
Arrays are assigned to using compound assignments of the form
the optional brackets and subscript are supplied, that index is assigned to;
otherwise the index of the element assigned is the last index assigned
to by the statement plus one.  Indexing starts at zero.
This syntax is also accepted by the
builtin.  Individual array elements may be assigned to using the
Any element of an array may be referenced using
conflicts with pathname expansion.  If
word appears within double quotes.  If the word is double-quoted,
word with the value of each array member separated by the first
character of the
If the double-quoted expansion occurs within a word, the expansion of
the first parameter is joined with the beginning part of the original
word, and the expansion of the last parameter is joined with the last
part of the original word.
This is analogous to the expansion
Referencing an array variable without a subscript is equivalent to
referencing element zero.
The
Care must be taken to avoid unwanted side effects caused by filename
generation.
The
and
builtins each accept a
option to specify an array.  The
builtin accepts a
option to assign a list of words read from the standard input
to an array.  The
and
builtins display array values in a way that allows them to be
reused as assignments.
Expansion is performed on the command line after it has been split into
words.  There are seven kinds of expansion performed:
and
The order of expansions is: brace expansion, tilde expansion,
parameter, variable and arithmetic expansion and
command substitution
(done in a left-to-right fashion), word splitting, and pathname
expansion.
On systems that can support it, there is an additional expansion
Only brace expansion, word splitting, and pathname expansion
can change the number of words of the expansion; other expansions
expand a single word to a single word.
The only exceptions to this are the expansions of
as explained above (see
is a mechanism by which arbitrary strings
may be generated.  This mechanism is similar to
need not exist.  Patterns to be brace expanded take
the form of an optional
followed by either a series of comma-separated strings or
a sequence expression between a pair of braces, followed by
an optional
The preamble is prefixed to each string contained
within the braces, and the postscript is then appended
to each resulting string, expanding left to right.
Brace expansions may be nested.  The results of each expanded
string are not sorted; left to right order is preserved.
When integers are supplied, the expression expands to each number between
When characters are supplied, the expression expands to each character
Brace expansion is performed before any other expansions,
and any characters special to other expansions are preserved
in the result.  It is strictly textual.
does not apply any syntactic interpretation to the context of the
expansion or the text between the braces.
A correctly-formed brace expansion must contain unquoted opening
and closing braces, and at least one unquoted comma or a valid
sequence expression.
Any incorrectly formed brace expansion is left unchanged.
being considered part of a brace expression.
is not considered eligible for brace expansion.
This construct is typically used as shorthand when the common
prefix of the strings to be generated is longer than in the
above example:
or
Brace expansion introduces a slight incompatibility with
historical versions of
does not treat opening or closing braces specially when they
appear as part of a word, and preserves them in the output.
removes braces from words as a consequence of brace
expansion.  For example, a word entered to
appears identically in the output.  The same word is
output as
after expansion by
If strict compatibility with
is desired, start
with the
option or disable brace expansion with the
option to the
command (see
below).
the characters preceding the first unquoted slash (or all characters,
If none of the characters in the tilde-prefix are quoted, the
characters in the tilde-prefix following the tilde are treated as a
If this login name is the null string, the tilde is replaced with the
value of the shell parameter
If
is unset, the home directory of the user executing the shell is
substituted instead.
Otherwise, the tilde-prefix is replaced with the home directory
associated with the specified login name.
If the tilde-prefix is a `~+', the value of the shell variable
replaces the tilde-prefix.
if it is set, is substituted.
If the characters following the tilde in the tilde-prefix consist
element from the directory stack, as it would be displayed by the
builtin invoked with the tilde-prefix as an argument.
If the characters following the tilde in the tilde-prefix consist of a
If the login name is invalid, or the tilde expansion fails, the word
is unchanged.
Each variable assignment is checked for unquoted tilde-prefixes immediately
following a
or the first
In these cases, tilde expansion is also performed.
Consequently, one may use file names with tildes in assignments to
and
and the shell assigns the expanded value.
command substitution, or arithmetic expansion.  The parameter name
or symbol to be expanded may be enclosed in braces, which
are optional but serve to protect the variable to be expanded from
characters immediately following it which could be
interpreted as part of the name.
not escaped by a backslash or within a quoted string, and not within an
embedded arithmetic expansion, command substitution, or parameter
expansion.
when
is a positional parameter with more than one digit,
or when
is followed by a character which is not to be
interpreted as part of its name.
a level of variable indirection is introduced.
expanded and that value is used in the rest of the substitution, rather
The exclamation point must immediately follow the left brace in order to
introduce indirection.
parameter expansion, command substitution, and arithmetic expansion.
that is unset or null; omitting the colon results in a test only for a
parameter that is unset.
is unset or null, the expansion of
is substituted.  Otherwise, the value of
is substituted.
If
is unset or null, the expansion of
is assigned to
The value of
is then substituted.  Positional parameters and special parameters may
not be assigned to in this way.
If
if
is not present) is written to the standard error and the shell, if it
substituted.
If
is null or unset, nothing is substituted, otherwise the expansion of
is substituted.
ARITHMETIC EVALUATION
below).
index of the specified array.
Note that a negative offset must be separated from the colon by at least
one space to avoid being confused with the :- expansion.
Substring indexing is zero-based unless the positional parameters 
are used, in which case the indexing starts at 1.
separated by the first character of the
special variable.
otherwise.
key expands to a separate word.
If
is
or 
the value substituted is the number of positional parameters.
If
is an array name subscripted by
or
the value substituted is the number of elements in the array.
The 
is expanded to produce a pattern just as in pathname
expansion.  If the pattern matches the beginning of
the value of
then the result of the expansion is the expanded value of
If
is
or
the pattern removal operation is applied to each positional
parameter in turn, and the expansion is the resultant list.
If
is an array variable subscripted with
or
the pattern removal operation is applied to each member of the
array in turn, and the expansion is the resultant list.
pathname expansion.
If the pattern matches a trailing portion of the expanded value of
then the result of the expansion is the expanded value of
If
is
or
the pattern removal operation is applied to each positional
parameter in turn, and the expansion is the resultant list.
If
is an array variable subscripted with
or
the pattern removal operation is applied to each member of the
array in turn, and the expansion is the resultant list.
pathname expansion.
If
is
or
the substitution operation is applied to each positional
parameter in turn, and the expansion is the resultant list.
If
is an array variable subscripted with
or
the substitution operation is applied to each member of the
array in turn, and the expansion is the resultant list.
the command name.  There are two forms:
or
replacing the command substitution with the standard output of the
command, with any trailing newlines deleted.
Embedded newlines are not deleted, but they may be removed during
word splitting.
When the old-style backquote form of substitution is used,
backslash retains its literal meaning except when followed by
or
The first backquote not preceded by a backslash terminates the
command substitution.
parentheses make up the command; none are treated specially.
Command substitutions may be nested.  To nest when using the backquoted form,
escape the inner backquotes with backslashes.
If the substitution appears within double quotes, word splitting and
pathname expansion are not performed on the results.
Arithmetic expansion allows the evaluation of an arithmetic expression
and the substitution of the result.  The format for arithmetic expansion is:
The
is treated as if it were within double quotes, but a double quote
inside the parentheses is not treated specially.
All tokens in the expression undergo parameter expansion, string
expansion, command substitution, and quote removal.
Arithmetic expansions may be nested.
The evaluation is performed according to the rules listed below under
If
is invalid,
prints a message indicating failure and no substitution occurs.
It takes the form of
or
passed as an argument to the current command as the result of the
When available, process substitution is performed
simultaneously with parameter and variable expansion, 
command substitution,
and arithmetic expansion.
The shell scans the results of
parameter expansion,
command substitution,
and
arithmetic expansion
that did not occur within double quotes for
The shell treats each character of
as a delimiter, and splits the results of the other
expansions into words on these characters.  If
is unset, or its
value is exactly
the default, then
any sequence of
characters serves to delimit words.  If
has a value other than the default, then sequences of
the whitespace characters
and
are ignored at the beginning and end of the
word, as long as the whitespace character is in the
value of
(an
whitespace character).
Any character in
that is not
whitespace, along with any adjacent
whitespace characters, delimits a field.
A sequence of
whitespace characters is also treated as a delimiter.
If the value of
is null, no word splitting occurs.
Unquoted implicit null arguments, resulting from the expansion of
parameters that have no values, are removed.
If a parameter with no value is expanded within double quotes, a
null argument results and is retained.
Note that if no expansion occurs, no splitting
is performed.
After word splitting,
unless the
option has been set,
scans each word for the characters
and
If one of these characters appears, then the word is
regarded as a
and replaced with an alphabetically sorted list of
file names matching the pattern.
If no matching file names are found,
and the shell option
is disabled, the word is left unchanged.
If the 
option is set, and no matches are found,
the word is removed.
If the
shell option is set, and no matches are found, an error message
is printed and the command is not executed.
If the shell option
is enabled, the match is performed without regard to the case
of alphabetic characters.
When a pattern is used for pathname expansion,
the character
at the start of a name or immediately following a slash
must be matched explicitly, unless the shell option
is set.
When matching a pathname, the slash character must always be
matched explicitly.
In other cases, the
character is not treated specially.
See the description of
below under
for a description of the
and
shell options.
The
shell variable may be used to restrict the set of file names matching a
If
is set, each matching file name that also matches one of the patterns in
is removed from the list of matches.
The file names
and
are always ignored when
is set and not null.  However, setting
to a non-null value has the effect of enabling the
shell option, so all other file names beginning with a
will match.
To get the old behavior of ignoring file names beginning with a
make
one of the patterns in
The
option is disabled when
is unset.
Any character that appears in a pattern, other than the special pattern
characters described below, matches itself.  The NUL character may not
occur in a pattern.  A backslash escapes the following character; the
escaping backslash is discarded when matching.
The special pattern characters must be quoted if
they are to be matched literally.
The special pattern characters have the following meanings:
Matches any string, including the null string.
Matches any single character.
Matches any one of the enclosed characters.  A pair of characters
separated by a hyphen denotes a
any character that sorts between those two characters, inclusive,
using the current locale's collating sequence and character set,
is matched.  If the first character following the
is a
or a
then any character not enclosed is matched.
The sorting order of characters in range expressions is determined by
if set.
A 
may be matched by including it as the first or last character
in the set.
A
may be matched by including it as the first character
in the set.
Within
and
following classes defined in the POSIX standard:
A character class matches any character belonging to that class.
Within
and 
same collation weight (as defined by the current locale) as
Within
and 
builtin, several extended pattern matching operators are recognized.
Composite patterns may be formed using one or more of the following
sub-patterns:
Matches zero or one occurrence of the given patterns
Matches zero or more occurrences of the given patterns
Matches one or more occurrences of the given patterns
Matches one of the given patterns
Matches anything except one of the given patterns
After the preceding expansions, all unquoted occurrences of the
characters
expansions are removed.
Before a command is executed, its input and output
may be
using a special notation interpreted by the shell.
Redirection may also be used to open and close files for the
current shell execution environment.  The following redirection
operators may precede or appear anywhere within a
or may follow a
Redirections are processed in the order they appear, from
left to right.
In the following descriptions, if the file descriptor number is
omitted, and the first character of the redirection operator is
the redirection refers to the standard input (file descriptor
0).  If the first character of the redirection operator is
the redirection refers to the standard output (file descriptor
1).
The word following the redirection operator in the following
descriptions, unless otherwise noted, is subjected to brace expansion,
tilde expansion, parameter expansion, command substitution, arithmetic
expansion, quote removal, pathname expansion, and word splitting.
If it expands to more than one word,
reports an error.
Note that the order of redirections is significant.  For example, 
the command
directs both standard output and standard error to the file 
while the command
directs only the standard output to file
because the standard error was duplicated as standard output
before the standard output was redirected to
redirections, as described in the following table:
File descriptor 0 is duplicated.
File descriptor 1 is duplicated.
File descriptor 2 is duplicated.
a TCP connection to the corresponding socket.
a UDP connection to the corresponding socket.
A failure to open or create a file causes the redirection to fail.
Redirections using file descriptors greater than 9 should be used with
care, as they may conflict with file descriptors the shell uses
internally.
Redirection of input causes the file whose name results from
the expansion of
to be opened for reading on file descriptor
or the standard input (file descriptor 0) if
is not specified.
The general format for redirecting input is:
Redirection of output causes the file whose name results from
the expansion of
to be opened for writing on file descriptor
or the standard output (file descriptor 1) if
is not specified.  If the file does not exist it is created;
if it does exist it is truncated to zero size.
The general format for redirecting output is:
If the redirection operator is
and the
option to the
builtin has been enabled, the redirection will fail if the file
a regular file.
If the redirection operator is
or the redirection operator is
and the
option to the
builtin command is not enabled, the redirection is attempted even
Redirection of output in this fashion
causes the file whose name results from
the expansion of
to be opened for appending on file descriptor
or the standard output (file descriptor 1) if
is not specified.  If the file does not exist it is created.
The general format for appending output is:
allows both the
standard output (file descriptor 1) and
the standard error output (file descriptor 2)
to be redirected to the file whose name is the
expansion of
with this construct.
There are two formats for redirecting standard output and
standard error:
and
Of the two forms, the first is preferred.
This is semantically equivalent to
This type of redirection instructs the shell to read input from the
current source until a line containing only
(with no trailing blanks)
is seen.  All of
the lines read up to that point are then used as the standard
input for a command.
The format of here-documents is:
No parameter expansion, command substitution, arithmetic expansion,
or pathname expansion is performed on
If any characters in
are quoted, the
is the result of quote removal on
and the lines in the here-document are not expanded.
all lines of the here-document are subjected to parameter expansion,
command substitution, and arithmetic expansion.  In the latter
case, the character sequence
is ignored, and
must be used to quote the characters
and
If the redirection operator is
then all leading tab characters are stripped from input lines and the
line containing
This allows
here-documents within shell scripts to be indented in a
natural fashion.
A variant of here documents, the format is:
input.
The redirection operator
is used to duplicate input file descriptors.
If
expands to one or more digits, the file descriptor denoted by
is made to be a copy of that file descriptor.
If the digits in
do not specify a file descriptor open for input, a redirection error occurs.
If
evaluates to
file descriptor
is closed.  If
is not specified, the standard input (file descriptor 0) is used.
The operator
is used similarly to duplicate output file descriptors.  If
is not specified, the standard output (file descriptor 1) is used.
If the digits in
do not specify a file descriptor open for output, a redirection error occurs.
expand to one or more digits, the standard output and standard
error are redirected as described previously.
The redirection operator
Similarly, the redirection operator
The redirection operator
causes the file whose name is the expansion of
to be opened for both reading and writing on file descriptor
or on file descriptor 0 if
is not specified.  If the file does not exist, it is created.
as the first word of a simple command.
The shell maintains a list of aliases that may be set and unset with the
and
builtin commands (see
below).
The first word of each simple command, if unquoted,
is checked to see if it has an
alias.  If so, that word is replaced by the text of the alias.
listed above may not appear in an alias name.
The replacement text may contain any valid shell input,
including shell metacharacters.
The first word of the replacement text is tested
for aliases, but a word that is identical to an alias being expanded
is not expanded a second time.
This means that one may alias
to
for instance, and
does not try to recursively expand the replacement text.
If the last character of the alias value is a
then the next command
word following the alias is also checked for alias expansion.
Aliases are created and listed with the
command, and removed with the
command.
There is no mechanism for using arguments in the replacement text.
If arguments are needed, a shell function should be used (see
below).
Aliases are not expanded when the shell is not interactive, unless
the
shell option is set using
(see the description of
under
below).
The rules concerning the definition and use of aliases are
somewhat confusing.
always reads at least one complete line
of input before executing any
of the commands on that line.  Aliases are expanded when a
command is read, not when it is executed.  Therefore, an
alias definition appearing on the same line as another
command does not take effect until the next line of input is read.
The commands following the alias definition
on that line are not affected by the new alias.
This behavior is also an issue when functions are executed.
Aliases are expanded when a function definition is read,
not when the function is executed, because a function definition
is itself a compound command.  As a consequence, aliases
defined in a function are not available until after that
function is executed.  To be safe, always put
alias definitions on a separate line, and do not use
in compound commands.
For almost every purpose, aliases are superseded by
shell functions.
A shell function, defined as described above under
stores a series of commands for later execution.
When the name of a shell function is used as a simple command name,
the list of commands associated with that function name is executed.
Functions are executed in the context of the
current shell; no new process is created to interpret
them (contrast this with the execution of a shell script).
When a function is executed, the arguments to the
function become the positional parameters
during its execution.
The special parameter
is updated to reflect the change.  Special parameter 0
is unchanged.
The first element of the
variable is set to the name of the function while the function
is executing.
All other aspects of the shell execution
environment are identical between a function and its caller
with the exception that the
and
traps (see the description of the
builtin under
below) are not inherited unless the function has been given the
builtin below) or the
Variables local to the function may be declared with the
builtin command.  Ordinarily, variables and their values
are shared between the function and its caller.
If the builtin command
is executed in a function, the function completes and
execution resumes with the next command after the function
call.
before execution resumes.
When a function completes, the values of the
positional parameters and the special parameter
are restored to the values they had prior to the function's
execution.
Function names and definitions may be listed with the
option to the
or
builtin commands.  The
option to
or
will list the function names only
shell option is enabled).
Functions may be exported so that subshells
automatically have them defined with the
option to the 
builtin.
the
builtin.
Note that shell functions and variables with the same name may result
in multiple identically-named entries in the environment passed to the
shell's children.
Care should be taken in cases where this may cause a problem.
Functions may be recursive.  No limit is imposed on the number
of recursive calls.
The shell allows arithmetic expressions to be evaluated, under
Evaluation is done in fixed-width integers with no check for overflow,
though division by 0 is trapped and flagged as an error.
The operators and their precedence, associativity, and values
are the same as in the C language.
The following list of operators is grouped into levels of
equal-precedence operators.
The levels are listed in order of decreasing precedence.
variable post-increment and post-decrement
variable pre-increment and pre-decrement
unary minus and plus
logical and bitwise negation
exponentiation
multiplication, division, remainder
addition, subtraction
left and right bitwise shifts
comparison
equality and inequality
bitwise AND
bitwise exclusive OR
bitwise OR
logical AND
logical OR
conditional operator
assignment
comma
Shell variables are allowed as operands; parameter expansion is
performed before the expression is evaluated.
Within an expression, shell variables may also be referenced by name
without using the parameter expansion syntax.
A shell variable that is null or unset evaluates to 0 when referenced
by name without using the parameter expansion syntax.
The value of a variable is evaluated as an arithmetic expression
when it is referenced, or when a variable which has been given the
A null value evaluates to 0.
A shell variable need not have its integer attribute
turned on to be used in an expression.
Constants with a leading 0 are interpreted as octal numbers.
A leading 0x or 0X denotes hexadecimal.
is a decimal number between 2 and 64 representing the arithmetic
The digits greater than 9 are represented by the lowercase letters,
the uppercase letters, @, and _, in that order.
letters may be used interchangeably to represent numbers between 10
and 35.
Operators are evaluated in order of precedence.  Sub-expressions in
parentheses are evaluated first and may override the precedence
rules above.
and perform string and arithmetic comparisons.
Expressions are formed from the following unary or binary primaries.
descriptor 0, 1, or 2, respectively, is checked.
Unless otherwise specified, primaries that operate on files follow symbolic
links and operate on the target of the link, rather than the link itself.
True if file descriptor
is open and refers to a terminal.
inode numbers.
True if shell option
is enabled.
See the list of options under the description of the
option to the
builtin below.
True if the length of
is non-zero.
True if the strings are not equal.
in the current locale.
in the current locale.
is one of
or
is equal to, not equal to, less than, less than or equal to,
and
may be positive or negative integers.
When a simple command is executed, the shell performs the following
expansions, assignments, and redirections, from left to right.
The words that the parser has marked as variable assignments (those
preceding the command name) and redirections are saved for later
processing.
The words that are not variable assignments or redirections are
expanded.  If any words remain after expansion, the first word
is taken to be the name of the command and the remaining words are
the arguments.
Redirections are performed as described above under
expansion, parameter expansion, command substitution, arithmetic expansion,
and quote removal before being assigned to the variable.
If no command name results, the variable assignments affect the current
shell environment.  Otherwise, the variables are added to the environment
of the executed command and do not affect the current shell environment.
If any of the assignments attempts to assign a value to a readonly variable,
an error occurs, and the command exits with a non-zero status.
If no command name results, redirections are performed, but do not
affect the current shell environment.  A redirection error causes the
command to exit with a non-zero status.
If there is a command name left after expansion, execution proceeds as
described below.  Otherwise, the command exits.  If one of the expansions
contained a command substitution, the exit status of the command is
the exit status of the last command substitution performed.  If there
were no command substitutions, the command exits with a status of zero.
After a command has been split into words, if it results in a
simple command and an optional list of arguments, the following
actions are taken.
If the command name contains no slashes, the shell attempts to
locate it.  If there exists a shell function by that name, that
function is invoked as described above in
If the name does not match a function, the shell searches for
it in the list of shell builtins.  If a match is found, that
builtin is invoked.
If the name is neither a shell function nor a builtin,
and contains no slashes,
searches each element of the
for a directory containing an executable file by that name.
uses a hash table to remember the full pathnames of executable
files (see
under
below).
A full search of the directories in
is performed only if the command is not found in the hash table.
If the search is unsuccessful, the shell prints an error
message and returns an exit status of 127.
If the search is successful, or if the command name contains
one or more slashes, the shell executes the named program in a
separate execution environment.
Argument 0 is set to the name given, and the remaining arguments
to the command are set to the arguments given, if any.
If this execution fails because the file is not in executable
format, and the file is not a directory, it is assumed to be
containing shell commands.  A subshell is spawned to execute
it.  This subshell reinitializes itself, so
that the effect is as if a new shell had been invoked
to handle the script, with the exception that the locations of
commands remembered by the parent (see
below under
are retained by the child.
If the program is a file beginning with
the remainder of the first line specifies an interpreter
for the program.  The shell executes the
specified interpreter on operating systems that do not
handle this executable format themselves.  The arguments to the 
interpreter consist of a single optional argument following the
interpreter name on the first line of the program, followed
by the name of the program, followed by the command
arguments, if any.
following:
open files inherited by the shell at invocation, as modified by
the shell's parent
or inherited from the shell's parent in the environment
shell functions defined during execution or inherited from the shell's
parent in the environment
options enabled at invocation (either by default or with command-line
various process IDs, including those of background jobs, the value
When a simple command other than a builtin or shell function
is to be executed, it
is invoked in a separate execution environment that consists of
the following.  Unless otherwise noted, the values are inherited
from the shell.
the shell's open files, plus any modifications and additions specified
by redirections to the command
the current working directory
the file creation mode mask
shell variables and functions marked for export, along with variables
exported for the command, passed in the environment
traps caught by the shell are reset to the values inherited from the
shell's parent, and traps ignored by the shell are ignored
A command invoked in this separate environment cannot affect the
shell's execution environment. 
Command substitution, commands grouped with parentheses,
and asynchronous commands are invoked in a
subshell environment that is a duplicate of the shell environment,
except that traps caught by the shell are reset to the values
that the shell inherited from its parent at invocation.  Builtin
commands that are invoked as part of a pipeline are also executed in a
subshell environment.  Changes made to the subshell environment
cannot affect the shell's execution environment.
Otherwise, the invoked command inherits the file descriptors of the calling
shell as modified by redirections.
When a program is invoked it is given an array of strings
called the
This is a list of 
The shell provides several ways to manipulate the environment.
On invocation, the shell scans its own environment and
creates a parameter for each name found, automatically marking
it for
to child processes.  Executed commands inherit the environment.
The
and
commands allow parameters and functions to be added to and
deleted from the environment.  If the value of a parameter
in the environment is modified, the new value becomes part
of the environment, replacing the old.  The environment
inherited by any executed command consists of the shell's
initial environment, whose values may be modified in the shell,
less any pairs removed by the
command, plus any additions via the
and
commands.
The environment for any
or function may be augmented temporarily by prefixing it with
parameter assignments, as described above in
These assignment statements affect only the environment seen
by that command.
If the 
option is set (see the
builtin command below), then
parameter assignments are placed in the environment for a command,
not just those that precede the command name.
When
invokes an external command, the variable
is set to the full file name of the command and passed to that
command in its environment.
For the shell's purposes, a command which exits with a 
zero exit status has succeeded.  An exit status of zero
indicates success.  A non-zero exit status indicates failure.
If a command is not found, the child process created to
execute it returns a status of 127.  If a command is found
but is not executable, the return status is 126.
If a command fails because of an error during expansion or redirection,
the exit status is greater than zero.
while they execute. 
All builtins return an exit status of 2 to indicate incorrect usage.
executed, unless a syntax error occurs, in which case it exits
command below.
and
If job control is in effect,
ignores
and
set to the values inherited by the shell from its parent.
When job control is not in effect, asynchronous commands
ignore
and
in addition to these inherited handlers.
Commands run as a result of command substitution ignore the
keyboard-generated job control signals
and
The shell exits by default upon receipt of a
Before exiting, an interactive shell resends the
to all jobs, running or stopped.
Stopped jobs are sent
to ensure that they receive the
To prevent the shell from
sending the signal to a particular job, it should be removed from the
jobs table with the 
builtin (see
below) or marked 
to not receive
using
If the
shell option has been set with
sends a 
to all jobs when an interactive login shell exits.
for which a trap has been set, the trap will not be executed until
the command completes. 
builtin, the reception of a signal for which a trap has been set will
greater than 128, immediately after which the trap is executed.
their execution at a later point.  A user typically employs
this facility via an interactive interface supplied jointly
by the system's terminal driver and
The shell associates a
with each pipeline.  It keeps a table of currently executing
jobs, which may be listed with the
command.  When
starts a job asynchronously (in the
it prints a line that looks like:
[1] 25647
indicating that this job is job number 1 and that the process ID
of the last process in the pipeline associated with this job is 25647.
All of the processes in a single pipeline are members of the same job.
uses the
abstraction as the basis for job control.
To facilitate the implementation of the user interface to job
process group ID is equal to the current terminal process group ID)
receive keyboard-generated signals such as
These processes are said to be in the
processes are those whose process group ID differs from the terminal's;
such processes are immune to keyboard-generated signals.
Only foreground processes are allowed to read from or write to the
terminal.  Background processes which attempt to read from (write to) the
terminal are sent a 
signal by the terminal driver, 
which, unless caught, suspends the process.
If the operating system on which
is running supports
job control,
contains facilities to use it.
Typing the
character (typically
Control-Z) while a process is running
causes that process to be stopped and returns control to 
Typing the
character (typically
Control-Y) causes the process to be stopped when it
attempts to read input from the terminal, and control to
be returned to
The user may then manipulate the state of this job, using the
command to continue it in the background, the
command to continue it in the foreground, or
the
and has the additional side effect of causing pending output
and typeahead to be discarded.
There are a number of ways to refer to a job in the shell.
The character
introduces a job name.  Job number
may be referred to as
A job may also be referred to using a prefix of the name used to
start it, or using a substring that appears in its command line.
For example,
refers to a stopped
job.  If a prefix matches more than one job,
reports an error.  Using
on the other hand, refers to any job containing the string
in its command line.  If the substring matches more than one job,
reports an error.  The symbols
and
refer to the shell's notion of the
which is the last job stopped while it was in
the foreground or started in the background.
The 
may be referenced using
In output pertaining to jobs (e.g., the output of the
command), the current job is always flagged with a
and the previous job with a
A single % (with no accompanying job specification) also refers to the
current job.
Simply naming a job can be used to bring it into the
foreground:
is a synonym for
bringing job 1 from the background into the foreground.
Similarly,
resumes job 1 in the background, equivalent to
The shell learns immediately whenever a job changes state.
Normally,
waits until it is about to print a prompt before reporting
changes in a job's status so as to not interrupt
any other output.  If the 
option to the
builtin command
is enabled,
reports such changes immediately.
Any trap on
is executed for each child that exits.
If an attempt to exit
is made while jobs are stopped, the shell prints a warning message.  The
command may then be used to inspect their status.
If a second attempt to exit is made without an intervening command,
the shell does not print another warning, and the stopped
jobs are terminated.
When executing interactively, 
displays the primary prompt
when it is ready to read a command, and the secondary prompt
when it needs more input to complete a command.
allows these prompt strings to be customized by inserting a number of
backslash-escaped special characters that are decoded as follows:
an ASCII bell character (07)
the date in "Weekday Month Date" format (e.g., "Tue May 26")
time representation.  The braces are required
an ASCII escape character (033)
the hostname up to the first `.'
the hostname
the number of jobs currently managed by the shell
the basename of the shell's terminal device name
newline
carriage return
the name of the shell, the basename of
(the portion following the final slash)
the current time in 24-hour HH:MM:SS format
the current time in 12-hour HH:MM:SS format
the current time in 24-hour HH:MM format
the username of the current user
abbreviated with a tilde
the history number of this command
the command number of this command
if the effective UID is 0, a
otherwise a
a backslash
begin a sequence of non-printing characters, which could be used to
embed a terminal control sequence into the prompt
end a sequence of non-printing characters
The command number and the history number are usually different:
the history number of a command is its position in the history
list, which may include commands restored from the history file
(see
below), while the command number is the position in the sequence
of commands executed during the current shell session.
After the string is decoded, it is expanded via
parameter expansion, command substitution, arithmetic
expansion, and quote removal, subject to the value of the
shell option (see the description of the
command under
below).
This is the library that handles reading input when using an interactive
shell, unless the
option is given at shell invocation.
By default, the line editing commands are similar to those of emacs.
A vi-style line editing interface is also available.
To turn off line editing after the shell is running, use the
or
options to the
builtin (see
below).
In this section, the emacs-style notation is used to denote
without a 
then the
or press the Escape key
then hold the Control key while pressing the
key.)
Readline commands may be given numeric
which normally act as a repeat count.
Sometimes, however, it is the sign of the argument that is significant.
Passing a negative argument to a command that acts in the forward
backward direction. 
Commands whose behavior with arguments deviates from this are noted
below.
deleted is saved for possible future retrieval
accumulated into one unit, which can be yanked all at once. 
Commands which do not kill text separate the chunks of text
on the kill ring.
Readline is customized by putting commands in an initialization
The name of this file is taken from the value of the
variable.  If that variable is unset, the default is
When a program which uses the readline library starts up, the
initialization file is read, and the key bindings and variables
are set.
There are only a few basic constructs allowed in the
readline initialization file.
Blank lines are ignored.
Other lines denote key bindings and variable settings.
The default key-bindings may be changed with an
file.
Other programs that use this library may add their own commands
and bindings.
For example, placing
or
into the 
The following symbolic character names are recognized:
and
In addition to command names, readline allows keys to be bound
The syntax for controlling key bindings in the
file is simple.  All that is required is the name of the
command or the text of a macro and a key sequence to which
it should be bound. The name may be specified in one of two ways:
prefixes, or as a key sequence.
is the name of a key spelled out in English.  For example:
Meta-Rubout: backward-kill-word
Control-o: "> output"
In the above example,
is bound to the function
is bound to the function
and
is bound to run the macro
expressed on the right hand side (that is, to insert the text
into the line).
differs from
above in that strings denoting
an entire key sequence may be specified by placing the sequence
within double quotes.  Some GNU Emacs style key escapes can be
used, as in the following example, but the symbolic character names
are not recognized.
In this example,
is again bound to the function
is bound to the function
and 
is bound to insert the text
The full set of GNU Emacs style escape sequences is
control prefix
meta prefix
an escape character
backslash
literal "
In addition to the GNU Emacs style escape sequences, a second
set of backslash escapes is available:
alert (bell)
backspace
delete
form feed
newline
carriage return
horizontal tab
vertical tab
(one to three digits)
(one or two hex digits)
When entering the text of a macro, single or double quotes must
be used to indicate a macro definition.
Unquoted text is assumed to be a function name.
In the macro body, the backslash escapes described above are expanded.
Backslash will quote any other character in the macro text,
allows the current readline key bindings to be displayed or modified
with the
builtin command.  The editing mode may be switched during interactive
use by using the
option to the
builtin command (see
below).
Readline has variables that can be used to further customize its
behavior.  A variable may be set in the
file with a statement of the form
Except where noted, readline variables can take the values
or
(without regard to case).
Unrecognized variable names are ignored.
When a variable value is read, empty or null values, "on" (case-insensitive),
The variables and their default values are:
Controls what happens when readline wants to ring the terminal bell.
treated specially by the kernel's terminal driver to their readline
equivalents.
The string that is inserted when the readline
command is executed.
This command is bound to
in emacs mode and to
in vi command mode.
This determines when the user is queried about viewing
the number of possible completions
It may be set to any integer value greater than or equal to
zero.  If the number of possible completions is greater than
or equal to the value of this variable, the user is asked whether
or not he wishes to view them; otherwise they are simply listed
on the terminal.
eighth bit set to an ASCII key sequence
by stripping the eighth bit and prefixing an
characters will be inserted into the line as if they had been
Controls whether readline begins with a set of key bindings similar
can be set to either
or
keypad when it is called.  Some systems need this to enable the
arrow keys.
attempts word completion.
scrolling the input horizontally on a single screen line when it
becomes longer than the screen width rather than wrapping to a new line.
it will not strip the high bit from the characters it reads),
regardless of what the terminal claims it can support.  The name
is a synonym for this variable.
The string of characters that should terminate an incremental
search without subsequently executing the character as a command.
If this variable has not been given a value, the characters
Set the current readline keymap.  The set of valid keymap names is
the value of
also affects the default keymap.
appended.
have a slash appended (subject to the value of
names begin with a `.' (hidden files) when performing filename 
completion, unless the leading `.' is
supplied by the user in the filename to be completed.
eighth bit set directly rather than as a meta-prefixed escape
sequence.
to display a screenful of possible completions at a time.
sorted horizontally in alphabetical order, rather than down the screen.
This alters the default behavior of the completion functions.  If
set to
words which have more than one possible completion cause the
matches to be listed immediately instead of ringing the bell.
This alters the default behavior of the completion functions in
If set to
words which have more than one possible completion without any
possible partial completion (the possible completions don't share
a common prefix) cause the matches to be listed immediately instead
of ringing the bell.
completions.
Readline implements a facility similar in spirit to the conditional
compilation features of the C preprocessor which allows key
bindings and variable settings to be performed as the result
of tests.  There are four parser directives used.
The 
construct allows bindings to be made based on the
editing mode, the terminal being used, or the application using
readline.  The text of the test extends to the end of the line;
no characters are required to isolate it.
whether readline is in emacs or vi mode.
This may be used in conjunction
readline is starting out in emacs mode.
key bindings, perhaps to bind the key sequences output by the
terminal's function keys.  The word on the right side of the
is tested against the both full name of the terminal and the portion
to match both
and
for instance.
application-specific settings.  Each program using the readline
file can test for a particular value.
This could be used to bind key sequences to functions useful for
a specific program.  For instance, the following command adds a
key sequence that quotes the current or previous word in Bash:
# Quote the current or previous word
This command, as seen in the previous example, terminates an
the test fails.
This directive takes a single filename as an argument and reads commands
and bindings from that file.  For example, the following directive
Readline provides commands for searching through the command history
(see
below) for lines containing a specified string.
There are two search modes:
and
Incremental searches begin before the user has finished typing the
search string.
As each character of the search string is typed, readline displays
the next entry from the history matching the string typed so far.
An incremental search requires only as many characters as needed to
find the desired history entry.
variable are used to terminate an incremental search.
If that variable has not been assigned a value the Escape and
Control-J characters will terminate an incremental search.
Control-G will abort an incremental search and restore the original
line.
When the search is terminated, the history entry containing the
search string becomes the current line.
To find other matching entries in the history list, type Control-S or
Control-R as appropriate.
This will search backward or forward in the history for the next
entry matching the search string typed so far.
Any other key sequence bound to a readline command will terminate
the search and execute that command.
the line, thereby executing the command from the history list.
Readline remembers the last incremental search string.  If two
Control-Rs are typed without any intervening characters defining a
new search string, any remembered search string is used.
Non-incremental searches read the entire search string before starting
to search for matching history lines.  The search string may be
typed by the user or be part of the contents of the current line.
The following is a list of the names of the commands and the default
key sequences to which they are bound.
Command names without an accompanying key sequence are unbound by default.
Move to the start of the current line.
Move to the end of the line.
Move forward a character.
Move back a character.
Move forward to the end of the next word.  Words are composed of
alphanumeric characters (letters and digits).
Move back to the start of the current or previous word.  Words are
composed of alphanumeric characters (letters and digits).
Clear the screen leaving the current line at the top of the screen.
With an argument, refresh the current line without clearing the
screen.
Refresh the current line.
Accept the line regardless of where the cursor is.  If this line is
non-empty, add it to the history list according to the state of the
variable.  If the line is a modified history
line, then restore the history line to its original state.
Fetch the previous command from the history list, moving back in
the list.
Fetch the next command from the history list, moving forward in the
list.
Move to the first line in the history.
Move to the end of the input history, i.e., the line currently being
entered.
Search backward starting at the current line and moving `up' through
the history as necessary.  This is an incremental search.
Search forward starting at the current line and moving `down' through
the history as necessary.  This is an incremental search.
Search backward through the history starting at the current line
using a non-incremental search for a string supplied by the user.
Search forward through the history using a non-incremental search for
a string supplied by the user.
Search forward through the history for the string of characters
between the start of the current line and the point.
This is a non-incremental search.
Search backward through the history for the string of characters
between the start of the current line and the point.
This is a non-incremental search.
Insert the first argument to the previous command (usually
the second word on the previous line) at point.
With an argument
in the previous command begin with word 0).  A negative argument
Insert the last argument to the previous command (the last word of
the previous history entry).  With an argument,
list, inserting the last argument of each line in turn.
The history expansion facilities are used to extract the last argument,
as if the "!$" history expansion had been specified.
Expand the line as the shell does.  This
performs alias and history expansion as well as all of the shell
word expansions.  See
below for a description of history expansion.
Perform history expansion on the current line.
See
below for a description of history expansion.
Perform history expansion on the current line and insert a space.
See
below for a description of history expansion.
Perform alias expansion on the current line.
See
above for a description of alias expansion.
Perform history and alias expansion on the current line.
Accept the current line for execution and fetch the next line
relative to the current line from the history for editing.  Any
argument is ignored.
Invoke an editor on the current command line, and execute the result as shell
commands.
Delete the character at point.  If point is at the
beginning of the line, there are no characters in the line, and
then return
Delete the character behind the cursor.  When given a numeric argument,
save the deleted text on the kill ring.
Delete the character under the cursor, unless the cursor is at the
end of the line, in which case the character behind the cursor is
deleted.
Add the next character typed to the line verbatim.  This is
Insert a tab character.
Insert the character typed.
Drag the character before point forward over the character at point,
moving point forward as well.
If point is at the end of the line, then this transposes
the two characters before point.
Negative arguments have no effect.
Drag the word before point past the word after point,
moving point over that word as well.
If point is at the end of the line, this transposes
the last two words on the line.   
Uppercase the current (or following) word.  With a negative argument,
uppercase the previous word, but do not move point.
Lowercase the current (or following) word.  With a negative argument,
lowercase the previous word, but do not move point.
Capitalize the current (or following) word.  With a negative argument,
capitalize the previous word, but do not move point.
Toggle overwrite mode.  With an explicit positive numeric argument,
switches to overwrite mode.  With an explicit non-positive numeric
argument, switches to insert mode.  This command affects only
the text at point rather than pushing the text to the right.
before point with a space.  By default, this command is unbound.
Kill the text from point to the end of the line.
Kill backward to the beginning of the line.
Kill backward from point to the beginning of the line.
The killed text is saved on the kill-ring.
Kill all characters on the current line, no matter where point is.
Kill from point to the end of the current word, or if between
words, to the end of the next word.
Kill the word behind point.
Kill the word behind point, using white space as a word boundary.
The killed text is saved on the kill-ring.
Kill the word behind point, using white space and the slash character
as the word boundaries.
The killed text is saved on the kill-ring.
Delete all spaces and tabs around point.
Kill the text in the current region.
Copy the text in the region to the kill buffer.
Copy the word before point to the kill buffer.
Copy the word following point to the kill buffer.
Yank the top of the kill ring into the buffer at point.
Rotate the kill ring, and yank the new top.  Only works following
or
Add this digit to the argument already accumulating, or start a new
This is another way to specify an argument.
If this command is followed by one or more digits, optionally with a
leading minus sign, those digits define the argument.
If the command is followed by digits, executing
again ends the numeric argument, but is otherwise ignored.
As a special case, if this command is immediately followed by a
character that is neither a digit or minus sign, the argument count
for the next command is multiplied by four.
The argument count is initially one, so executing this function the
first time makes the argument count four, a second time makes the
argument count sixteen, and so on.
Attempt to perform completion on the text before point.
attempts completion treating the text as a variable (if the
command (including aliases and functions) in turn.  If none
of these produces a match, filename completion is attempted.
List the possible completions of the text before point.
Insert all completions of the text before point
that would have been generated by
with a single match from the list of possible completions.
of possible completions, inserting each match in turn.
At the end of the list of completions, the bell is rung
and the original text is restored.
of matches; a negative argument may be used to move backward
through the list.
by default.
Deletes the character under the cursor if not at the beginning or
If at the end of the line, behaves identically to
This command is unbound by default.
Attempt filename completion on the text before point.
List the possible completions of the text before point,
treating it as a filename.
Attempt completion on the text before point, treating
it as a username.
List the possible completions of the text before point,
treating it as a username.
Attempt completion on the text before point, treating
it as a shell variable.
List the possible completions of the text before point,
treating it as a shell variable.
Attempt completion on the text before point, treating
it as a hostname.
List the possible completions of the text before point,
treating it as a hostname.
Attempt completion on the text before point, treating
it as a command name.  Command completion attempts to
match the text against aliases, reserved words, shell
functions, shell builtins, and finally executable filenames,
in that order.
List the possible completions of the text before point,
treating it as a command name.
Attempt completion on the text before point, comparing
the text against lines from the history list for possible
completion matches.
Perform filename completion and insert the list of possible completions
enclosed within braces so the list is available to the shell (see
above).
Begin saving the characters typed into the current keyboard macro.
Stop saving the characters typed into the current keyboard macro
and store the definition.
Re-execute the last keyboard macro defined, by making the characters
in the macro appear as if typed at the keyboard.
any bindings or variable assignments found there.
Abort the current editing command and
ring the terminal's bell (subject to the setting of
that is bound to the corresponding uppercase character.
Metafy the next character typed.
is equivalent to
Incremental undo, separately remembered for each line.
Undo all changes made to this line.  This is like executing the
command enough times to return the line to its initial state.
Perform tilde expansion on the current word.
Set the mark to the point.  If a
numeric argument is supplied, the mark is set to that position.
Swap the point with the mark.  The current cursor position is set to
the saved position, and the old cursor position is saved as the mark.
A character is read and point is moved to the next occurrence of that
character.  A negative count searches for previous occurrences.
A character is read and point is moved to the previous occurrence of that
character.  A negative count searches for subsequent occurrences.
Without a numeric argument, the value of the readline
variable is inserted at the beginning of the current line.
If a numeric argument is supplied, this command acts as a toggle:  if
the characters at the beginning of the line do not match the value
the line.
In either case, the line is accepted as if a newline had been typed.
The default value of
a shell comment.
If a numeric argument causes the comment character to be removed, the line
will be executed by the shell.
The word before point is treated as a pattern for pathname expansion,
with an asterisk implicitly appended.  This pattern is used to
generate a list of matching file names for possible completions.
The word before point is treated as a pattern for pathname expansion,
and the list of matching file names is inserted, replacing the word.
If a numeric argument is supplied, an asterisk is appended before
pathname expansion.
The list of expansions that would have been generated by
is displayed, and the line is redrawn.
If a numeric argument is supplied, an asterisk is appended before
pathname expansion.
Print all of the functions and their key bindings to the
readline output stream.  If a numeric argument is supplied,
the output is formatted in such a way that it can be made part
Print all of the settable readline variables and their values to the
readline output stream.  If a numeric argument is supplied,
the output is formatted in such a way that it can be made part
Print all of the readline key sequences bound to macros and the
strings they output.  If a numeric argument is supplied,
the output is formatted in such a way that it can be made part
Display version information about the current instance of
When word completion is attempted for an argument to a command for
below), the programmable completion facilities are invoked.
First, the command name is identified.
If a compspec has been defined for that command, the
compspec is used to generate the list of possible completions for the word.
If the command word is a full pathname, a compspec for the full
pathname is searched for first.
If no compspec is found for the full pathname, an attempt is made to
find a compspec for the portion following the final slash.
Once a compspec has been found, it is used to generate the list of
matching words.
First, the actions specified by the compspec are used.
Only matches which are prefixed by the word being completed are
returned.
When the
or
option is used for filename or directory name completion, the shell
variable
is used to filter the matches.
Any completions specified by a filename expansion pattern to the
The words generated by the pattern need not match the word
being completed.
The
shell variable is not used to filter the matches, but the
variable is used.
is considered.
The string is first split using the characters in the
special variable as delimiters.
Shell quoting is honored.
Each word is then expanded using
brace expansion, tilde expansion, parameter and variable expansion,
command substitution, and arithmetic expansion,
as described above under 
The results are split using the rules described above under
The results of the expansion are prefix-matched against the word being
completed, and the matching words become the possible completions.
After these matches have been generated, any shell function or command
When the command or function is invoked, the
and
variables are assigned values as described above under
If a shell function is being invoked, the 
and
variables are also set.
When the function or command is invoked, the first argument is the
name of the command whose arguments are being completed, the
second argument is the word being completed, and the third argument
is the word preceding the word being completed on the current command line.
No filtering of the generated completions against the word being completed
is performed; the function or command has complete freedom in generating
the matches.
The function may use any of the shell facilities, including the
It must put the possible completions in the
array variable.
in an environment equivalent to command substitution.
It should print a list of completions, one per line, to the
standard output.
Backslash may be used to escape a newline, if necessary.
After all of the possible completions are generated, any filter
in the pattern is replaced with the text of the word being completed.
is removed before attempting a match.
Any completion that matches the pattern will be removed from the list.
not matching the pattern will be removed.
options are added to each member of the completion list, and the result is
returned to the readline completion code as the list of possible
completions.
If the previously-applied actions do not generate any matches, and the
compspec was defined, directory name completion is attempted.
compspec was defined, directory name completion is attempted and any
matches are added to the results of the other actions.
By default, if a compspec is found, whatever it generates is returned
to the completion code as the full set of possible completions.
default of filename completion is disabled.
if the compspec generates no matches.
compspec was defined, readline's default completion will be performed
generate no matches.
When a compspec indicates that directory name completion is desired,
the programmable completion functions force readline to append a slash
to completed names which are symbolic links to directories, subject to  
When the
option to the
builtin is enabled, the shell provides access to the
the list of commands previously typed.
number of commands to save in a history list.
The text of the last
commands (default 500) is saved.  The shell
stores each command in the history list prior to parameter and
variable expansion (see
above) but after history expansion is performed, subject to the
values of the shell variables
and
On startup, the history is initialized from the file named by
the variable
The file named by the value of
is truncated, if necessary, to contain no more than
the number of lines specified by the value of
When an interactive shell exits, the last
lines are copied from the history list to
If the
shell option is enabled
(see the description of
under
below), the lines are appended to the history file,
otherwise the history file is overwritten.
If
is unset, or if the history file is unwritable, the history is
not saved.  After saving the history, the history file is truncated
to contain no more than
lines.  If
is not set, no truncation is performed.
The builtin command
(see
below) may be used to list or edit and re-execute a portion of
the history list.
The
builtin may be used to display or modify the history list and
manipulate the history file.
When using command-line editing, search commands
are available in each editing mode that provide access to the
history list.
The shell allows control over which commands are saved on the history
list.  The
and
variables may be set to cause the shell to save only a subset of the
commands entered.
The
shell option, if enabled, causes the shell to attempt to save each
line of a multi-line command in the same history entry, adding
semicolons where necessary to preserve syntactic correctness.
The
shell option causes the shell to save the command with embedded newlines
instead of semicolons.  See the description of the
builtin below under
for information on setting and unsetting shell options.
The shell supports a history expansion feature that
is similar to the history expansion in
This section describes what syntax features are available.  This
feature is enabled by default for interactive shells, and can be
disabled using the
option to the
builtin command (see
below).  Non-interactive shells do not perform history expansion
by default.
History expansions introduce words from the history list into
the input stream, making it easy to repeat commands, insert the
arguments to a previous command into the current input line, or
fix errors in previous commands quickly.
History expansion is performed immediately after a complete line
is read, before the shell breaks it into words.
It takes place in two parts.
The first is to determine which line from the history list
to use during substitution.
The second is to select portions of that line for inclusion into
the current one.
The line is broken into words in the same fashion as when reading input,
quotes are considered one word.
History expansions are introduced by the appearance of the
the history expansion character.
Several characters inhibit history expansion if found immediately
following the history expansion character, even if it is unquoted:
inhibit expansion.
Several shell options settable with the
builtin may be used to tailor the behavior of history expansion.
If the
shell option is enabled (see the description of the
builtin), and
is being used, history substitutions are not immediately passed to
the shell parser.
Instead, the expanded line is reloaded into the
editing buffer for further modification.
If
is being used, and the
shell option is enabled, a failed history substitution will be reloaded
into the
editing buffer for correction.
The
option to the
builtin command may be used to see what a history expansion will
do before using it.
The
option to the
builtin may be used to add commands to the end of the history list
without actually executing them, so that they are available for
subsequent recall.
The shell allows control of the various characters used by the
history expansion mechanism (see the description of
above under
An event designator is a reference to a command line entry in the
history list.
Start a history substitution, except when followed by a
newline, carriage return, =
Refer to command line
Refer to the current command line minus
Refer to the most recent command starting with 
Refer to the most recent command containing
is followed immediately by a newline.
Quick substitution.  Repeat the last command, replacing
with
Equivalent to
The entire command line typed so far.
Word designators are used to select desired words from the event.
A 
separates the event specification from the word designator.
It may be omitted if the word designator begins with a
or
Words are numbered from the beginning of the line,
with the first word being denoted by 0 (zero).
Words are inserted into the current line separated by single spaces.
The zeroth word.  For the shell, this is the command
word.
The first argument.  That is, word 1.
The last argument.
All of the words but the zeroth.  This is a synonym
if there is just one
word in the event; the empty string is returned in that case.
If a word designator is supplied without an event specification, the
previous command is used as the event.
After the optional word designator, there may appear a sequence of
one or more of the following modifiers, each preceded by a `:'.
Remove a trailing file name component, leaving only the head.
Remove all leading file name components, leaving the tail.
basename.
Remove all but the trailing suffix.
Print the new command but do not execute it.
Quote the substituted words, escaping further substitutions.
Quote the substituted words as with
but break into words at
and newlines.
Substitute
for the first occurrence of
final delimiter is optional if it is the last character of the
event line.  The delimiter may be quoted in
and
with a single backslash.  If & appears in
it is replaced by
A single backslash will quote the &.  If
is null, it is set to the last
substituted, or, if no previous history substitutions took place,
the last
in a
search.
Repeat the previous substitution.
Cause changes to be applied over the entire event line.  This is
if it is the last character of the event line.
Unless otherwise noted, each builtin command documented in this
section as accepting options preceded by
accepts
to signify the end of the options.
do not accept options.
No effect; the command does nothing beyond expanding
and performing any specified
redirections.  A zero exit code is returned.
Read and execute commands from
in the current
shell environment and return the exit status of the last command
executed from
If
does not contain a slash, file names in
are used to find the directory containing
The file searched for in
need not be executable.
searched if no file is found in
If the
option to the
builtin command is turned off, the
is not searched.
parameters are unchanged.
The return status is the status of the last command exited within
the script (0 if no commands are executed), and false if
is not found or cannot be read.
option prints the list of aliases in the form
When arguments are supplied, an alias is defined for
checked for alias substitution when the alias is expanded.
is supplied, the name and value of the alias is printed.
no alias has been defined.
had been started with
returns 0 unless run when job control is disabled or, when run with
or was started without job control.
Display current
key and function bindings, bind a key sequence to a
function or macro, or set a
variable.
Each non-option argument is a command as it would appear in
but each binding or command must be passed as a separate argument;
Options, if supplied, have the following meanings:
Use
as the keymap to be affected by the subsequent bindings.
Acceptable
names are
that they can be re-read.
can be re-read.
they output in such a way that they can be re-read.
they output.
entered.
The return value is 0 unless an unrecognized option is given or an
error occurred.
Exit from within a
or
is greater than the number of enclosing loops, all enclosing loops
are exited.  The return value is 0 unless the shell is not executing
a loop when
is executed.
Execute the specified shell builtin, passing it
and return its exit status.
This is useful when defining a
function whose name is the same as a shell builtin,
retaining the functionality of the builtin within the function.
The return status is false if
is not a shell builtin command.
is the
default
The variable
defines the search path for the directory containing
Alternative directory names in
are separated by a colon (:).  A null directory name in
then
is not used. The
option says to use the physical directory structure instead of
following symbolic links (see also the
option to the
builtin command); the
option forces symbolic links to be followed.  An argument of
is equivalent to
successful, the absolute pathname of the new working directory is
written to the standard output.
The return value is true if the directory was successfully changed;
false otherwise.
Returns the context of any active subroutine call (a shell function or
filename of the current subroutine call.
displays the line number, subroutine name, and source file corresponding
to that position in the current execution call stack.  This extra
information may be used, for example, to print a stack trace.  The
current frame is frame 0.
The return value is 0 unless the shell is not executing a subroutine
call stack.
Run
with
suppressing the normal shell function lookup. Only builtin
commands or commands found in the
are executed.  If the
option is given, the search for
is performed using a default value for
that is guaranteed to find all of the standard utilities.
If either the
or
option is supplied, a description of
is printed.  The
option causes a single word indicating the command or file name
used to invoke
to be displayed; the
option produces a more verbose description.
If the
or
option is supplied, the exit status is 0 if
was found, and 1 if not.  If neither option is supplied and
an error occurred or
cannot be found, the exit status is 127.  Otherwise, the exit status of the
builtin is the exit status of
the matches to the standard output.
set by the programmable completion facilities, while available, will not
have useful values.
The matches will be generated in the same way as if the programmable
completion code had generated them directly from a completion specification
with the same flags.
will be displayed.
The return value is true unless an invalid option is supplied, or no
matches were generated.
existing completion specifications are printed in a way that allows
them to be reused as input.
completion specifications.
The process of applying these completion specifications when word completion
Other options, if specified, have the following meanings.
should be quoted to protect them from expansion before the
builtin is invoked.
beyond the simple generation of completions.
generates no matches.
Use readline's default filename completion if the compspec generates
no matches.
Perform directory name completion if the compspec generates no matches.
Tell readline that the compspec generates filenames, so it can perform any
suppressing trailing spaces).  Intended to be used with shell functions.
Tell readline not to append a space (the default) to words completed at
the end of the line.
After any matches defined by the compspec are generated, 
directory name completion is attempted and any
matches are added to the results of the other actions.
completions:
Array variable names.
Names of disabled shell builtins.
Names of enabled shell builtins.
Names of shell functions.
Hostnames, as taken from the file specified by the
shell variable.
Names of running jobs, if job control is active.
Signal names.
Names of stopped jobs, if job control is active.
the possible completions.
special variable as delimiters, and each resultant word is expanded.
The possible completions are the members of the resultant list which
match the word being completed.
used as the possible completions.
environment.
When it finishes, the possible completions are retrieved from the value
of the
array variable.
It is applied to the list of possible completions generated by the
preceding options and arguments, and each completion matching
after all other options have been applied.
after all other options have been applied.
The return value is true unless an invalid option is supplied, an option
argument, an attempt is made to remove a completion specification for
an error occurs adding a completion specification.
Resume the next iteration of the enclosing
or
loop.
If
is greater than the number of enclosing loops, the last enclosing loop
(the ``top-level'' loop) is resumed.  The return value is 0 unless the
shell is not executing a loop when
is executed.
The
option will display the attributes and values of each
When
is used, additional options are ignored.
The
option inhibits the display of function definitions; only the
function name and attributes are printed.
the source file name and line number where the function is defined
are displayed as well.  The
option implies
The following options can
be used to restrict output to variables with the specified attribute or
to give variables attributes:
above).
Use function names only.
The variable is treated as an integer; arithmetic evaluation (see
is performed when the variable is assigned a value.
by subsequent assignment statements or unset.
the calling shell.
The trace attribute has no special meaning for variables.
may not be used to destroy an array variable.  When used in a function,
makes each
command.
The return value is 0 unless an invalid option is encountered,
an attempt is made to define a function using
an attempt is made to assign a value to a readonly variable,
an attempt is made to assign a value to an array variable without
using the compound assignment syntax (see
an attempt is made to turn off readonly status for a readonly variable,
an attempt is made to turn off array status for an array variable,
Without options, displays the list of currently remembered directories.
The default display is on a single line with directory names separated
by spaces.
Directories are added to the list with the 
command; the
command removes entries from the list.
shown by
when invoked without options, starting with zero.
shown by
when invoked without options, starting with zero.
Clears the directory stack by deleting all of the entries.
Produces a longer listing; the default listing format uses a 
tilde to denote the home directory.
Print the directory stack with one entry per line.
Print the directory stack with one entry per line,
prefixing each entry with its index in the stack.
The return value is 0 unless an
of the directory stack.
Without options, each
is removed from the table of active jobs.
is not removed from the table, but is marked so that
is not sent to the job if the shell receives a
If no
is present, and neither the
nor the
If no
is supplied, the
option means to remove or mark all jobs; the
option without a
argument restricts operation to running jobs.
The return value is 0 unless a
does not specify a valid job.
The return status is always 0.
the following backslash-escaped characters is enabled.  The
option disables the interpretation of these escape characters,
even on systems where they are interpreted by default.
escape characters by default.
interprets the following escape sequences:
alert (bell)
backspace
suppress trailing newline
an escape character
form feed
new line
carriage return
horizontal tab
vertical tab
backslash
(zero to three octal digits)
(one or two hex digits)
Enable and disable builtin shell commands.
Disabling a builtin allows a disk command which has the same name
as a shell builtin to be executed without specifying a full pathname,
even though the shell normally searches for builtins before disk commands.
is disabled; otherwise,
binary found via the
instead of the shell builtin version, run
The
option means to load the new builtin command
from shared object
on systems that support dynamic loading.  The
option will delete a builtin previously loaded with
option is supplied, a list of shell builtins is printed.
With no other option arguments, the list consists of all enabled
shell builtins.
indication of whether or not each is enabled.
The return value is 0 unless a
is not a shell builtin or there is an error loading a new builtin
from a shared object.
command.  This command is then read and executed by the shell, and
its exit status is returned as the value of
If there are no
or only null arguments,
returns 0.
If
is specified, it replaces the shell.
No new process is created.  The
If the
option is supplied,
the shell places a dash at the beginning of the zeroth arg passed to 
This is what
does.  The
option causes
to be executed with an empty environment.  If
is supplied, the shell passes
as the zeroth argument to the executed command.  If
cannot be executed for some reason, a non-interactive shell exits,
unless the shell option
is enabled, in which case it returns failure.
An interactive shell returns failure if the file cannot be executed.
If
is not specified, any redirections take effect in the current shell,
and the return status is 0.  If there is a redirection error, the
return status is 1.
Cause the shell to exit
is omitted, the exit status
is that of the last command executed.
A trap on
is executed before the shell terminates.
The supplied
are marked for automatic export to the environment of
subsequently executed commands.  If the 
option is given,
the 
refer to functions.
If no
are given, or if the
option is supplied, a list
of all names that are exported in this shell is printed.
The
option causes the export property to be removed from each
returns an exit status of 0 unless an invalid option is
encountered,
is supplied with a
that is not a function.
Fix Command.  In the first form, a range of commands from
to
is selected from the history list.
and
may be specified as a string (to locate the last command beginning
with that string) or as a number (an index into the history list,
where a negative number is used as an offset from the current
command number).  If 
is not specified it is set to
the current command for listing (so that
prints the last 10 commands) and to
otherwise.
If
is not specified it is set to the previous
The
option suppresses
the command numbers when listing.  The
option reverses the order of
the commands.  If the
option is given,
the commands are listed on
standard output.  Otherwise, the editor given by
is invoked
on a file containing those commands.  If
is not given, the
value of the
variable is used, and
the value of
if
is not set.  If neither variable is set,
is used.  When editing is complete, the edited commands are
echoed and executed.
A useful alias to use with this is
so that typing
runs the last command beginning with
and typing
re-executes the last command.
If the first form is used, the return value is 0 unless an invalid
option is encountered or
or
specify history lines out of range.
If the
option is supplied, the return value is the value of the last
command executed or failure if an error occurs with the temporary
file of commands.  If the second form is used, the return status
is that of the command re-executed, unless
does not specify a valid history line, in which case
returns failure.
Resume
in the foreground, and make it the current job.
If
The return value is that of the command placed into the foreground,
or failure if run when job control is disabled or, when run with
job control enabled, if
does not specify a valid job or
specifies a job that was started without job control.
is used by shell procedures to parse positional parameters.
contains the option characters to be recognized; if a character
is followed by a colon, the option is expected to have an
argument, which should be separated from it by white space.
The colon and question mark characters may not be used as
option characters.
Each time it is invoked,
places the next option in the shell variable
initializing
if it does not exist,
and the index of the next argument to be processed into the
variable
is initialized to 1 each time the shell or a shell script
is invoked.  When an option requires an argument,
places that argument into the variable
The shell does not reset
automatically; it must be manually reset between multiple
calls to
within the same shell invocation if a new set of parameters
is to be used.
return value greater than zero.
normally parses the positional parameters, but if more arguments are
given in
parses those instead.
can report errors in two ways.  If the first character of
is a colon,
error reporting is used.  In normal operation diagnostic messages
are printed when invalid options or missing option arguments are
encountered.
If the variable
is set to 0, no error messages will be displayed, even if the first
character of 
is not a colon.
If an invalid option is seen,
places ? into
and, if not silent,
prints an error message and unsets
If
is silent,
the option character found is placed in
and no diagnostic message is printed.
If a required argument is not found, and
is not silent,
is unset, and a diagnostic message is printed.
If
and
is set to the option character found.
returns true if an option, specified or unspecified, is found.
It returns false if the end of options is encountered or an
error occurs.
For each
the full file name of the command is determined by searching
the directories in
and remembered.
If the
option is supplied, no path search is performed, and
is used as the full file name of the command.
The
option causes the shell to forget all
remembered locations.
The
If the
The
option causes output to be displayed in a format that may be reused as input.
information about remembered commands is printed.
The return status is true unless a
is not found or an invalid option is supplied.
Display helpful information about builtin commands.  If
is specified,
gives detailed help on all commands matching
otherwise help for all the builtins and shell control structures
is printed.
usage synopsis.
The return status is 0 unless no command matches
With no options, display the command
history list with line numbers.  Lines listed
with a 
have been modified.  An argument of
lists only the last
lines.
the time stamp associated with each displayed history entry.
No intervening blank is printed between the formatted time stamp
and the history line.
name of the history file; if not, the value of
is used.  Options, if supplied, have the following meanings:
Clear the history list by deleting all the entries.
Append the ``new'' history lines (history lines entered since the
Read the history lines not already read from the history
file into the current history list.  These are lines
appended to the history file since the beginning of the
Read the contents of the history file
and use them as the current history.
Write the current history to the history file, overwriting the
history file's contents.
the result on the standard output.
Does not store the results in the history list.
Store the
in the history list as a single entry.  The last command in the
history list is removed before the
are added.
associated with each history entry is written to the history file.
The return value is 0 unless an invalid option is encountered, an
error occurs while reading or writing the history file, an invalid
The first form lists the active jobs.  The options have the following
meanings:
List process IDs
in addition to the normal information.
List only the process ID of the job's process group
leader.
Display information only about jobs that have changed status since
the user was last notified of their status.
Restrict output to running jobs.
Restrict output to stopped jobs.
If
is given, output is restricted to information about that job.
The return status is 0 unless an invalid option is encountered
or an invalid
is supplied.
If the
option is supplied,
replaces any
found in
or
with the corresponding process group ID, and executes
passing it
returning its exit status.
Send the signal named by
or
to the processes named by
or
is either a case-insensitive signal name such as
(with or without the
prefix) or a signal number;
is a signal number.
If
is not present, then
is assumed.
An argument of
lists the signal names.
If any arguments are supplied when
is given, the names of the signals corresponding to the arguments are
listed, and the return status is 0.
is a number specifying either a signal number or the exit status of
a process terminated by a signal.
returns true if at least one signal was successfully sent, or false
if an error occurs or an invalid option is encountered.
Each
is an arithmetic expression to be evaluated (see
If the last
evaluates to 0,
returns 1; 0 is returned otherwise.
For each argument, a local variable named
is created, and assigned
When
is used within a function, it causes the variable
to have a visible scope restricted to that function and its children.
With no operands,
writes a list of local variables to the standard output.  It is
an error to use
when not within a function.  The return status is 0 unless
is used outside a function, an invalid
is supplied, or
Exit a login shell.
Removes entries from the directory stack.  With no arguments,
removes the top directory from the stack, and performs a
to the new top directory.
Arguments, if supplied, have the following meanings:
shown by
starting with zero.  For example:
removes the first directory,
the second.
shown by
starting with zero.  For example:
removes the last directory,
the next to last.
Suppresses the normal change of directory when removing directories
from the stack, so that only the stack is manipulated.
If the
command is successful, a 
is performed as well, and the return status is 0.
returns false if an invalid option is encountered, the directory stack
is empty, a non-existent directory stack entry is specified, or the
directory change fails.
plain characters, which are simply copied to standard output, character
escape sequences, which are converted and copied to the standard output, and
format specifications, each of which causes printing of the next successive
extra format specifications behave as if a zero value or null string, as
appropriate, had been supplied.  The return value is zero on success,
non-zero on failure.
Adds a directory to the top of the directory stack, or rotates
the stack, making the new top of the stack the current working
directory.  With no arguments, exchanges the top two directories
and returns 0, unless the directory stack is empty.
Arguments, if supplied, have the following meanings:
(counting from the left of the list shown by
starting with zero)
is at the top.
(counting from the right of the list shown by
starting with zero) is at the top.
Suppresses the normal change of directory when adding directories
to the stack, so that only the stack is manipulated.
Adds
to the directory stack at the top, making it the
new current working directory.
If the
command is successful, a 
is performed as well.
If the first form is used,
returns 0 unless the cd to
fails.  With the second form,
returns 0 unless the directory stack is empty,
a non-existent directory stack element is specified,
or the directory change to the specified new current directory
fails.
Print the absolute pathname of the current working directory.
The pathname printed contains no symbolic links if the
option is supplied or the 
option to the
builtin command is enabled.
If the
option is used, the pathname printed may contain symbolic links.
The return status is 0 unless an error occurs while
reading the name of the current directory or an
invalid option is supplied.
One line is read from the standard input, or from the file descriptor
is assigned to the first
the second word to the second
and so on, with leftover words and their intervening separators assigned
to the last
If there are fewer words read from the input stream than names,
the remaining names are assigned empty values.
The characters in 
are used to split the line into words.
meaning for the next character read and for line continuation.
Options, if supplied, have the following meanings:
The words are assigned to sequential indices
of the array variable
starting at 0.
is unset before any new values are assigned.
rather than newline.
If the standard input
is coming from a terminal,
(see
above) is used to obtain the line.
waiting for a complete line of input.
trailing newline, before attempting to read any input.  The prompt
is displayed only if input is coming from a terminal.
Backslash does not act as an escape character.
The backslash is considered to be part of the line.
In particular, a backslash-newline pair may not be used as a line
continuation.
Silent mode.  If input is coming from a terminal, characters are
not echoed.
terminal or a pipe.
If no
are supplied, the line read is assigned to the variable
times out, or an invalid file descriptor is supplied as the argument to
The given
may not be changed by subsequent assignment.
If the
option is supplied, the functions corresponding to the
marked.
The
option restricts the variables to arrays.
If no
arguments are given, or if the
option is supplied, a list of all readonly names is printed.
The
option causes output to be displayed in a format that
may be reused as input.
The return status is 0 unless an invalid option is encountered,
one of the
is not a valid shell variable name, or
is supplied with a
that is not a function.
Causes a function to exit with the return value specified by
If 
is omitted, the return status is that of the last command
executed in the function body.  If used outside a function,
but during execution of a script by the 
that script and return either
or the exit status of the last command executed within the
script as the exit status of the script.  If used outside a
the return status is false.
before execution resumes after the function or script.
Without options, the name and value of each shell variable are displayed
in a format that can be reused as input
for setting or resetting the currently-set variables.
Read-only variables cannot be reset.
The output is sorted according to the current locale.
When options are specified, they set or unset shell attributes.
Any arguments remaining after the options are processed are treated
as values for the positional parameters and are assigned, in order, to 
Options, if specified, have the following meanings:
Automatically mark variables and functions which are modified or
created for export to the environment of subsequent commands.
Report the status of terminated background jobs
immediately, rather than before the next primary prompt.  This is
effective only when job control is enabled.
above) exits with a non-zero status.
The shell does not exit if the
command that fails is part of the command list immediately following a
or
keyword, 
part of the test in an
statement, part of a
or
list, or if the command's return value is
being inverted via
Disable pathname expansion.
Remember the location of commands as they are looked up for execution.
This is enabled by default.
All arguments in the form of assignment statements
are placed in the environment for a command, not just
those that precede the command name.
Monitor mode.  Job control is enabled.  This option is on
by default for interactive shells on systems that support
it (see
above).  Background processes run in a separate process
group and a line containing their exit status is printed
upon their completion.
Read commands but do not execute them.  This may be used to 
check a shell script for syntax errors.  This is ignored by
interactive shells.
Same as
Same as
Use an emacs-style command line editing interface.  This is enabled
by default when the shell is interactive, unless the shell is started
with the
option.
Same as
Same as
Same as
Same as
Same as
Enable command history, as described above under
This option is on by default in interactive shells.
The effect is as if the shell command
had been executed
(see
above).
Same as
Same as
Same as
Same as
Same as
Currently ignored.
Same as
Same as
Same as
Same as
If set, the return value of a pipeline is the value of the last
(rightmost) command to exit with a non-zero status, or zero if all
commands in the pipeline exit successfully.
This option is disabled by default.
Change the behavior of
where the default operation differs
Same as
Same as
Use a vi-style command line editing interface.
Same as
If
printed.
If
commands to recreate the current option settings is displayed on
the standard output.
Turn on
mode.  In this mode, the
and
files are not processed, shell functions are not inherited from the
environment, and the
variable, if it appears in the environment, is ignored.
If the shell is started with the effective user (group) id not equal to the
are taken and the effective user id is set to the real user id.
not reset.
Turning this option off causes the effective user
and group ids to be set to the real user and group ids.
Exit after reading and executing one command.
Treat unset variables as an error when performing
parameter expansion.  If expansion is attempted on an
unset variable, the shell prints an error message, and,
if not interactive, exits with a non-zero status.
Print shell input lines as they are read.
followed by the command and its expanded arguments
or associated word list.
The shell performs brace expansion (see
above).  This is on by default.
If set,
does not overwrite an existing file with the
and
redirection operators.  This may be overridden when 
creating output files by using the redirection operator
instead of
substitutions, and commands executed in a subshell environment.
Enable
style history substitution.  This option is on by
default when the shell is interactive.
If set, the shell does not follow symbolic links when executing
commands such as
that change the current working directory.  It uses the
physical directory structure instead.  By default,
follows the logical chain of directories when performing commands
which change the current directory.
functions, command substitutions, and commands executed in a
subshell environment.
in such cases.
If no arguments follow this option, then the positional parameters are
unset.  Otherwise, the positional parameters are set to the
assigned to the positional parameters.  The
and
options are turned off.
the positional parameters remain unchanged.
The options are off by default unless otherwise noted.
The options can also be specified as arguments to an invocation of
the shell.
The current set of options may be found in
The return status is always true unless an invalid option is encountered.
If
is 0, no parameters are changed.
If
is not given, it is assumed to be 1.
If
The return status is greater than zero if
is greater than
or less than zero; otherwise 0.
Toggle the values of variables controlling optional shell behavior.
With no options, or with the
option, a list of all settable options is displayed, with
an indication of whether or not each is set.
may be reused as input.
Other options have the following meanings:
Suppresses normal output (quiet mode); the return status indicates
otherwise.
option to the
builtin.
If either
or
those options which are set or unset, respectively.
by default.
are enabled, non-zero otherwise.  When setting or unsetting options,
option.
If set, an argument to the
builtin command that
is not a directory is assumed to be the name of a variable whose
value is the directory to change to.
If set, minor errors in the spelling of a directory component in a
command will be corrected.
The errors checked for are transposed characters,
a missing character, and one character too many.
If a correction is found, the corrected file name is printed,
and the command proceeds.
This option is only used by interactive shells.
table exists before trying to execute it.  If a hashed command no
longer exists, a normal path search is performed.
and, if necessary, updates the values of
and
If set,
attempts to save all lines of a multiple-line
command in the same history entry.  This allows
easy re-editing of multi-line commands.
If set,
changes its behavior to that of version 3.1 with respect to quoted
arguments to the conditional command's =~ operator.
If set, 
includes filenames beginning with a `.' in the results of pathname
expansion.
If set, a non-interactive shell will not exit if
it cannot execute the file specified as an argument to the
builtin command.  An interactive shell does not exit if
fails.
If set, aliases are expanded as described above under
This option is enabled by default for interactive shells.
If set, behavior intended for use by debuggers is enabled:
file name and line number corresponding to each function name supplied
as an argument.
next command is skipped and not executed.
shell is executing in a subroutine (a shell function or a shell script
descriptions above.
Function tracing is enabled:  command substitution, shell functions, and
Error tracing is enabled:  command substitution, shell functions, and
If set, the extended pattern matching features described above under
enclosed in double quotes.  This option is enabled by default.
If set, patterns which fail to match filenames during pathname expansion
result in an expansion error.
cause words to be ignored when performing word completion even if
the ignored words are the only possible completions.
See
This option is enabled by default.
If set, shell error messages are written in the standard GNU error
message format.
If set, the history list is appended to the file named by the value
of the
variable when the shell exits, rather than overwriting the file.
If set, and
is being used, a user is given the opportunity to re-edit a
failed history substitution.
If set, and 
is being used, the results of history substitution are not immediately
passed to the shell parser.  Instead, the resulting line is loaded into
If set, and
under
above).
This is enabled by default.
to all jobs when an interactive login shell exits.
If set, allow a word beginning with
to cause that word and all remaining characters on that
line to be ignored in an interactive shell (see
above).  This option is enabled by default.
If set, and the
option is enabled, multi-line commands are saved to the history with
embedded newlines rather than using semicolon separators where possible.
The shell sets this option if it is started as a login shell (see
above).
The value may not be changed.
accessed since the last time it was checked, the message ``The mail in
If set, and
is being used,
completion is attempted on an empty line.
If set,
expansion (see
above).
If set,
If set,
allows patterns which match no
files (see
above)
to expand to a null string, rather than themselves.
If set, the programmable completion facilities (see
This option is enabled by default.
If set, prompt strings undergo
parameter expansion, command substitution, arithmetic
expansion, and quote removal after being expanded as described in
above.  This option is enabled by default.
The shell sets this option if it is started in restricted mode (see
below).
The value may not be changed.
This is not reset when the startup files are executed, allowing
the startup files to discover whether or not a shell is restricted.
If set, the
builtin prints an error message when the shift count exceeds the
number of positional parameters.
If set, the
to find the directory containing the file supplied as an argument.
This option is enabled by default.
by default.
Suspend the execution of this shell until it receives a
signal.  The
option says not to complain if this is 
a login shell; just suspend anyway.  The return status is 0 unless
the shell is a login shell and
is not supplied, or if job control is not enabled.
Return a status of 0 or 1 depending on
the evaluation of the conditional expression
Each operator and operand must be a separate argument.
Expressions are composed of the primaries described above under
Expressions may be combined using the following operators, listed
in decreasing order of precedence.
True if
is false.
This may be used to override the normal precedence of operators.
True if both
and
are true.
True if either
or
is true.
expressions using a set of rules based on the number of arguments.
0 arguments
The expression is false.
1 argument
The expression is true if and only if the argument is not null.
2 arguments
only if the second argument is null.
If the first argument is one of the unary conditional operators listed above
under
the expression is true if the unary test is true.
If the first argument is not a valid unary conditional operator, the expression
is false.
3 arguments
If the second argument is one of the binary conditional operators listed above
under
the result of the expression is the result of the binary test using
the first and third arguments as operands.
the two-argument test using the second and third arguments.
argument.
Otherwise, the expression is false.
in this case.  
4 arguments
the three-argument expression composed of the remaining arguments.
Otherwise, the expression is parsed and evaluated according to 
precedence using the rules listed above.
5 or more arguments
The expression is parsed and evaluated according to precedence
using the rules listed above.
Print the accumulated user and system times for the shell and
for processes run from the shell.  The return status is 0.
The command
is to be read and executed when the shell receives
signal(s)
If
each specified signal is
reset to its original disposition (the value it had
upon entrance to the shell).
If 
is the null string the signal specified by each
is ignored by the shell and by the commands it invokes.
If
is not present and
has been supplied, then the trap commands associated with each
are displayed.
If no arguments are supplied or if only
is given,
prints the list of commands associated with each signal.
The
option causes the shell to print a list of signal names and
their corresponding numbers.
Each
is either
Signal names are case insensitive and the SIG prefix is optional.
If a
is
(0) the command
is executed on exit from the shell.
If a
is
the command
command, and before the first command executes in a shell function (see
above).
If a
is
the command
subject to the following conditions.
The
trap is not executed if the failed
command is part of the command list immediately following a
or
keyword, 
part of the test in an
statement, part of a
or
list, or if the command's return value is
being inverted via
If a
is
the command
is executed each time a shell function or a script executed with the
Signals ignored upon entry to the shell cannot be trapped or reset.
Trapped signals that are not being ignored are reset to their original
values in a child process when it is created.
The return status is false if any
is invalid; otherwise
returns true.
With no options, 
indicate how each
would be interpreted if used as a command name.
If the
option is used,
prints a string which is one of
or
if
is an alias, shell reserved word, function, builtin, or disk file,
respectively.
If the
is not found, then nothing is printed, and an exit status of false
is returned.
If the
option is used,
either returns the name of the disk file
that would be executed if
were specified as a command name,
or nothing if
would not return
The
option forces a
would not return
If a command is hashed,
and
print the hashed value, not necessarily the file that appears
first in 
If the
option is used, 
prints all of the places that contain
an executable named 
This includes aliases and functions,
if and only if the 
option is not also used.
The table of hashed commands is not consulted
when using
The
returns true if any of the arguments are found, false if
none are found.
Provides control over the resources available to the shell and to
processes started by it, on systems that allow such control.
set for the given resource.  A hard limit cannot be increased once it
is set; a soft limit may be increased up to the value of the hard limit.
limits are set.
The value of
can be a number in the unit specified for the resource
or one of the special values
or
which stand for the current hard limit, the current soft limit, and
no limit, respectively.
If
is omitted, the current value of the soft limit of the resource is
resource is specified, the limit name and unit are printed before the value.
Other options are interpreted as follows:
All current limits are reported
The maximum size of core files created
The maximum size of a process's data segment
The maximum scheduling priority ("nice")
The maximum size of files written by the shell and its children
The maximum number of pending signals
The maximum size that may be locked into memory
The maximum resident set size
The maximum number of open file descriptors (most systems do not
allow this value to be set)
The pipe size in 512-byte blocks (this may not be set)
The maximum number of bytes in POSIX message queues
The maximum real-time scheduling priority
The maximum stack size
The maximum amount of cpu time in seconds
The maximum number of processes available to a single user
The maximum amount of virtual memory available to the shell
The maximum number of file locks
If
is given, it is the new value of the specified resource (the
option is display only).
If no option is given, then
is assumed.  Values are in 1024-byte increments, except for
which is in seconds,
which is in units of 512-byte blocks,
and
and
which are unscaled values.
The return status is 0 unless an invalid option or argument is supplied,
or an error occurs while setting a new limit.
The user file-creation mask is set to 
If
begins with a digit, it
is interpreted as an octal number; otherwise
it is interpreted as a symbolic mode mask similar
to that accepted by
If
is omitted, the current value of the mask is printed.
The
option causes the mask to be printed in symbolic form; the
default output is an octal number.
If the
option is supplied, and
is omitted, the output is in a form that may be reused as input.
The return status is 0 if the mode was successfully changed or if
is supplied, all alias definitions are removed.  The return
value is true unless a supplied
is not a defined alias.
For each
remove the corresponding variable or function.
If no options are supplied, or the
option is given, each
refers to a shell variable.
Read-only variables may not be unset.
If
is specified, each
refers to a shell function, and the function definition
is removed.
Each unset variable or function is removed from the environment
passed to subsequent commands.
If any of
or
are unset, they lose their special properties, even if they are
subsequently reset.  The exit status is true unless a
is readonly.
Wait for each specified process and return its termination status.
Each
may be a process
ID or a job specification; if a job spec is given, all processes
in that job's pipeline are waited for.  If
is not given, all currently active child processes
are waited for, and the return status is zero.  If
specifies a non-existent process or job, the return status is
127.  Otherwise, the return status is the exit status of the last
process or job waited for.
If
is started with the name
or the
option is supplied at invocation,
the shell becomes restricted.
A restricted shell is used to
set up an environment more controlled than the standard shell.
It behaves identically to
with the exception that the following are disallowed or not performed:
setting or unsetting the values of
or
specifying command names containing
specifying a file name containing a
as an argument to the
builtin command
Specifying a filename containing a slash as an argument to the
option to the
builtin command
importing function definitions from the shell environment at startup
redirecting output using the >, >|, <>, >&, &>, and >> redirection operators
using the
builtin command to replace the shell with another command
adding or deleting builtin commands with the
and
options to the
builtin command
specifying the
option to the
builtin command
turning off restricted mode with
These restrictions are enforced after any startup files are read.
(see
above),
turns off any restrictions in the shell spawned to execute the
script.
The systemwide initialization file, executed for login shells
The personal initialization file, executed for login shells
The individual per-interactive-shell startup file
The individual login shell cleanup file, executed when a login shell exits
Brian Fox, Free Software Foundation
bfox@gnu.org
Chet Ramey, Case Western Reserve University
chet@po.cwru.edu
If you find a bug in
you should report it.  But first, you should
make sure that it really is a bug, and that it appears in the latest
version of
The latest version is always available from
Once you have determined that a bug actually exists, use the
command to submit a bug report.
If you have a fix, you are encouraged to mail that as well!
Suggestions and `philosophical' bug reports may be mailed
newsgroup
ALL bug reports should include:
The hardware and operating system
The compiler used to compile
A description of the bug behaviour
A short script or `recipe' which exercises the bug
inserts the first three items automatically into the template
it provides for filing a bug report.
Comments and bug reports concerning
this manual page should be directed to
It's too big and too slow.
There are some subtle differences between 
and traditional versions of
mostly because of the
specification.
Aliases are confusing in some uses.
Compound commands and command sequences of the form `a ; b ; c'
are not handled gracefully when process suspension is attempted.
When a process is stopped, the shell immediately executes the next
command in the sequence.
It suffices to place the sequence of commands between
parentheses to force it into a subshell, which may be stopped as
a unit.
parsed until substitution is attempted.  This will delay error
reporting until some time after the command is entered.  For example,
unmatched parentheses, even inside shell comments, will result in
error messages while the construct is being read.
Array variables may not (yet) be exported.
is a shell script to help the user compose and mail bug reports
concerning bash in a standard format.
invokes the editor specified by the environment variable
on a temporary copy of the bug report format outline. The user must
fill in the appropriate fields and exit the editor.
The bug report format outline consists of several sections.  The first
section provides information about the machine, operating system, the
bash version, and the compilation environment.  The second section
should be filled in with a description of the bug.  The third section
should be a description of how to reproduce the bug.  The optional
fourth section is for a proposed fix.  Fixes are encouraged.
will utilize the following environment variables if they exist:
Specifies the preferred editor. If
is not set,
defaults to
Directory in which the failed bug report is saved if the mail fails.
bc - An arbitrary precision calculator language
This man page documents GNU bc version 1.06.
with interactive execution of statements.  There are some similarities
in the syntax to the C programming language. 
A standard math library is available by command line option.
If requested, the math library is defined before processing any files.
on the command line in the order listed.  After all files have been
executed as it is read.  (If a file contains a command to halt the
Command line options can cause these extensions to print a warning 
or to be rejected.  This 
document describes the language accepted by this processor.
Extensions will be identified as such.
Print the usage and exit.
Force interactive mode.
Define the standard math library.
Do not print the normal GNU bc welcome.
Print the version number and copyright and quit.
arbitrary precision numbers.  This precision is both in the integer
part and the fractional part.  All numbers are represented internally
in decimal and all computation is done in decimal.  (This version
truncates results from divide and multiply operations.)  There are two
attributes of numbers, the length and the scale.  The length is the
total number of significant decimal digits in a number and the scale
is the total number of decimal digits after the decimal point.  For
example:
 .000001 has a length of 6 and scale of 6.
 1935.000 has a length of 7 and a scale of 3.
Numbers are stored in two types of variables, simple variables and
arrays.  Both simple variables and array variables are named.  Names
begin with a letter followed by any number of letters, digits and
underscores.  All letters must be lower case.  (Full alpha-numeric
lower case letter.)  The type of variable is clear by the context
because all array variable names will be followed by brackets ([]).
numbers.  The default for both input and output is base 10.
printed number.  These will be discussed in further detail where
appropriate.  All of these variables may have values assigned to them
as well as used in expressions.
single space in the input.  (This causes comments to delimit other
input items.  For example, a comment can not be found in the middle of
a variable name.)  Comments include any newlines (end of line) between
the start and the end of the comment.
character and continues to the next end of the line.  The end of line
character is not part of the comment and is processed normally.
The numbers are manipulated by expressions and statements.  Since
the language was designed to be interactive, statements and expressions
are executed as soon as possible.  There is no "main" program.  Instead,
code is executed as it is encountered.  (Functions, discussed in
detail later, are defined when encountered.)
into internal decimal numbers using the current input base, specified
or 16.  Input numbers may contain the characters 0-9 and A-F. (Note:
They must be capitals.  Lower case letters are variable names.)
Single digit numbers always have the value of the digit regardless of
the largest 3 digit number of the input base.
Full expressions are similar to many other high level languages.
Since there is only one kind of number, there are no rules for mixing
types.  Instead, there are rules on the scale of expressions.  Every
expression has a scale.  This is derived from the scale of original
numbers, the operation performed and in many cases, the value of the
0 to the maximum number representable by a C integer.
In the following descriptions of legal expressions, "expr" refers to a
complete expression and "var" refers to a simple or an array variable.
A simple variable is just a
and an array variable is specified as
Unless specifically
mentioned the scale of the result is the maximum scale of the
expressions involved.
The result is the negation of the expression.
The variable is incremented by one and the new value is the result of
the expression.
The variable
is decremented by one and the new value is the result of the
expression.
 The result of the expression is the value of
the variable and then the variable is incremented by one.
The result of the expression is the value of the variable and then
the variable is decremented by one.
The result of the expression is the sum of the two expressions.
The result of the expression is the difference of the two expressions.
The result of the expression is the product of the two expressions.
The result of the expression is the quotient of the two expressions.
The result of the expression is the "remainder" and it is computed in the
to zero and both expressions are integers this expression is the
integer remainder function.
The result of the expression is the value of the first raised to the
second. The second expression must be an integer.  (If the second
expression is not an integer, a warning is generated and the
expression is truncated to get an integer value.)  The scale of the
is positive the scale of the result is the minimum of the scale of the
first expression times the value of the exponent and the maximum of
that expr^0 will always return the value of 1.
This alters the standard precedence to force the evaluation of the
expression.
The variable is assigned the value of the expression.
This is equivalent to "var = var <op> expr" with the exception that
the "var" part is evaluated only once.  This can make a difference if
"var" is an array.
 Relational expressions are a special kind of expression
that always evaluate to 0 or 1, 0 if the relation is false and 1 if
the relation is true.  These may appear in any legal expression.
(POSIX bc requires that relational expressions are used only in if,
while, and for statements and that only one relational test may be
done in them.)  The relational operators are
The result is 1 if expr1 is strictly less than expr2.
The result is 1 if expr1 is less than or equal to expr2.
The result is 1 if expr1 is strictly greater than expr2.
The result is 1 if expr1 is greater than or equal to expr2.
The result is 1 if expr1 is equal to expr2.
The result is 1 if expr1 is not equal to expr2.
boolean operations). The result of all boolean operations are 0 and 1
(for false and true) as in relational expressions.  The boolean
operators are:
The result is 1 if expr is 0.
The result is 1 if both expressions are non-zero.
The result is 1 if either expression is non-zero.
The expression precedence is as follows: (lowest to highest)
|| operator, left associative
&& operator, left associative
! operator, nonassociative
Relational operators, left associative
Assignment operator, right associative
+ and - operators, left associative
^ operator, right associative
unary - operator, nonassociative
++ and -- operators, nonassociative
will run correctly. This will cause the use of the relational and
logical operators to have some unusual behavior when used with
assignment expressions.  Consider the expression:
a = 3 < 5
Most C programmers would assume this would assign the result of "3 <
assign the value 3 to the variable "a" and then compare 3 to 5.  It is
best to use parenthesis when using relational and logical operators
with the assignment operators.
These have to do with user defined functions and standard
See the section on functions for user defined functions.  The standard
functions are:
The value of the length function is the number of significant digits in the
expression.
The read function (an extension) will read a number from the standard
input, regardless of where the function occurs.   Beware, this can
cause problems with the mixing of data and program in the standard input.
The best use for this function is in a previously written program that
needs input from the user, but never allows program code to be input
from the user.  The value of the read function is the number read from
the standard input using the current value of the variable 
The value of the scale function is the number of digits after the decimal
point in the expression.
The value of the sqrt function is the square root of the expression.  If
the expression is negative, a run time error is generated.
Statements (as in most algebraic languages) provide the sequencing of
as possible."  Execution happens when a newline in encountered and
there is one or more complete statements.  Due to this immediate
semicolon and a newline are used as statement separators.  An
improperly placed newline will cause a syntax error.  Because newlines
are statement separators, it is possible to hide a newline by using
statement list is a series of statements separated by semicolons and
they do: (Things enclosed in brackets ([]) are optional parts of the
statement.)
This statement does one of two things.  If the expression starts with
"<variable> <assignment> ...", it is considered to be an assignment
statement.  If the expression is not an assignment statement, the
expression is evaluated and printed to the output.  After the number
is printed, a newline is printed.  For example, "a=1" is an assignment
statement and "(a=1)" is an expression that has an embedded
assignment.  All numbers that are printed are printed in the base
bases 2 through 16, the usual method of writing numbers is used.  For
of printing the numbers where each higher base digit is printed as a
base 10 number.  The multi-character digits are separated by spaces.
Each digit contains the number of characters required to represent the
base ten value of "obase-1".  Since numbers are of arbitrary
precision, some numbers may not be printable on a single output line.
last character on a line.  The maximum number of characters printed
a number causes the side effect of assigning the printed value to the
last value printed without having to retype the expression that
overwrite the last printed value with the assigned value.  The newly
assigned value will remain until the next number is printed or another
use of a single period (.) which is not part of a number as a short
The string is printed to the output.  Strings start with a double quote
character and contain all characters until the next double quote character.
All characters are take literally, including any newline.  No newline
character is printed after the string.
The print statement (an extension) provides another method of output.
The "list" is a list of strings and expressions separated by commas.
Each string or expression is printed in the order of the list.  No
terminating newline is printed.  Expressions are evaluated and their
in the print statement are printed to the output and may contain
special characters.  Special characters start with the backslash
"a" (alert or bell), "b" (backspace), "f" (form feed), "n" (newline),
Any other character following the backslash will be ignored.  
This is the compound statement.  It allows multiple statements to be
grouped together for execution.
The if statement evaluates the expression and executes statement1 or
statement2 depending on the value of the expression.  If the expression
is non-zero, statement1 is executed.  If statement2 is present and
the value of the expression is 0, then statement2 is executed.  (The
else clause is an extension.)
The while statement will execute the statement while the expression
is non-zero.  It evaluates the expression before each execution of
the statement.   Termination of the loop is caused by a zero
expression value or the execution of a break statement.
The for statement controls repeated execution of the statement.  
Expression1 is evaluated before the loop.  Expression2 is evaluated
before each execution of the statement.  If it is non-zero, the statement
is evaluated.  If it is zero, the loop is terminated.  After each
execution of the statement, expression3 is evaluated before the reevaluation
of expression2.  If expression1 or expression3 are missing, nothing is
evaluated at the point they would be evaluated.
If expression2 is missing, it is the same as substituting
the value 1 for expression2.  (The optional expressions are an
The following is equivalent code for the for statement:
expression1;
while (expression2) {
   statement;
   expression3;
}
This statement causes a forced exit of the most recent enclosing while
statement or for statement.
The continue statement (an extension)  causes the most recent enclosing
for statement to start the next iteration.
The halt statement (an extension) is an executed statement that causes
not executed.
Return the value 0 from a function.  (See the section on functions.)
Return the value of the expression from a function.  (See the section on 
functions.)  As an extension, the parenthesis are not required.
These statements are not statements in the traditional sense.  They are
not executed statements.  Their function is performed at "compile" time.
is an extension.
is terminated, regardless of where the quit statement is found.  For
Print a longer warranty notice.  This is an extension.
Functions provide a method of defining a computation that can be executed
later.  Functions in 
always compute a value and return it to the caller.  Function definitions
are "dynamic" in the sense that a function is undefined until a definition
is encountered in the input.  That definition is then used until another
definition function for the same name is encountered.  The new definition
then replaces the older definition.  A function is defined as follows:
A function call is just an expression of the form
Parameters are numbers or arrays (an extension).  In the function definition,
zero or more parameters are defined by listing their names separated by
commas.  Numbers are only call by value parameters.  Arrays are only
call by variable.  Arrays are specified in the parameter definition by
are full expressions for number parameters.  The same notation is used
for passing arrays as for defining array parameters.  The named array is
passed by variable to the function.  Since function definitions are dynamic,
parameter numbers and types are checked when a function is called.  Any
mismatch in number or types of parameters will cause a runtime error.
A runtime error will also occur for the call to an undefined function.
the name of an auto variable.  Arrays may be specified by using the
same notation as used in parameters.  These variables have their
values pushed onto a stack at the start of the function.  The
variables are then initialized to zero and used throughout the
execution of the function.  At function exit, these variables are
popped so that the original value (at the time of the function call)
of these variables are restored.  The parameters are really auto
variables that are initialized to a value provided in the function
call.  Auto variables are different than traditional local variables
because if function A calls function B, B may access function
A's auto variables by just using the same name, unless function B has
called them auto variables.  Due to the fact that auto variables and
are separated by semicolons or newlines.  Return statements cause the
termination of a function and the return of a value.  There are two
the value 0 to the calling expression.  The second form, 
and returns that value to the calling expression.  There is an implied
to terminate and return 0 without an explicit return statement.
constants in the function body will be converted using the value of
will be ignored during the execution of the function except for the
As an extension, the format of the definition has been slightly relaxed.
The standard requires the opening brace be on the same line as the 
after the opening brace of the function.  For example, the following
definitions are legal.
define d (n) { return (2*n); }
define d (n)
  { return (2*n); }
and the default scale is set to 20.   The math functions will calculate their
results to the scale set at the time of their call.  
The math library defines the following functions:
The sine of x, x is in radians.
The cosine of x, x is in radians.
The arctangent of x, arctangent returns radians.
The natural logarithm of x.
The exponential function of raising e to the value x.
The bessel function of integer order n of x.
pi=$(echo "scale=10; 4*a(1)" | bc -l)
The following is the definition of the exponential function used in the
scale = 20

   When x is small enough, we use the series:

define e(x) {
  auto  a, d, e, f, i, m, v, z

  if (x<0) {
    m = 1
    x = -x
  } 

  z = scale;
  scale = 4 + z + .44*x;
  while (x > 1) {
    f += 1;
  }

  v = 1+x
  a = x
  d = 1

  for (i=2; 1; i++) {
    if (e == 0) {
      if (f>0) while (f--)  v = v*v;
      scale = z
    }
    v += e
  }
}
implement a simple program for calculating checkbook balances.  This
program is best kept in a file so that it can be used many times 
without having to retype it at every use.
scale=2

print "Initial balance? "; bal = read()
while (1) {
  "current balance = "; bal
  "transaction? "; trans = read()
  if (trans == 0) break;
  bal -= trans
}
quit
The following is the definition of the recursive factorial function.
define f (x) {
  if (x <= 1) return (1);
  return (f(x-1) * x);
}
This allows the user to do editing of lines before sending them
number of history lines are retained.  Setting the value of
lines to the number given.  The value of 0 disables the history
feature.  The default value is 100. For more information, read the
at the same time.
This version of 
several differences and extensions relative to the draft and
traditional implementations.
It is not implemented in the traditional way using
This version is a single process which parses and runs a byte code
translation of the program.  There is an "undocumented" option (-c)
that causes the program to output the byte code to
the standard output instead of running it.  It was mainly used for
debugging the parser and preparing the math library.
A major source of differences is
extensions, where a feature is extended to add more functionality and
additions, where new features are added. 
The following is the list of differences and extensions.
This version does not conform to the POSIX standard in the processing
of the LANG environment variable and all environment variables starting
with LC_.
Traditional and POSIX
have single letter names for functions, variables and arrays.  They have
been extended to be multi-character names that start with a letter and
may contain letters, numbers and the underscore character.
Strings are not allowed to contain NUL characters.  POSIX says all characters
must be included in strings.
statement, and the second expression of the for statement.  Also, only
one relational operation is allowed in each of those statements.
The POSIX grammar allows for arrays in function definitions, but does
not provide a method to specify an array as an actual parameter.  (This
is most likely an oversight in the grammar.)  Traditional implementations
be defined.  This version may allow these "old style" assignments.  Use
the limits statement to see if the installed version supports them.  If
it does support the "old style" assignment operators, the statement
value -1.
"x=1 3" would assign the value 13 to the variable x.  The same statement
This implementation varies from other implementations in terms of what
code will be executed when syntax and other errors are found in the
program.  If a syntax error is found in a function definition, error
recovery tries to find the beginning of a statement and continue to
parse the function.  Once a syntax error is found in the function, the
function will not be callable and becomes undefined.
Syntax errors in the interactive execution code will invalidate the
current execution block.  The execution block is terminated by an
end of line that appears after a complete sequence of statements.
For example, 
a = 1
b = 2
has two execution blocks and
{ a = 1
  b = 2 }
has one execution block.  Any runtime error will terminate the execution
of the current execution block.  A runtime warning will not terminate the
current execution block.
During an interactive session, the SIGINT signal (usually generated by
the control-C character from the terminal) will cause execution of the
current execution block to be interrupted.  It will display a "runtime"
error indicating which function was interrupted.  After all runtime
structures have been cleaned up, a message will be printed to notify the
remain defined and the value of all non-auto variables are the value at
the point of interruption.  All auto variables and function parameters
are removed during the
clean up process.  During a non-interactive
The following are the limits currently in place for this 
processor.  Some of them may have been changed by an installation.
Use the limits statement to see the actual values.
The maximum output base is currently set at 999.  The maximum input base
is 16.
This is currently an arbitrary limit of 65535 as distributed.  Your
installation may be different.
The number of digits after the decimal point is limited to INT_MAX digits.
Also, the number of digits before the decimal point is limited to INT_MAX
digits.
The limit on the number of characters in a string is INT_MAX characters.
The value of the exponent in the raise operation (^) is limited to LONG_MAX.
The current limit on the number of unique names is 32767 for each of
simple variables, arrays and functions.
format is the same as the command line arguments.  These arguments
are processed first, so any files listed in the environent arguments
are processed before any command line argument files.  This allows
the user to set up "standard" options and files to be processed
variables would typically contain function definitions for functions
This should be an integer specifing the number of characters in an
output line for numbers. This includes the backslash and newline characters
for long numbers.
that the file is unavailable and terminate.  Also, there are compile
and run time diagnostics that should be self-explanatory.
Error recovery is not very good yet.
Email bug reports to
Be sure to include the word ``bc'' somewhere in the ``Subject:'' field.
Philip A. Nelson
philnelson@acm.org
The author would like to thank Steve Sommars (Steve.Sommars@att.com) for
his extensive help in testing the implementation.  Many great suggestions
were given.  This is a much better product due to his involvement.
The
utility informs the system whether you want to be notified on your terminal
when mail arrives.
Affected is the first terminal associated with the standard input,
standard output or standard error file descriptor, in that order.
Thus, it is possible to use the redirection facilities of a shell to
toggle the notification for other terminals than the one
runs on.
The following options are available:
Disable notification.
Enable header notification.
Enable bell notification.
When header notification is enabled, the header and first few lines of
the message will be printed on your terminal whenever mail arrives.
A
command is often included in the file
or
to be executed at each login.
When bell notification is enabled, only two bell characters
will be printed on your terminal whenever mail arrives.
If no arguments are given,
displays the present notification status of the terminal to the
standard output.
The
utility operates asynchronously.
For synchronous notification use the
variable of
or the
variable of
The
utility exits with one of the following values:
Notification is enabled.
Notification is disabled.
An error occurred.
Previous versions of the
utility affected the terminal attached to standard error without first
trying the standard input or output devices.
The
command appeared in
It was named after the dog of Heidi Stettner.
He died
in August 1993, at 15.
Usage:
Where the options are:
Each file is converted to file.hqx.
Largely untested.
his grubby paws off anything...
Usage:
Where the options are:
Each file is converted to file.hqx.
Largely untested.
his grubby paws off anything...
understands the following commands:
    diagnose and collect logs
    -M,--collect-mobile-documents[=<container>]  (default: all containers)
    -s,--sysdiagnose     Do not collect what's already part of sysdiagnose
    -n,--name=<name>     Change the device name
    [<diagnosis-output-path>]
                         Specifies the output path of the diagnosis; -n becomes useless.
    -c,--color[={yes,no}]
                         turn on or off color use
    -d,--path=<logs-dir> use <logs-dir> instead of default
    -f,--filter=<predicate>
                         only show lines matching predicate
    -m,--multiline[={yes,no}]
                         turn on or off multiple line logging
    -n=<number>          number of initial lines to display
    -p,--page            use paging
    -w,--wait            wait for new logs continuously (syslog -w)
    -t,--shorten         Shorten UUIDs, paths, etc
    -s,--digest          Only print digest logs
    dump the CloudDocs database
    -o,--output=<file-path>
                         redirect output to <file-path>
    -d,--database-path=<db-path>
                         Use the database at <db-path>
    [<container>]        the container to be dumped
    use NSMetadataQuery to monitor the container
    -S,--scope=<scope>
                         restrict the NSMDQ scope to DOCS, DATA, or BOTH
creates and manipulates streaming archive files.
This implementation can extract from tar, pax, cpio, zip, jar, ar,
and ISO 9660 cdrom images and can create tar, pax, cpio, ar,
and shar archives.
The first synopsis form shows a
option word.
This usage is provided for compatibility with historical implementations.
See COMPATIBILITY below for details.
The other synopsis forms show the preferred usage.
The first option to
is a mode indicator from the following list:
Create a new archive containing the specified items.
Like
but new entries are appended to the archive.
Note that this only works on uncompressed archives stored in regular files.
The
option is required.
List archive contents to stdout.
Like
but new entries are added only if they have a modification date
newer than the corresponding entry in the archive.
Note that this only works on uncompressed archives stored in regular files.
The
option is required.
Extract to disk from the archive.
If a file with the same name appears more than once in the archive,
each copy will be extracted, with later copies overwriting (replacing)
earlier copies.
In
or
mode, each specified file or directory is added to the
archive in the order specified on the command line.
By default, the contents of each directory are also archived.
In extract or list mode, the entire command line
is read and parsed before the archive is opened.
The pathnames or patterns on the command line indicate
which items in the archive should be processed.
Patterns are shell-style globbing patterns as
documented in
Unless specifically stated otherwise, options are applicable in
all operating modes.
(c and r mode only)
The specified archive is opened and the entries
in it will be appended to the current archive.
As a simple example,
writes a new archive to standard output containing a file
and all of the entries from
In contrast,
creates a new archive with only two entries.
Similarly,
reads an archive from standard input (whose format will be determined
automatically) and converts it into a gzip-compressed
pax-format archive on stdout.
In this way,
can be used to convert archives from one format to another.
As a rule, this argument is only needed when reading from or writing
to tape drives, and usually not even then as the default block size of
20 records (10240 bytes) is very common.
In c and r mode, this changes the directory before adding
the following files.
In x mode, change directories after opening the archive
but before extracting entries from the archive.
(c and r modes only)
Issue a warning message unless all links to each file are archived.
(x mode only)
to the current directory after processing any
options and before extracting any files.
Do not process files or directories that match the
specified pattern.
Note that exclusions take precedence over patterns or filenames
specified on the command line.
(c, r, u mode only)
Use the specified format for the created archive.
Supported formats include
and
Other formats may also be supported; see
for more information about currently-supported formats.
In r and u modes, when extending an existing archive, the format specified
here must be compatible with the format of the existing archive on disk.
Read the archive from or write the archive to the specified file.
The filename can be
for standard input or standard output.
(c and r mode only)
Symbolic links named on the command line will be followed; the
target of the link will be archived, not the link itself.
(c and r mode only)
Synonym for
Synonym for
Process only files or directories that match the specified pattern.
Note that exclusions specified with
take precedence over inclusions.
If no inclusions are explicitly specified, all entries are processed by
default.
The
option is especially useful when filtering archives.
For example, the command
creates a new archive
containing only the entries from
containing the string
(c mode only)
Compress the resulting archive with
In extract or list modes, this option is ignored.
Note that, unlike other
implementations, this implementation recognizes bzip2 compression
automatically when reading archives.
(x mode only)
Do not overwrite existing files.
In particular, if a file appears more than once in an archive,
later copies will not overwrite earlier copies.
(x mode only)
Do not overwrite existing files that are newer than the
versions appearing in the archive being extracted.
(c and r mode only)
All symbolic links will be followed.
Normally, symbolic links are archived as such.
With this option, the target of the link will be archived instead.
This is a synonym for the
option.
(x mode only)
Do not extract modification time.
By default, the modification time is set to the time stored in the archive.
(c, r, u modes only)
Do not recursively archive the contents of directories.
(c, r, u modes only)
Only include files and directories newer than the specified date.
This compares ctime entries.
(c, r, u modes only)
Like
except it compares mtime entries instead of ctime entries.
(c, r, u modes only)
Only include files and directories newer than the specified file.
This compares ctime entries.
(c, r, u modes only)
Like
except it compares mtime entries instead of ctime entries.
(c and r modes only)
Honor the nodump file flag by skipping this file.
(use with
or
Filenames or patterns are separated by null characters,
not by newlines.
This is often used to read filenames output by the
option to
(x mode only)
Ignore symbolic user and group names when restoring archives to disk,
only numeric uid and gid values will be obeyed.
(x, t modes only)
In extract (-x) mode, files will be written to standard out rather than
being extracted to disk.
In list (-t) mode, the file listing will be written to stderr rather than
the usual stdout.
(x mode)
Use the user and group of the user running the program rather
than those specified in the archive.
Note that this has no significance unless
is specified, and the program is being run by the root user.
In this case, the file modes and flags from
the archive will be restored, but ACLs or owner information in
the archive will be discarded.
(c, r, u mode)
A synonym for
(c, r, and u modes)
Do not cross mount points.
Select optional behaviors for particular modules.
The argument is a text string containing comma-separated
keywords and values.
These are passed to the modules that handle particular
formats to control how those formats will behave.
Each option has one of the following forms:
The key will be set to the specified value in every module that supports it.
Modules that do not support this key will ignore it.
The key will be enabled in every module that supports it.
This is equivalent to
The key will be disabled in every module that supports it.
As above, but the corresponding key and value will be provided
only to modules whose name matches
The currently supported modules and keys are:
Support Joliet extensions.
This is enabled by default, use
or
to disable.
Support Rock Ridge extensions.
This is enabled by default, use
or
to disable.
A decimal integer from 0 to 9 specifying the gzip compression level.
A decimal integer from 0 to 9 specifying the xz compression level.
The mtree writer module allows you to specify which mtree keywords
will be included in the output.
Supported keywords include:
The default is equivalent to:
Enables all of the above keywords.
You can also use
to disable all keywords.
Enable generation of
lines in the output.
Produce human-readable output by indenting options and splitting lines
to fit into 80 columns.
Use
as compression method.
Supported values are store (uncompressed) and deflate (gzip algorithm).
If a provided option is not supported by any module, that
is a fatal error.
Preserve pathnames.
character) have the leading slash removed both when creating archives
and extracting from them.
Also,
will refuse to extract archive entries whose pathnames contain
or whose target directory would be altered by a symlink.
This option suppresses these behaviors.
(x mode only)
Preserve file permissions.
Attempt to restore the full permissions, including owner, file modes, file
flags and ACLs, if available, for each item extracted from the archive.
By default, newly-created files are owned by the user running
the file mode is restored for newly-created regular files, and
all other types of entries receive default permissions.
If
is being run by root, the default is to restore the owner unless the
option is also specified.
(x and t mode only)
Extract or list only the first archive entry that matches each pattern
or filename operand.
Exit as soon as each specified pattern or filename has been matched.
By default, the archive is always read to the very end, since
there can be multiple entries with the same name and, by convention,
later entries overwrite earlier entries.
This option is provided as a performance optimization.
(x mode only)
Extract files as sparse files.
For every block on disk, check first if it contains only NULL bytes and seek
over it otherwise.
This works similiar to the conv=sparse option of dd.
(x mode only)
Remove the specified number of leading path elements.
Pathnames with fewer elements will be silently skipped.
but before security checks.
Modify file or archive member names according to
The pattern has the format
where
is a basic regular expression,
is the replacement string of the matched part,
and the optional trailing letters modify
how the replacement is handled.
If
is not matched, the pattern is skipped.
Within
the corresponding captured group.
The optional trailing g specifies that matching should continue
after the matched part and stopped on the first unmatched pattern.
The optional trailing s specifies that the pattern applies to the value
of symbolic links.
The optional trailing p specifies that after a successful substitution
the original path name and the new path name should be printed to
standard error.
In x or t mode,
will read the list of names to be extracted from
In c mode,
will read names to be archived from
The special name
on a line by itself will cause the current directory to be changed to
the directory specified on the following line.
Names are terminated by newlines unless
is specified.
Note that
also disables the special handling of lines containing
(x mode only)
Unlink files before creating them.
Without this option,
overwrites existing files, which preserves existing hardlinks.
With this option, existing hardlinks will be broken, as will any
symlink that would affect the location of an extracted file.
Pipe the input (in x or t mode) or the output (in c mode) through
instead of using the builtin compression support.
Produce verbose output.
In create and extract modes,
will list each file name as it is read from or written to
the archive.
In list mode,
will produce output similar to that of
Additional
options will provide additional detail.
Print version of
and
and exit.
Ask for confirmation for every action.
Read a list of exclusion patterns from the specified file.
See
for more information about the handling of exclusions.
(c mode only)
Compress the resulting archive with
In extract or list modes, this option is ignored.
Note that, unlike other
implementations, this implementation recognizes bzip2 compression
automatically when reading archives.
(c mode only)
Compress the resulting archive with
In extract or list modes, this option is ignored.
Note that, unlike other
implementations, this implementation recognizes gzip compression
automatically when reading archives.
(c mode only)
Compress the resulting archive with
In extract or list modes, this option is ignored.
Note that, unlike other
implementations, this implementation recognizes compress compression
automatically when reading archives.
The following environment variables affect the execution of
The locale to use.
See
for more information.
The timezone to use when displaying dates.
See
for more information.
The following creates a new archive
called
that contains two files
and
To view a detailed table of contents for this
archive:
To examine the contents of an ISO 9660 cdrom image:
To move file hierarchies, invoke
as
or more traditionally
In create mode, the list of files and directories to be archived
can also include directory change instructions of the form
and archive inclusions of the form
For example, the command line
will create a new archive
will read the file
from the current directory and add it to the output archive.
It will then read each entry from
and add those entries to the output archive.
Finally, it will switch to the
directory and add
to the output archive.
An input file in
format can be used to create an output archive with arbitrary ownership,
permissions, or names that differ from existing data on disk:
The
and
switches accept a variety of common date and time specifications, including
and
The
argument can be used to control various details of archive generation
or reading.
For example, you can generate mtree output which only contains
and
keywords:
or you can set the compression level used by gzip or xz compression:
For more details, see the explanation of the
and
API calls that are described in
and
The bundled-arguments format is supported for compatibility
with historic implementations.
It consists of an initial word (with no leading - character) in which
each character indicates an option.
Arguments follow as separate words.
The order of the arguments must match the order
of the corresponding characters in the bundled command word.
For example,
specifies three flags
and
The
and
flags both require arguments,
so there must be two additional items
on the command line.
The
is the argument to the
flag, and
is the argument to the
flag.
The mode options c, r, t, u, and x and the options
b, f, l, m, o, v, and w comply with SUSv2.
For maximum portability, scripts that invoke
should use the bundled-argument format above, should limit
themselves to the
and
modes, and the
and
options.
Additional long options are provided to improve compatibility with other
tar implementations.
Certain security issues are common to many archiving programs, including
In particular, carefully-crafted archives can request that
extract files to locations outside of the target directory.
This can potentially be used to cause unwitting users to overwrite
files they did not intend to overwrite.
If the archive is being extracted by the superuser, any file
on the system can potentially be overwritten.
There are three ways this can happen.
Although
has mechanisms to protect against each one,
savvy users should be aware of the implications:
Archive entries can have absolute pathnames.
By default,
removes the leading
character from filenames before restoring them to guard against this problem.
Archive entries can have pathnames that include
components.
By default,
will not extract files containing
components in their pathname.
Archive entries can exploit symbolic links to restore
files to other directories.
An archive can restore a symbolic link to another directory,
then use that link to restore a file into that directory.
To guard against this,
checks each extracted path for symlinks.
If the final path element is a symlink, it will be removed
and replaced with the archive entry.
If
is specified, any intermediate symlink will also be unconditionally removed.
If neither
nor
is specified,
will refuse to extract the entry.
To protect yourself, you should be wary of any archives that
come from untrusted sources.
You should examine the contents of an archive with
before extraction.
You should use the
option to ensure that
will not overwrite any existing files or the
option to remove any pre-existing files.
You should generally not extract archives while running with super-user
privileges.
Note that the
option to
disables the security checks above and allows you to extract
an archive while preserving any absolute pathnames,
components, or symlinks to other directories.
There is no current POSIX standard for the tar command; it appeared
in
but was dropped from
The options used by this implementation were developed by surveying a
number of existing tar implementations as well as the old POSIX specification
for tar and the current POSIX specification for pax.
The ustar and pax interchange file formats are defined by
for the pax command.
A
command appeared in Seventh Edition Unix, which was released in January, 1979.
There have been numerous other implementations,
many of which extended the file format.
John Gilmore's
public-domain implementation (circa November, 1987)
was quite influential, and formed the basis of GNU tar.
GNU tar was included as the standard system tar
in
beginning with
This is a complete re-implementation based on the
library.
This program follows
for the definition of the
option.
Note that GNU tar prior to version 1.15 treated
as a synonym for the
option.
The
option may differ from historic implementations.
All archive output is written in correctly-sized blocks, even
if the output is being compressed.
Whether or not the last output block is padded to a full
block size varies depending on the format and the
output device.
For tar and cpio formats, the last block of output is padded
to a full block size if the output is being
written to standard output or to a character or block device such as
a tape drive.
If the output is being written to a regular file, the last block
will not be padded.
Many compressors, including
and
complain about the null padding when decompressing an archive created by
although they still extract it correctly.
The compression and decompression is implemented internally, so
there may be insignificant differences between the compressed output
generated by
and that generated by
but tradition (and POSIX) dictates otherwise.
The
and
modes require that the archive be uncompressed
and located in a regular file on disk.
Other archives can be modified using
mode with the
extension.
To archive a file called
or
you must specify it as
or
respectively.
In create mode, a leading
is always removed.
A leading
is stripped unless the
option is specified.
There needs to be better support for file selection on both create
and extract.
There is not yet any support for multi-volume archives or for archiving
sparse files.
Converting between dissimilar archive formats (such as tar and cpio) using the
convention can cause hard link information to be lost.
(This is a consequence of the incompatible ways that different archive
formats store hardlink information.)
There are alternative long options for many of the short options that
are deliberately not documented.
generates
from
and
where
is a binary patch built by bsdiff(1).
uses memory equal to the size of 
plus the size of 
but can tolerate a very small working set without a dramatic loss
of performance.
Shell builtin commands are commands that can be executed within the
running shell's process.
Note that, in the case of
builtin commands, the command is executed in a subshell if it occurs as
any component of a pipeline except the last.
If a command specified to the shell contains a slash
the shell will not execute a builtin command, even if the last component
of the specified command matches the name of a builtin command.
Thus, while specifying
causes a builtin command to be executed under shells that support the
builtin command,
specifying
or
does not.
While some builtin commands may exist in more than one shell, their
operation may be different under each shell which supports them.
Below is a table which lists shell builtin commands, the standard shells
that support them and whether they exist as standalone utilities.
Only builtin commands for the
and
shells are listed here.
Consult a shell's manual page for
details on the operation of its builtin commands.
Beware that the
manual page, at least, calls some of these commands
and some of them
Users of other shells may need to consult an
page or other sources of documentation.
Commands marked
under
do exist externally,
but are implemented as scripts using a builtin command of the same name.
The
manual page first appeared in
This manual page was written by

[
]
[ 
]
[ 
]

compresses files using the Burrows-Wheeler block sorting
text compression algorithm, and Huffman coding.  Compression is
generally considerably better than that achieved by more conventional
family of statistical compressors.

The command-line options are deliberately very similar to 
those of 
but they are not identical.

expects a list of file names to accompany the
command-line flags.  Each file is replaced by a compressed version of
itself, with the name "original_name.bz2".  
Each compressed file
has the same modification date, permissions, and, when possible,
ownership as the corresponding original, so that these properties can
be correctly restored at decompression time.  File name handling is
naive in the sense that there is no mechanism for preserving original
file names, permissions, ownerships or dates in filesystems which lack
these concepts, or have serious file name length restrictions, such as
MS-DOS.

and
will by default not overwrite existing

If no file names are specified,
compresses from standard
input to standard output.  In this case,
will decline to
write compressed output to a terminal, as this would be entirely
incomprehensible and therefore pointless.

(or
decompresses all
specified files.  Files which were not created by 
will be detected and ignored, and a warning issued.  
attempts to guess the filename for the decompressed file 
from that of the compressed file as follows:

       filename.bz2    becomes   filename
       filename.bz     becomes   filename
       filename.tbz2   becomes   filename.tar
       filename.tbz    becomes   filename.tar
       anyothername    becomes   anyothername.out

If the file does not end in one of the recognised endings, 
or
complains that it cannot
guess the name of the original file, and uses the original name
with
appended.

As with compression, supplying no
filenames causes decompression from 
standard input to standard output.

will correctly decompress a file which is the
concatenation of two or more compressed files.  The result is the
concatenation of the corresponding uncompressed files.  Integrity
of concatenated 
compressed files is also supported.

You can also compress or decompress files to the standard output by
decompressed like this.  The resulting outputs are fed sequentially to
stdout.  Compression of multiple files 
in this manner generates a stream
containing multiple compressed file representations.  Such a stream
can be decompressed correctly only by
version 0.9.0 or
later.  Earlier versions of
will stop after decompressing
the first file in the stream.

(or
decompresses all specified files to
the standard output.

will read arguments from the environment variables
and
in that order, and will process them
before any arguments read from the command line.  This gives a 
convenient way to supply default arguments.

Compression is always performed, even if the compressed 
file is slightly
larger than the original.  Files of less than about one hundred bytes
tend to get larger, since the compression mechanism has a constant
overhead in the region of 50 bytes.  Random data (including the output
of most file compressors) is coded at about 8.05 bits per byte, giving
an expansion of around 0.5%.

As a self-check for your protection, 
bzip2
uses 32-bit CRCs to
make sure that the decompressed version of a file is identical to the
original.  This guards against corruption of the compressed data, and
against undetected bugs in
(hopefully very unlikely).  The
chances of data corruption going undetected is microscopic, about one
chance in four billion for each file processed.  Be aware, though, that
the check occurs upon decompression, so it can only tell you that
something is wrong.  It can't help you 
recover the original uncompressed
data.  You can use 
to try to recover data from
damaged files.

Return values: 0 for a normal exit, 1 for environmental problems (file
compressed file, 3 for an internal consistency error (eg, bug) which
caused
to panic.

Compress or decompress to standard output.
Force decompression.  
and
are
really the same program, and the decision about what actions to take is
done on the basis of which name is used.  This flag overrides that
mechanism, and forces 
to decompress.
invocation name.
Check integrity of the specified file(s), but don't decompress them.
This really performs a trial decompression and throws away the result.
Force overwrite of output files.  Normally,
will not overwrite
existing output files.  Also forces 
to break hard links
to files, which it otherwise wouldn't do.

bzip2 normally declines to decompress files which don't have the
correct magic header bytes.  If forced (-f), however, it will pass
such files through unmodified.  This is how GNU gzip behaves.
Keep (don't delete) input files during compression
or decompression.
Reduce memory usage, for compression, decompression and testing.  Files
are decompressed and tested using a modified algorithm which only
requires 2.5 bytes per block byte.  This means any file can be
decompressed in 2300k of memory, albeit at about half the normal speed.

memory use to around the same figure, at the expense of your compression
ratio.  In short, if your machine is low on memory (8 megabytes or
Suppress non-essential warning messages.  Messages pertaining to
Verbose mode -- show the compression ratio for each file processed.
information which is primarily of interest for diagnostic purposes.
Display the software version, license terms and conditions.
Set the block size to 100 k, 200 k ..  900 k when compressing.  Has no
effect when decompressing.  See MEMORY MANAGEMENT below.
significantly faster.  
Treats all subsequent arguments as file names, even if they start
with a dash.  This is so you can handle files with names beginning
These flags are redundant in versions 0.9.5 and above.  They provided
some coarse control over the behaviour of the sorting algorithm in
earlier versions, which was sometimes useful.  0.9.5 and above have an
improved algorithm which renders these flags irrelevant.

compresses large files in blocks.  The block size affects
both the compression ratio achieved, and the amount of memory needed for
specify the block size to be 100,000 bytes through 900,000 bytes (the
default) respectively.  At decompression time, the block size used for
compression is read from the header of the compressed file, and
then allocates itself just enough memory to decompress
the file.  Since block sizes are stored in compressed files, it follows
during decompression.

Compression and decompression requirements, 
in bytes, can be estimated as:

       Compression:   400k + ( 8 x block size )

       Decompression: 100k + ( 4 x block size ), or
                      100k + ( 2.5 x block size )

Larger block sizes give rapidly diminishing marginal returns.  Most of
the compression comes from the first two or three hundred k of block
size, a fact worth bearing in mind when using
on small machines.
It is also important to appreciate that the decompression memory
requirement is set at compression time by the choice of block size.

For files compressed with the default 900k block size,
will require about 3700 kbytes to decompress.  To support decompression
of any file on a 4 megabyte machine, 
has an option to
decompress using approximately half this amount of memory, about 2300
kbytes.  Decompression speed is also halved, so you should use this
option only where necessary.  The relevant flag is -s.

In general, try and use the largest block size memory constraints allow,
since that maximises the compression achieved.  Compression and
decompression speed are virtually unaffected by block size.

Another significant point applies to files which fit in a single block
-- that means most files you'd encounter using a large block size.  The
amount of real memory touched is proportional to the size of the file,
since the file is smaller than a block.  For example, compressing a file
20,000 bytes long with the flag -9 will cause the compressor to
allocate around 7600k of memory, but only touch 400k + 20000 * 8 = 560
kbytes of it.  Similarly, the decompressor will allocate 3700k but only
touch 100k + 20000 * 4 = 180 kbytes.

Here is a table which summarises the maximum memory usage for different
block sizes.  Also recorded is the total compressed size for 14 files of
the Calgary Text Compression Corpus totalling 3,141,622 bytes.  This
column gives some feel for how compression varies with block size.
These figures tend to understate the advantage of larger block sizes for
larger files, since the Corpus is dominated by smaller files.

           Compress   Decompress   Decompress   Corpus
    Flag     usage      usage       -s usage     Size

     -1      1200k       500k         350k      914704
     -2      2000k       900k         600k      877703
     -3      2800k      1300k         850k      860338
     -4      3600k      1700k        1100k      846899
     -5      4400k      2100k        1350k      845160
     -6      5200k      2500k        1600k      838626
     -7      6100k      2900k        1850k      834096
     -8      6800k      3300k        2100k      828642
     -9      7600k      3700k        2350k      828642

compresses files in blocks, usually 900kbytes long.  Each
block is handled independently.  If a media or transmission error causes
a multi-block .bz2
file to become damaged, it may be possible to
recover data from the undamaged blocks in the file.

The compressed representation of each block is delimited by a 48-bit
pattern, which makes it possible to find the block boundaries with
reasonable certainty.  Each block also carries its own 32-bit CRC, so
damaged blocks can be distinguished from undamaged ones.

is a simple program whose purpose is to search for
blocks in .bz2 files, and write each block out into its own .bz2 
file.  You can then use
to test the
integrity of the resulting files, and decompress those which are
undamaged.

takes a single argument, the name of the damaged file, 
and writes a number of files "rec00001file.bz2",
"rec00002file.bz2", etc, containing the  extracted  blocks.
The  output  filenames  are  designed  so  that the use of
wildcards in subsequent processing -- for example,  
"bzip2 -dc  rec*file.bz2 > recovered_data" -- processes the files in
the correct order.

should be of most use dealing with large .bz2
files,  as  these will contain many blocks.  It is clearly
futile to use it on damaged single-block  files,  since  a
damaged  block  cannot  be recovered.  If you wish to minimise 
any potential data loss through media  or  transmission errors, 
you might consider compressing with a smaller
block size.

The sorting phase of compression gathers together similar strings in the
file.  Because of this, files containing very long runs of repeated
symbols, like "aabaabaabaab ..."  (repeated several hundred times) may
compress more slowly than normal.  Versions 0.9.5 and above fare much
better than previous versions in this respect.  The ratio between
worst-case and average-case compression time is in the region of 10:1.
For previous versions, this figure was more like 100:1.  You can use the

Decompression speed is unaffected by these phenomena.

usually allocates several megabytes of memory to operate
in, and then charges all over it in a fairly random fashion.  This means
that performance, both for compressing and decompressing, is largely
determined by the speed at which your machine can service cache misses.
Because of this, small changes to the code to reduce the miss rate have
been observed to give disproportionately large performance improvements.
I imagine 
will perform best on machines with very large caches.

what the problem is sometimes seem rather misleading.

This manual page pertains to version 1.0.6 of
Compressed data created by this version is entirely forwards and
backwards compatible with the previous public releases, versions
0.1pl2, 0.9.0, 0.9.5, 1.0.0, 1.0.1, 1.0.2 and above, but with the following
exception: 0.9.0 and above can correctly decompress multiple
concatenated compressed files.  0.1pl2 cannot do this; it will stop
after decompressing just the first file in the stream.

versions prior to 1.0.2 used 32-bit integers to represent
bit positions in compressed files, so they could not handle compressed
files more than 512 megabytes long.  Versions 1.0.2 and above use
64-bit ints on some platforms which support them (GNU supported
targets, and Windows).  To establish whether or not bzip2recover was
built with such a limitation, run it without arguments.  In any event
you can build yourself an unlimited version if you can recompile it
with MaybeUInt64 set to be an unsigned 64-bit integer.



Julian Seward, jsewardbzip.org.


The ideas embodied in
are due to (at least) the following
people: Michael Burrows and David Wheeler (for the block sorting
transformation), David Wheeler (again, for the Huffman coder), Peter
Fenwick (for the structured coding model in the original
and many refinements), and Alistair Moffat, Radford Neal and Ian Witten
(for the arithmetic coder in the original
I am much
indebted for their help, support and advice.  See the manual in the
source distribution for pointers to sources of documentation.  Christian
von Roques encouraged me to look for faster sorting algorithms, so as to
speed up compression.  Bela Lubkin encouraged me to improve the
worst-case compression performance.  
Donna Robinson XMLised the documentation.
The bz* scripts are derived from those of GNU gzip.
Many people sent patches, helped
with portability problems, lent machines, gave advice and were generally
helpful.

[
]
[ 
]
[ 
]

compresses files using the Burrows-Wheeler block sorting
text compression algorithm, and Huffman coding.  Compression is
generally considerably better than that achieved by more conventional
family of statistical compressors.

The command-line options are deliberately very similar to 
those of 
but they are not identical.

expects a list of file names to accompany the
command-line flags.  Each file is replaced by a compressed version of
itself, with the name "original_name.bz2".  
Each compressed file
has the same modification date, permissions, and, when possible,
ownership as the corresponding original, so that these properties can
be correctly restored at decompression time.  File name handling is
naive in the sense that there is no mechanism for preserving original
file names, permissions, ownerships or dates in filesystems which lack
these concepts, or have serious file name length restrictions, such as
MS-DOS.

and
will by default not overwrite existing

If no file names are specified,
compresses from standard
input to standard output.  In this case,
will decline to
write compressed output to a terminal, as this would be entirely
incomprehensible and therefore pointless.

(or
decompresses all
specified files.  Files which were not created by 
will be detected and ignored, and a warning issued.  
attempts to guess the filename for the decompressed file 
from that of the compressed file as follows:

       filename.bz2    becomes   filename
       filename.bz     becomes   filename
       filename.tbz2   becomes   filename.tar
       filename.tbz    becomes   filename.tar
       anyothername    becomes   anyothername.out

If the file does not end in one of the recognised endings, 
or
complains that it cannot
guess the name of the original file, and uses the original name
with
appended.

As with compression, supplying no
filenames causes decompression from 
standard input to standard output.

will correctly decompress a file which is the
concatenation of two or more compressed files.  The result is the
concatenation of the corresponding uncompressed files.  Integrity
of concatenated 
compressed files is also supported.

You can also compress or decompress files to the standard output by
decompressed like this.  The resulting outputs are fed sequentially to
stdout.  Compression of multiple files 
in this manner generates a stream
containing multiple compressed file representations.  Such a stream
can be decompressed correctly only by
version 0.9.0 or
later.  Earlier versions of
will stop after decompressing
the first file in the stream.

(or
decompresses all specified files to
the standard output.

will read arguments from the environment variables
and
in that order, and will process them
before any arguments read from the command line.  This gives a 
convenient way to supply default arguments.

Compression is always performed, even if the compressed 
file is slightly
larger than the original.  Files of less than about one hundred bytes
tend to get larger, since the compression mechanism has a constant
overhead in the region of 50 bytes.  Random data (including the output
of most file compressors) is coded at about 8.05 bits per byte, giving
an expansion of around 0.5%.

As a self-check for your protection, 
bzip2
uses 32-bit CRCs to
make sure that the decompressed version of a file is identical to the
original.  This guards against corruption of the compressed data, and
against undetected bugs in
(hopefully very unlikely).  The
chances of data corruption going undetected is microscopic, about one
chance in four billion for each file processed.  Be aware, though, that
the check occurs upon decompression, so it can only tell you that
something is wrong.  It can't help you 
recover the original uncompressed
data.  You can use 
to try to recover data from
damaged files.

Return values: 0 for a normal exit, 1 for environmental problems (file
compressed file, 3 for an internal consistency error (eg, bug) which
caused
to panic.

Compress or decompress to standard output.
Force decompression.  
and
are
really the same program, and the decision about what actions to take is
done on the basis of which name is used.  This flag overrides that
mechanism, and forces 
to decompress.
invocation name.
Check integrity of the specified file(s), but don't decompress them.
This really performs a trial decompression and throws away the result.
Force overwrite of output files.  Normally,
will not overwrite
existing output files.  Also forces 
to break hard links
to files, which it otherwise wouldn't do.

bzip2 normally declines to decompress files which don't have the
correct magic header bytes.  If forced (-f), however, it will pass
such files through unmodified.  This is how GNU gzip behaves.
Keep (don't delete) input files during compression
or decompression.
Reduce memory usage, for compression, decompression and testing.  Files
are decompressed and tested using a modified algorithm which only
requires 2.5 bytes per block byte.  This means any file can be
decompressed in 2300k of memory, albeit at about half the normal speed.

memory use to around the same figure, at the expense of your compression
ratio.  In short, if your machine is low on memory (8 megabytes or
Suppress non-essential warning messages.  Messages pertaining to
Verbose mode -- show the compression ratio for each file processed.
information which is primarily of interest for diagnostic purposes.
Display the software version, license terms and conditions.
Set the block size to 100 k, 200 k ..  900 k when compressing.  Has no
effect when decompressing.  See MEMORY MANAGEMENT below.
significantly faster.  
Treats all subsequent arguments as file names, even if they start
with a dash.  This is so you can handle files with names beginning
These flags are redundant in versions 0.9.5 and above.  They provided
some coarse control over the behaviour of the sorting algorithm in
earlier versions, which was sometimes useful.  0.9.5 and above have an
improved algorithm which renders these flags irrelevant.

compresses large files in blocks.  The block size affects
both the compression ratio achieved, and the amount of memory needed for
specify the block size to be 100,000 bytes through 900,000 bytes (the
default) respectively.  At decompression time, the block size used for
compression is read from the header of the compressed file, and
then allocates itself just enough memory to decompress
the file.  Since block sizes are stored in compressed files, it follows
during decompression.

Compression and decompression requirements, 
in bytes, can be estimated as:

       Compression:   400k + ( 8 x block size )

       Decompression: 100k + ( 4 x block size ), or
                      100k + ( 2.5 x block size )

Larger block sizes give rapidly diminishing marginal returns.  Most of
the compression comes from the first two or three hundred k of block
size, a fact worth bearing in mind when using
on small machines.
It is also important to appreciate that the decompression memory
requirement is set at compression time by the choice of block size.

For files compressed with the default 900k block size,
will require about 3700 kbytes to decompress.  To support decompression
of any file on a 4 megabyte machine, 
has an option to
decompress using approximately half this amount of memory, about 2300
kbytes.  Decompression speed is also halved, so you should use this
option only where necessary.  The relevant flag is -s.

In general, try and use the largest block size memory constraints allow,
since that maximises the compression achieved.  Compression and
decompression speed are virtually unaffected by block size.

Another significant point applies to files which fit in a single block
-- that means most files you'd encounter using a large block size.  The
amount of real memory touched is proportional to the size of the file,
since the file is smaller than a block.  For example, compressing a file
20,000 bytes long with the flag -9 will cause the compressor to
allocate around 7600k of memory, but only touch 400k + 20000 * 8 = 560
kbytes of it.  Similarly, the decompressor will allocate 3700k but only
touch 100k + 20000 * 4 = 180 kbytes.

Here is a table which summarises the maximum memory usage for different
block sizes.  Also recorded is the total compressed size for 14 files of
the Calgary Text Compression Corpus totalling 3,141,622 bytes.  This
column gives some feel for how compression varies with block size.
These figures tend to understate the advantage of larger block sizes for
larger files, since the Corpus is dominated by smaller files.

           Compress   Decompress   Decompress   Corpus
    Flag     usage      usage       -s usage     Size

     -1      1200k       500k         350k      914704
     -2      2000k       900k         600k      877703
     -3      2800k      1300k         850k      860338
     -4      3600k      1700k        1100k      846899
     -5      4400k      2100k        1350k      845160
     -6      5200k      2500k        1600k      838626
     -7      6100k      2900k        1850k      834096
     -8      6800k      3300k        2100k      828642
     -9      7600k      3700k        2350k      828642

compresses files in blocks, usually 900kbytes long.  Each
block is handled independently.  If a media or transmission error causes
a multi-block .bz2
file to become damaged, it may be possible to
recover data from the undamaged blocks in the file.

The compressed representation of each block is delimited by a 48-bit
pattern, which makes it possible to find the block boundaries with
reasonable certainty.  Each block also carries its own 32-bit CRC, so
damaged blocks can be distinguished from undamaged ones.

is a simple program whose purpose is to search for
blocks in .bz2 files, and write each block out into its own .bz2 
file.  You can then use
to test the
integrity of the resulting files, and decompress those which are
undamaged.

takes a single argument, the name of the damaged file, 
and writes a number of files "rec00001file.bz2",
"rec00002file.bz2", etc, containing the  extracted  blocks.
The  output  filenames  are  designed  so  that the use of
wildcards in subsequent processing -- for example,  
"bzip2 -dc  rec*file.bz2 > recovered_data" -- processes the files in
the correct order.

should be of most use dealing with large .bz2
files,  as  these will contain many blocks.  It is clearly
futile to use it on damaged single-block  files,  since  a
damaged  block  cannot  be recovered.  If you wish to minimise 
any potential data loss through media  or  transmission errors, 
you might consider compressing with a smaller
block size.

The sorting phase of compression gathers together similar strings in the
file.  Because of this, files containing very long runs of repeated
symbols, like "aabaabaabaab ..."  (repeated several hundred times) may
compress more slowly than normal.  Versions 0.9.5 and above fare much
better than previous versions in this respect.  The ratio between
worst-case and average-case compression time is in the region of 10:1.
For previous versions, this figure was more like 100:1.  You can use the

Decompression speed is unaffected by these phenomena.

usually allocates several megabytes of memory to operate
in, and then charges all over it in a fairly random fashion.  This means
that performance, both for compressing and decompressing, is largely
determined by the speed at which your machine can service cache misses.
Because of this, small changes to the code to reduce the miss rate have
been observed to give disproportionately large performance improvements.
I imagine 
will perform best on machines with very large caches.

what the problem is sometimes seem rather misleading.

This manual page pertains to version 1.0.6 of
Compressed data created by this version is entirely forwards and
backwards compatible with the previous public releases, versions
0.1pl2, 0.9.0, 0.9.5, 1.0.0, 1.0.1, 1.0.2 and above, but with the following
exception: 0.9.0 and above can correctly decompress multiple
concatenated compressed files.  0.1pl2 cannot do this; it will stop
after decompressing just the first file in the stream.

versions prior to 1.0.2 used 32-bit integers to represent
bit positions in compressed files, so they could not handle compressed
files more than 512 megabytes long.  Versions 1.0.2 and above use
64-bit ints on some platforms which support them (GNU supported
targets, and Windows).  To establish whether or not bzip2recover was
built with such a limitation, run it without arguments.  In any event
you can build yourself an unlimited version if you can recompile it
with MaybeUInt64 set to be an unsigned 64-bit integer.



Julian Seward, jsewardbzip.org.


The ideas embodied in
are due to (at least) the following
people: Michael Burrows and David Wheeler (for the block sorting
transformation), David Wheeler (again, for the Huffman coder), Peter
Fenwick (for the structured coding model in the original
and many refinements), and Alistair Moffat, Radford Neal and Ian Witten
(for the arithmetic coder in the original
I am much
indebted for their help, support and advice.  See the manual in the
source distribution for pointers to sources of documentation.  Christian
von Roques encouraged me to look for faster sorting algorithms, so as to
speed up compression.  Bela Lubkin encouraged me to improve the
worst-case compression performance.  
Donna Robinson XMLised the documentation.
The bz* scripts are derived from those of GNU gzip.
Many people sent patches, helped
with portability problems, lent machines, gave advice and were generally
helpful.
[ cmp_options ] file1
[ file2 ]
[ diff_options ] file1
[ file2 ]
and 
are used to invoke the
or the
program on bzip2 compressed files.  All options specified are passed
directly to
or
If only 1 file is specified, then the files compared are
and an uncompressed
If two files are specified, then they are uncompressed if necessary and fed to
or
The exit status from 
or
is preserved.
cmp(1), diff(1), bzmore(1), bzless(1), bzgrep(1), bzip2(1)
Messages from the
or
programs refer to temporary filenames instead of those specified.
[ cmp_options ] file1
[ file2 ]
[ diff_options ] file1
[ file2 ]
and 
are used to invoke the
or the
program on bzip2 compressed files.  All options specified are passed
directly to
or
If only 1 file is specified, then the files compared are
and an uncompressed
If two files are specified, then they are uncompressed if necessary and fed to
or
The exit status from 
or
is preserved.
cmp(1), diff(1), bzmore(1), bzless(1), bzgrep(1), bzip2(1)
Messages from the
or
programs refer to temporary filenames instead of those specified.
The
utility searches any given input files,
selecting lines that match one or more patterns.
By default, a pattern matches an input line if the regular expression
(RE) in the pattern matches the input line
without its trailing newline.
An empty expression matches every line.
Each input line that matches at least one of the patterns is written
to the standard output.
is used for simple patterns and
basic regular expressions
can handle extended regular expressions
See
for more information on regular expressions.
is quicker than both
and
but can only handle fixed patterns
(i.e. it does not interpret regular expressions).
Patterns may consist of one or more lines,
allowing any of the pattern lines to match a portion of the input.
and
act like
and
respectively, but accept input files compressed with the
or
compression utilities.
The following options are available:
Print
lines of trailing context after each match.
See also the
and
options.
Treat all files as ASCII text.
Normally
will simply print
if files contain binary characters.
Use of this option forces
to output lines matching the specified pattern.
Print
lines of leading context before each match.
See also the
and
options.
The offset in bytes of a matched pattern is
displayed in front of the respective matched line.
Print
lines of leading and trailing context surrounding each match.
The default is 2 and is equivalent to
Note:
no whitespace may be given between the option and its argument.
Only a count of selected lines is written to standard output.
Mark up the matching text with the expression stored in
environment variable.
The possible values of when can be `never', `always' or `auto'.
Specify the demanded action for devices, FIFOs and sockets.
The default action is `read', which means, that they are read
as if they were normal files.
If the action is set to `skip', devices will be silently skipped.
Specify the demanded action for directories.
It is `read' by default, which means that the directories
are read in the same manner as normal files.
Other possible values are `skip' to silently ignore the
directories, and `recurse' to read them recursively, which
has the same effect as the
and
option.
Interpret
as an extended regular expression
(i.e. force
to behave as
Specify a pattern used during the search of the input:
an input line is selected if it matches any of the specified patterns.
This option is most useful when multiple
options are used to specify multiple patterns,
or when a pattern begins with a dash
If specified, it excludes files matching the given
filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all files are searched that are
not excluded.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, it excludes directories matching the
given filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all directories are searched that are
not excluded.
Interpret
as a set of fixed strings
(i.e. force
to behave as
Read one or more newline separated patterns from
Empty pattern lines match every input line.
Newlines are not considered part of a pattern.
If
is empty, nothing is matched.
Interpret
as a basic regular expression
(i.e. force
to behave as traditional
Always print filename headers with output lines.
Never print filename headers
with output lines.
Print a brief help message.
Ignore binary files.
This option is equivalent to
option.
Perform case insensitive matching.
By default,
is case sensitive.
If specified, only files matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, only directories matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Decompress the
compressed file before looking for the text.
Only the names of files not containing selected lines are written to
standard output.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Only the names of files containing selected lines are written to
standard output.
will only search a file until a match has been found,
making searches potentially less expensive.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Use
instead of
to read input, which can result in better performance under some
circumstances but can cause undefined behaviour.
Stop reading the file after
matches.
Each output line is preceded by its relative line number in the file,
starting at line 1.
The line number counter is reset for each file processed.
This option is ignored if
or
is
specified.
Prints a zero-byte after the file name.
If
is specified, follow symbolic links only if they were explicitly listed
on the command line.
The default is not to follow symbolic links.
Prints only the matching part of the lines.
If
is specified, no symbolic links are followed.
This is the default.
Quiet mode:
suppress normal output.
will only search a file until a match has been found,
making searches potentially less expensive.
Recursively search subdirectories listed.
If
is specified, all symbolic links are followed.
The default is not to follow symbolic links.
Silent mode.
Nonexistent and unreadable files are ignored
(i.e. their error messages are suppressed).
Search binary files, but do not attempt to print them.
Display version information and exit.
Selected lines are those
matching any of the specified patterns.
The expression is searched for as a word (as if surrounded by
and
see
Only input lines selected against an entire fixed string or regular
expression are considered to be matching lines.
Equivalent to
Obsoleted.
Force
to behave as
Controls searching and printing of binary files.
Options are
the default: search binary files but do not print them;
do not search binary files;
and
treat all files as text.
Print
lines of leading and trailing context.
The default is 2.
Force output to be line buffered.
By default, output is line buffered when standard output is a terminal
and block buffered otherwise.
If no file arguments are specified, the standard input is used.
May be used to specify default options that will be placed at the beginning
of the argument list.
Backslash-escaping is not supported, unlike the behavior in GNU grep.
The
utility exits with one of the following values:
One or more lines were selected.
No lines were selected.
An error occurred.
To find all occurrences of the word
in a file:
To find all occurrences of the pattern
at the beginning of a line:
The apostrophes ensure the entire expression is evaluated by
instead of by the user's shell.
The caret
matches the null string at the beginning of a line,
and the
escapes the
which would otherwise match any character.
To find all lines in a file which do not contain the words
or
A simple example of an extended regular expression:
Peruses the file
looking for either 19, 20, or 25.
The
utility is compliant with the
specification.
The flags
are extensions to that specification, and the behaviour of the
flag when used with an empty pattern file is left undefined.
All long options are provided for compatibility with
GNU versions of this utility.
Historic versions of the
utility also supported the flags
This implementation supports those options;
however, their use is strongly discouraged.
The
command first appeared in
The
utility does not normalize Unicode input, so a pattern containing composed
characters will not match decomposed input, and vice versa.
The
utility searches any given input files,
selecting lines that match one or more patterns.
By default, a pattern matches an input line if the regular expression
(RE) in the pattern matches the input line
without its trailing newline.
An empty expression matches every line.
Each input line that matches at least one of the patterns is written
to the standard output.
is used for simple patterns and
basic regular expressions
can handle extended regular expressions
See
for more information on regular expressions.
is quicker than both
and
but can only handle fixed patterns
(i.e. it does not interpret regular expressions).
Patterns may consist of one or more lines,
allowing any of the pattern lines to match a portion of the input.
and
act like
and
respectively, but accept input files compressed with the
or
compression utilities.
The following options are available:
Print
lines of trailing context after each match.
See also the
and
options.
Treat all files as ASCII text.
Normally
will simply print
if files contain binary characters.
Use of this option forces
to output lines matching the specified pattern.
Print
lines of leading context before each match.
See also the
and
options.
The offset in bytes of a matched pattern is
displayed in front of the respective matched line.
Print
lines of leading and trailing context surrounding each match.
The default is 2 and is equivalent to
Note:
no whitespace may be given between the option and its argument.
Only a count of selected lines is written to standard output.
Mark up the matching text with the expression stored in
environment variable.
The possible values of when can be `never', `always' or `auto'.
Specify the demanded action for devices, FIFOs and sockets.
The default action is `read', which means, that they are read
as if they were normal files.
If the action is set to `skip', devices will be silently skipped.
Specify the demanded action for directories.
It is `read' by default, which means that the directories
are read in the same manner as normal files.
Other possible values are `skip' to silently ignore the
directories, and `recurse' to read them recursively, which
has the same effect as the
and
option.
Interpret
as an extended regular expression
(i.e. force
to behave as
Specify a pattern used during the search of the input:
an input line is selected if it matches any of the specified patterns.
This option is most useful when multiple
options are used to specify multiple patterns,
or when a pattern begins with a dash
If specified, it excludes files matching the given
filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all files are searched that are
not excluded.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, it excludes directories matching the
given filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all directories are searched that are
not excluded.
Interpret
as a set of fixed strings
(i.e. force
to behave as
Read one or more newline separated patterns from
Empty pattern lines match every input line.
Newlines are not considered part of a pattern.
If
is empty, nothing is matched.
Interpret
as a basic regular expression
(i.e. force
to behave as traditional
Always print filename headers with output lines.
Never print filename headers
with output lines.
Print a brief help message.
Ignore binary files.
This option is equivalent to
option.
Perform case insensitive matching.
By default,
is case sensitive.
If specified, only files matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, only directories matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Decompress the
compressed file before looking for the text.
Only the names of files not containing selected lines are written to
standard output.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Only the names of files containing selected lines are written to
standard output.
will only search a file until a match has been found,
making searches potentially less expensive.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Use
instead of
to read input, which can result in better performance under some
circumstances but can cause undefined behaviour.
Stop reading the file after
matches.
Each output line is preceded by its relative line number in the file,
starting at line 1.
The line number counter is reset for each file processed.
This option is ignored if
or
is
specified.
Prints a zero-byte after the file name.
If
is specified, follow symbolic links only if they were explicitly listed
on the command line.
The default is not to follow symbolic links.
Prints only the matching part of the lines.
If
is specified, no symbolic links are followed.
This is the default.
Quiet mode:
suppress normal output.
will only search a file until a match has been found,
making searches potentially less expensive.
Recursively search subdirectories listed.
If
is specified, all symbolic links are followed.
The default is not to follow symbolic links.
Silent mode.
Nonexistent and unreadable files are ignored
(i.e. their error messages are suppressed).
Search binary files, but do not attempt to print them.
Display version information and exit.
Selected lines are those
matching any of the specified patterns.
The expression is searched for as a word (as if surrounded by
and
see
Only input lines selected against an entire fixed string or regular
expression are considered to be matching lines.
Equivalent to
Obsoleted.
Force
to behave as
Controls searching and printing of binary files.
Options are
the default: search binary files but do not print them;
do not search binary files;
and
treat all files as text.
Print
lines of leading and trailing context.
The default is 2.
Force output to be line buffered.
By default, output is line buffered when standard output is a terminal
and block buffered otherwise.
If no file arguments are specified, the standard input is used.
May be used to specify default options that will be placed at the beginning
of the argument list.
Backslash-escaping is not supported, unlike the behavior in GNU grep.
The
utility exits with one of the following values:
One or more lines were selected.
No lines were selected.
An error occurred.
To find all occurrences of the word
in a file:
To find all occurrences of the pattern
at the beginning of a line:
The apostrophes ensure the entire expression is evaluated by
instead of by the user's shell.
The caret
matches the null string at the beginning of a line,
and the
escapes the
which would otherwise match any character.
To find all lines in a file which do not contain the words
or
A simple example of an extended regular expression:
Peruses the file
looking for either 19, 20, or 25.
The
utility is compliant with the
specification.
The flags
are extensions to that specification, and the behaviour of the
flag when used with an empty pattern file is left undefined.
All long options are provided for compatibility with
GNU versions of this utility.
Historic versions of the
utility also supported the flags
This implementation supports those options;
however, their use is strongly discouraged.
The
command first appeared in
The
utility does not normalize Unicode input, so a pattern containing composed
characters will not match decomposed input, and vice versa.
The
utility searches any given input files,
selecting lines that match one or more patterns.
By default, a pattern matches an input line if the regular expression
(RE) in the pattern matches the input line
without its trailing newline.
An empty expression matches every line.
Each input line that matches at least one of the patterns is written
to the standard output.
is used for simple patterns and
basic regular expressions
can handle extended regular expressions
See
for more information on regular expressions.
is quicker than both
and
but can only handle fixed patterns
(i.e. it does not interpret regular expressions).
Patterns may consist of one or more lines,
allowing any of the pattern lines to match a portion of the input.
and
act like
and
respectively, but accept input files compressed with the
or
compression utilities.
The following options are available:
Print
lines of trailing context after each match.
See also the
and
options.
Treat all files as ASCII text.
Normally
will simply print
if files contain binary characters.
Use of this option forces
to output lines matching the specified pattern.
Print
lines of leading context before each match.
See also the
and
options.
The offset in bytes of a matched pattern is
displayed in front of the respective matched line.
Print
lines of leading and trailing context surrounding each match.
The default is 2 and is equivalent to
Note:
no whitespace may be given between the option and its argument.
Only a count of selected lines is written to standard output.
Mark up the matching text with the expression stored in
environment variable.
The possible values of when can be `never', `always' or `auto'.
Specify the demanded action for devices, FIFOs and sockets.
The default action is `read', which means, that they are read
as if they were normal files.
If the action is set to `skip', devices will be silently skipped.
Specify the demanded action for directories.
It is `read' by default, which means that the directories
are read in the same manner as normal files.
Other possible values are `skip' to silently ignore the
directories, and `recurse' to read them recursively, which
has the same effect as the
and
option.
Interpret
as an extended regular expression
(i.e. force
to behave as
Specify a pattern used during the search of the input:
an input line is selected if it matches any of the specified patterns.
This option is most useful when multiple
options are used to specify multiple patterns,
or when a pattern begins with a dash
If specified, it excludes files matching the given
filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all files are searched that are
not excluded.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, it excludes directories matching the
given filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all directories are searched that are
not excluded.
Interpret
as a set of fixed strings
(i.e. force
to behave as
Read one or more newline separated patterns from
Empty pattern lines match every input line.
Newlines are not considered part of a pattern.
If
is empty, nothing is matched.
Interpret
as a basic regular expression
(i.e. force
to behave as traditional
Always print filename headers with output lines.
Never print filename headers
with output lines.
Print a brief help message.
Ignore binary files.
This option is equivalent to
option.
Perform case insensitive matching.
By default,
is case sensitive.
If specified, only files matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, only directories matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Decompress the
compressed file before looking for the text.
Only the names of files not containing selected lines are written to
standard output.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Only the names of files containing selected lines are written to
standard output.
will only search a file until a match has been found,
making searches potentially less expensive.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Use
instead of
to read input, which can result in better performance under some
circumstances but can cause undefined behaviour.
Stop reading the file after
matches.
Each output line is preceded by its relative line number in the file,
starting at line 1.
The line number counter is reset for each file processed.
This option is ignored if
or
is
specified.
Prints a zero-byte after the file name.
If
is specified, follow symbolic links only if they were explicitly listed
on the command line.
The default is not to follow symbolic links.
Prints only the matching part of the lines.
If
is specified, no symbolic links are followed.
This is the default.
Quiet mode:
suppress normal output.
will only search a file until a match has been found,
making searches potentially less expensive.
Recursively search subdirectories listed.
If
is specified, all symbolic links are followed.
The default is not to follow symbolic links.
Silent mode.
Nonexistent and unreadable files are ignored
(i.e. their error messages are suppressed).
Search binary files, but do not attempt to print them.
Display version information and exit.
Selected lines are those
matching any of the specified patterns.
The expression is searched for as a word (as if surrounded by
and
see
Only input lines selected against an entire fixed string or regular
expression are considered to be matching lines.
Equivalent to
Obsoleted.
Force
to behave as
Controls searching and printing of binary files.
Options are
the default: search binary files but do not print them;
do not search binary files;
and
treat all files as text.
Print
lines of leading and trailing context.
The default is 2.
Force output to be line buffered.
By default, output is line buffered when standard output is a terminal
and block buffered otherwise.
If no file arguments are specified, the standard input is used.
May be used to specify default options that will be placed at the beginning
of the argument list.
Backslash-escaping is not supported, unlike the behavior in GNU grep.
The
utility exits with one of the following values:
One or more lines were selected.
No lines were selected.
An error occurred.
To find all occurrences of the word
in a file:
To find all occurrences of the pattern
at the beginning of a line:
The apostrophes ensure the entire expression is evaluated by
instead of by the user's shell.
The caret
matches the null string at the beginning of a line,
and the
escapes the
which would otherwise match any character.
To find all lines in a file which do not contain the words
or
A simple example of an extended regular expression:
Peruses the file
looking for either 19, 20, or 25.
The
utility is compliant with the
specification.
The flags
are extensions to that specification, and the behaviour of the
flag when used with an empty pattern file is left undefined.
All long options are provided for compatibility with
GNU versions of this utility.
Historic versions of the
utility also supported the flags
This implementation supports those options;
however, their use is strongly discouraged.
The
command first appeared in
The
utility does not normalize Unicode input, so a pattern containing composed
characters will not match decomposed input, and vice versa.

[
]
[ 
]
[ 
]

compresses files using the Burrows-Wheeler block sorting
text compression algorithm, and Huffman coding.  Compression is
generally considerably better than that achieved by more conventional
family of statistical compressors.

The command-line options are deliberately very similar to 
those of 
but they are not identical.

expects a list of file names to accompany the
command-line flags.  Each file is replaced by a compressed version of
itself, with the name "original_name.bz2".  
Each compressed file
has the same modification date, permissions, and, when possible,
ownership as the corresponding original, so that these properties can
be correctly restored at decompression time.  File name handling is
naive in the sense that there is no mechanism for preserving original
file names, permissions, ownerships or dates in filesystems which lack
these concepts, or have serious file name length restrictions, such as
MS-DOS.

and
will by default not overwrite existing

If no file names are specified,
compresses from standard
input to standard output.  In this case,
will decline to
write compressed output to a terminal, as this would be entirely
incomprehensible and therefore pointless.

(or
decompresses all
specified files.  Files which were not created by 
will be detected and ignored, and a warning issued.  
attempts to guess the filename for the decompressed file 
from that of the compressed file as follows:

       filename.bz2    becomes   filename
       filename.bz     becomes   filename
       filename.tbz2   becomes   filename.tar
       filename.tbz    becomes   filename.tar
       anyothername    becomes   anyothername.out

If the file does not end in one of the recognised endings, 
or
complains that it cannot
guess the name of the original file, and uses the original name
with
appended.

As with compression, supplying no
filenames causes decompression from 
standard input to standard output.

will correctly decompress a file which is the
concatenation of two or more compressed files.  The result is the
concatenation of the corresponding uncompressed files.  Integrity
of concatenated 
compressed files is also supported.

You can also compress or decompress files to the standard output by
decompressed like this.  The resulting outputs are fed sequentially to
stdout.  Compression of multiple files 
in this manner generates a stream
containing multiple compressed file representations.  Such a stream
can be decompressed correctly only by
version 0.9.0 or
later.  Earlier versions of
will stop after decompressing
the first file in the stream.

(or
decompresses all specified files to
the standard output.

will read arguments from the environment variables
and
in that order, and will process them
before any arguments read from the command line.  This gives a 
convenient way to supply default arguments.

Compression is always performed, even if the compressed 
file is slightly
larger than the original.  Files of less than about one hundred bytes
tend to get larger, since the compression mechanism has a constant
overhead in the region of 50 bytes.  Random data (including the output
of most file compressors) is coded at about 8.05 bits per byte, giving
an expansion of around 0.5%.

As a self-check for your protection, 
bzip2
uses 32-bit CRCs to
make sure that the decompressed version of a file is identical to the
original.  This guards against corruption of the compressed data, and
against undetected bugs in
(hopefully very unlikely).  The
chances of data corruption going undetected is microscopic, about one
chance in four billion for each file processed.  Be aware, though, that
the check occurs upon decompression, so it can only tell you that
something is wrong.  It can't help you 
recover the original uncompressed
data.  You can use 
to try to recover data from
damaged files.

Return values: 0 for a normal exit, 1 for environmental problems (file
compressed file, 3 for an internal consistency error (eg, bug) which
caused
to panic.

Compress or decompress to standard output.
Force decompression.  
and
are
really the same program, and the decision about what actions to take is
done on the basis of which name is used.  This flag overrides that
mechanism, and forces 
to decompress.
invocation name.
Check integrity of the specified file(s), but don't decompress them.
This really performs a trial decompression and throws away the result.
Force overwrite of output files.  Normally,
will not overwrite
existing output files.  Also forces 
to break hard links
to files, which it otherwise wouldn't do.

bzip2 normally declines to decompress files which don't have the
correct magic header bytes.  If forced (-f), however, it will pass
such files through unmodified.  This is how GNU gzip behaves.
Keep (don't delete) input files during compression
or decompression.
Reduce memory usage, for compression, decompression and testing.  Files
are decompressed and tested using a modified algorithm which only
requires 2.5 bytes per block byte.  This means any file can be
decompressed in 2300k of memory, albeit at about half the normal speed.

memory use to around the same figure, at the expense of your compression
ratio.  In short, if your machine is low on memory (8 megabytes or
Suppress non-essential warning messages.  Messages pertaining to
Verbose mode -- show the compression ratio for each file processed.
information which is primarily of interest for diagnostic purposes.
Display the software version, license terms and conditions.
Set the block size to 100 k, 200 k ..  900 k when compressing.  Has no
effect when decompressing.  See MEMORY MANAGEMENT below.
significantly faster.  
Treats all subsequent arguments as file names, even if they start
with a dash.  This is so you can handle files with names beginning
These flags are redundant in versions 0.9.5 and above.  They provided
some coarse control over the behaviour of the sorting algorithm in
earlier versions, which was sometimes useful.  0.9.5 and above have an
improved algorithm which renders these flags irrelevant.

compresses large files in blocks.  The block size affects
both the compression ratio achieved, and the amount of memory needed for
specify the block size to be 100,000 bytes through 900,000 bytes (the
default) respectively.  At decompression time, the block size used for
compression is read from the header of the compressed file, and
then allocates itself just enough memory to decompress
the file.  Since block sizes are stored in compressed files, it follows
during decompression.

Compression and decompression requirements, 
in bytes, can be estimated as:

       Compression:   400k + ( 8 x block size )

       Decompression: 100k + ( 4 x block size ), or
                      100k + ( 2.5 x block size )

Larger block sizes give rapidly diminishing marginal returns.  Most of
the compression comes from the first two or three hundred k of block
size, a fact worth bearing in mind when using
on small machines.
It is also important to appreciate that the decompression memory
requirement is set at compression time by the choice of block size.

For files compressed with the default 900k block size,
will require about 3700 kbytes to decompress.  To support decompression
of any file on a 4 megabyte machine, 
has an option to
decompress using approximately half this amount of memory, about 2300
kbytes.  Decompression speed is also halved, so you should use this
option only where necessary.  The relevant flag is -s.

In general, try and use the largest block size memory constraints allow,
since that maximises the compression achieved.  Compression and
decompression speed are virtually unaffected by block size.

Another significant point applies to files which fit in a single block
-- that means most files you'd encounter using a large block size.  The
amount of real memory touched is proportional to the size of the file,
since the file is smaller than a block.  For example, compressing a file
20,000 bytes long with the flag -9 will cause the compressor to
allocate around 7600k of memory, but only touch 400k + 20000 * 8 = 560
kbytes of it.  Similarly, the decompressor will allocate 3700k but only
touch 100k + 20000 * 4 = 180 kbytes.

Here is a table which summarises the maximum memory usage for different
block sizes.  Also recorded is the total compressed size for 14 files of
the Calgary Text Compression Corpus totalling 3,141,622 bytes.  This
column gives some feel for how compression varies with block size.
These figures tend to understate the advantage of larger block sizes for
larger files, since the Corpus is dominated by smaller files.

           Compress   Decompress   Decompress   Corpus
    Flag     usage      usage       -s usage     Size

     -1      1200k       500k         350k      914704
     -2      2000k       900k         600k      877703
     -3      2800k      1300k         850k      860338
     -4      3600k      1700k        1100k      846899
     -5      4400k      2100k        1350k      845160
     -6      5200k      2500k        1600k      838626
     -7      6100k      2900k        1850k      834096
     -8      6800k      3300k        2100k      828642
     -9      7600k      3700k        2350k      828642

compresses files in blocks, usually 900kbytes long.  Each
block is handled independently.  If a media or transmission error causes
a multi-block .bz2
file to become damaged, it may be possible to
recover data from the undamaged blocks in the file.

The compressed representation of each block is delimited by a 48-bit
pattern, which makes it possible to find the block boundaries with
reasonable certainty.  Each block also carries its own 32-bit CRC, so
damaged blocks can be distinguished from undamaged ones.

is a simple program whose purpose is to search for
blocks in .bz2 files, and write each block out into its own .bz2 
file.  You can then use
to test the
integrity of the resulting files, and decompress those which are
undamaged.

takes a single argument, the name of the damaged file, 
and writes a number of files "rec00001file.bz2",
"rec00002file.bz2", etc, containing the  extracted  blocks.
The  output  filenames  are  designed  so  that the use of
wildcards in subsequent processing -- for example,  
"bzip2 -dc  rec*file.bz2 > recovered_data" -- processes the files in
the correct order.

should be of most use dealing with large .bz2
files,  as  these will contain many blocks.  It is clearly
futile to use it on damaged single-block  files,  since  a
damaged  block  cannot  be recovered.  If you wish to minimise 
any potential data loss through media  or  transmission errors, 
you might consider compressing with a smaller
block size.

The sorting phase of compression gathers together similar strings in the
file.  Because of this, files containing very long runs of repeated
symbols, like "aabaabaabaab ..."  (repeated several hundred times) may
compress more slowly than normal.  Versions 0.9.5 and above fare much
better than previous versions in this respect.  The ratio between
worst-case and average-case compression time is in the region of 10:1.
For previous versions, this figure was more like 100:1.  You can use the

Decompression speed is unaffected by these phenomena.

usually allocates several megabytes of memory to operate
in, and then charges all over it in a fairly random fashion.  This means
that performance, both for compressing and decompressing, is largely
determined by the speed at which your machine can service cache misses.
Because of this, small changes to the code to reduce the miss rate have
been observed to give disproportionately large performance improvements.
I imagine 
will perform best on machines with very large caches.

what the problem is sometimes seem rather misleading.

This manual page pertains to version 1.0.6 of
Compressed data created by this version is entirely forwards and
backwards compatible with the previous public releases, versions
0.1pl2, 0.9.0, 0.9.5, 1.0.0, 1.0.1, 1.0.2 and above, but with the following
exception: 0.9.0 and above can correctly decompress multiple
concatenated compressed files.  0.1pl2 cannot do this; it will stop
after decompressing just the first file in the stream.

versions prior to 1.0.2 used 32-bit integers to represent
bit positions in compressed files, so they could not handle compressed
files more than 512 megabytes long.  Versions 1.0.2 and above use
64-bit ints on some platforms which support them (GNU supported
targets, and Windows).  To establish whether or not bzip2recover was
built with such a limitation, run it without arguments.  In any event
you can build yourself an unlimited version if you can recompile it
with MaybeUInt64 set to be an unsigned 64-bit integer.



Julian Seward, jsewardbzip.org.


The ideas embodied in
are due to (at least) the following
people: Michael Burrows and David Wheeler (for the block sorting
transformation), David Wheeler (again, for the Huffman coder), Peter
Fenwick (for the structured coding model in the original
and many refinements), and Alistair Moffat, Radford Neal and Ian Witten
(for the arithmetic coder in the original
I am much
indebted for their help, support and advice.  See the manual in the
source distribution for pointers to sources of documentation.  Christian
von Roques encouraged me to look for faster sorting algorithms, so as to
speed up compression.  Bela Lubkin encouraged me to improve the
worst-case compression performance.  
Donna Robinson XMLised the documentation.
The bz* scripts are derived from those of GNU gzip.
Many people sent patches, helped
with portability problems, lent machines, gave advice and were generally
helpful.

[
]
[ 
]
[ 
]

compresses files using the Burrows-Wheeler block sorting
text compression algorithm, and Huffman coding.  Compression is
generally considerably better than that achieved by more conventional
family of statistical compressors.

The command-line options are deliberately very similar to 
those of 
but they are not identical.

expects a list of file names to accompany the
command-line flags.  Each file is replaced by a compressed version of
itself, with the name "original_name.bz2".  
Each compressed file
has the same modification date, permissions, and, when possible,
ownership as the corresponding original, so that these properties can
be correctly restored at decompression time.  File name handling is
naive in the sense that there is no mechanism for preserving original
file names, permissions, ownerships or dates in filesystems which lack
these concepts, or have serious file name length restrictions, such as
MS-DOS.

and
will by default not overwrite existing

If no file names are specified,
compresses from standard
input to standard output.  In this case,
will decline to
write compressed output to a terminal, as this would be entirely
incomprehensible and therefore pointless.

(or
decompresses all
specified files.  Files which were not created by 
will be detected and ignored, and a warning issued.  
attempts to guess the filename for the decompressed file 
from that of the compressed file as follows:

       filename.bz2    becomes   filename
       filename.bz     becomes   filename
       filename.tbz2   becomes   filename.tar
       filename.tbz    becomes   filename.tar
       anyothername    becomes   anyothername.out

If the file does not end in one of the recognised endings, 
or
complains that it cannot
guess the name of the original file, and uses the original name
with
appended.

As with compression, supplying no
filenames causes decompression from 
standard input to standard output.

will correctly decompress a file which is the
concatenation of two or more compressed files.  The result is the
concatenation of the corresponding uncompressed files.  Integrity
of concatenated 
compressed files is also supported.

You can also compress or decompress files to the standard output by
decompressed like this.  The resulting outputs are fed sequentially to
stdout.  Compression of multiple files 
in this manner generates a stream
containing multiple compressed file representations.  Such a stream
can be decompressed correctly only by
version 0.9.0 or
later.  Earlier versions of
will stop after decompressing
the first file in the stream.

(or
decompresses all specified files to
the standard output.

will read arguments from the environment variables
and
in that order, and will process them
before any arguments read from the command line.  This gives a 
convenient way to supply default arguments.

Compression is always performed, even if the compressed 
file is slightly
larger than the original.  Files of less than about one hundred bytes
tend to get larger, since the compression mechanism has a constant
overhead in the region of 50 bytes.  Random data (including the output
of most file compressors) is coded at about 8.05 bits per byte, giving
an expansion of around 0.5%.

As a self-check for your protection, 
bzip2
uses 32-bit CRCs to
make sure that the decompressed version of a file is identical to the
original.  This guards against corruption of the compressed data, and
against undetected bugs in
(hopefully very unlikely).  The
chances of data corruption going undetected is microscopic, about one
chance in four billion for each file processed.  Be aware, though, that
the check occurs upon decompression, so it can only tell you that
something is wrong.  It can't help you 
recover the original uncompressed
data.  You can use 
to try to recover data from
damaged files.

Return values: 0 for a normal exit, 1 for environmental problems (file
compressed file, 3 for an internal consistency error (eg, bug) which
caused
to panic.

Compress or decompress to standard output.
Force decompression.  
and
are
really the same program, and the decision about what actions to take is
done on the basis of which name is used.  This flag overrides that
mechanism, and forces 
to decompress.
invocation name.
Check integrity of the specified file(s), but don't decompress them.
This really performs a trial decompression and throws away the result.
Force overwrite of output files.  Normally,
will not overwrite
existing output files.  Also forces 
to break hard links
to files, which it otherwise wouldn't do.

bzip2 normally declines to decompress files which don't have the
correct magic header bytes.  If forced (-f), however, it will pass
such files through unmodified.  This is how GNU gzip behaves.
Keep (don't delete) input files during compression
or decompression.
Reduce memory usage, for compression, decompression and testing.  Files
are decompressed and tested using a modified algorithm which only
requires 2.5 bytes per block byte.  This means any file can be
decompressed in 2300k of memory, albeit at about half the normal speed.

memory use to around the same figure, at the expense of your compression
ratio.  In short, if your machine is low on memory (8 megabytes or
Suppress non-essential warning messages.  Messages pertaining to
Verbose mode -- show the compression ratio for each file processed.
information which is primarily of interest for diagnostic purposes.
Display the software version, license terms and conditions.
Set the block size to 100 k, 200 k ..  900 k when compressing.  Has no
effect when decompressing.  See MEMORY MANAGEMENT below.
significantly faster.  
Treats all subsequent arguments as file names, even if they start
with a dash.  This is so you can handle files with names beginning
These flags are redundant in versions 0.9.5 and above.  They provided
some coarse control over the behaviour of the sorting algorithm in
earlier versions, which was sometimes useful.  0.9.5 and above have an
improved algorithm which renders these flags irrelevant.

compresses large files in blocks.  The block size affects
both the compression ratio achieved, and the amount of memory needed for
specify the block size to be 100,000 bytes through 900,000 bytes (the
default) respectively.  At decompression time, the block size used for
compression is read from the header of the compressed file, and
then allocates itself just enough memory to decompress
the file.  Since block sizes are stored in compressed files, it follows
during decompression.

Compression and decompression requirements, 
in bytes, can be estimated as:

       Compression:   400k + ( 8 x block size )

       Decompression: 100k + ( 4 x block size ), or
                      100k + ( 2.5 x block size )

Larger block sizes give rapidly diminishing marginal returns.  Most of
the compression comes from the first two or three hundred k of block
size, a fact worth bearing in mind when using
on small machines.
It is also important to appreciate that the decompression memory
requirement is set at compression time by the choice of block size.

For files compressed with the default 900k block size,
will require about 3700 kbytes to decompress.  To support decompression
of any file on a 4 megabyte machine, 
has an option to
decompress using approximately half this amount of memory, about 2300
kbytes.  Decompression speed is also halved, so you should use this
option only where necessary.  The relevant flag is -s.

In general, try and use the largest block size memory constraints allow,
since that maximises the compression achieved.  Compression and
decompression speed are virtually unaffected by block size.

Another significant point applies to files which fit in a single block
-- that means most files you'd encounter using a large block size.  The
amount of real memory touched is proportional to the size of the file,
since the file is smaller than a block.  For example, compressing a file
20,000 bytes long with the flag -9 will cause the compressor to
allocate around 7600k of memory, but only touch 400k + 20000 * 8 = 560
kbytes of it.  Similarly, the decompressor will allocate 3700k but only
touch 100k + 20000 * 4 = 180 kbytes.

Here is a table which summarises the maximum memory usage for different
block sizes.  Also recorded is the total compressed size for 14 files of
the Calgary Text Compression Corpus totalling 3,141,622 bytes.  This
column gives some feel for how compression varies with block size.
These figures tend to understate the advantage of larger block sizes for
larger files, since the Corpus is dominated by smaller files.

           Compress   Decompress   Decompress   Corpus
    Flag     usage      usage       -s usage     Size

     -1      1200k       500k         350k      914704
     -2      2000k       900k         600k      877703
     -3      2800k      1300k         850k      860338
     -4      3600k      1700k        1100k      846899
     -5      4400k      2100k        1350k      845160
     -6      5200k      2500k        1600k      838626
     -7      6100k      2900k        1850k      834096
     -8      6800k      3300k        2100k      828642
     -9      7600k      3700k        2350k      828642

compresses files in blocks, usually 900kbytes long.  Each
block is handled independently.  If a media or transmission error causes
a multi-block .bz2
file to become damaged, it may be possible to
recover data from the undamaged blocks in the file.

The compressed representation of each block is delimited by a 48-bit
pattern, which makes it possible to find the block boundaries with
reasonable certainty.  Each block also carries its own 32-bit CRC, so
damaged blocks can be distinguished from undamaged ones.

is a simple program whose purpose is to search for
blocks in .bz2 files, and write each block out into its own .bz2 
file.  You can then use
to test the
integrity of the resulting files, and decompress those which are
undamaged.

takes a single argument, the name of the damaged file, 
and writes a number of files "rec00001file.bz2",
"rec00002file.bz2", etc, containing the  extracted  blocks.
The  output  filenames  are  designed  so  that the use of
wildcards in subsequent processing -- for example,  
"bzip2 -dc  rec*file.bz2 > recovered_data" -- processes the files in
the correct order.

should be of most use dealing with large .bz2
files,  as  these will contain many blocks.  It is clearly
futile to use it on damaged single-block  files,  since  a
damaged  block  cannot  be recovered.  If you wish to minimise 
any potential data loss through media  or  transmission errors, 
you might consider compressing with a smaller
block size.

The sorting phase of compression gathers together similar strings in the
file.  Because of this, files containing very long runs of repeated
symbols, like "aabaabaabaab ..."  (repeated several hundred times) may
compress more slowly than normal.  Versions 0.9.5 and above fare much
better than previous versions in this respect.  The ratio between
worst-case and average-case compression time is in the region of 10:1.
For previous versions, this figure was more like 100:1.  You can use the

Decompression speed is unaffected by these phenomena.

usually allocates several megabytes of memory to operate
in, and then charges all over it in a fairly random fashion.  This means
that performance, both for compressing and decompressing, is largely
determined by the speed at which your machine can service cache misses.
Because of this, small changes to the code to reduce the miss rate have
been observed to give disproportionately large performance improvements.
I imagine 
will perform best on machines with very large caches.

what the problem is sometimes seem rather misleading.

This manual page pertains to version 1.0.6 of
Compressed data created by this version is entirely forwards and
backwards compatible with the previous public releases, versions
0.1pl2, 0.9.0, 0.9.5, 1.0.0, 1.0.1, 1.0.2 and above, but with the following
exception: 0.9.0 and above can correctly decompress multiple
concatenated compressed files.  0.1pl2 cannot do this; it will stop
after decompressing just the first file in the stream.

versions prior to 1.0.2 used 32-bit integers to represent
bit positions in compressed files, so they could not handle compressed
files more than 512 megabytes long.  Versions 1.0.2 and above use
64-bit ints on some platforms which support them (GNU supported
targets, and Windows).  To establish whether or not bzip2recover was
built with such a limitation, run it without arguments.  In any event
you can build yourself an unlimited version if you can recompile it
with MaybeUInt64 set to be an unsigned 64-bit integer.



Julian Seward, jsewardbzip.org.


The ideas embodied in
are due to (at least) the following
people: Michael Burrows and David Wheeler (for the block sorting
transformation), David Wheeler (again, for the Huffman coder), Peter
Fenwick (for the structured coding model in the original
and many refinements), and Alistair Moffat, Radford Neal and Ian Witten
(for the arithmetic coder in the original
I am much
indebted for their help, support and advice.  See the manual in the
source distribution for pointers to sources of documentation.  Christian
von Roques encouraged me to look for faster sorting algorithms, so as to
speed up compression.  Bela Lubkin encouraged me to improve the
worst-case compression performance.  
Donna Robinson XMLised the documentation.
The bz* scripts are derived from those of GNU gzip.
Many people sent patches, helped
with portability problems, lent machines, gave advice and were generally
helpful.
[ name ...  ]
[ name ...  ]
In the following description,
and
can be used interchangeably with
and
is a filter which allows examination of compressed or plain text files
one screenful at a time on a soft-copy terminal.
works on files compressed with
and also on uncompressed files.
If a file does not exist,
looks for a file of the same name with the addition of a .bz2 suffix.
normally pauses after each screenful, printing --More--
at the bottom of the screen.
If the user then types a carriage return, one more line is displayed.
If the user hits a space,
another screenful is displayed.  Other possibilities are enumerated later.
looks in the file
to determine terminal characteristics,
and to determine the default window size.
On a terminal capable of displaying 24 lines,
the default window size is 22 lines.
Other sequences which may be typed when
argument, defaulting to 1) :
display
more lines, (or another screenful if no argument is given)
display 11 more lines (a ``scroll'').
If
same as ^D (control-D)
window size.  Note that the window size reverts back to the default at the
end of the current file.
quit reading the current file; go on to the next (if any)
When the prompt --More--(Next file: 
is printed, this command causes bzmore to exit.
When the prompt --More--(Next file: 
is printed, this command causes bzmore to skip the next file and continue.
Display the current line number.
If the pattern is not found,
goes on to the next file (if any).
Otherwise, a screenful is displayed, starting two lines before the place
where the expression was found.
The user's erase and kill characters may be used to edit the regular
expression.
Erasing back past the first column cancels the search command.
The character `!' in "command" are replaced with the
quit reading the current file; go on to the next (if any)
(same as q or Q).
(dot) repeat the previous command.
The commands take effect immediately, i.e., it is not necessary to
type a carriage return.
Up to the time when the command character itself is given,
the user may hit the line kill character to cancel the numerical
argument being formed.
In addition, the user may hit the erase character to redisplay the
--More-- message.
At any time when output is being sent to the terminal, the user can
will stop sending output, and will display the usual --More--
prompt.
The user may then enter one of the above commands in the normal manner.
Unfortunately, some output is lost when this is done, due to the
fact that any characters waiting in the terminal's output queue
are flushed when the quit signal occurs.
The terminal is set to
mode by this program so that the output can be continuous.
commands.
If the standard output is not a teletype, then
acts just like
except that a header is printed before each file.
more(1), less(1), bzip2(1), bzdiff(1), bzgrep(1)
[ name ...  ]
[ name ...  ]
In the following description,
and
can be used interchangeably with
and
is a filter which allows examination of compressed or plain text files
one screenful at a time on a soft-copy terminal.
works on files compressed with
and also on uncompressed files.
If a file does not exist,
looks for a file of the same name with the addition of a .bz2 suffix.
normally pauses after each screenful, printing --More--
at the bottom of the screen.
If the user then types a carriage return, one more line is displayed.
If the user hits a space,
another screenful is displayed.  Other possibilities are enumerated later.
looks in the file
to determine terminal characteristics,
and to determine the default window size.
On a terminal capable of displaying 24 lines,
the default window size is 22 lines.
Other sequences which may be typed when
argument, defaulting to 1) :
display
more lines, (or another screenful if no argument is given)
display 11 more lines (a ``scroll'').
If
same as ^D (control-D)
window size.  Note that the window size reverts back to the default at the
end of the current file.
quit reading the current file; go on to the next (if any)
When the prompt --More--(Next file: 
is printed, this command causes bzmore to exit.
When the prompt --More--(Next file: 
is printed, this command causes bzmore to skip the next file and continue.
Display the current line number.
If the pattern is not found,
goes on to the next file (if any).
Otherwise, a screenful is displayed, starting two lines before the place
where the expression was found.
The user's erase and kill characters may be used to edit the regular
expression.
Erasing back past the first column cancels the search command.
The character `!' in "command" are replaced with the
quit reading the current file; go on to the next (if any)
(same as q or Q).
(dot) repeat the previous command.
The commands take effect immediately, i.e., it is not necessary to
type a carriage return.
Up to the time when the command character itself is given,
the user may hit the line kill character to cancel the numerical
argument being formed.
In addition, the user may hit the erase character to redisplay the
--More-- message.
At any time when output is being sent to the terminal, the user can
will stop sending output, and will display the usual --More--
prompt.
The user may then enter one of the above commands in the normal manner.
Unfortunately, some output is lost when this is done, due to the
fact that any characters waiting in the terminal's output queue
are flushed when the quit signal occurs.
The terminal is set to
mode by this program so that the output can be continuous.
commands.
If the standard output is not a teletype, then
acts just like
except that a header is printed before each file.
more(1), less(1), bzip2(1), bzdiff(1), bzgrep(1)
that you can write many functions with the same name, providing that
each function takes parameters of different types.  In order to be
encode them into a low-level assembler name which uniquely identifies
[1]
names into user-level names so that they can be read.
Every alphanumeric word (consisting of letters, digits, underscores,
dollars, or periods) seen in the input is a potential mangled name.
low-level name in the output, otherwise the original word is output.
In this way you can pass an entire assembler source file, containing
containing demangled names.
passing them on the command line:
names from the standard input instead.  All the results are printed on
the standard output.  The difference between reading names from the
command line versus reading names from the standard input is that
command line arguments are expected to be just mangled names and no
checking is performed to separate them from surrounding text.  Thus
for example:
will not work.  (Note the extra comma at the end of the mangled
name which makes it invalid).  This command however will work:
trailing comma.  This behaviour is because when the names are read
from the standard input it is expected that they might be part of an
assembler source file where there might be extra, extraneous
characters trailing after a mangled name.  eg:
syntax.
Do not remove the initial underscore.
When demangling the name of a function, do not display the types of
the function's parameters.
Attempt to demangle types as well as function names.  This is disabled
by default since mangled types are normally only used internally in
the compiler, and they can be confused with non-mangled names.  eg
Do not include implementation details (if any) in the demangled
output.
different compilers.  The argument to this option selects which
method it uses:
Automatic selection based on executable (the default method)
the one used by the Lucid compiler (lcc)
does not exist, or cannot be read, then the option will be treated
literally, and not removed.  
character may be included in an option by surrounding the entire
option in either single or double quotes.  Any character (including a
backslash) may be included by prefixing the character to be included
Copyright (c) 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,
2000, 2001, 2002, 2003, 2004, 2005, 2006 Free Software Foundation, Inc.
or any later version published by the Free Software Foundation;
with no Invariant Sections, with no Front-Cover Texts, and with no
Back-Cover Texts.  A copy of the license is included in the
The following is the old c2ph.doc documentation by Tom Christiansen
<tchrist@perl.com>
Once upon a time, I wrote a program called pstruct.  It was a perl
program that tried to parse out C structures and display their member
offsets for you.  This was especially useful for people looking at
binary dumps or poking around the kernel.
Pstruct was not a pretty program.  Neither was it particularly robust.
The problem, you see, was that the C compiler was much better at parsing
C than I could ever hope to be.
So I got smart:  I decided to be lazy and let the C compiler parse the C,
which would spit out debugger stabs for me to read.  These were much
easier to parse.  It's still not a pretty program, but at least it's more
robust.
Pstruct takes any .c or .h files, or preferably .s ones, since that's
the format it is going to massage them into anyway, and spits out
listings like this:
etc.
Actually, this was generated by a particular set of options.  You can control
the formatting of each column, whether you prefer wide or fat, hex or decimal,
leading zeroes or whatever.
All you need to be able to use this is a C compiler than generates
should get this for you.
will be provided.  There are a fair number of possibilities.
If you're only a C programmer, than this is the end of the message for you.
You can quit right now, and if you care to, save off the source and run it
when you feel like it.  Or not.
But if you're a perl programmer, then for you I have something much more
wondrous than just a structure offset printer.
You see, if you call pstruct by its other incybernation, c2ph, you have a code
generator that translates C code into perl code!  Well, structure and union
declarations at least, but that's quite a bit.
Prior to this point, anyone programming in perl who wanted to interact
with C programs, like the kernel, was forced to guess the layouts of
the C structures, and then hardwire these into his program.  Of course,
when you took your wonderfully crafted program to a system where the
sgtty structure was laid out differently, your program broke.  Which is
a shame.
We've had Larry's h2ph translator, which helped, but that only works on
cpp symbols, not real C, which was also very much needed.  What I offer
you is a symbolic way of getting at all the C structures.  I've couched
them in terms of packages and functions.  Consider the following program:
As you see, the name of the package is the name of the structure.  Regular
fields are just their own names.  Plus the following accessor functions are
provided for your convenience:
The way I see this being used is like basically this:
It's a little tricker with c2ph because you have to get the includes right.
I can't know this for your system, but it's not usually too terribly difficult.
been less cavalier in how the parts of the program communicated with each
other, etc.  It might also have helped if I didn't have to divine the makeup
of the stabs on the fly, and then account for micro differences between my
compiler and gcc.
Anyway, here it is.  Should run on perl v4 or greater.  Maybe less.
The following is the old c2ph.doc documentation by Tom Christiansen
<tchrist@perl.com>
Once upon a time, I wrote a program called pstruct.  It was a perl
program that tried to parse out C structures and display their member
offsets for you.  This was especially useful for people looking at
binary dumps or poking around the kernel.
Pstruct was not a pretty program.  Neither was it particularly robust.
The problem, you see, was that the C compiler was much better at parsing
C than I could ever hope to be.
So I got smart:  I decided to be lazy and let the C compiler parse the C,
which would spit out debugger stabs for me to read.  These were much
easier to parse.  It's still not a pretty program, but at least it's more
robust.
Pstruct takes any .c or .h files, or preferably .s ones, since that's
the format it is going to massage them into anyway, and spits out
listings like this:
etc.
Actually, this was generated by a particular set of options.  You can control
the formatting of each column, whether you prefer wide or fat, hex or decimal,
leading zeroes or whatever.
All you need to be able to use this is a C compiler than generates
should get this for you.
will be provided.  There are a fair number of possibilities.
If you're only a C programmer, than this is the end of the message for you.
You can quit right now, and if you care to, save off the source and run it
when you feel like it.  Or not.
But if you're a perl programmer, then for you I have something much more
wondrous than just a structure offset printer.
You see, if you call pstruct by its other incybernation, c2ph, you have a code
generator that translates C code into perl code!  Well, structure and union
declarations at least, but that's quite a bit.
Prior to this point, anyone programming in perl who wanted to interact
with C programs, like the kernel, was forced to guess the layouts of
the C structures, and then hardwire these into his program.  Of course,
when you took your wonderfully crafted program to a system where the
sgtty structure was laid out differently, your program broke.  Which is
a shame.
We've had Larry's h2ph translator, which helped, but that only works on
cpp symbols, not real C, which was also very much needed.  What I offer
you is a symbolic way of getting at all the C structures.  I've couched
them in terms of packages and functions.  Consider the following program:
As you see, the name of the package is the name of the structure.  Regular
fields are just their own names.  Plus the following accessor functions are
provided for your convenience:
The way I see this being used is like basically this:
It's a little tricker with c2ph because you have to get the includes right.
I can't know this for your system, but it's not usually too terribly difficult.
been less cavalier in how the parts of the program communicated with each
other, etc.  It might also have helped if I didn't have to divine the makeup
of the stabs on the fly, and then account for micro differences between my
compiler and gcc.
Anyway, here it is.  Should run on perl v4 or greater.  Maybe less.
The following is the old c2ph.doc documentation by Tom Christiansen
<tchrist@perl.com>
Once upon a time, I wrote a program called pstruct.  It was a perl
program that tried to parse out C structures and display their member
offsets for you.  This was especially useful for people looking at
binary dumps or poking around the kernel.
Pstruct was not a pretty program.  Neither was it particularly robust.
The problem, you see, was that the C compiler was much better at parsing
C than I could ever hope to be.
So I got smart:  I decided to be lazy and let the C compiler parse the C,
which would spit out debugger stabs for me to read.  These were much
easier to parse.  It's still not a pretty program, but at least it's more
robust.
Pstruct takes any .c or .h files, or preferably .s ones, since that's
the format it is going to massage them into anyway, and spits out
listings like this:
etc.
Actually, this was generated by a particular set of options.  You can control
the formatting of each column, whether you prefer wide or fat, hex or decimal,
leading zeroes or whatever.
All you need to be able to use this is a C compiler than generates
should get this for you.
will be provided.  There are a fair number of possibilities.
If you're only a C programmer, than this is the end of the message for you.
You can quit right now, and if you care to, save off the source and run it
when you feel like it.  Or not.
But if you're a perl programmer, then for you I have something much more
wondrous than just a structure offset printer.
You see, if you call pstruct by its other incybernation, c2ph, you have a code
generator that translates C code into perl code!  Well, structure and union
declarations at least, but that's quite a bit.
Prior to this point, anyone programming in perl who wanted to interact
with C programs, like the kernel, was forced to guess the layouts of
the C structures, and then hardwire these into his program.  Of course,
when you took your wonderfully crafted program to a system where the
sgtty structure was laid out differently, your program broke.  Which is
a shame.
We've had Larry's h2ph translator, which helped, but that only works on
cpp symbols, not real C, which was also very much needed.  What I offer
you is a symbolic way of getting at all the C structures.  I've couched
them in terms of packages and functions.  Consider the following program:
As you see, the name of the package is the name of the structure.  Regular
fields are just their own names.  Plus the following accessor functions are
provided for your convenience:
The way I see this being used is like basically this:
It's a little tricker with c2ph because you have to get the includes right.
I can't know this for your system, but it's not usually too terribly difficult.
been less cavalier in how the parts of the program communicated with each
other, etc.  It might also have helped if I didn't have to divine the makeup
of the stabs on the fly, and then account for micro differences between my
compiler and gcc.
Anyway, here it is.  Should run on perl v4 or greater.  Maybe less.
The
utility displays a simple calendar in traditional format and
offers an alternative layout, more options and the date of easter.
The new format is a little cramped but it makes a year fit
on a 25x80 terminal.
If arguments are not specified,
the current month is displayed.
The options are as follows:
Display Julian Calendar, if combined with the
option, display date of easter according to the Julian Calendar.
Display date of easter (for western churches).
Display Julian days (days one-based, numbered from January 1).
Display the specified
Display date of orthodox easter (Greek and Russian
Orthodox Churches).
Print the country codes and switching days from Julian to Gregorian
Calendar as they are assumed by
The country code as determined from the local environment is marked
with an asterisk.
Assume the switch from Julian to Gregorian Calendar at the date
associated with the
If not specified,
tries to guess the switch date from the local environment or
falls back to September 2, 1752.
This was when Great
Britain and her colonies switched to the Gregorian Calendar.
Print the number of the week below each week column.
Display a calendar for the specified year.
A single parameter specifies the year (1 - 9999) to be displayed;
note the year must be fully specified:
will
display a calendar for 1989.
Two parameters denote the month and year; the month is either a number between
1 and 12, or a full or abbreviated name as specified by the current locale.
Month and year default to those of the current system clock and time zone (so
will display a calendar for the month of August in the current year).
A year starts on Jan 1.
A
command appeared in
The
command appeared in
The
command and manual were written by
country codes is historically naive for many countries.
The
utility checks the current directory for a file named
and displays lines that begin with either today's date
or tomorrow's.
On the day before a weekend (normally Friday), events for the next
three days are displayed.
The following options are available:
Print lines from today and the next
days (forward, future).
Process the ``calendar'' files of all users and mail the results
to them.
This requires super-user privileges.
Print lines from today and the previous
days (backward, past).
Specify which day of the week is ``Friday'' (the day before the
weekend begins).
Default is 5.
Use
as the default calendar file.
For test purposes only: set date directly to argument values.
Print lines from today and the next
days (forward, future).
Ignore weekends when calculating the number of days.
To handle calendars in your national code table you can specify
in the calendar file as early as possible.
To handle national Easter
names in the calendars
(for Catholic Easter) or
(for Orthodox Easter) can be used.
Other lines should begin with a month and day.
They may be entered in almost any format, either numeric or as character
strings.
If the proper locale is set, national month and weekday
names can be used.
A single asterisk (``*'') matches every month.
A day without a month matches that day of every week.
A month without a day matches the first of that month.
Two numbers default to the month followed by the day.
Lines with leading tabs default to the last entered date, allowing
multiple line specifications for a single date.
``Easter'', is Easter for this year, and may be followed by a positive
or negative integer.
``Paskha'', is Orthodox Easter for this year, and may be followed by a
positive or negative integer.
last, first, second, third, fourth) for moving events like
``the last Monday in April''.
By convention, dates followed by an asterisk are not fixed, i.e., change
from year to year.
Day descriptions start after the first <tab> character in the line;
if the line does not contain a <tab> character, it is not displayed.
If the first character in the line is a <tab> character, it is treated as
a continuation of the previous line.
The ``calendar'' file is preprocessed by
allowing the inclusion of shared files such as lists of company holidays or
meetings.
If the shared file is not referenced by a full pathname,
searches in the current (or home) directory first, and then in the
directory
Empty lines and lines protected by the C commenting syntax
are ignored.
Some possible calendar entries (<tab> characters highlighted by
LANG=C
Easter=Ostern

#include <calendar.usholiday>
#include <calendar.birthday>



file in current directory
HOME directory.
A chdir is done into this directory if it exists.
calendar file to use if no calendar file exists in the current directory.
do not send mail if this file exists.
The following default calendar files are provided:
File which includes all the default files.
Calendar of events in Australia.
Births and deaths of famous (and not-so-famous) people.
Christian holidays.
This calendar should be updated yearly by the local system administrator
so that roving holidays are set correctly for the current year.
Days of special significance to computer people.
Calendar of events in Croatia.
Birthdays of
committers.
Calendar of events in France.
Calendar of events in Germany.
Other holidays, including the not-well-known, obscure, and
obscure.
Jewish holidays.
This calendar should be updated yearly by the local system administrator
so that roving holidays are set correctly for the current year.
Musical events, births, and deaths.
Strongly oriented toward rock 'n' roll.
Calendar of events in New Zealand.
Russian calendar.
Calendar of events in South Africa.
This calendar should be updated yearly by the local system administrator
so that roving holidays are set correctly for the current year.
Includes all calendar files except for national files.
The
program previously selected lines which had the correct date anywhere
in the line.
This is no longer true, the date is only recognized when it occurs
at the beginning of a line.
A
command appeared in
The
utility does not handle Jewish holidays and moon phases.
builds a hashed database out of the
logical database constructed by the concatenation of the specified
files .
The database is named by the basename of the first file argument and
the string
The
routines can access the database in this form much more quickly
than they can the original text file(s).
The ``tc'' capabilities of the records are expanded before the
record is stored into the database.
The options as as follows:
Specify a different database basename.
Print out the number of capability records in the database.
Each record is stored in the database using two different types of keys.
The first type is a key which consists of the first capability of
the record (not including the trailing colon (``:'')) with a data
field consisting of a special byte followed by the rest of the record.
The special byte is either a 0 or 1, where a 0 means that the record
is okay, and a 1 means that there was a ``tc'' capability in the record
that couldn't be expanded.
The second type is a key which consists of one of the names from the
first capability of the record with a data field consisting a special
byte followed by the the first capability of the record.
The special byte is a 2.
In normal operation names are looked up in the database, resulting
pair of the first type which has the real data associated with the
name.
The
utility exits 0 on success and >0 if an error occurs.
The
utility reads files sequentially, writing them to the standard output.
The
operands are processed in command-line order.
If
is a single dash
or absent,
reads from the standard input.
If
is a
domain socket,
connects to it and then reads it until
This complements the
domain binding capability available in
The options are as follows:
Number the non-blank output lines, starting at 1.
Display non-printing characters (see the
option), and display a dollar sign
at the end of each line.
Number the output lines, starting at 1.
Squeeze multiple adjacent empty lines, causing the output to be
single spaced.
Display non-printing characters (see the
option), and display tab characters as
Disable output buffering.
Display non-printing characters so they are visible.
Control characters print as
for control-X; the delete
character (octal 0177) prints as
characters (with the high bit set) are printed as
(for meta) followed by the character for the low 7 bits.
The command:
will print the contents of
to the standard output.
The command:
will sequentially print the contents of
and
to the file
truncating
if it already exists.
See the manual page for your shell (i.e.,
for more information on redirection.
The command:
will print the contents of
print data it receives from the standard input until it receives an
character, print the contents of
read and output contents of the standard input again, then finally output
the contents of
Note that if the standard input referred to a file, the second dash
on the command-line would have no effect, since the entire contents of the file
would have already been read and printed by
when it encountered the first
operand.
The
utility is compliant with the
specification.
The flags
are extensions to the specification.
A
utility appeared in
designed and wrote the first man page.
It appears to have been
Because of the shell language mechanism used to perform output
redirection, the command
will cause the original data in file1 to be destroyed!
The
utility does not recognize multibyte characters when the
or
option is in effect.
Use the .Nm macro to refer to your program throughout the man page like such:
Underlining is accomplished with the .Ar macro like this:
A list of items with descriptions:
Description of item a
Description of item b
A list of flags and their descriptions:
Description of -a flag
Description of -b flag
FILE_1 description
FILE_2 description
Use the .Nm macro to refer to your program throughout the man page like such:
Underlining is accomplished with the .Ar macro like this:
A list of items with descriptions:
Description of item a
Description of item b
A list of flags and their descriptions:
Description of -a flag
Description of -b flag
FILE_1 description
FILE_2 description
Use the .Nm macro to refer to your program throughout the man page like such:
Underlining is accomplished with the .Ar macro like this:
A list of items with descriptions:
Description of item a
Description of item b
A list of flags and their descriptions:
Description of -a flag
Description of -b flag
FILE_1 description
FILE_2 description
Use the .Nm macro to refer to your program throughout the man page like such:
Underlining is accomplished with the .Ar macro like this:
A list of items with descriptions:
Description of item a
Description of item b
A list of flags and their descriptions:
Description of -a flag
Description of -b flag
FILE_1 description
FILE_2 description

use with Keychains
command [command-args] [options]
c [options]
r outFileName [options]
v infileName [options]
C domainName [options]
i inFileName [options]
d inFileName [options]
I inFileName [options]
D inFileName [options]
y [options]
Create keypair and Certificate
Create CSR
Verify CSR
Create a System Identity
Import Certificate
Display Certificate
Import CRL
Display CRL
Import a CRL
Display all certs and CRLs in keychain
Create the keychain, if one is needed.
Create a CSR in DER format; default is PEM
Specify the keychain passphrase when creating
Optional private key, for Import Certificate only
Extended Key Usage: a=Any; s=SSL Client; S=SSL Server; m=SMIME
Generate private key with default ACL
Generate private key with ACL limiting access to current user
Don't create System Identity if one already exists for specified domain
Print usage message
Execute in verbose mode.
is a UNIX command-line program which is used to create key pairs, certificates,
and certificate signing requests; to import externally generated certificates
and Certificate Revocation Lists (CRLs) into a Keychain, and to display the 
contents of certificates and CRLs. 
This command generates a key pair and a self-signed (root) certificate
and places them in a keychain. The root cert is signed by the private
key generated during this command. The cert generated by this command 
is totally untrustworthy and cannot be used in the "real world"; the 
primary use of this command is to facilitate early development of SSL 
server applications based on SecureTransport. In particular, 
"real world" SSL clients (e.g., web browsers) will complain to
varying degrees when they attempt to connect to an SSL server which
presents a cert which is generated by this command. Some broswers,
after a fair amount of handholding, will allow you to conditionally
"trust" this cert. 
# CertTool c [options]
The available options are:
k=keyChainName 
Where "keyChainName" is the name of the keychain into which keys and the cert
will be added. The specified keychain must exist. If it doesn't exist and
you want the keychain created for you, specify the 'c' option. If no keychain
is specified, keys and certs are added to the default keychain. 
c 
Specifies that the designated keychain is to be created.
x=[aSsm]
a
Results the the private key being created with a default ACL. If not specified, the private key is created with no ACL. 
u
Create the private key with an ACL limiting access to the current user. 
This is an interactive command; you will be prompted for a number of different
items which are used to generate the keypair and the cert. A sample session
follows. 
# CertTool k=certkc 
Enter key and certificate label: testCert 

Please specify parameters for the key pair you will generate. 

	r RSA 
	d DSA 
	f FEE 

Select key algorithm by letter: r 

Valid key sizes for RSA are 512..2048; default is 512 
Enter key size in bits or CR for default: 512 

You have selected algorithm RSA, key size 512 bits. 
 ...Generating key pair... 

Note: you will be prompted for the Keychain's passphrase by the Keychain
system at this point if the specified keychain is not open and you have not specified the passphrase via the 'p' option. 
Please specify the algorithm with which your certificate will be signed. 

	5 RSA with MD5 
	s RSA with SHA1 

Select signature algorithm by letter: s 

You have selected algorithm RSA with SHA1. 
You will now specify the various components of the certificate's 
Relative Distinguished Name (RDN). An RDN has a number of 
components, all of which are optional, but at least one of 
which must be present. 
Note that if you are creating a certificate for use in an 
exactly the host name of the server. This must not be an IP 
address, but the actual domain name, e.g. www.apple.com. 
Entering a CR for a given RDN component results in no value for 
that component. 
Common Name       (e.g. www.apple.com) : 10.0.61.5
Country           (e.g. US) : 
Organization      (e.g. Apple Computer, Inc.) : Apple 
Organization Unit (e.g. Apple Data Security) : 
Email Address     (e.g. johngalt@rand.com) : 
You have specified: 
 Common Name	: 10.0.61.5 
 Organization	: Apple 
#
The "Common Name" portion of the RDN - in the above case, "10.0.61.5" - MUST
the test machine doesn't have an actual hostname; it's DHCP'd behind a firewall
which is why "10.0.61.5" was specified for Common Name.) This is part of SSL's
certificate verification; it prevents an attack using DNS spoofing. 
is that the server cert specified in SSLSetCertificate() is capable of both
signing and encryption. If this cert is only capable of signing, you must
create a second keychain containing a cert which is capable of encryption, and
pass that to SSLSetEncryptionCertificate(). 
A CSR is the standard means by which an administrator of a web server provides
information to a Certificate Authority (CA) in order to obtain a valid
certificate which is signed by the CA. This type of cert is used in the real
world; certs signed by CAs such as Verisign and Thawte are recognized by most web
browsers when performing SSL transactions. 
The general procedure for obtaining a "real" cert is: 
Generate a key pair
Generate a CSR
CA sends you a certificate which is signed by the CA.
You import that certificate, obtained from the CA, into your keychain.
The
items in that keychain can now be used in SecureTransport's SSLSetCertificate()
call.
This command performs the first two steps in the above procedure. See the 
section below entitled "Importing a Certificate" for information on 
importing the resulting certificate into your keychain. The format of 
this command is 
# CertTool r outFileName [options] 
The resulting CSR will be written to "outFileName". 
The available options are: 
k=keyChainName 
Where "KeyChainName" is the name of the keychain into which keys and the cert
will be added. If no keychain is specified, keys and certs are added to the
default keychain. The specified keychain must exist unless you specify the 'c'
option.
 d 
The 'd' option tells CertTool to create the CSR in DER-encoded format. The
default is PEM-encoded, which is what most CAs expect. PEM encoded data consists
of printable ASCII text which can, for example, be pasted into an email message.
DER-encoded data is nonprintable binary data.
 c 
Specifies that the designated keychain is to be created.
a
Results the the private key being created with a default ACL. If not specified, the private key is created with no ACL. 
u
Create the private key with an ACL limiting access to the current user. 
This is an interactive command; you will be prompted for a number of different
items which are used to generate the keypair and the CSR. The prompts given, and
the format of the data you must supply, are identical to the data shown in the
sample session in Section 2. 
A CSR contains, among other things, the public key which was generated in
as described above. The CSR is signed with the associated private key. Thus the
integrity of a CSR can be verified by extracting its public key and verifying the signature of the CSR. This command performs this integrity check. The format of this command is 
# CertTool v inFileName [options] 
The only available option is the 'd' flag, which as described above in the
section entitled "Generating a Certificate Signing Request", indiciates 
that the CSR is in DER format rather than the default PEM format. 
A typical (successful) run of this command is like so: 
# CertTool v myCsr.pem 
 ...CSR verified successfully. 
A large number of things can go wrong if the verification fails; suffice it to
say that if you see anything other than the above success message, you have a
bad or corrupted CSR. 
This creates a key pair and a self-signed (root) certificate in the System keychain, and registers the result in the System Identity database as being the IDentity associated with the specified domain name. The domain name is typically a string of the form "com.apple.somedomain...". You must be running as root to execute this command. 
The format of this command is 
# CertTool C domainName [options] 
The available options are:
u
Create the private key with an ACL limiting access to the current user. If not specified, the private key wil be created with a default ACL. 
P
Don't create system identity if one already exists for specified domain.
Once you have negotiated with your CA, and provided them with the CSR generated
as described above as well as any other information, documentation, and payment they
require, the CA will provide you with a certificate. Use this command to add
that certificate to the keychain containing the keypair you generated previously.
The format of this command is 
# CertTool i inFileName [options] 
The cert to import is obtained from "inFileName". The available options are: 
k=keyChainName 
Where "keyChainName" is the name of the keychain to which the cert will be
added. If no keychain is specified, the cert is added to the default keychain.
The specified keychain typically contains the keypair you generated previously.
(Note you can import a certificate into a keychain which does not contain keys
you generated but there will be no linkage between the imported certificate and
a private key if you do this.) If the keychain is not open when this command is
executed, you will be prompted by the Keychain system for its passphrase.
r=privateKeyFileName
f=privateKeyFormat
Where "privateKeyFormat" is the format of the private key specified with the 'r' option. The formats are: '1' for PKCS1 (OpenSSL format), '8' (PKCS8), and 'f' (FIPS186, BSAFE format). The default is OpenSSL format for both RSA and DSA keys.   
 d 
Specifies DER format as described above. The default is PEM format.
 c 
Specifies that the designated keychain is to be created.
This displays the contents of an existing certificate, obtained from a file. 
The format of this command is 
# CertTool d inFileName [options] 
The cert to display is obtained from "inFileName". 
The only available option is the 'd' flag, specifying DER format as described above. The default is PEM format. Actually, in the absence of this option, certtool will correctly determine the format of the certificate (PEM or DER). 
This command is used to add a Certificate Revocation List (CRL) to a keychain. 
The format of this command is 
# CertTool I inFileName [options] 
The CRL to import is obtained from "inFileName".  The available options are: 
k=keyChainName 
Where "KeyChainName" is the name of the keychain to which the CRL will be added.
If no keychain is specified, the cert is added to the default keychain.  If the
keychain is not open when this command is executed, you will be prompted by the
Keychain system for its passphrase.
 d 
Specifies DER format as described above. The default is PEM format.
 c 
Specifies that the designated keychain is to be created.
This displays the contents of an existing Certificate Revocation List (CRL),
obtained from a file. The format of this command is 
# CertTool D inFileName [options] 
The cert to display is obtained from "inFileName". 
The only available option is the 'd' flag, specifying DER format as described
above. The default is PEM format.
This displays the contents of all certificates and CRLs in a keychain. The format of this command is 
# CertTool y [options] 
The available options are: 
k=keyChainName 
Where "KeyChainName" is the name of the keychain to display.
v
Specifies verbose mode.
As mentioned above, the general procedure for obtaining a "real" cert is: 
Generate a key pair
Generate a CSR
CA sends you a certificate which is signed by the CA.
You import that certificate, obtained from the CA, into your keychain.
The items in that keychain can now be used in SecureTranspoert's SSLSetCertificate()
call.
One CA with an excellent web-based interface for obtaining a cert is Verisign
trial certificate using nothing but CertTool, Verisign's web site, and email.
You need to provide some personal information. Paste the CSR
generated as described in the section entitled "Generating a Certificate 
Signing Request" into a form on the web site. A few minutes later Verisign
emails you a certificate, which you import into your keychain.
The whole process takes less than 10 minutes. The free certificate obtained in
this manner is signed by a temporary root cert which is not recognized by any
browsers, but Verisign also provides a means of installing this temporary root
cert into your browser, directly from their web site. Typically one would use
the free, temporary cert to perform initial configuration of a server and to
ring out the general SSL infrastructure. Once you feel comfortable with the
operation of the server, then it's time to buy a "real" certificate which will
allow your web server to be trusted by any browser. 
System root certificate database
System Keychain
Use
to exercise the content filter subsystem.
The flags have the following meaning:
Auto start filtering with given offset.
Default values for offset passin, peekin, passout, peekout, pass or peek.
Display this help.
Interactive mode.
Peek mode with increment.
Pass loopback traffic.
Maximum dump length.
Pass mode (all or after given offset if it is > 0).
Decrease verbosity.
Random drop rate.
display content filter statistics (all, sock, filt, cfil).
Pass delay in microseconds.
NECP filter control unit.
Increase verbosity.
checks the integrity of a LocalKDC and its principals.
The script is non-destructive and can be run multiple times.
does not own, but references the following files:
first appeared in version 10.7 of Mac OS X.
The
utility checks a list of
or
input files for certain kinds of errors
involving mismatched opening and closing delimiters
and unknown commands.
If no files are specified,
checks the standard input.
The following options are available:
Add additional pairs of macros to the list of known macros.
This must be followed by groups of six characters, each group defining
a pair of macros.
The six characters are
a period,
the first macro name,
another period,
and the second macro name.
For example, to define a pair .BS and .ES, use
Define commands which would otherwise be complained about
as undefined.
Request
to ignore
font changes.
Ignore
size changes.
Delimiters checked are:
the .TS and .TE macros which must always come in pairs.
The
utility is intended for use on documents that are prepared with
in mind, much the same as
It expects a certain document writing style for
and
commands,
in that each
must be terminated with
and
each
must be terminated with
While it will work to directly go into the next font or explicitly
specify the original font or point size,
and many existing documents actually do this,
such a practice will produce complaints from
Since it is probably better to use the
and
forms anyway,
you should think of this as a contribution to your document
preparation style.
The
utility knows about the
and
macro packages.
Complaints about unmatched delimiters.
Complaints about unrecognized commands.
Various complaints about the syntax of commands.
There is no way to define a 1 character macro name using
Does not correctly recognize certain reasonable constructs,
such as conditionals.
The
command appeared in
The
utility modifies the file flags of the listed files
as specified by the
operand.
The options are as follows:
Do not display a diagnostic message if
could not modify the flags for
nor modify the exit status to reflect such failures.
If the
option is specified, symbolic links on the command line are followed.
(Symbolic links encountered in the tree traversal are not followed.)
If the
is a symbolic link,
change the file flags of the link itself rather than the file to which it points.
If the
option is specified, all symbolic links are followed.
If the
option is specified, no symbolic links are followed.
This is the default.
Change the file flags for the file hierarchies rooted
in the files instead of just the files themselves.
Cause
to be verbose, showing filenames as the flags are modified.
If the
option is specified more than once, the old and new flags of the file
will also be printed, in octal notation.
The flags are specified as an octal number or a comma separated list
of keywords.
The following keywords are currently defined:
set the archived flag (super-user only)
set the opaque flag (owner or super-user only).
[Directory is opaque when viewed through a union mount]
set the nodump flag (owner or super-user only)
set the system append-only flag (super-user only)
set the system immutable flag (super-user only)
set the user append-only flag (owner or super-user only)
set the user immutable flag (owner or super-user only)
set the hidden flag
[Hide item from GUI]
As discussed in
the
and
flags may only be unset when the system is in single-user mode.
Putting the letters
before or removing the letters
from a keyword causes the flag to be cleared.
For example:
clear the user immutable flag (owner or super-user only)
clear the nodump flag (owner or super-user only)
Unless the
or
options are given,
on a symbolic link always succeeds and has no effect.
The
and
options are ignored unless the
option is specified.
In addition, these options override each other and the
command's actions are determined by the last one specified.
You can use "ls -lO" to see the flags of existing files.
The
command first appeared in
Only a limited number of utilities are
aware.
Some of these tools include
and
In particular a tool which is not currently
aware is the
utility.
The
utility sets the group ID of the file named by each
operand to the
ID specified by the group operand.
The following options are available:
The force option ignores errors, except for usage errors and doesn't
query about strange modes (unless the user does not have proper permissions).
If the
option is specified, symbolic links on the command line are followed.
(Symbolic links encountered in the tree traversal are not followed).
If the file is a symbolic link, the group ID of the link itself is changed
rather than the file that is pointed to.
If the
option is specified, all symbolic links are followed.
If the
option is specified, no symbolic links are followed.
This is the default. Use
to change the group ID of a symbolic link.
Change the group ID for the file hierarchies rooted
in the files instead of just the files themselves.
Cause
to be verbose, showing files as the group is modified.
The
and
options are ignored unless the
option is specified.
In addition, these options override each other and the
command's actions are determined by the last one specified.
The
operand can be either a group name from the group database,
or a numeric group ID.
If a group name is also a numeric group ID, the operand is used as a
group name.
The user invoking
must belong to the specified group and be the owner of the file,
or be the super-user.
In previous versions of this system, symbolic links did not have groups.
The
option is non-standard and its use in scripts is not recommended.
group ID file
The
utility is expected to be
compatible.
The
utility modifies the file mode bits of the listed files
as specified by the
operand. It may also be used to modify the Access Control
Lists (ACLs) associated with the listed files.
The generic options are as follows:
Do not display a diagnostic message if
could not modify the mode for
If the
option is specified, symbolic links on the command line are followed.
(Symbolic links encountered in the tree traversal are not followed by
default.)
If the file is a symbolic link, change the mode of the link itself
rather than the file that the link points to.
If the
option is specified, all symbolic links are followed.
If the
option is specified, no symbolic links are followed.
This is the default.
Change the modes of the file hierarchies rooted in the files
instead of just the files themselves.
Cause
to be verbose, showing filenames as the mode is modified.
If the
flag is specified more than once, the old and new modes of the file
will also be printed, in both octal and symbolic notation.
The
and
options are ignored unless the
option is specified.
In addition, these options override each other and the
command's actions are determined by the last one specified.
Only the owner of a file or the super-user is permitted to change
the mode of a file.
Modes may be absolute or symbolic.
An absolute mode is an octal number constructed from the sum of
one or more of the following values:
(the set-user-ID-on-execution bit) Executable files with this bit set
will run with effective uid set to the uid of the file owner.
Directories with the set-user-id bit set will force all files and
sub-directories created in them to be owned by the directory owner
and not by the uid of the creating process, if the underlying file
system supports this feature: see
and the
option to
(the set-group-ID-on-execution bit) Executable files with this bit set
will run with effective gid set to the gid of the file owner.
(the sticky bit)
See
and
Allow read by owner.
Allow write by owner.
For files, allow execution by owner.
For directories, allow the owner to
search in the directory.
Allow read by group members.
Allow write by group members.
For files, allow execution by group members.
For directories, allow
group members to search in the directory.
Allow read by others.
Allow write by others.
For files, allow execution by others.
For directories allow others to
search in the directory.
For example, the absolute mode that permits read, write and execute by
the owner, read and execute by group members, read and execute by
others, and no set-uid or set-gid behaviour is 755
(400+200+100+040+010+004+001).
The symbolic mode is described by the following grammar:
mode         ::= clause [, clause ...]
clause       ::= [who ...] [action ...] action
action       ::= op [perm ...]
who          ::= a | u | g | o
perm         ::= r | s | t | w | x | X | u | g | o
The
symbols ``u'', ``g'', and ``o'' specify the user, group, and other parts
of the mode bits, respectively.
The
symbol ``a'' is equivalent to ``ugo''.
The
symbols represent the portions of the mode bits as follows:
The read bits.
The set-user-ID-on-execution and set-group-ID-on-execution bits.
The sticky bit.
The write bits.
Operations with the
symbol ``X'' are only meaningful in conjunction with the
symbol ``+'', and are ignored in all other cases.
The user permission bits in the original mode of the file.
The group permission bits in the original mode of the file.
The other permission bits in the original mode of the file.
The
symbols represent the operation performed, as follows:
If no value is supplied for
the ``+'' operation has no effect.
If no value is supplied for
each permission bit specified in
for which the corresponding bit in the file mode creation mask
is clear, is set.
Otherwise, the mode bits represented by the specified
and
values are set.
If no value is supplied for
If no value is supplied for
each permission bit specified in
for which the corresponding bit in the file mode creation mask
is clear, is cleared.
Otherwise, the mode bits represented by the specified
and
values are cleared.
The mode bits specified by the
value are cleared, or, if no who value is specified, the owner, group
and other mode bits are cleared.
Then, if no value is supplied for
each permission bit specified in
for which the corresponding bit in the file mode creation mask
is clear, is set.
Otherwise, the mode bits represented by the specified
and
values are set.
Each
specifies one or more operations to be performed on the mode
bits, and each operation is applied to the mode bits in the
order specified.
Operations upon the other permissions only (specified by the symbol
``o'' by itself), in combination with the
symbols ``s'' or ``t'', are ignored.
make a file readable by anyone and writable by the owner only.
deny write permission to group and others.
set the read and write permissions to the usual defaults, but
retain any execute permissions that are currently set.
clear all mode bits for group and others.
set the group bits equal to the user bits, but clear the group write bit.
ACLs are manipulated using extensions to the symbolic mode
grammar.  Each file has one ACL, containing an ordered list of entries.
Each entry refers to a user or group, and grants or denies a set of
permissions.
In cases where a user and a group exist with the same name, the
specify the type of name.
If the user or group name contains spaces you can use ':' as the delimiter
between name and permission.
The following permissions are applicable to all filesystem objects:
Delete the item.  Deletion may be granted by either this permission
on an object or the delete_child right on the containing directory.
Read an objects basic attributes.  This is implicitly granted if 
the object can be looked up and not explicitly denied.
Write an object's basic attributes.
Read extended attributes.
Write extended attributes.
Read an object's extended security information (ACL).
Write an object's security information (ownership, mode, ACL).
Change an object's ownership.
The following permissions are applicable to directories:
List entries.
Look up files by name.
Add a file.
Add a subdirectory.
Delete a contained object.  See the file delete permission above.
The following permissions are applicable to non-directory filesystem objects:
Open for reading.
Open for writing.
Open for writing, but in a fashion that only allows writes into areas of 
the file not previously written.
Execute the file as a script or program.
ACL inheritance is controlled with the following permissions words, which
may only be applied to directories:
Inherit to files.
Inherit to directories.
This flag is only relevant to entries inherited by subdirectories; it
causes the directory_inherit flag to be cleared in the entry that is
inherited, preventing further nested subdirectories from also
inheriting the entry.
The entry is inherited by created items but not considered when processing
the ACL.
The ACL manipulation options are as follows:
The +a mode parses a new ACL entry from the next argument on
the commandline and inserts it into the canonical location in the
ACL. If the supplied entry refers to an identity already listed, the
two entries are combined.
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
 # chmod +a "admin allow write" file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: admin allow write
 # chmod +a "guest deny read" file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: admin allow write
 # chmod +a "admin allow delete" file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: admin allow write,delete
 # chmod +a "User 1:allow:read" file
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: User 1 allow read
   3: admin allow write,delete
The +a mode strives to maintain correct canonical form for the ACL.
                 local deny
                 local allow
                 inherited deny
                 inherited allow
By default, chmod adds entries to the top of the local deny and local
allow lists. Inherited entries are added by using the +ai mode.
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: admin allow write,delete
   3: juser inherited deny delete
   4: admin inherited allow delete
   5: backup inherited deny read
   6: admin inherited allow write-security
 # chmod +ai "others allow read" file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: admin allow write,delete
   3: juser inherited deny delete
   4: others inherited allow read
   5: admin inherited allow delete
   6: backup inherited deny read
   7: admin inherited allow write-security
When a specific ordering is required, the exact location at which an
entry will be inserted is specified with the +a# mode.
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: admin allow write
 # chmod +a# 2 "others deny read" file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: others deny read
   3: admin allow write
The +ai# mode may be used to insert inherited entries at a specific
location. Note that these modes allow non-canonical ACL ordering to
be constructed.
The -a mode is used to delete ACL entries. All entries exactly
matching the supplied entry will be deleted. If the entry lists a
subset of rights granted by an entry, only the rights listed are
removed. Entries may also be deleted by index using the -a# mode.
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: guest deny read
   2: admin allow write,delete
 # chmod -a# 1 file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: admin allow write,delete
 # chmod -a "admin allow write" file1
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: admin allow delete
Inheritance is not considered when processing the -a mode; rights and
entries will be removed regardless of their inherited state.
If the user or group name contains spaces you can use ':' as the delimiter
 # chmod +a "User 1:allow:read" file
Individual entries are rewritten using the =a# mode.
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: admin allow delete
 # chmod =a# 1 "admin allow write,chown"
 # ls -le
 -rw-r--r--+ 1 juser  wheel  0 Apr 28 14:06 file1
   owner: juser
   1: admin allow write,chown
This mode may not be used to add new entries.
Reads the ACL information from stdin, as a sequential list
of ACEs, separated by newlines.  If the information parses correctly,
the existing information is replaced.
Returns false if any of the named files have ACLs in non-canonical order.
Removes the 'inherited' bit from all entries in the named file(s) ACLs.
Removes all inherited entries from the named file(s) ACL(s).
Removes the ACL from the named file(s).
The
option is non-standard and its use in scripts is not recommended.
The
utility is expected to be
compatible with the exception of the
symbol
which is not included in that standard.
A
command appeared in
The
utility
allows editing of the user database information associated
with
or, by default, the current user.
The
utility 
change the user's password on Open Directory
systems.  Use the
utility instead.
The
and
utilities behave identically to
(There is only one program.)
The information is formatted and supplied to an editor for changes.
Only the information that the user is allowed to change is displayed.
The options are as follows:
If not specified,
will perform a search for the user record on all available
Open Directory nodes.
When specified,
will edit the user record on the directory node at the given
The user name to use when authenticating to the directory node containing the
user.
Attempt to change the user's shell to
Possible display items are as follows:
user's login name
user's login
user's login group
user's UUID
user's real name
user's office location
user's office phone
user's home phone
user's home directory
user's login shell
The
field is the user name used to access the computer account.
The
field is the number associated with the
field.
Both of these fields should be unique across the system (and often
across a group of systems) as they control file access.
While it is possible to have multiple entries with identical login names
Routines
that manipulate these files will often return only one of the multiple
entries, and that one by random selection.
The
field is the group that the user will be placed in at login.
Since
supports multiple groups (see
this field currently has little special meaning.
This field may be filled in with either a number or a group name (see
The
field is the globally unique identifier (UUID) for the user.
The
field contains the full name of the user.
The user's
is the full
path name where the user
will be placed at login.
The
field is the command interpreter the user prefers.
If the
field is empty, the Bourne shell,
is assumed.
When altering a login shell, and not the super-user, the user
may not change from a non-standard shell or to a non-standard
shell.
Non-standard is defined as a shell not found in
The
field is the path to a picture to be displayed for the user.
User database entries are under the control of
and may be physically located in many different places,
including the local Directory Service node, 
and remote LDAP servers.
This version of
uses Open Directory to change user database information.
It does not interact with the historic flat file
database
The
editor will be used unless the environment variable
is set to
an alternate editor.
When the editor terminates, the information is re-read and used to
update the user database itself.
Only the user, or the super-user, may edit the information associated
with the user.
temporary copy of the data to edit
the list of approved shells
The
utility appeared in
The
utility writes to the standard output three whitespace separated
fields for each input file.
These fields are a checksum
the total number of octets in the file and the file name.
If no file name is specified, the standard input is used and no file name
is written.
The
utility is identical to the
utility, except that it defaults to using historic algorithm 1, as
described below.
It is provided for compatibility only.
The options are as follows:
Use historic algorithms instead of the (superior) default one.
Algorithm 1 is the algorithm used by historic
systems as the
algorithm and by historic
systems as the
algorithm when using the
option.
This is a 16-bit checksum, with a right rotation before each addition;
overflow is discarded.
Algorithm 2 is the algorithm used by historic
systems as the
default
algorithm.
This is a 32-bit checksum, and is defined as follows:
s = sum of all bytes;
Algorithm 3 is what is commonly called the
algorithm.
This is a 32-bit checksum.
Both algorithm 1 and 2 write to the standard output the same fields as
the default algorithm except that the size of the file in bytes is
replaced with the size of the file in blocks.
For historic reasons, the block size is 1024 for algorithm 1 and 512
for algorithm 2.
Partial blocks are rounded up.
The default
used is based on the polynomial used for
error checking
in the networking standard
The
checksum encoding is defined by the generating polynomial:
G(x) = x^32 + x^26 + x^23 + x^22 + x^16 + x^12 +
     x^11 + x^10 + x^8 + x^7 + x^5 + x^4 + x^2 + x + 1
Mathematically, the
value corresponding to a given file is defined by
the following procedure:
The
bits to be evaluated are considered to be the coefficients of a mod 2
polynomial M(x) of degree
These
bits are the bits from the file, with the most significant bit being the most
significant bit of the first octet of the file and the last bit being the least
significant bit of the last octet, padded with zero bits (if necessary) to
achieve an integral number of octets, followed by one or more octets
representing the length of the file as a binary value, least significant octet
first.
The smallest number of octets capable of representing this integer are used.
M(x) is multiplied by x^32 (i.e., shifted left 32 bits) and divided by
G(x) using mod 2 division, producing a remainder R(x) of degree <= 31.
The coefficients of R(x) are considered to be a 32-bit sequence.
The bit sequence is complemented and the result is the CRC.
The default calculation is identical to that given in pseudo-code
in the following
article.
The
utility is expected to conform to
The
utility appeared in
figure out how to clear the screen.
version 5.7 (patch 20081102).
Compare two files byte by byte.
Print differing bytes.
Skip the first SKIP bytes of input.
Skip the first SKIP1 bytes of FILE1 and the first SKIP2 bytes of FILE2.
Output byte numbers and values of all differing bytes.
Compare at most LIMIT bytes.
Output nothing; yield exit status only.
Output version info.
Output this help.
SKIP1 and SKIP2 are the number of bytes to skip in each file.
SKIP values may be followed by the following multiplicative suffixes:
kB 1000, K 1024, MB 1,000,000, M 1,048,576,
GB 1,000,000,000, G 1,073,741,824, and so on for T, P, E, Z, Y.
If a FILE is `-' or missing, read standard input.
Written by Torbjorn Granlund and David MacKenzie.
Report bugs to <bug-gnu-utils@gnu.org>.
This program comes with NO WARRANTY, to the extent permitted by law.
You may redistribute copies of this program
under the terms of the GNU General Public License.
For more information about these matters, see the file named COPYING.
The full documentation for
is maintained as a Texinfo manual.  If the
and
programs are properly installed at your site, the command
should give you access to the complete manual.
The
command is used to create, check, and display code signatures, as well as
inquire into the dynamic status of signed code in the system.
requires exactly one
option to determine what action is to be performed, as well as any number of
other options to modify its behavior. It can act on any number of objects per invocation,
but performs the same operation on all of them.
accepts single-character (classic) options, as well as GNU-style long
options of the form --name and --name=value. Common options have both
forms; less frequent and specialized options have only long form.
Note that the form --name value (without equal sign) will not work as expected
on options with optional values.
The options are as follows:
When verifying a code signature on code that has a universal ("fat") Mach-O binary,
separately verify each architecture contained. This is the default unless overridden
with the -a (--architecture) option.
When verifying or displaying signatures, explicitly select the Mach-O architecture
given. The
can be specified either by name (e.g. i386) or by number; if by number, a sub-architecture
may be appended separated by a comma.
This option applies only to Mach-O binary code and is ignored for other types.
If the
uses the Mach-O format and contains no code of the given architecture, the command will fail.
The default for verification is --all-architectures, to verify all architectures present.
The default for display is to report on the native architecture of the host system.
When signing,
will always sign all architectures contained in a universal Mach-O file.
When handling versioned bundles such as frameworks, explicitly specify the version
to operate on. This must be one of the names in the "Versions" directory of the bundle.
If not specified,
uses the bundle's default version.
Note that most frameworks delivered with the system have only one version, and thus
this option is irrelevant for them.
There is currently no facility for operating on all versions of a bundle at once.
Display information about the code at the path(s) given. Increasing levels
of verbosity produce more output.
The format is designed to be moderately easy to parse by simple scripts while still
making sense to human eyes.
In addition, the -r, --file-list, --extract-certificates, and --entitlements options can be used to retrieve additional information.
When signing, designates that a detached signature should be written to
the specified file. The code being signed is not modified and need not be
writable.
When verifying, designates a file containing a detached signature to be used
for verification. Any embedded signature in the code is ignored.
When signing a bundle, specifies that nested code content such as helpers, frameworks,
and plug-ins, should be recursively signed in turn. Beware that all signing options you
specify will apply, in turn, to such nested content.
When verifying a bundle, specifies that any nested code content will be recursively
verified as to its full content. By default, verification of nested content is limited
to a shallow investigation that may not detect changes to the nested code.
When displaying a signature, specifies that a list of directly nested code should be
written to the display output. This lists only code directly nested within the subject;
anything nested indirectly will require recursive application of the
command.
When signing, specifies that a detached signature should be generated as with
the --detached option, but that the resulting signature should be written into a system
database, from where it is made automatically available whenever apparently unsigned
code is validated on the system.
Writing to this system database requires elevated process privileges that are
not available to ordinary users.
When signing, causes
to replace any existing signature on the path(s) given. Without this option,
existing signatures will not be replaced, and the signing operation fails.
Constructs and prints the hosting chain of a running program. The
arguments must denote running code (pids etc.) With verbose options, this also
displays the individual dynamic validity status of each element of the hosting chain.
During signing, explicitly specify the unique identifier string that is embedded
in code signatures. If this option is omitted, the identifier is derived from
either the Info.plist (if present), or the filename of the executable being signed,
possibly modified by the --prefix option.
During signing, specifies a set of option flags to be embedded in the code
signature. The value takes the form of a comma-separated list of names (with
no spaces). Alternatively, a numeric value can be used to directly
specify the option mask (CodeDirectory flag word). See OPTION FLAGS below.
Indicates the granularity of code signing. Pagesize must be a power of two.
Chunks of pagesize bytes are separately signed and can thus be independently verified as needed.
As a special case, a pagesize of zero
indicates that the entire code should be signed and verified as a single,
possibly gigantic page. This option only applies to the main executable and has
no effect on the sealing of associated data, including resources.
During signing, indicates that internal requirements should be embedded in the
code path(s) as specified. See "specifying requirements" below.
Defaults will be applied to requirement types that are not explicitly specified;
if you want to defeat such a default, specify "never" for that type.
During display, indicates where to write the code's internal requirements. Use -r-
to write them to standard output.
During verification, indicates that the path(s) given should be verified against
the code requirement specified. If this option is omitted, the code is verified
only for internal integrity and against its own designated requirement.
Sign the code at the path(s) given using this identity. See SIGNING IDENTITIES below.
Sets (with a numeric value) or increments the verbosity level of output. Without
the verbose option, no output is produced upon success, in the classic UNIX style.
If no other options request a different action, the first -v encountered will be
interpreted as --verify instead (and does not increase verbosity).
Requests verification of code signatures.
If other actions (sign, display, etc.) are also requested, -v is interpreted
to mean --verbose.
Instructs
to continue processing path arguments even if processing one fails.
If this option is given, exit due to operational errors is deferred until
all path arguments have been considered. The exit code will then indicate
the most severe failure (or, with equal severity, the first such failure encountered).
During signing, performs almost all signing operations, but does not actually
write the result anywhere. Cryptographic signatures are still generated,
actually using the given signing identity and triggering any access control
checks normally, though the resulting signature is then discarded.
When signing, take the file at the given
and embed its contents in the signature as entitlement data. If the data at
does not already begin with a suitable binary ("blob") header, one is attached automatically.
When displaying a signature, extract any entitlement data from the signature
and write it to the
given. Use "-" to write to standard output.
By default, the binary "blob" header is returned intact; prefix the path with a colon ":"
to automatically strip it off.
If the signature has no entitlement data,
nothing is written (this is not an error).
When displaying a signature, extract the certificates in the embedded certificate chain
and write them to individual files. The
argument is appended with numbers 0, 1, ... to form the filenames, which can be relative
or absolute. Certificate 0 is the leaf (signing) certificate, and as many files are written
as there are certificates in the signature. The files are in ASN.1 (DER) form.
If
is omitted, the default prefix is "codesign" in the current directory.
When signing or displaying a signature,
writes to the given path a list of
files that may have been modified as part of the signing process. This is useful
for installer or patcher programs that need to know what was changed or what files
are needed to make up the "signature" of a program. The file given is appended-to,
with one line per absolute path written. An argument of "-" (single dash) denotes standard
output.
Note that the list may be
somewhat pessimistic - all files not listed are guaranteed to be unchanged by the
signing process, but some of the listed files may not actually have changed.
Also note that changes may have been made to extended attributes of these
files.
During static validation, do not validate the contents of the code's resources.
In effect, this will pass validation on code whose resources have been corrupted
(or inappropriately signed). On large programs, it will also substantially speed
up static validation, since all the resources will not be read into memory.
Obviously, the outcome of such a validation should be considered on its merits.
During signing, only search for the signing identity in the keychain file
specified. This can be used to break any matching ties if you have multiple
similarly-named identities in several keychains on the user's search list.
Note that the standard keychain search path is still consulted while constructing
the certificate chain being embedded in the signature.
Note that
will not be searched to resolve the signing identity's certificate chain unless it
is also on the user's keychain search list.
If no explicit unique identifier is specified (using the -i option), and if
the implicitly generated identifier does not contain any dot (.) characters,
then the given string is prefixed to the identifier before use. If the implicit
identifier contains a dot, it is used as-is. Typically,
this is used to deal with command tools without Info.plists, whose default
identifier is simply the command's filename; the conventional prefix used
is com.domain. (note that the final dot needs to be explicit).
When re-signing code that is already signed, reuse some information from the old signature.
If new data is specified explicitly, it is preferred.
You still need to specify the -f (--force) option to enable overwriting signatures at all.
If this option is absent, any old signature has no effect on the signing process.
This option takes a comma-separated list of names, which you may reasonably abbreviate:
Preserve the signing identifier (--identifier) instead of generating a default identifier.
Preserve the entitlement data (--entitlements).
Preserve the internal requirements (--requirements option), including any explicit Designated
Requirement. Note that all internal requirements are preserved or regenerated as a whole; you
cannot pick and choose individual elements with this option.
For historical reasons, this option can be given without a value, which preserves all
of these values as presently known. This use is deprecated and will eventually be removed;
always specify an explicit list of preserved items.
If this option is given without a value, a default server provided by Apple is used.
Note that this server may not support signatures made with identities not furnished by Apple.
If the timestamp authority service cannot be contacted over the Internet, or it malfunctions
If this option is not given at all, a system-specific default behavior is invoked.
This may result in some but not all code signatures being timestamped.
In the first synopsis form,
attempts to sign the code objects at the
given, using the
provided. Internal
and
are embedded if requested. Internal requirements not specified may be assigned suitable
default values. Defaulting applies separately to each type of internal requirement.
If an
is explicitly given, it is sealed into all
Otherwise, each path derives its
independently from its Info.plist or pathname.
Code nested within bundle directories
option is given, in which case any unsigned nested code will be recursively signed
before proceeding, using the same signing options and parameters. If the
option is given, any existing top-level signature is replaced, subject to any
options also present. Combining the
and
options results in forcible replacement of all signatures within the target bundle.
In the second synopsis form,
verifies the code signatures on all the
given. The verification confirms that the code at those
is signed, that the signature is valid, and that all sealed components are
unaltered. If a
is given, each
is also checked against this requirement (but see DIAGNOSTICS below).
If verbose verification is requested, the program is also checked against its own
designated requirement, which should never fail for a properly signed program.
If a
begins with a decimal digit, it is interpreted as the process id of a running
process in the system, and dynamic validation is performed on that process instead.
This checks the code's dynamic status and just enough static data to close the
nominal security envelope. Add at least one level of verbosity to also perform
a full static check.
In the third synopsis form,
displays the contents of the signatures on the
given. More information is displayed as the verbosity level increases.
This form may not completely verify the signatures
on the
though it may perform some verification steps in the process of obtaining information
about the
If the
option is given, internal requirements will be extracted from the
and written to
specify a dash "-" to write to standard output. If the code does not contain
an explicit designated requirement, the implied one will be retrieved and written
out as a source comment.
If the
option is given, embedded entitlement data will be extracted likewise and written to
the file specified.
In the fourth synopsis form,
constructs the hosting path for each
given and writes it, one host per line, to standard output. The hosting path is the
chain of code signing hosts starting with the most specific code known to be running,
and ending with the root of trust (the kernel). If the
option is given, the dynamic validity status of each host is also displayed, separated
from the path by a tab character.
Note that hosting chains can at times be constructed for invalid or even unsigned code,
and the output of this form of the
command should not be taken as a statement of formal code validity. Only
can do that; and in fact, formal verification constructs the hosting chain as part of
its operation (but does not display it).
To be used for code signing, a digital identity must be stored in a keychain that
is on the calling user's keychain search list.
All keychain sources are supported if properly configured. In particular, it is
possible to sign code with an identity stored on a supported smart card.
If your signing identity is stored in a different form, you need to make it available
in keychain form to sign code with it.
If the
argument is used,
is only looked-for in the
specific keychain given. This is meant to help disambiguate references to identities.
Even in that case, the full keychain search list is still
consulted for additional certificates needed to complete the signature.
The
If such a preference exists, it directly names the identity used.
Otherwise, the identity is located by searching
string given. If there are multiple matches, the operation fails and no signing
is performed; however, an exact match is preferred over a partial match.
These comparisons are case sensitive.
Multiple instances of the exactly same certificate in multiple keychains are tolerated
as harmless.
If
consists of exactly forty hexadecimal digits, it is instead
interpreted as the SHA-1 hash of the certificate part of the desired identity.
In this case, the identity's subject name is not considered.
a particular signing identity regardless of name. Identity preferences are global
are very explicit and local. These choices, combined with what is placed into Xcode
designation of signing identities.
If
Ad-hoc signing does not use an identity at all, and identifies exactly one instance
of code. Significant restrictions apply to the use of ad-hoc signed code; consult
documentation before using this.
will attempt to embed the entire certificate chain documenting the signing identity
in the code signature it generates, including any intermediate certificates and
the anchor certificate. It looks for those in the keychain search list of the user
performing the signing operation. If it cannot generate the entire certificate chain,
signing may still succeed, but verification may fail if the verifying code does not
The
arguments (-r and -R) can be given in various forms. A plain text argument is taken
to be a path to a file containing the requirement(s).
will accept both binary files containing properly compiled requirements code, and source files
that are automatically compiled before use.
An argument of "-" requests that the requirement(s) are read from standard input.
Finally, an argument that begins with an equal sign "=" is taken as a literal
requirements source text, and is compiled accordingly for use.
When signing, a set of option flags can be specified to change the behavior
of the system when using the signed code. The following flags are recognized
by
other flags may exist at the API level. Note that you can specify any valid
flags by giving a (single) numeric value instead of a list of option names.
Forces the signed code's kill flag to be set when the code begins execution.
Code with the kill flag set will die when it becomes dynamically invalid. It is
therefore safe to assume that code marked this way, once validated, will have continue
to have a valid identity while alive.
Forces the signed code's hard flag to be set when the code begins execution.
The hard flag is a hint to the system that the code prefers to be denied
access to resources if gaining such access would invalidate its identity.
Marks the code as capable of hosting guest code. You must set this option
if you want the code to act as a code signing host, controlling subsidiary
("guest") code. This flag is set automatically if you specify an internal
guest requirement.
Forces any validation of the code to consider expiration of the certificates
involved. Code signatures generated with this flag will fail to verify once any of
the certificates in the chain has expired, regardless of the intentions of the
verifier. Note that this flag does not affect any other checks that may cause
signature validation to fail, including checks for certificate revocation.
Forces the signed code's library validation flag to be set when the code begins execution.
The code will only be able to link against system libraries and frameworks, or libraries, frameworks, 
and plug-in bundles with the same team identifier embedded in the code directory. 
Team identifiers are automatically recorded in signatures when signing with suitable Apple-issued signing certificates. 
Note that the flag is not supported for i386 binaries, and only applies to the main executable. 
The flag has no effect when set on frameworks and libraries.
Note that code can set the hard and kill flags on itself at any time. The signing
options only affect their initial state. Once set by any means, these flags
cannot be cleared for the lifetime of the code. Therefore, specifying such flags
as signing options guarantees that they will be set whenever the signed code runs.
If the code being signed has an Info.plist that contains a key named CSFlags,
the value of that key is taken as the default value for the options. The value
of CSFlags can be a string in the same form as the --options option, or an
integer number specifying the absolute numeric value. Note however that while you
can abbreviate flag names on the command lines, you must spell them out in the Info.plist.
To sign application Terminal.app with a signing identity named "authority":
To sign the command-line tool "helper" with the same identity, overwriting
any existing signature, using the signing identifier "com.mycorp.helper",
and embedding a custom designated requirement
To verify the signature on Terminal.app and produce some verbose output:
To verify the dynamic validity of process 666:
To display all information about Terminal.app's code signature:
To extract the internal requirements from Terminal.app to standard output:
exits 0 if all operations succeed. This indicates that all codes were
signed, or all codes verified properly as requested. If a signing or verification
operation fails, the exit code is 1. Exit code 2 indicates invalid arguments
or parameters. Exit code 3 indicates that during verification, all path(s) were
properly signed but at least one of them failed to satisfy the requirement specified
with the
option.
For verification, all path arguments are always investigated before the program exits.
For all other operations, the program exits upon the first error encountered,
and any further path arguments are ignored, unless the --continue option was
specified, in which case
will defer the failure exit until after it has attempted to process all path
arguments in turn.
When a signing operation fails for a particular code, the code may already have been modified
in certain ways by adding requisite signature data. Such information will not
change the operation of the code, and the code will not be considered signed even with
these pieces in place. You may repeat the signing operation without difficulty.
Note however that a previous valid signature may have been effectively destroyed
if you specified the -f option.
If you require atomicity of signing stricter than provided by
you need to make an explicit copy of your code and sign that.
If the CODESIGN_ALLOCATE environment variable is set, it identifies a substitute codesign_allocate
tool used to allocate space for code signatures in Mach-O binaries. This is used by Xcode SDK
distributions to provide architectural support for non-native platforms such as iPhones.
The system will not accept such substitutes unless they are specially signed (by Apple).
System-wide database of detached code signatures for unsigned code.
The
command first appeared in Mac OS 10.5.0 (Leopard).
Some options only apply to particular operations, and
ignores them (without complaining)
if you specify them for an operation for which they have no meaning.
The --preserve-metadata option used to take no value, and varied across releases in what exactly
it preserved. The ensuing confusion is still with you if you need to make backward-compatible
scripts.
The dual meaning of the
option, indicating either verbosity or verification, confuses some people. If you find it confusing,
use the unambiguous long forms
and
instead.
The Xcode build system invokes
automatically if the CODE_SIGN_IDENTITY build variable is set.
You can express any combination of
options with additional build variables there.
is fundamentally a shell around the code signing APIs, and performs nothing of the underlying work.
Replacing it with older or newer versions is unlikely to have a useful effect.
has several operations and options that are purposely left undocumented in this manual page because they
are either experimental (and subject to change at any time), or unadvised to the unwary.
The interminably curious are referred to the published source code.
The
utility filters out reverse (and half reverse) line feeds so that the output is
in the correct order with only forward and half forward line
feeds, and replaces white-space characters with tabs where possible.
This can be useful in processing the output of
and
The
utility reads from the standard input and writes to the standard output.
The options are as follows:
Do not output any backspaces, printing only the last character
written to each column position.
Forward half line feeds are permitted (``fine'' mode).
Normally characters printed on a half line boundary are printed
on the following line.
Do not output multiple spaces instead of tabs (default).
Buffer at least
lines in memory.
By default, 128 lines are buffered.
Force unknown control sequences to be passed through unchanged.
Normally,
will filter out any control sequences from the input other than those
recognized and interpreted by itself, which are listed below.
Output multiple spaces instead of tabs.
The control sequences for carriage motion that
understands and their decimal values are listed in the following
table:
reverse line feed (escape then 7)
half reverse line feed (escape then 8)
half forward line feed (escape then 9)
moves back one column (8); ignored in the first column
(13)
forward line feed (10); also does carriage return
shift to normal character set (15)
shift to alternate character set (14)
moves forward one column (32)
moves forward to next tab stop (9)
reverse line feed (11)
All unrecognized control characters and escape sequences are
discarded.
The
utility keeps track of the character set as characters are read and makes
sure the character set is correct when they are output.
If the input attempts to back up to the last flushed line,
will display a warning message.
The
and
environment variables affect the execution of
as described in
The
utility conforms to
A
command
appeared in
The
utility provides virtual half-line and reverse line feed sequences
for terminals without such capability, and on which overstriking
is destructive.
are placed on new lines in between the normal output lines.
The following options are available:
Suppress all underlining.
This option is especially useful for previewing
tables from
Cause all half-lines to be printed, effectively double spacing the output.
Normally, a minimal space output format is used which will suppress empty
lines.
The program never suppresses two consecutive empty lines, however.
The
option is useful for sending output to the line printer when the output
contains superscripts and subscripts which would otherwise be invisible.
The
and
environment variables affect the execution of
as described in
A typical use of
would be
Should fold underlines onto blanks even with the
option so that
a true underline character would show.
Can't back up more than 102 lines.
General overstriking is lost;
as a special case
overstruck with
or underline becomes
Lines are trimmed to 132 characters.
Some provision should be made for processing superscripts and subscripts
in documents which are already double-spaced.
Characters that take up more than one column position may not be
underlined correctly.
The
command appeared in
The
utility converts a collation sequence source definition
into a format usable by the
and
functions.
It is used to define the many ways in which
strings can be ordered and collated.
The
function transforms
its first argument and places the result in its second
argument.
The transformed string is such that it can be
correctly ordered with other transformed strings by using
or
The
function transforms its arguments and does a
comparison.
The
utility reads the collation sequence source definition
from the standard input and stores the converted definition in filename.
The output file produced contains the
database with collating sequence information in a form
usable by system commands and routines.
The following options are available:
Set directory name where
files can be found, current directory by default.
Set output file name,
by default.
The collation sequence definition specifies a set of collating elements and
the rules defining how strings containing these should be ordered.
This is most useful for different language definitions.
The specification file can consist of three statements:
and
Of these, only the
statement is required.
When
or
is
supplied, these statements must be ordered as above.
Any
statements after the order statement are ignored.
Lines in the specification file beginning with a
are
treated as comments and are ignored.
Blank lines are also
ignored.
defines where a mapping of the character
and collating element symbols to the actual
character encoding can be found.
The format of
is shown below.
Symbol
names are separated from their values by TAB or
SPACE characters.
Symbol-value can be specified in
representation, and can be only one character in length.
symbol-name1 symbol-value1
symbol-name2 symbol-value2
Symbol names cannot be specified in
fields.
The
statement is optional.
substitute "symbol" with "repl_string"
The
statement substitutes the character
with the string
Symbol names cannot be specified in
field.
The
statement is optional.
is a list of symbols, separated by semi colons, that defines the
collating sequence.
The
special symbol
specifies, in a short-hand
form, symbols that are sequential in machine code
order.
An order list element
can be represented in any one of the following
ways:
The symbol itself (for example,
for the lower-case letter
The symbol in octal representation (for example,
for the letter
The symbol in hexadecimal representation (for example,
for the letter
The symbol name as defined in the
file (for example,
for
record in
If character map name have
character, it must be escaped as
single
must be escaped as
Symbols
are permitted in its usual C-language meaning.
The symbol chain (for example:
The symbol range (for example,
Comma-separated symbols, ranges and chains enclosed in parenthesis (for example
are assigned the
same primary ordering but different secondary
ordering.
Comma-separated symbols, ranges and chains enclosed in curly brackets (for example
are assigned the same primary ordering only.
The backslash character
is used for continuation.
In this case, no characters are permitted
after the backslash character.
The
utility exits with the following values:
No errors were found and the output was successfully created.
Errors were found.
The standard shared location for collation orders
under the locale
The
utility removes selected columns from the lines of a file.
A column is defined as a single character in a line.
Input is read from the standard input.
Output is written to the standard output.
If only the
column is specified, columns numbered less than the
column will be written.
If both
and
columns are specified, columns numbered less than the
column
or greater than the
column will be written.
Column numbering starts with one, not zero.
Tab characters increment the column count to the next multiple of eight.
Backspace characters decrement the column count by one.
The
and
environment variables affect the execution of
as described in
The
command appeared in
The
utility formats its input into multiple columns.
Rows are filled before columns.
Input is taken from
operands, or, by default, from the standard input.
Empty lines are ignored.
The options are as follows:
Output is formatted for a display
wide.
Specify a set of characters to be used to delimit columns for the
option.
Determine the number of columns the input contains and create a table.
Columns are delimited with whitespace, by default, or with the characters
supplied using the
option.
Useful for pretty-printing displays.
Fill columns before filling rows.
The
and
environment variables affect the execution of
as described in
The
command appeared in
Input lines are limited to
(2048) bytes in length.
The
utility reads
and
which should be
sorted lexically, and produces three text
columns as output: lines only in
lines only in
and lines in both files.
The filename ``-'' means the standard input.
The following options are available:
Suppress printing of column 1.
Suppress printing of column 2.
Suppress printing of column 3.
Case insensitive comparison of lines.
Each column will have a number of tab characters prepended to it
equal to the number of lower numbered columns that are being printed.
For example, if column number two is being suppressed, lines printed
in column number one will not have any tabs preceding them, and lines
printed in column number three will have one.
The
utility assumes that the files are lexically sorted; all characters
participate in line comparisons.
The
and
environment variables affect the execution of
as described in
The
utility conforms to
The
option is an extension to the
standard.
A
command appeared in
Input lines are limited to
(2048) characters in length.
The
utility reduces the size of files using adaptive Lempel-Ziv coding.
Each
is renamed to the same name plus the extension
A
argument with a
extension will be ignored except it will cause an
error exit after other arguments are processed.
If compression would not reduce the size of a
the file is ignored.
The
utility restores compressed files to their original form, renaming the
files by deleting the
extensions.
A file specification need not include the file's
extension.
If a file's name in its file system does not have a
extension, it will not be uncompressed and it will cause
an error exit after other arguments are processed.
If renaming the files would cause files to be overwritten and the standard
input device is a terminal, the user is prompted (on the standard error
output) for confirmation.
If prompting is not possible or confirmation is not received, the files
are not overwritten.
As many of the modification time, access time, file flags, file mode,
user ID, and group ID as allowed by permissions are retained in the
new file.
If no files are specified or a
argument is a single dash
the standard input is compressed or uncompressed to the standard output.
If either the input and output files are not regular files, the checks for
reduction in size and file overwriting are not performed, the input file is
not removed, and the attributes of the input file are not retained
in the output file.
The options are as follows:
The code size (see below) is limited to
which must be in the range 9..16.
The default is 16.
Compressed or uncompressed output is written to the standard output.
No files are modified.
The
option is ignored.
Compression is attempted even if the results will be larger than the
original.
Files are overwritten without prompting for confirmation.
Also, for
files are compressed even if they are not actually reduced in size.
Print the percentage reduction of each file.
Ignored by
or if the
option is also used.
The
utility uses a modified Lempel-Ziv algorithm.
Common substrings in the file are first replaced by 9-bit codes 257 and up.
When code 512 is reached, the algorithm switches to 10-bit codes and
continues to use more bits until the
limit specified by the
option or its default is reached.
After the limit is reached,
periodically checks the compression ratio.
If it is increasing,
continues to use the existing code dictionary.
However, if the compression ratio decreases,
discards the table of substrings and rebuilds it from scratch.
This allows
the algorithm to adapt to the next "block" of the file.
The
option is unavailable for
since the
parameter specified during compression
is encoded within the output, along with
a magic number to ensure that neither decompression of random data nor
recompression of compressed data is attempted.
The amount of compression obtained depends on the size of the
input, the number of
per code, and the distribution of common substrings.
Compression is generally much better than that achieved by Huffman
coding (as used in the historical command pack), or adaptive Huffman
coding (as used in the historical command compact), and takes less
time to compute.
The
utility exits 2 if attempting to compress a file would not reduce its size
and the
option was not specified and if no other error occurs.
The
and
utilities conform to
The
command appeared in
Some of these might be considered otherwise-undocumented features.
If the utility does not compress a file because doing so would not
reduce its size, and a file of the same name except with an
extension exists, the named file is not really ignored as stated above;
it causes a prompt to confirm the overwriting of the file with the extension.
If the operation is confirmed, that file is deleted.
If an empty file is compressed (using
the resulting
file is also empty.
That seems right, but if
is then used on that file, an error will occur.
Both utilities: If a
argument is used and the utility prompts the user, the standard input
is taken as the user's reply to the prompt.
Both utilities:
If the specified file does not exist, but a similarly-named one with (for
or without (for
a
extension does exist, the utility will waste the user's time by not
immediately emitting an error message about the missing file and
continuing.
Instead, it first asks for confirmation to overwrite
the existing file and then does not overwrite it.
formalization and abstraction of the systems that people like Andreas
have developed independently.
The configuration system employed here was developed in the context of
was taken by all those other systems mentioned in the previous
configuration data, as well as publicly accessible methods for
querying and setting (yes, actually re-writing) the configuration
reading) is merely a front-end for those methods.  If you wish, you
may create alternate front-ends.
including references to complex data structures.  It must, however, be
0) value.
configuration of a single module.  On the command line, specify which
module's configuration you're interested in, and pass options to get
supported:
Specifies the name of the module to configure (required).
be 1 if the feature is enabled, 0 if the feature is not enabled, or
empty if the feature is unknown.  When no feature name is supplied,
the names and values of all known features will be shown.
When no config name is supplied, the names and values of all known
config entries will be shown.
as either 1 or 0.
evaluated as perl code before being stored.  This allows moderately
complicated data structures to be stored.  For really complicated
structures, you probably shouldn't use this command-line interface,
Prints a help message, including a few examples, and exits.
Ken Williams, kwilliams@cpan.org
Copyright (c) 1999, Ken Williams.  All rights reserved.
it under the same terms as Perl itself.
formalization and abstraction of the systems that people like Andreas
have developed independently.
The configuration system emplyed here was developed in the context of
was taken by all those other systems mentioned in the previous
configuration data, as well as publically accessible methods for
querying and setting (yes, actually re-writing) the configuration
reading) is merely a front-end for those methods.  If you wish, you
may create alternate front-ends.
including references to complex data structures.  It must, however, be
0) value.
configuration of a single module.  On the command line, specify which
module's configuration you're interested in, and pass options to get
supported:
Specifies the name of the module to configure (required).
be 1 if the feature is enabled, 0 if the feature is not enabled, or
empty if the feature is unknown.  When no feature name is supplied,
the names and values of all known features will be shown.
When no config name is supplied, the names and values of all known
config entries will be shown.
as either 1 or 0.
evaluated as perl code before being stored.  This allows moderately
complicated data structures to be stored.  For really complicated
structures, you probably shouldn't use this command-line interface,
Prints a help message, including a few examples, and exits.
Ken Williams, kwilliams@cpan.org
Copyright (c) 1999, Ken Williams.  All rights reserved.
it under the same terms as Perl itself.
formalization and abstraction of the systems that people like Andreas
have developed independently.
The configuration system employed here was developed in the context of
was taken by all those other systems mentioned in the previous
configuration data, as well as publicly accessible methods for
querying and setting (yes, actually re-writing) the configuration
reading) is merely a front-end for those methods.  If you wish, you
may create alternate front-ends.
including references to complex data structures.  It must, however, be
0) value.
configuration of a single module.  On the command line, specify which
module's configuration you're interested in, and pass options to get
supported:
Specifies the name of the module to configure (required).
be 1 if the feature is enabled, 0 if the feature is not enabled, or
empty if the feature is unknown.  When no feature name is supplied,
the names and values of all known features will be shown.
When no config name is supplied, the names and values of all known
config entries will be shown.
as either 1 or 0.
evaluated as perl code before being stored.  This allows moderately
complicated data structures to be stored.  For really complicated
structures, you probably shouldn't use this command-line interface,
Prints a help message, including a few examples, and exits.
Ken Williams, kwilliams@cpan.org
Copyright (c) 1999, Ken Williams.  All rights reserved.
it under the same terms as Perl itself.
generates a LocalKDC and provisions LKDC service principals.
The script is non-destructive and can be run multiple times.
does not own, but references the following files:
first appeared in version 10.5 of Mac OS X.
See Module::CoreList for one.
lists all versions of the given module (or the matching modules, in case you
used a module regexp) in the perls Module::CoreList knows about.
finds the first perl version where a module has been released by
date, and not by version number (as is the default).
Given two versions of perl, this prints a human-readable table of all module
changes between the two.  The output format may change in the future, and is
all of the help
lists all of the perl release versions we got the CoreList for.
you get a list of all the modules and their respective versions.
In module filtering context, it can be used as Perl version filter.
lists all of the perl releases and when they were released
If you pass a perl version you get the release date for that version only.
lists the first version bundle of each named feature given
the version number of the Unicode Character Database bundled with the
requested perl versions.
This program is distributed under the same terms as perl itself.
See Module::CoreList for one.
lists all versions of the given module (or the matching modules, in case you
used a module regexp) in the perls Module::CoreList knows about.
finds the first perl version where a module has been released by
date, and not by version number (as is the default).
Given two versions of perl, this prints a human-readable table of all module
changes between the two.  The output format may change in the future, and is
all of the help
lists all of the perl release versions we got the CoreList for.
you get a list of all the modules and their respective versions.
In module filtering context, it can be used as Perl version filter.
lists all of the perl releases and when they were released
If you pass a perl version you get the release date for that version only.
the version number of the Unicode Character Database bundled with the
requested perl versions.
This program is distributed under the same terms as perl itself.
See Module::CoreList for one.
lists all versions of the given module (or the matching modules, in case you
used a module regexp) in the perls Module::CoreList knows about.
finds the first perl version where a module has been released by
date, and not by version number (as is the default).
Given two versions of perl, this prints a human-readable table of all module
changes between the two.  The output format may change in the future, and is
all of the help
lists all of the perl release versions we got the CoreList for.
you get a list of all the modules and their respective versions.
In module filtering context, it can be used as Perl version filter.
lists all of the perl releases and when they were released
If you pass a perl version you get the release date for that version only.
lists the first version bundle of each named feature given
the version number of the Unicode Character Database bundled with the
requested perl versions.
This program is distributed under the same terms as perl itself.
In the first synopsis form, the
utility copies the contents of the
to the
In the second synopsis form,
the contents of each named
is copied to the destination
The names of the files themselves are not changed.
If
detects an attempt to copy a file to itself, the copy will fail.
The following options are available:
Same as 
options. Preserves structure and attributes of files
but not directory structure.
If the destination file cannot be opened, remove it and
create a new file, without prompting for confirmation
regardless of its permissions.
(The
option overrides any previous
option.)
The target file is not unlinked before the copy.
Thus, any existing access rights will be retained.
If the
option is specified, symbolic links on the command line are followed.
(Symbolic links encountered in the tree traversal are not followed.)
Cause
to write a prompt to the standard error output before copying a file
that would overwrite an existing file.
If the response from the standard input begins with the character
or
the file copy is attempted.
(The
option overrides any previous
option.)
If the
option is specified, all symbolic links are followed.
Do not overwrite an existing file.
(The
option overrides any previous
or
options.)
If the
option is specified, no symbolic links are followed.
This is the default.
Cause
to preserve the following attributes of each source
file in the copy: modification time, access time,
file flags, file mode, user ID, and group ID, as allowed by permissions.
Access Control Lists (ACLs) and Extended Attributes (EAs),
including resource forks, will also be preserved.
If the user ID and group ID cannot be preserved, no error message
is displayed and the exit value is not altered.
If the source file has its set-user-ID bit on and the user ID cannot
be preserved, the set-user-ID bit is not preserved
in the copy's permissions.
If the source file has its set-group-ID bit on and the group ID cannot
be preserved, the set-group-ID bit is not preserved
in the copy's permissions.
If the source file has both its set-user-ID and set-group-ID bits on,
and either the user ID or group ID cannot be preserved, neither
the set-user-ID nor set-group-ID bits are preserved in the copy's
permissions.
If
designates a directory,
copies the directory and the entire subtree connected at that point.
If the
ends in a
the contents of the directory are copied rather than the
directory itself.
This option also causes symbolic links to be copied, rather than
indirected through, and for
to create special files rather than copying them as normal files.
Created directories have the same mode as the corresponding source
directory, unmodified by the process' umask.
In
mode,
will continue copying even if errors are detected. 
Note that
copies hard-linked files as separate files.
If you need to preserve hard links, consider using
or
instead.
Cause
to be verbose, showing files as they are copied.
Do not copy Extended Attributes (EAs) or resource forks.
For each destination file that already exists, its contents are
overwritten if permissions allow.
Its mode, user ID, and group
ID are unchanged unless the
option was specified.
In the second synopsis form,
must exist unless there is only one named
which is a directory and the
flag is specified.
If the destination file does not exist, the mode of the source file is
used as modified by the file mode creation mask
see
If the source file has its set-user-ID bit on, that bit is removed
unless both the source file and the destination file are owned by the
same user.
If the source file has its set-group-ID bit on, that bit is removed
unless both the source file and the destination file are in the same
group and the user is a member of that group.
If both the set-user-ID and set-group-ID bits are set, all of the above
conditions must be fulfilled or both bits are removed.
Appropriate permissions are required for file creation or overwriting.
Symbolic links are always followed unless the
flag is set, in which case symbolic links are not followed, by default.
The
or
flags (in conjunction with the
flag) cause symbolic links to be followed as described above.
The
and
options are ignored unless the
option is specified.
In addition, these options override each other and the
command's actions are determined by the last one specified.
If
receives a
(see the
argument for
signal, the current input and output file and the percentage complete
will be written to the standard output.
Historic versions of the
utility had a
option.
This implementation supports that option;
however, its use is strongly discouraged,
as it does not correctly copy special files, symbolic links, or fifo's.
The
and
options are non-standard and their use in scripts is not recommended.
In legacy mode,
will override
Also, under the
option, the target file is always unlinked before the copy.
Thus, new access rights will always be set.
In
mode, copying will terminate if an error is encountered.
For more information about legacy mode, see
The
command is expected to be
compatible.
A
command appeared in
Shows the primary maintainers for the specified modules.
Runs a `make clean` in the specified module's directories.
Show the module details.
Force the specified action, when it normally would have failed. Use this
to install a module even if its tests fail. When you use this option,
this since you might end up with multiple scripts trying to muck in the
same directory. This isn't so much of a concern if you're loading a special
Downloads to the current directory the latest distribution of the module.
Download to the current directory the latest distribution of the
modules, unpack each distribution, and create a git repository for each
distribution.
distribution.
of the other options and arguments.
Install the specified modules.
for checking the configuration as well as using the dump as a starting point
for a new, custom configuration.
List all installed modules wth their versions
List the modules by the specified authors.
Make the specified modules.
Show the out-of-date modules.
Ping the configured mirrors
Find the best mirrors you could be using (but doesn't configure them just yet)
Run a `make test` on the specified modules.
Do not test modules. Simply install them.
Upgrade all installed modules. Blindly doing this can really break things,
so keep a backup.
Print detailed information about the cpan client.
Turn on cpan warnings. This checks various things, like directory permissions,
and tells you about problems you might have.
before it processes the command-line arguments. For instance, if you always
The script exits with zero if it thinks that everything worked, or a 
positive number if it thinks that something failed. Note, however, that
in some cases it has to divine a failure by the output of things it does
not control. For now, the exit codes are vague:
* one shot configuration values from the command line
* none noted
Most behaviour, including environment variables and configuration,
This code is in Github:
Jim Brandt suggest and provided the initial implementation for the
up-to-date and Changes features.
where this script ends up with a .bat extension
You may redistribute this under the same terms as Perl itself.
you specify, including its prerequisites. These packages can then be
installed using the corresponding package manager for the format.
Note, you can also do this interactively from the default shell,
as well as the documentation of your format of choice for any format
specific documentation.
Options:
Examples:
Some modules you'd rather not package. Some because they
are part of core-perl and you dont want a new package.
Some because they won't build on your system. Some because
your package manager of choice already packages them for you.
lists that catch common cases. You can use these built-in lists
if you like, or supply your own if need be.
You can use this list of regexes to ignore modules matching
to be listed as prerequisites of a package. Particularly useful
if they are bundled with core-perl anyway and they have known
issues building.
You can use this list of regexes to disable building of these
modules altogether.
CPANPLUS::Dist, CPANPLUS::Module, CPANPLUS::Shell::Default,
This module by Jos Boumans <kane@cpan.org>.
under the same terms as Perl itself.
you specify, including its prerequisites. These packages can then be
installed using the corresponding package manager for the format.
Note, you can also do this interactively from the default shell,
as well as the documentation of your format of choice for any format
specific documentation.
Options:
Examples:
Some modules you'd rather not package. Some because they
are part of core-perl and you dont want a new package.
Some because they won't build on your system. Some because
your package manager of choice already packages them for you.
lists that catch common cases. You can use these built-in lists
if you like, or supply your own if need be.
You can use this list of regexes to ignore modules matching
to be listed as prerequisites of a package. Particularly useful
if they are bundled with core-perl anyway and they have known
issues building.
You can use this list of regexes to disable building of these
modules altogether.
CPANPLUS::Dist, CPANPLUS::Module, CPANPLUS::Shell::Default,
This module by Jos Boumans <kane@cpan.org>.
under the same terms as Perl itself.
you specify, including its prerequisites. These packages can then be
installed using the corresponding package manager for the format.
Note, you can also do this interactively from the default shell,
as well as the documentation of your format of choice for any format
specific documentation.
Options:
Examples:
Some modules you'd rather not package. Some because they
are part of core-perl and you dont want a new package.
Some because they won't build on your system. Some because
your package manager of choice already packages them for you.
lists that catch common cases. You can use these built-in lists
if you like, or supply your own if need be.
You can use this list of regexes to ignore modules matching
to be listed as prerequisites of a package. Particularly useful
if they are bundled with core-perl anyway and they have known
issues building.
You can use this list of regexes to disable building of these
modules altogether.
CPANPLUS::Dist, CPANPLUS::Module, CPANPLUS::Shell::Default,
This module by Jos Boumans <kane@cpan.org>.
under the same terms as Perl itself.
Shows the primary maintainers for the specified modules.
Runs a `make clean` in the specified module's directories.
Show the module details. This prints one line for each out-of-date module
version.
Force the specified action, when it normally would have failed. Use this
to install a module even if its tests fail. When you use this option,
this since you might end up with multiple scripts trying to muck in the
same directory. This isn't so much of a concern if you're loading a special
Downloads to the current directory the latest distribution of the module.
Download to the current directory the latest distribution of the
modules, unpack each distribution, and create a git repository for each
distribution.
distribution.
of the other options and arguments.
Install the specified modules.
for checking the configuration as well as using the dump as a starting point
for a new, custom configuration.
List the modules by the specified authors.
Make the specified modules.
Show the out-of-date modules.
Run a `make test` on the specified modules.
The script exits with zero if it thinks that everything worked, or a 
positive number if it thinks that something failed. Note, however, that
in some cases it has to divine a failure by the output of things it does
not control. For now, the exit codes are vague:
* one shot configuration values from the command line
* none noted
Most behaviour, including environment variables and configuration,
This code is in Github:
Jim Brandt suggest and provided the initial implementation for the
up-to-date and Changes features.
where this script ends up with a .bat extension
You may redistribute this under the same terms as Perl itself.
Shows the primary maintainers for the specified modules.
Runs a `make clean` in the specified module's directories.
Show the module details.
Force the specified action, when it normally would have failed. Use this
to install a module even if its tests fail. When you use this option,
this since you might end up with multiple scripts trying to muck in the
same directory. This isn't so much of a concern if you're loading a special
Downloads to the current directory the latest distribution of the module.
Download to the current directory the latest distribution of the
modules, unpack each distribution, and create a git repository for each
distribution.
distribution.
of the other options and arguments.
Install the specified modules.
for checking the configuration as well as using the dump as a starting point
for a new, custom configuration.
List all installed modules wth their versions
List the modules by the specified authors.
Make the specified modules.
Show the out-of-date modules.
Ping the configured mirrors
Find the best mirrors you could be using (but doesn't configure them just yet)
Run a `make test` on the specified modules.
Do not test modules. Simply install them.
Upgrade all installed modules. Blindly doing this can really break things,
so keep a backup.
Print detailed information about the cpan client.
Turn on cpan warnings. This checks various things, like directory permissions,
and tells you about problems you might have.
before it processes the command-line arguments. For instance, if you always
The script exits with zero if it thinks that everything worked, or a 
positive number if it thinks that something failed. Note, however, that
in some cases it has to divine a failure by the output of things it does
not control. For now, the exit codes are vague:
* one shot configuration values from the command line
* none noted
Most behaviour, including environment variables and configuration,
This code is in Github:
Jim Brandt suggest and provided the initial implementation for the
up-to-date and Changes features.
where this script ends up with a .bat extension
You may redistribute this under the same terms as Perl itself.
from the command line. If it's invoked without arguments, an interactive
shell is executed by default.
Optionally, it can take a single-letter switch and one or more argument,
to perform the associated action on each arguments.  A summary of the
Example: To skip a module's tests,
for an explanation to their meanings.
Example: To download a module's tarball to the current directory,
from the command line. If it's invoked without arguments, an interactive
shell is executed by default.
Optionally, it can take a single-letter switch and one or more argument,
to perform the associated action on each arguments.  A summary of the
Example: To skip a module's tests,
for an explanation to their meanings.
Example: To download a module's tarball to the current directory,
from the command line. If it's invoked without arguments, an interactive
shell is executed by default.
Optionally, it can take a single-letter switch and one or more argument,
to perform the associated action on each arguments.  A summary of the
Example: To skip a module's tests,
for an explanation to their meanings.
Example: To download a module's tarball to the current directory,
copies files between archives and directories.
This implementation can extract from tar, pax, cpio, zip, jar, ar,
and ISO 9660 cdrom images and can create tar, pax, cpio, ar,
and shar archives.
The first option to
is a mode indicator from the following list:
Input.
Read an archive from standard input (unless overriden) and extract the
contents to disk or (if the
option is specified)
list the contents to standard output.
If one or more file patterns are specified, only files matching
one of the patterns will be extracted.
Output.
Read a list of filenames from standard input and produce a new archive
on standard output (unless overriden) containing the specified items.
Pass-through.
Read a list of filenames from standard input and copy the files to the
specified directory.
Unless specifically stated otherwise, options are applicable in
all operating modes.
Read filenames separated by NUL characters instead of newlines.
This is necessary if any of the filenames being read might contain newlines.
(o mode only)
Append to the specified archive.
(Not yet implemented.)
(o and p modes)
Reset access times on files after they are read.
(o mode only)
Block output to records of 5120 bytes.
(o mode only)
Block output to records of
bytes.
(o mode only)
Use the old POSIX portable character format.
Equivalent to
(i and p modes)
Create directories as necessary.
(i mode only)
Read list of file name patterns from
to list and extract.
Read archive from or write archive to
(i mode only)
Ignore files that match
(o mode only)
Produce the output archive in the specified format.
Supported formats include:
Synonym for
The SVR4 portable cpio format.
The old POSIX.1 portable octet-oriented cpio format.
The POSIX.1 pax format, an extension of the ustar format.
The POSIX.1 tar format.
The default format is
See
for more complete information about the
formats currently supported by the underlying
library.
Synonym for
Print usage information.
Read archive from
Input mode.
See above for description.
(i and p mode only)
Disable security checks during extraction or copying.
This allows extraction via symbolic links and path names containing
in the name.
(o mode only)
Compress the file with xz-compatible compression before writing it.
In input mode, this option is ignored; xz compression is recognized
automatically on input.
Synonym for
(o and p modes)
All symbolic links will be followed.
Normally, symbolic links are archived and copied as symbolic links.
With this option, the target of the link will be archived or copied instead.
(p mode only)
Create links from the target directory to the original files,
instead of copying.
(o mode only)
Compress the file with lzma-compatible compression before writing it.
In input mode, this option is ignored; lzma compression is recognized
automatically on input.
(i and p modes)
Set file modification time on created files to match
those in the source.
(i mode, only with
Display numeric uid and gid.
By default,
displays the user and group names when they are provided in the
archive, or looks up the user and group names in the system
password database.
(i mode only)
Do not attempt to restore file ownership.
This is the default when run by non-root users.
Write archive to
Output mode.
See above for description.
Pass-through mode.
See above for description.
(i mode only)
Restore file ownership.
This is the default when run by the root user.
Suppress unnecessary messages.
If group is specified with no user
(for example,
then the group will be set but not the user.
If the user is specified with a trailing colon and no group
(for example,
then the group will be set to the user's default group.
If the user is specified with no trailing colon, then
the user will be set but not the group.
In
and
modes, this option can only be used by the super-user.
(For compatibility, a period can be used in place of the colon.)
(All modes.)
Rename files interactively.
For each file, a prompt is written to
containing the name of the file and a line is read from
If the line read is blank, the file is skipped.
If the line contains a single period, the file is processed normally.
Otherwise, the line is taken to be the new name of the file.
(i mode only)
List the contents of the archive to stdout;
do not restore the contents to disk.
(i and p modes)
Unconditionally overwrite existing files.
Ordinarily, an older file will not overwrite a newer file on disk.
Print the name of each file to stderr as it is processed.
With
provide a detailed listing of each file.
Print the program version information and exit.
(o mode only)
Compress the archive with bzip2-compatible compression before writing it.
In input mode, this option is ignored;
bzip2 compression is recognized automatically on input.
(o mode only)
Compress the archive with compress-compatible compression before writing it.
In input mode, this option is ignored;
compression is recognized automatically on input.
(o mode only)
Compress the archive with gzip-compatible compression before writing it.
In input mode, this option is ignored;
gzip compression is recognized automatically on input.
The following environment variables affect the execution of
The locale to use.
See
for more information.
The timezone to use when displaying dates.
See
for more information.
The
command is traditionally used to copy file heirarchies in conjunction
with the
command.
The first example here simply copies all files from
to
By carefully selecting options to the
command and combining it with other standard utilities,
it is possible to exercise very fine control over which files are copied.
This next example copies files from
to
that are more than 2 days old and whose names match a particular pattern:
This example copies files from
to
that are more than 2 days old and which contain the word
The mode options i, o, and p and the options
a, B, c, d, f, l, m, r, t, u, and v comply with SUSv2.
The old POSIX.1 standard specified that only
and
were interpreted as command-line options.
Each took a single argument of a list of modifier
characters.
For example, the standard syntax allows
but does not support
or
since
and
are only modifiers to
they are not command-line options in their own right.
The syntax supported by this implementation is backwards-compatible
with the standard.
For best compatibility, scripts should limit themselves to the
standard syntax.
There is no current POSIX standard for the cpio command; it appeared
in
but was dropped from
The cpio, ustar, and pax interchange file formats are defined by
for the pax command.
The original
and
utilities were written by Dick Haight
while working in AT&T's Unix Support Group.
system developed for use within AT&T.
They were first released outside of AT&T as part of System III Unix in 1981.
As a result,
actually predates
even though it was not well-known outside of AT&T until some time later.
This is a complete re-implementation based on the
library.
The cpio archive format has several basic limitations:
It does not store user and group names, only numbers.
As a result, it cannot be reliably used to transfer
files between systems with dissimilar user and group numbering.
Older cpio formats limit the user and group numbers to
16 or 18 bits, which is insufficient for modern systems.
The cpio archive formats cannot support files over 4 gigabytes,
except for the
variant, which can support files up to 8 gigabytes.
provides several options for creating and populating home directories.
creates home directories for server home paths only (default).
creates home directories for local home paths only.
creates home directories for both server and local home paths.
creates home directories for users defined in all directory domains of the server's search path.
creates home directories for users defined in the local directory domain.
creates home directories for users defined in a specific directory domain in the server's search path.
creates a home directory for a specific user defined in the domain(s) identified in the -a, -l, or -n parameter. If you omit the -a, -l, and -n parameters when you use the -u parameter, -a is assumed.
reads username list from standard input and creates specified home directories. Each username should be on its own line.
usage help.
location of tool
When using the -a option, search limits of various directory servers (such as Open Directory or Active Directory) can prevent all possible home directories from being created. In this case, you may need to specify the usernames explicitly.

command [command-args] [options]
r [options]
f URL [options]
F URI [options]
Refresh the entire CRL cache
Fetch a CRL from specified URL
Fetch a Certificate from specified URL
Crlrefresh is also use to fetch specific CRLs and certificates from the network; CRLs fetched via 
will be added to the CRL cache as well as provided to the specified output file (or to stdout if no output file is provided). The URL specified in the 
and 
commands must have schema "http:" or "ldap:".
Typically,
would be run on a regular basis via one of the configuration files used by the 
program.
Specify the time in days which, having elapsed after a CRL is expired, that the CRL is deleted fromt he CRL cache. The default is 10 days.
Specify the time in seconds prior to a CRL's expiration when a refresh action will attempt to replace the CRL with a fresh copy.
Purge all entries from the CRL cache, ensuring refresh with fresh CRLs. Normally, CRLs whose expiration date is more than expire_overlap past the current time are not refreshed.
Perform full cryptographic verification of all CRLs in the CRL cache. Normally this step is only performed when a CRL is actually used to validate a certificate.
Provide verbose output during operation. 
When fetching a CRL or certificate, specifies the destination to which the fetched entity will be written. If this is not specified then the fetched entity is sent to stdout.
When fetching a CRL, this inhibits the addition of the fetched CRL to the system CRL cache.
Execute in verbose mode.
System CRL cache database
{
}
The
utility is the program used to install, deinstall or list the tables
used to drive the
daemon in Vixie Cron.
Each user can have their own crontab, and
they are not intended to be edited directly.
(Darwin note: Although
and
are officially supported under Darwin, their functionality has been
absorbed into
which provides a more flexible way of automatically executing commands.
See
for more information.)
If the
file exists, then you must be listed therein in order to be allowed to use
this command.
If the
file does not exist but the
file does exist, then you must
be listed in the
file in order to use this command.
If neither of these files exists, then
depending on site-dependent configuration parameters, only the super user
will be allowed to use this command, or all users will be able to use this
command.
The format of these files is one username per line,
with no leading or trailing whitespace.
Lines of other formats will be ignored,
and so can be used for comments.
The first form of this command is used to install a new crontab from some
named file or standard input if the pseudo-filename
is given.
The following options are available:
Specify the name of the user whose crontab is to be
tweaked.
If this option is not given,
examines
crontab, i.e., the crontab of the person executing the
command.
Note that
can confuse
and that if you are running inside of
you should always use the
option for safety's sake.
Display the current crontab on standard output.
Remove the current crontab.
Edit the current crontab using the editor specified by
the
or
environment variables.
The specified editor
edit the file in place;
any editor that unlinks the file and recreates it cannot be used.
After you exit
from the editor, the modified crontab will be installed automatically.
A fairly informative usage message appears if you run it with a bad command
line.
The
command conforms to
The new command syntax
differs from previous versions of Vixie Cron, as well as from the classic
SVR3 syntax.
collects information to help Apple investigate issues related to CoreStorage (File Vault 2, Fusion Drive, File Vault Everywhere, etc).  This tool invokes sudo, so you will be asked to authenticate.
This script requires
to be installed in the PATH.
If
is not given, all disks in the system will be inspected.  This is the recommended method of invoking
Advanced users can provide a list of
in the form of
or
Only information of the given
is collected.  To fully collect information of a CoreStorage volume, the CoreStorage Physical Volume (i.e., the Apple_CoreStorage partition), the Apple_Boot partition after the physical volume, and the Logical Volume published by CoreStorage (which can be found out using the
command) should all be provided on the command line.
The following information is collected:
OS version.
system logs, kernel logs, install logs, filesystem logs, and other useful information for CoreStorage debugging from
output of
output of
output of
of every Apple_CoreStorage partition, which includes the CoreStorage metadata.  If a list of
is provided, only information on the partitions included in the list will be collected.
of every Apple_Boot partition.  If a list of
is provided, only information on the partitions included in the list will be collected.
The following user information is contained in the collected file:
Number and types of disks attached to the system.
The volume names, UUIDs, and size of each partition.
Encrypted versions of the volume key(s) that unlock the encrypted disk(s) attached to the system.  Refer to
for what information could leak from the volume key(s).
User names, pictures, and password hints for the users.
No other user information (such as directory structures, file names,
file content, etc) is collected.
The following options are available:
Show this help information.
Specify an output path which will hold the file generated by this script.  By default this will be the user's Desktop folder.  The given path must already exist.
Verbose mode, which prints every command it invokes.
The
utility first appeared along with CoreStorage in OS X 10.10.0.
gathers CoreStorage metadata for diagnosis.  It works in two modes.
In the first mode where -G and a list of devices are provided, CoreStorage
metadata on these list of devices will be collected.  The collected
information includes the size and UUID of the CoreStorage logical and
physical volumes, the name of the logical volumes, the wrapped (encrypted)
volume key (which can
only be decrypted by a brute-force attack), user name and user login image
file.  No other user information (such as directory structure, file names,
file content, etc) is collected.
In the second mode where -r is provided, the encryption
context which includes the wrapped volume key (which can only be decrypted by
a brute-force attack), user name and user login image file will be collected.
If the wrapped volume key is decrypted by a brute-force attack, the volume
key used to encrypt data on CoreStorage Logical Volumes is in the clear.  It
is not mathematically possible to derive the user's passphrase from the
volume key.  The volume key is only useful when the attacker has access to
the encrypted data in the CoreStorage Logical Volume, which are not collected
by
The following options are available:
Gather all CoreStorage metadata and write into the specified directory.  The given directory
must not already exist.
Specify the output file generated by the -r option.  If not given, use standard output.
Find out the CoreStorage logical volume identified by the given mount point, and print its encryption
context to the file given in the -o option.
The
utility first appeared along with CoreStorage in OS X 10.10.0.
It is a command language interpreter usable both as an interactive login
shell and a shell script command processor.
and a C-like syntax.
Throughout this manual, features of
but not usually documented are labeled with `(u)'.
login shell.  A login shell can be also specified by invoking the shell with
The rest of the flag arguments are interpreted as follows:
Forces a ``break'' from option processing, causing any
further shell arguments to be treated as non-option arguments.  The remaining
arguments will not be interpreted as shell options.  This may be used to pass
options to a shell script without confusion or possible subterfuge.  The shell
will not run a set-user ID script without this option.
Commands are read from the following argument (which must be present, and
must be a single argument),
The shell exits if any invoked command terminates abnormally or
yields a non-zero exit status.
The shell does not load any resource or startup files, or perform any 
command hashing, and thus starts faster.
The shell is interactive and prompts for its top-level input, even if
it appears to not be a terminal.  Shells are interactive without this option if
their inputs and outputs are terminals.
flag specified.
The shell parses commands but does not execute them.
This aids in debugging shell scripts.
it is used under a debugger.  Job control is disabled. (u)
Command input is taken from the standard input.
escape the newline at the end of this line and continue onto another line.
command input is echoed after history substitution.
immediately before execution.
Print a help message on the standard output and exit. (+)
After processing of flag arguments, if arguments remain but none of the
argument is taken as the name of a file of commands, or ``script'', to
be executed.  The shell opens this file and saves its name for possible
resubstitution by `$0'.  Because many systems use either the standard
version 6 or version 7 shells whose shell scripts are not compatible
with this shell, the shell uses such a `standard' shell to execute a script
whose first character is not a `#', i.e., that does not start with a
comment.
A login shell begins by executing commands from the system files
For examples of startup files, please consult
In the normal case, the shell begins reading commands from the terminal,
prompting with `> '.  (Processing of arguments and the use of the shell to
process files containing command scripts are described later.)
The shell repeatedly reads a line of command input, breaks it into words,
places it on the command history list, parses it and executes each command
in the line.
One can log out by typing `^D' on an empty line, `logout' or `login' or
`normal' or `automatic' as appropriate, then
executes commands from the files
The names of the system login and logout files vary from system to system for
describe two sets of functionality that are implemented as editor commands
but which deserve their own treatment.
the editor commands specific to the shell and their default bindings.
Command-line input can be edited using key sequences much like those used in
it is by default in interactive shells.
Emacs-style key bindings are used by default
environment variable) to
down
up
left
right
unless doing so would alter another single-character binding.
to prevent these bindings.
commands with a short description of each.
Note that editor commands do not have the same notion of a ``word'' as does the
shell.  The editor delimits words with any non-alphanumeric characters not in
and some of the characters with special meanings to it, listed under
The shell is often able to complete words when given a unique abbreviation.
replacing the incomplete word with the complete word in the input buffer.
end of completed directories and a space to the end of other completed words,
to speed typing and provide a visual indicator of successful completion.
the terminal bell rings.
system, or perhaps you were thinking too far ahead and typed the whole thing)
Completion works anywhere in the line, not at just the end; completed
text pushes the rest of the line to the right.  Completion in the middle of a word
often results in leftover characters to the right of the cursor that need
to be deleted.
Commands and variables can be completed in much the same way.
For example, typing `em[tab]' would complete `em' to
given a full pathname.
Typing `echo $ar[tab]' would complete `$ar' to `$argv'
if no other variable began with `ar'.
The shell parses the input buffer to determine whether the word you want to
complete should be completed as a filename, command or variable.
The first word in the buffer and the first word following
`;', `|', `|&', `&&' or `||' is considered to be a command.
A word beginning with `$' is considered to be a variable.
Anything else is a filename.  An empty line is `completed' as a filename.
You can list the possible completions of a word at any time by typing `^D'
and reprints the prompt and unfinished command line, for example:
choices (if any) whenever completion fails:
> set autolist
libtermcap.a@ libtermlib.a@
completion fails and adds no new characters to the word being completed.
A filename to be completed can contain variables, your own or others' home
directory stack entries abbreviated with `='
> ls ~k[^D]
kahn    kas     kellogg
> ls ~ke[tab]
or
> ls $lo[tab]
Note that variables can also be expanded explicitly with the
in the middle of a line it deletes the character under the cursor and
(not bound to any keys by default) can be used to cycle up and down through
the list of possible completions, replacing the current word with the next or
previous word in the list.
ignored by completion.  Consider the following:
> ls
Makefile        condiments.h~   main.o          side.c
README          main.c          meal            side.o
condiments.h    main.c~
> emacs ma[^D]
main.c   main.c~  main.o
> emacs ma[tab]
> emacs main.c
`main.c~' and `main.o' are ignored by completion (but not listing),
1) ignores case and 2) considers periods, hyphens and underscores
be equivalent.  If you had the following files
comp.lang.c      comp.lang.perl   comp.std.c++
comp.lang.c++    comp.std.c
A_silly_file    a-hyphenated-file    another_silly_file
would list all three files, because case is ignored and hyphens and
underscores are equivalent.  Periods, however, are not equivalent to
hyphens or underscores.
ignores case and differences between a hyphen and an underscore word
separator only when the user types a lowercase character or a hyphen.
Entering an uppercase character or an underscore will not match the 
corresponding lowercase character or hyphen word separator.  
`A_silly_file' and typing `rm a__file[^D]' would match just `A_silly_file' 
and `another_silly_file' because the user explicitly used an uppercase 
or an underscore character.  
Completion and listing are affected by several other shell variables:
match, even if more typing might result in a longer match:
> ls
fodder   foo      food     foonly
> set recexact
> rm fo[tab]
just beeps, because `fo' could expand to `fod' or `foo', but if we type
another `o',
> rm foo[tab]
> rm foo
the completion completes on `foo', even though `food' and `foonly'
also match.
commands automatically after one hits `return'.
those directories.
and rows (respectively) that are listed without asking first.
executables when listing commands, but it is quite slow.
to complete words other than filenames, commands and variables.
equivalent functions for glob-patterns.
The shell can sometimes correct the spelling of filenames, commands and variable names
as well as completing and listing them.
editor command (usually bound to M-s and M-S)
command name or `all' to correct the entire line each time return is typed,
before each completion attempt.
When spelling correction is invoked in any of these ways and
the shell thinks that any part of the command line is misspelled,
it prompts with the corrected line:
> set correct = cmd
One can answer `y' or space to execute the corrected line,
`e' to leave the uncorrected command in the input buffer,
`a' to abort the command as if `^C' had been hit, and
anything else to execute the original line unchanged.
Spelling correction recognizes user-defined completions (see the
which a completion is defined resembles a word in the completion list,
spelling correction registers a misspelling and suggests the latter
word as a correction.  However, if the input word does not match any of
the possible completions for that position, spelling correction does
not register a misspelling.
Like completion, spelling correction works anywhere in the line,
pushing the rest of the line to the right and possibly leaving
extra characters to the right of the cursor.
Beware: spelling correction is not guaranteed to work the way one intends,
and is provided mostly as an experimental feature.
Suggestions and improvements are welcome.
editor commands.
Only new or especially interesting editor commands are described here.
key bindings.
The character or characters to which each command is bound by default is
on terminals without a meta key.  Case counts, but commands that are bound
to letters by default are bound to both lower- and uppercase letters for
convenience.
Replaces the current word with the first word in the list of possible
completions.  May be repeated to step down through the list.
At the end of the list, beeps and reverts to the incomplete word.
Copies the previous word in the current line into the input buffer.
Expands the current word to the most recent preceding one for which
the current is a leading substring, wrapping around the history list
(once) if necessary.
changes to the next previous word etc., skipping identical matches
Deletes the character under the cursor.
See also those three commands, each of which does only a single action, and
each of which does a different two out of the three.
shell variable (q.v.) is set to prevent this.
Expands history substitutions in the current word.
Expands the glob-pattern to the left of the cursor.
expands history substitutions in each word in the input buffer.
Expands the variable to the left of the cursor.
Searches backwards through the history list for a command beginning with
the current contents of the input buffer up to the cursor and copies it
into the input buffer.
containing `*', `?', `[]' or `{}'.
appropriate point in the history list.
Emacs mode only.
into the input buffer with the cursor positioned at the end of the pattern,
and prompts with `bck: ' and the first match.  Additional characters may be
searching with the same pattern, wrapping around the history list if
single character for this to work) or one of the following special characters
may be typed:
^W
Appends the rest of the word under the cursor to the search pattern.
Undoes the effect of the last character typed and deletes a character
from the search pattern if appropriate.
^G
If the previous search was successful, aborts the entire search.
If not, goes back to the last successful search.
escape
Ends the search, leaving the current line in the input buffer.
search, leaving the current line in the input buffer, and
is then interpreted as normal input.  In particular, a carriage return
causes the current line to be executed.
Emacs mode only.
Inserts the last word of the previous input line (`!$') into the input buffer.
Expands history substitutions in the current line,
but is not bound by default.
Searches for the current word in PATH and, if it is found, replaces it with
the full path to the executable.  Special characters are quoted.  Aliases are
expanded and quoted but commands within aliases are not.  This command is
Expands the current word as described under the `expand' setting
Toggles between input and overwrite modes.
Saves the current input line and
looks for a stopped job with a name equal to the last component of the
or, if neither is set, `ed' or `vi'.
typed.  This is used to toggle back and forth between an editor and
the shell easily.  Some people bind this command to `^Z' so they
can do this even more easily.
Searches for documentation on the current command, using the same notion of
`current command' as the completion routines, and prints it.  There is no way
command name as a sole argument.  Else,
If there is more than one help file only the first is printed.
In insert mode (the default), inserts the typed character into the input line after the character under the cursor.
In overwrite mode, replaces the character under the cursor with the typed character.
The input mode is normally preserved between lines, but the
editor in that mode at the beginning of each line.
Indicates that the following characters are part of a
multi-key sequence.  Binding a command to a multi-key sequence really creates
whole sequence to the command.  All sequences beginning with a character
unless bound to another command.
Attempts to correct the spelling of each word in the input buffer, like
with switches, substitutions and the like.
Attempts to correct the spelling of the current word as described
Checks each component of a word which appears to be a pathname.
Expands or `unexpands' history substitutions in the input buffer.
Beeps.
Copies the previous entry in the history list into the input buffer.
May be repeated to step up through the history list, stopping at the top.
Prompts with `?' for a search string (which may be a glob-pattern, as with
input buffer.  The bell rings if no match is found.
Hitting return ends the search and leaves the last match in the input
buffer.
Hitting escape ends the search and executes the match.
first word of the input buffer.
replaces the yanked string with the next previous string from the
killring. This also has the effect of rotating the killring, such that
this string will be considered the most recently killed by a later
killring any number of times.
The shell splits input lines into words at blanks and tabs.  The special
characters `&', `|', `;', `<', `>', `(', and `)' and the doubled characters
`&&', `||', `<<' and `>>' are always separate words, whether or not they are
surrounded by whitespace.
When the shell's input is not a terminal, the character `#' is taken to begin a
comment.  Each `#' and the rest of the input line on which it appears is
discarded before further parsing.
A special character (including a blank or tab) may be prevented from having
its special meaning, and possibly made part of another word, by preceding it
is equivalent to a blank, but inside quotes this sequence results in a
newline.
can be prevented by enclosing the strings (or parts of strings)
in which they appear with single quotes or by quoting the crucial character(s)
substitution of the alias.  The usual way of quoting an alias is to precede it
backslashes but not by single quotes.  Strings quoted with double or backward
substitutions are prevented.
Text inside single or double quotes becomes a single word (or part of one).
Metacharacters in these strings, including blanks and tabs, do not form
below) can a double-quoted string yield parts of more than one word;
single-quoted strings never do.  Backward quotes are special: they signal
Quoting complex strings, particularly strings which themselves contain quoting
characters, can be confusing.  Remember that quotes need not be used as they are
in human writing!  It may be easier to quote not an entire string, but only
those parts of the string which need quoting, using different types of quoting
to do so if appropriate.
We now describe the various transformations the shell performs on the input in
the order in which they occur.  We note in passing the data structures involved
and the commands and variables which affect them.  Remember that substitutions
Each command, or ``event'', input from the terminal is saved in the history
shell variable can be set to not save duplicate events or consecutive duplicate
events.
Saved commands are numbered sequentially from 1 and stamped with the time.
It is not usually necessary to use event numbers, but the current event number
The shell actually saves history in expanded and literal (unexpanded) forms.
history use the literal form.
and clear the history list at any time,
store the history list automatically on logout and restore it on login.
History substitutions introduce words from the history list into the input
stream, making it easy to repeat commands, repeat arguments of a previous
command in the current command, or fix spelling mistakes in the previous
command with little typing and a high degree of confidence.
History substitutions begin with the character `!'.  They may begin anywhere in
prevent its special meaning; for convenience, a `!' is passed unchanged when it
is followed by a blank, tab, newline, `=' or `('.  History substitutions also
occur when an input line begins with `^'.  This special abbreviation will be
described later.  The characters used to signal history substitution (`!' and
line which contains a history substitution is printed before it is executed.
A history substitution may have an ``event specification'', which indicates
the event from which words are to be taken, a ``word designator'',
which manipulates the selected words.
An event specification can be
A number, referring to a particular event
#
The current event.
!
The second `?' can be omitted if it is immediately followed by a newline.
For example, consider this bit of someone's history list:
10  8:31    cp wumpus.man wumpus.man.old
11  8:36    vi wumpus.man
12  8:37    diff wumpus.man.old wumpus.man
The commands are shown with their event numbers and time stamps.
The current event, which we haven't typed in yet, is event 13.
`!!' refers to the previous event, 12.  `!!' can be abbreviated `!' if it is
followed by `:' (`:' is described below).
`!n' refers to event 9, which begins with `n'.
`!?old?' also refers to event 12, which contains `old'.
Without word designators or modifiers history references simply expand to the
entire event, so we might type `!cp' to redo the copy command or `!!|more'
if the `diff' output scrolled off the top of the screen.
History references may be insulated from the surrounding text with braces if
necessary.  For example, `!vdoc' would look for a command beginning with
`vdoc', and, in this example, not find one, but `!{v}doc' would expand
unambiguously to `vi wumpus.mandoc'.
Even in braces, history substitutions do not nest.
with `3d'; only completely numeric arguments are treated as event numbers.
This makes it possible to recall events beginning with numbers.
To select words from an event we can follow the event specification by a `:'
and a designator for the desired words.  The words of an input line are
numbered from 0, the first (usually command) word being 0, the second word
(first argument) being 1, etc.  The basic word designators are:
0
The first (command) word
^
The first argument, equivalent to `1'
$
The last argument
%
A range of words
*
Selected words are inserted into the command line separated by single blanks.
For example, the `diff' command in the previous example might have been
typed as `diff !!:1.old !!:1' (using `:1' to select the first argument
arguments from the `cp' command.  If we didn't care about the order of the
The `cp' command might have been written `cp wumpus.man !#:1.old', using `#'
to refer to the current event.
The `:' separating the event specification from the word designator can be
For example, our `diff' command might have been `diff !!^.old !!^' or,
equivalently, `diff !!$.old !!$'.  However, if `!!' is abbreviated `!',
specification.
A history reference may have a word designator but no event specification.
It then references the previous command.
Continuing our `diff' example, we could have said simply `diff
!^.old !^' or, to get the arguments in the opposite order, just `diff !*'.
The word or words in a history reference can be edited, or ``modified'',
by following it with one or more modifiers, each preceded by a `:':
h
Remove a trailing pathname component, leaving the head.
t
Remove all leading pathname components, leaving the tail.
r
Remove a filename extension `.xxx', leaving the root name.
e
Remove all but the extension.
u
Uppercase the first lowercase letter.
l
Lowercase the first uppercase letter.
The trailing delimiter may be omitted if it is immediately followed by a newline.
&
Repeat the previous substitution.
g
Apply the following modifier once to each word.
a (+)
Apply the following modifier as many times as possible to a single word.
`a' and `g' can be used together to apply a modifier globally.
With the `s' modifier, only the patterns contained in the original word are
substituted, not patterns that contain any substitution result.
p
Print the new command line but do not execute it.
q
Quote the substituted words, preventing further substitutions.
x
Like q, but break into words at blanks, tabs and newlines.
Modifiers are applied to only the first modifiable word (unless `g' is used).
It is an error for no word to be modifiable.
For example, the `diff' command might have been written as `diff wumpus.man.old
!#^:r', using `:r' to remove `.old' from the first argument on the same line
(`!#^').  We could say `echo hello out there', then `echo !*:u' to capitalize
`hello', `echo !*:au' to say it out loud, or `echo !*:agu' to really shout.
different approach).
There is a special abbreviation for substitutions.
`^', when it is the first character on an input line, is equivalent to `!:s^'.
Thus we might have said `^rot^root' to make the spelling correction in the
previous example.
This is the only history substitution which does not explicitly begin with `!'.
% man !$:t:r
man wumpus
colon may need to be insulated from it with braces:
> setenv PATH !$:h:$PATH
Bad ! modifier: $.
rather than `$'.
Finally, history can be accessed through the editor as well as through
the substitutions just described.
events in the history list and copy them into the input buffer.
expanded and literal forms of history lines in the input buffer.
in the current word and in the entire input buffer respectively.
The shell maintains a list of aliases which can be set, unset and printed by
left-to-right, is checked to see if it has an alias.  If so, the first word is
replaced by the alias.  If the alias contains a history reference, it undergoes
previous input line.  If the alias does not contain a history reference, the
argument list is left untouched.
Alias substitution is repeated until the first word of the command has no
alias.  If an alias substitution does not change the first word (as in the
previous example) it is flagged to prevent a loop.  Other loops are detected and
cause an error.
The shell maintains a list of variables, each of which has as value a list of
zero or more words.
The values of shell variables can be displayed and changed with the
The system maintains its own list of ``environment'' variables.
Read-only variables may not be modified or unset;
attempting to do so will cause an error.
Once made read-only, a variable cannot be made writable,
Environment variables cannot be made read-only.
Some variables are set by the shell or referred to by it.
list, and words of this variable's value are referred to in special ways.
Some of the variables referred to by the shell are toggles;
the shell does not care what their value is, only whether they are set or not.
Other operations treat variables numerically.  The `@' command permits numeric
calculations to be performed and the result assigned to a variable.  Variable
values are, however, always represented as (zero or more) strings.  For the
purposes of numeric operations, the null string is considered to be zero, and
the second and subsequent words of multi-word values are ignored.
After the input line is aliased and parsed, and before each command is
executed, variable substitution is performed keyed by `$' characters.  This
below) so `$' substitution does not occur there until later,
if at all.  A `$' is passed unchanged if followed by a blank, tab, or
end-of-line.
variable expanded separately.  Otherwise, the command name and entire argument
list are expanded together.  It is thus possible for the first (command) word
(to this point) to generate more than one word, the first of which becomes the
command name, and the rest of which become arguments.
Unless enclosed in `"' or given the `:q' modifier the results of variable
substitution may eventually be command and filename substituted.  Within `"', a
variable whose value consists of multiple words expands to a (portion of a)
single word, with the words of the variable's value separated by blanks.  When
the `:q' modifier is applied to a substitution the variable will expand to
multiple words with each word separated by a blank and quoted to prevent later
command or filename substitution.
The following metasequences are provided for introducing variable values into
the shell input.  Except as noted, it is an error to reference a variable which
is not set.
otherwise be part of it.  Shell variables have names consisting of
letters and digits starting with a letter.  The underscore character is
environment, then that value is returned (but some of the other forms
given below are not available in this case).
The first word of a variable's value is numbered `1'.
If the first number of a range is omitted it defaults to `1'.
It is not an error for a range to be empty if the
second argument is omitted or in range.
$0
Substitutes the name of the file from which command input
is being read.  An error occurs if the name is not known.
$*
Equivalent to `$argv', which is equivalent to `$argv[*]'.
can be applied to the substitutions above.  More than one may be used.  (+)
Braces may be needed to insulate a variable substitution from a literal colon
within the braces.
The following substitutions can not be modified with `:' modifiers.
$?0
Substitutes `1' if the current input filename is known, `0' if it is not.
Always `0' in interactive shells.
$#
Equivalent to `$#argv'.  (+)
$?
Equivalent to `$status'.  (+)
$$
Substitutes the (decimal) process number of the (parent) shell.
$!
Substitutes the (decimal) process number of the last
background process started by this shell.  (+)
$_
Substitutes the command line of the last command executed.  (+)
$<
Substitutes a line from the standard input, with no further interpretation
thereafter.  It can be used to read from the keyboard in a shell script.
typed the user may type an interrupt to interrupt the sequence into
can be used to interactively expand individual variables.
The remaining substitutions are applied selectively to the arguments of builtin
commands.  This means that portions of expressions which are not evaluated are
not subjected to these expansions.  For commands which are not internal to the
shell, the command name is substituted separately from the argument list.  This
occurs very late, after input-output redirection is performed, and in a child
of the main shell.
Command substitution is indicated by a command enclosed in ``'.  The output
from such a command is broken into separate words at blanks, tabs and newlines,
and null words are discarded.  The output is variable and command substituted
and put in place of the original string.
Command substitutions inside double
quotes (`"') retain blanks and tabs; only newlines force new words.  The single
final newline does not force a new word in any case.  It is thus possible for a
command substitution to yield only part of a word, even if the command outputs
a complete line.
By default, the shell since version 6.12 replaces all newline and carriage 
return characters in the command by spaces.  If this is switched off by
If a word contains any of the characters `*', `?', `[' or `{' or begins with
the character `~' it is a candidate for filename substitution, also known as
``globbing''.  This word is then regarded as a pattern (``glob-pattern''), and
replaced with an alphabetically sorted list of file names which match the
pattern.
In matching filenames, the character `.' at the beginning of a filename or
explicitly (unless either
or
or both are set(+)).  The character `*' matches any string of characters, 
including the null string.  The character `?' matches any single character.  
The sequence `[...]' matches any one of the characters enclosed.  
Within `[...]', a pair of
(+) Some glob-patterns can be negated:
An entire glob-pattern can also be negated with `^':
> echo *
bang crash crunch ouch
> echo ^cr*
bang ouch
Glob-patterns which do not use `?', `*', or `[]' or which use `{}' or `~'
(below) are not negated correctly.
The metanotation `a{b,c,d}e' is a shorthand for `abe ace ade'.
sorted separately at a low level to preserve this order:
(Note that `memo' was not sorted with the results of matching `*box'.)
It is not an error when this construct expands to files which do not exist,
but it is possible to get an error from a command to which the expanded list
is passed.
This construct may be nested.
As a special case the words `{', `}' and `{}' are passed undisturbed.
The character `~' at the beginning of a filename refers to home directories.
Standing alone, i.e., `~', it expands to the invoker's home directory as
user with that name and substitutes their home directory; thus `~ken' might
than at the beginning of a word, it is left undisturbed.
therefore, do home directory substitution as one might hope.
It is an error for a glob-pattern containing `*', `?', `[' or `~', with or
without `^', not to match any files.  However, only one pattern in a list of
glob-patterns must match a file (so that, e.g., `rm *.a *.c *.o' would fail
only if there were no files in the current directory ending in `.a', `.c', or
of patterns) which matches nothing is left unchanged rather than causing
an error.
recursively traversing any existing sub-directories.  For example, 
`ls **.c' will list all the .c files in the current directory tree.
If used by itself, it will match match zero or more sub-directories
in a subdirectory name or in the filename itself).
To prevent problems with recursion, the `**' glob-pattern will not 
descend into a symbolic link containing a directory.  To override this,
use `***' (+)
used to interactively expand individual filename substitutions.
The directory stack is a list of directories, numbered from zero, used by the
store the directory stack automatically on logout and restore it on login.
set to put arbitrary directories into the directory stack.
The character `=' followed by one or more digits expands to an entry in
the stack.  For example,
> echo =1
editor command apply to directory stack as well as filename substitutions.
There are several more transformations involving filenames, not strictly
related to the above but mentioned here for completeness.
Quoting prevents this expansion, and
full paths on demand.
This is not a substitution at all, but an abbreviation recognized by only
those commands.  Nonetheless, it too can be prevented by quoting.
The next three sections describe how the shell executes commands and
deals with their input and output.
A simple command is a sequence of words, the first of which specifies the
command to be executed.  A series of simple commands joined by `|' characters
forms a pipeline.  The output of each command in a pipeline is connected to the
input of the next.
Simple commands and pipelines may be joined into sequences with `;', and will
be executed sequentially.  Commands and pipelines can also be joined into
sequences with `||' or `&&', indicating, as in the C language, that the second
is to be executed only if the first fails or succeeds respectively.
A simple command, pipeline or sequence may be placed in parentheses, `()',
to form a simple command, which may in turn be a component of a pipeline or
sequence.  A command, pipeline or sequence can be executed
without waiting for it to terminate by following it with an `&'.
Builtin commands are executed within the shell.  If any component of a
pipeline except the last is a builtin command, the pipeline is executed
in a subshell.
Parenthesized commands are always executed in a subshell.
(cd; pwd); pwd
(printing this after the home directory), while
cd; pwd
When a command to be executed is found not to be a builtin command the shell
hashes the names in these directories into an internal table so that it will
command resides there.  This greatly speeds command location when a large
number of directories are present in the search path. This hashing mechanism is
not used:
In the above four cases the shell concatenates each component of the path
vector with the given command name to form a path name of a file which it
then attempts to execute it. If execution is successful, the search stops.
If the file has execute permissions but is not an executable to the system
(i.e., it is neither an executable binary nor a script that specifies its
interpreter), then it is assumed to be a file containing shell commands and
to specify an interpreter other than the shell itself.
On systems which do not understand the `#!' script interpreter convention
variable.  If so, the shell checks the first line of the file to
file to it on standard input.
The standard input and standard output of a command may be redirected with the
following syntax:
expanded) as the standard input.
is not subjected to variable, filename or command substitution, and each input
and newlines preserved, except for the final newline which is dropped.  The
resultant text is placed in an anonymous temporary file which is given to the
command as standard input.
then it is created; if the file exists, it is truncated, its previous contents
being lost.
This helps prevent accidental destruction of files.  In this case the `!' forms
can be used to suppress this check.
The forms involving `&' route the diagnostic output into the specified file as
input filenames are.
A command receives the environment in which the shell was invoked as modified
by the input-output parameters and the presence of the command in a pipeline.
Thus, unlike some previous shells, commands run from a file of shell commands
have no access to the text of the commands by default; rather they receive the
original standard input of the shell.  The `<<' mechanism should be used to
present inline data.  This permits shell command scripts to function as
components of pipelines and allows the shell to block read its input.  Note
If this is a terminal and if the process attempts to read from the terminal,
Diagnostic output may be directed through a pipe with the standard output.
Simply use the form `|&' rather than just `|'.
The shell cannot presently redirect diagnostic output without also redirecting
Having described how the shell accepts, parses and executes
command lines, we now turn to a variety of its useful features.
The shell contains a number of commands which can be used to regulate the
flow of control in command files (shell scripts) and (in limited but
useful ways) from terminal input.  These commands all operate by forcing the
shell to reread or skip in its input and, due to the implementation,
restrict the placement of some of the commands.
keywords appear in a single simple command on an input line as shown below.
If the shell's input is not seekable, the shell buffers up input whenever
a loop is being read and performs seeks in this internal buffer to
accomplish the rereading implied by the loop.  (To the extent that this
use expressions with a common syntax.  The expressions can include any
builtin command (q.v.) has its own separate syntax.
These operators are similar to those of C and have the same precedence.
They include
||  &&  |  ^  &  ==  !=  =~  !~  <=  >=
Here the precedence increases to the right, `==' `!=' `=~' and `!~', `<='
groups, at the same level.  The `==' `!=' `=~' and `!~' operators compare
their arguments as strings; all others operate on numbers.  The operators
`=~' and `!~' are like `!=' and `==' except that the right hand side is a
builtin command in shell scripts when all that is really needed is
pattern matching.
Null or
missing arguments are considered `0'.  The results of all expressions are
strings, which represent decimal numbers.  It is important to note that
no two components of an expression can appear in the same word; except
when adjacent to components of expressions which are syntactically
significant to the parser (`&' `|' `<' `>' `(' `)') they should be
surrounded by spaces.
Commands can be executed in expressions and their exit status
returned by enclosing them in braces (`{}').  Remember that the braces should
be separated from the words of the command by spaces.  Command executions
succeed, returning true, i.e., `1', if the command exits with status 0,
otherwise they fail, returning false, i.e., `0'.  If more detailed status
information is required then the command should be executed outside of an
Read access
Write access
Execute access
Existence
Ownership
Zero size
Non-zero size (+)
Plain file
Directory
Symbolic link (+) *
Block special file (+)
Character special file (+)
Named pipe (fifo) (+) *
Socket special file (+) *
Set-user-ID bit is set (+)
Set-group-ID bit is set (+)
Sticky bit is set (+)
for a terminal device (+)
Has been migrated (Convex only) (+)
Applies subsequent operators in a multiple-operator test to a symbolic link
rather than to the file to which the link points (+) *
does not exist or is inaccessible or, for the operators indicated by `*',
if the specified file type does not exist on the current system,
then all enquiries return false, i.e., `0'.
(returns `1') for plain executable files, but not for directories.
to a symbolic link rather than to the file to which the link points.
in a multiple-operator test; see below.
It is possible but not useful, and sometimes misleading, to combine operators
can lead to particularly strange results.
Other operators return other information, i.e., not just `0' or `1'.  (+)
Last file access time, as the number of seconds since the epoch
Last file modification time
Last inode modification time
Device number
Inode number
The name of the file pointed to by a symbolic link
Number of (hard) links
Permissions, in octal, without leading zero
and `0' if by neither
Numeric userid
Username, or the numeric userid if the username is unknown
Numeric groupid
Groupname, or the numeric groupid if the groupname is unknown
Size, in bytes
Only one of these operators may appear in a multiple-operator test, and it
elsewhere in a multiple-operator test.  Because `0' is a valid return value
for many of these operators, they do not return `0' when they fail: most
variable), the result of a file inquiry is based on the permission bits of
ordinarily allow writing but which is on a file system mounted read-only,
the test will succeed in a POSIX shell but fail in a non-POSIX shell.
command (q.v.) (+).
numbers.  When a job is started asynchronously with `&', the shell prints a
line which looks like
[1] 1234
indicating that the job which was started asynchronously was job number 1 and
had one (top-level) process, whose process id was 1234.
If you are running a job and wish to do something else you may hit the suspend
key (usually `^Z'),
which sends a STOP signal to the current job.  The shell will then normally
indicate that the job has been `Suspended' and print another prompt.
You can then manipulate the state of the suspended job.
You can put it in the
A `^Z' takes effect immediately and is like an interrupt
in that pending output and unread input are discarded when it is typed.
jobs to complete.
The `^]' key sends a delayed suspend signal, which does not generate a STOP
This can usefully be typed ahead when you have prepared some commands for a
job which you wish to stop after it has read them.
`^Y' is an editing command.  (+)
A job being run in the background stops if it tries to read from the
terminal.  Background jobs are normally allowed to produce output, but this can
be disabled by giving the command `stty tostop'.  If you set this tty option,
then background jobs will stop when they try to produce output like they do
when they try to read input.
There are several ways to refer to jobs in the shell.  The character `%'
introduces a job name.  If you wish to refer to job number 1, you can name it
as `%1'.  Just naming a job brings it to the foreground; thus `%1' is a synonym
for `fg %1', bringing job 1 back into the foreground.  Similarly, saying `%1 &'
resumes job 1 in the background, just like `bg %1'.  A job can also be named
by an unambiguous prefix of the string typed in to start it: `%ex' would
job whose name began with the string `ex'.  It is also possible to say
is only one such job.
The shell maintains a notion of the current and previous jobs.  In output
pertaining to jobs, the current job is marked with a `+' and the previous job
to the previous job.
on some systems.  It is an artifact from a `new' implementation of the tty
driver which allows generation of interrupt characters from the keyboard to
details on setting options in the new tty driver.
The shell learns immediately whenever a process changes state.  It normally
informs you whenever a job becomes blocked so that no further progress is
possible, but only right before it prints a prompt.  This is done so that it
does not otherwise disturb your work.  If, however, you set the shell variable
single process so that its status changes will be immediately reported.  By
starting a background job to mark it.
When you try to leave the shell while jobs are stopped, you will be
see what they are.  If you do this or immediately try to exit again, the shell
will not warn you a second time, and the suspended jobs will be terminated.
There are various ways to run commands and take other actions automatically
at various times in the ``life cycle'' of the shell.  They are summarized here,
to be executed by the shell at a given time.
minutes, before each prompt, before each command gets executed, after each
command gets executed, and when a job is started or is brought into the
foreground.
after a given number of minutes of inactivity.
of commands which exit with a status other than zero.
typed, if that is really what was meant.
command after the completion of any process that takes more than a given
number of CPU seconds.
on those users at any time.
The shell is eight bit clean
and thus supports character sets needing this capability.
NLS support differs depending on whether or not
In either case, 7-bit ASCII is the default character code
(e.g., the classification of which characters are printable) and sorting,
causes a check for possible changes in these respects.
(e.g., a 'en_CA.UTF-8' would yield "UTF-8" as a character code).
environment variables; refer to the system documentation for further details.
When not using the system's NLS, the shell simulates it by assuming that the
ISO 8859-1 character set is used
their values.  Sorting is not affected for the simulated NLS.
In addition, with both real and simulated NLS, all printable
left alone.
is set.  This may be useful for the simulated NLS or a primitive real NLS
is of course still possible.
Unknown characters (i.e., those that are neither printable nor control
If the tty is not in 8 bit mode, other 8 bit characters are printed by
converting them to ASCII and using standout mode.  The shell
use a meta key) may need to explicitly set
A number of new builtin commands are provided to support features in
particular operating systems.  All are described in detail in the
On systems that support TCF (aix-ibm370, aix-ps2),
prints the site on which each job is executing.
operating system.
universe.
indicate respectively the vendor, operating system and machine type
(microprocessor class or machine model) of the
system on which the shell thinks it is running.
These are particularly useful when sharing one's home directory between several
types of machines; one can, for example,
appropriate directory.
variable indicates what options were chosen when the shell was compiled.
Login shells catch the terminate signal, but non-login shells inherit the
terminate behavior from their parents.
Other signals have the values which the shell inherited from its parent.
In shell scripts, the shell's handling of interrupt and terminate signals
default, the shell's children do too, but the shell does not send them a
The shell uses three different sets of terminal (``tty'') modes:
`edit', used when editing, `quote', used when quoting literal characters,
and `execute', used when executing commands.
The shell holds some settings in each mode constant, so commands which leave
the tty in a confused state do not interfere with the shell.
The shell also matches changes in the speed and padding of the tty.
The list of tty modes that are kept constant
Note that although the editor uses CBREAK mode (or its equivalent),
it takes typed-ahead characters anyway.
manipulate and debug terminal capabilities from the command line.
On systems that support SIGWINCH or SIGWINDOW, the shell
adapts to window resizing automatically and adjusts the environment
them to reflect the new window size.
The next sections of this manual describe all of the available
Does nothing, successfully.
The first form prints the values of all shell variables.
must already exist.
Without arguments, prints all aliases.
Shows the amount of dynamic memory acquired, broken down into used and free
memory.  With an argument shows the number of free and used blocks in each size
category.  The categories start at size 8 and double at each step.  This
command's output may vary across system types, because systems other than the VAX
may use a different memory allocator.
Puts the specified jobs (or, without arguments, the current job)
into the background, continuing each if it is stopped.
Without options, the first form lists all bound keys and the editor command to which each is bound,
Options include:
Lists all editor commands and a short description of each.
Binds all keys to the standard bindings for the default editor.
Binds all keys to the standard GNU Emacs-like bindings.
Lists or changes key-bindings in the alternative key map.
`down', `up', `left' or `right'.
editor command.
reinterpreted, and this continues for ten levels of interpretation.
Prints a usage message.
If a command is bound to a string, the first character of the string is bound to
written caret-character style, e.g., `^A'.  Delete is written `^?'
Bell
Backspace
Escape
Form feed
Newline
Carriage return
Horizontal tab
Vertical tab
execution. Only non-interactive commands can be executed, and it is
not possible to execute any command that would overlay the image
current line are executed.  Multi-level breaks are thus
possible by writing them all on one line.
Prints the names of all builtin commands.
Available only if the shell was so compiled;
Without arguments, lists all completions.
is to be completed, and may be one of the following:
Current-word completion.
Next-word completion.
the command line.
Position-dependent completion.
variables, which must include the current word.
Aliases
Bindings (editor commands)
Commands (builtin or external commands)
External commands which begin with the supplied path prefix
Directories
Directories which begin with the supplied path prefix
Environment variables
Filenames
Filenames which begin with the supplied path prefix
Groupnames
Jobs
Limits
Nothing
Shell variables
Signals
Plain (``text'') files
Plain (``text'') files which begin with the supplied path prefix
Any variables
Usernames
Completions
(...)
Words from the given list
`...`
Words from the output of command
completion.  If null, no character is appended.  If omitted (in which
case the fourth delimiter can also be omitted), a slash is appended to
directories and a space to other words.
contains (as its name indicates) contents of the current (already
typed in) command line. One can examine and use contents of the
sophisticated completions (see completion for svn(1) included in
this package).
Now for some examples.  Some commands take only directories as arguments,
so there's no point completing plain files.
> co[^D]
complete compress
> co[^D]
> compress
which begin with `co' (thus matching `co*') to `compress' (the only
word in the list).
ambiguous commands.
These complete words following `alias' with aliases, `man' with commands,
and `set' with shell variables.
is attempted and prints `Truth has no options.' when completion choices are listed.
Words can be completed from a variable evaluated at completion time,
> set hostnames = (rtfm.mit.edu tesla.ee.cornell.edu)
> ftp [^D]
rtfm.mit.edu tesla.ee.cornell.edu
> ftp [^C]
> set hostnames = (rtfm.mit.edu tesla.ee.cornell.edu uunet.uu.net)
> ftp [^D]
rtfm.mit.edu tesla.ee.cornell.edu uunet.uu.net
or from a command run at completion time:
23113 23377 23380 23406 23429 23529 23530 PID
so the braces, space and `$' in `{print $1}' must be quoted explicitly.
One command can have multiple completions:
completes the second argument to `dbx' with the word `core' and all other
arguments with commands.  Note that the positional completion is specified
before the next-word completion.
Because completions are evaluated from left to right, if
the next-word completion were specified first it would always match
and the positional completion would never be executed.  This is a
common mistake when defining a completion.
particular forms as arguments.  For example,
completes `cc' arguments to files ending in only `.c', `.a', or `.o'.
to exclude precious source code from `rm' completion.  Of course, one
could still type excluded names manually or override the completion
editor commands (q.v.).
restrict completion to files beginning with a particular path prefix.  For
example, the Elm mail program uses `=' as an abbreviation for one's mail
directory.  One might use
`$HOME' instead of `~' because home directory substitution works at only the
beginning of a word.
completes arguments to `finger' from the list of users, appends an `@',
and then completes after the `@' from the `hostnames' variable.  Note
again the order in which the completions are specified.
Finally, here's a complex example for inspiration:
(note the pattern which matches both) to files,
and `group' to users and groups respectively
given lists.  It also completes the switches themselves from the given list
and completes anything not otherwise completed to a directory.  Whew.
Remember that programmed completions are ignored if the word being completed
is a tilde substitution (beginning with `~') or a variable (beginning with `$').
in future versions of the shell.
The rest of the commands on the current line are executed.
The first form prints the directory stack.  The top of the stack is at the
left and the first directory in the stack is the current directory.
mechanism.
The last form clears the directory stack.
output, separated by spaces and terminated with a newline.
For example, 'echotc home' sends the cursor to the home position,
in the status line.
value of that capability ("yes" or "no" indicating that the terminal does
or does not have that capability).  One might use this to make the output
from a shell script less verbose on slow terminals, or limit command
output to the number of lines on the screen:
> set history=`echotc lines`
Termcap strings may contain wildcards which will not echo correctly.
One should use double quotes when setting a shell variable to a terminal
capability string, as in the following example that places the date in
the status line:
> set tosl="`echotc ts 0`"
> set frsl="`echotc fs`"
than causing an error.
Treats the arguments as input to the
shell and executes the resulting command(s) in the context
of the current shell.  This is usually used to execute commands
generated as the result of command or variable substitution,
because parsing occurs before these substitutions.
Executes the specified command in place of the current shell.
Brings the specified jobs (or, without arguments, the current job)
into the foreground, continuing each if it is stopped.
space-separated list.
must appear alone on separate lines.)  The builtin command
When this command is read from the terminal, the loop is read once
the loop are executed.  If you make a mistake typing in a
loop at the terminal you can rub it out.
Prints the system execution path.  (TCF only)
Prints the experimental version prefix.  (TCF only)
delimited by null characters in the output.  Useful for
programs which wish to use the shell to filename expand a list of words.
yield a string of the form `label'.  The shell rewinds its
input as much as possible, searches for a line of the
form `label:', possibly preceded by blanks or tabs, and
continues execution after that line.
Prints a statistics line indicating how effective the
internal hash table has been at locating commands (and avoiding
hash buckets.
The first form prints the history event list.
(This can be used to
first rather than oldest first.
number, at most that many lines are saved.  If the second word of
existing history file instead of replacing it (if there is one) and
sorted by time stamp.  (+) Merging is intended for an environment like
the X Window System
with several shells in simultaneous use.  Currently it succeeds
only when the shells quit nicely one after another.
to the history list.
into the history list and sorted by timestamp.
filename.
(unexpanded) form of the history list.
The last form clears the history list.
signal and arranges for the shell to send it a hangup signal when the shell
exits.
Without an argument, causes the non-interactive shell only to
exit on a hangup for the remainder of the script.
or a parenthesized command list, but it may have arguments.
IDs in addition to the normal information.  On TCF systems, prints
the site on which each job is executing.
is given, the TERM (terminate) signal) to the specified jobs or processes.
Signals are either given by number or by name (as given in
to the current job.  If the signal being sent is TERM (terminate)
or HUP (hangup), then the job or process is sent a
CONT (continue) signal as well.
The third form lists the signal names.
Limits the consumption by the current process and each
hard limits are used instead of the current limits.  The
hard limits impose a ceiling on the values of the current
limits.  Only the super-user may raise the hard limits, but
a user may lower or raise the current limits within the legal range.
Controllable resources currently include (if supported by the OS):
the maximum number of cpu-seconds to be used by each process
the largest single file which can be created
the maximum growth of the data+stack region via sbrk(2) beyond
the end of the program text
the maximum size of the automatically-extended stack region
the size of the largest core dump that will be created
the maximum amount of physical memory a process
may have allocated to it at a given time
the maximum amount of virtual memory a process
may have allocated to it at a given time (address space)
the maximum amount of virtual memory a process
may have allocated to it at a given time
the maximum amount of memory a process
the maximum number of open files for this process
the maximum number of threads for this process
the maximum size which a process may lock into memory using mlock(2)
the maximum number of simultaneous processes for this user id
the maximum size of socket buffer usage for this user
the maximum amount of swap space reserved or used for this user
the maximum number of locks for this user
the maximum number of pending signals for this user
the maximum number of bytes in POSIX mqueues for this user
the maximum nice priority the user is allowed to raise mapped from [19...-20]
to [0...39] for this user
the maximum realtime priority for this user
the timeout for RT tasks in microseconds for this user.
integer) number followed by a scale factor.  For all limits
(1024 bytes); a scale factor of `m' or `megabytes' or `g' or `gigabytes'
while `m' for minutes or `h' for hours, or a time of the
form `mm:ss' giving minutes and seconds may be used.
prefixes of the names suffice.
Terminates a login shell, replacing it with an instance of
special file in the listing with a special character:
Directory
*
Executable
#
Block device
%
Character device
|
Named pipe (systems with named pipes only)
=
Socket (systems with sockets only)
@
Symbolic link (systems with symbolic links only)
+
:
in more detail (on only systems that have them, of course):
@
Symbolic link to a non-directory
>
Symbolic link to a directory
&
Symbolic link to nowhere
files pointed to by symbolic links to be mounted.
The first form migrates the process or job to the site specified or the
default site determined by the system path.
current process to the specified site.  Migrating the shell
itself can cause unexpected behavior, because the shell
does not like to lose its tty.  (TCF only)
Available only if the shell was so compiled;
priority.
the process gets.  The super-user may specify negative
executed in a sub-shell, and the restrictions placed on
Without an argument, causes the non-interactive shell only to
ignore hangups for the remainder of the script.
Causes the shell to notify the user asynchronously when the status of any
instead of waiting until the next prompt as is usual.
Controls the action of the shell on interrupts.  Without arguments,
restores the default action of the shell on interrupts,
which is to terminate shell scripts or to return to the
terminal command input level.
when an interrupt is received or a child process terminates because it was
interrupted.
Without arguments, pops the directory stack and returns to the new top directory.
Prints the names and values of all environment variables or,
Without arguments, exchanges the top two elements of the directory stack.
from the stack before pushing it onto the stack.  (+)
directory stack around to be the top element and changes to it.
directory, pushes it onto the top of the stack and changes to it.  (+)
Causes the internal hash table of the contents of the
automatically, except in the special case where another command of
the same name which is located in a different directory already
exists in the hash table.  Also flushes the cache of home directories
built by tilde expansion.
The first form prints the scheduled-event list.
the scheduled-event list is printed.
For example,
causes the shell to echo `It's eleven o'clock.' at 11 AM.
or may be relative to the current time:
> sched
     2  Wed Apr  4 17:00  set prompt=[%h] It's after 5; go home: >
> sched
A command in the scheduled-event list is executed just before the first
prompt is printed after the time when the command is scheduled.
It is possible to miss the exact time when the command is to be run, but
an overdue command will execute at the next prompt.
A command which comes due while the shell
is waiting for user input is executed immediately.
However, normal operation of an already-running command will not
be interrupted so that a scheduled-event list element may be run.
command on some Unix systems.
Its major disadvantage is that it may not run a command at exactly the
specified time.
the shell, it has access to shell variables and other structures.
This provides a mechanism for changing one's working environment
based on the time of day.
The first form of the command prints the value of all shell variables.
Variables which contain more than a single word print as a
parenthesized word list.
this component must already exist.
The sixth form lists only the names of all shell variables that are read-only.
The eighth form is the same as the third form, but
in a single set command.  Note, however, that variable expansion
happens for all arguments before any setting occurs.  Note also that `=' can
whitespace, but cannot be adjacent to only one or the other.
Without arguments, prints the names and values of all environment variables.
Sets the system execution path.  (TCF only)
No sanity checking is done.
Concept terminal users may have to `settc xn no' to get proper
wrapping at the rightmost column.
the shell does not allow to change.
on the `edit', `quote' or `execute' set of tty modes respectively; without
The available modes, and thus the display, vary from system to system.
whether or not they are fixed.
For example, `setty +echok echoe' fixes `echok' mode on and allows commands
to turn `echoe' mode on or off, both when the shell is executing commands.
The commands are not placed on the history list.
if they are nested too deeply the shell may run out of file descriptors.
Stops the specified jobs or processes which are executing in the background.
the current job.
Causes the shell to stop in its tracks, much as if it had
Each case label is successively matched, against the
The file metacharacters `*', `?' and `[...]'  may be used
in the case labels, which are variable expanded.  If none
of the labels match before a `default' label is found, then
the execution begins after the default label.  Each case
label and the default label must appear at the beginning of
labels and default labels as in C.  If no label matches and
terminfo(5) database. Prints the terminal type to stdout and returns 0
if an entry is present otherwise returns 1.
a pipeline, a command list or a parenthesized command list)
If necessary, an extra shell is created to print the time statistic when
the command completes.
children.
Common values for the mask are
002, giving all access to the group and read and execute access to others, and
022, giving read and execute access to the group and others.
`unalias *' thus removes all aliases.
`uncomplete *' thus removes all completions.
Disables use of the internal hash table to speed location of
executed programs.
Only the super-user may do this.
`unset *' thus removes all variables unless they are read-only;
this is a bad idea.
`unsetenv *' thus removes all environment variables;
this is a bad idea.
The shell waits for all background jobs.  If the shell is interactive, an
interrupt will disrupt the wait and cause the shell to print the names and job
numbers of all outstanding jobs.
Available only if the shell was so compiled;
Displays the command that will be executed by the shell after substitutions,
evaluates non-zero.
loop prematurely.
If the input is a terminal, the user is prompted the first time
If set, each of these aliases executes automatically at the indicated time.
They are all initially undefined.
Runs when the shell wants to ring the terminal bell.
Runs after every change of working directory.  For example, if the user is
to be the name of the host, a colon, and the full current working directory.
A fancier way to do that is
This will put the hostname and working directory on the title bar but
only the hostname in the icon manager menu.
may cause an infinite loop.  It is the author's opinion that anyone doing
so will get what they deserve.
Runs before each command gets executed, or when the command changes state.
is sought is passed as sole argument.
For example, if one does
then the help display of the command itself will be invoked, using the GNU
help calling convention.
Currently there is no easy way to account for various calling conventions (e.g.,
the customary Unix `-h'), except by using a table of many commands.
checking on common but infrequent changes such as new mail.  For example,
if one does
> set tperiod = 30
> alias periodic checknews
Runs just before each prompt is printed.  For example, if one does
> alias precmd date
should be used.
Runs before each command gets executed.
Specifies the interpreter for executable scripts which do not themselves
specify an interpreter.  The first word should be a full path name to the
The variables described in this section have special meaning to the shell.
startup; they do not change thereafter unless changed by the user.  The shell
whenever the environment variable changes the shell changes the corresponding
shell variable to match (unless the shell variable is read-only) and vice
are not synchronized in this manner, and that the shell automatically
to the end of normal files when they are matched exactly.
Set by default.
the local username for kerberos authentication.
i.e., `$1' is replaced by `$argv[1]', etc.
Set by default, but usually empty in interactive shells.
each completion attempt.
only history will be expanded and a second completion will expand filenames.
If set, possibilities are listed after an ambiguous completion.
If set to `ambiguous', possibilities are listed only when no new
characters are added by completion.
The first word is the number of minutes of inactivity before automatic
logout.  The optional second word is the number of minutes of inactivity
before automatic locking.
When the shell automatically logs out, it prints `auto-logout', sets the
When the shell automatically locks, the user is required to enter his password
to continue working.  Five incorrect attempts result in automatic logout.
Set to `60' (automatic logout after 60 minutes, and no locking) by default
in login and superuser shells, but not if the shell thinks it is running
the tty is a pseudo-tty (pty) or the shell was not so compiled (see the
If set, the internal hash table of the contents of the directories in the
table.  In addition, the list of available commands will be rebuilt for each
command completion or spelling correction attempt if set to `complete' or
`correct' respectively; if set to `always', this will be done for both
cases.
scripts.
The file name of the message catalog.
If set, tcsh use `tcsh.${catalog}' as a message catalog instead of
default `tcsh'.
subdirectories if they aren't found in the current directory.
If set, it enables color escape sequence for NLS message files.
And display colorful NLS messages.
If set, the shell will evaluate expressions right to left, like the original
If set to `igncase', the completion becomes case insensitive.
If set to `enhance', completion ignores case and considers
hyphens and underscores to be equivalent; it will also treat
separators.
If set to `Enhance', completion matches uppercase and underscore
characters explicitly and matches lowercase and hyphens in a
case-insensivite manner; it will treat periods, hypens and underscores
as word separators.
If set to a list of commands, the shell will continue the listed
commands, instead of starting a new one.
Same as continue, but the shell will execute:
If set to `cmd', commands are automatically spelling-corrected.
If set to `complete', commands are automatically completed.
If set to `all', the entire command line is corrected.
If set, newlines and carriage returns in command substitution are
replaced by spaces.  Set by default.
The full pathname of the current directory.
stack rather than rotating it to the top.
An array of all the directories on the directory stack.
`$dirstack[1]' is the current working directory, `$dirstack[2]'
the first directory on the stack, etc.
Note that the current working directory is `$dirstack[1]' but `=0' in
directory stack substitutions, etc.
but the first element (the current working directory) is always correct.
If set to `euc', it enables display and editing EUC-kanji(Japanese) code.
If set to `sjis', it enables display and editing Shift-JIS(Japanese) code.
If set to `big5', it enables display and editing Big5(Chinese) code.
If set to `utf8', it enables display and editing Utf8(Unicode) code.
If set to the following format, it enables display and editing of original
multi-byte code format:
> set dspmbyte = 0000....(256 bytes)....0000
corresponds (from left to right) to the ASCII codes 0x00, 0x01, ... 0xff.  Each
character
is set to number 0,1,2 and 3.  Each number has the following meaning:
  0 ... not used for multi-byte characters.
  1 ... used for the first byte of a multi-byte character.
  2 ... used for the second byte of a multi-byte character.
  3 ... used for both the first byte and second byte of a multi-byte character.
  Example:
If set to `001322', the first character (means 0x00 of the ASCII code) and
second character (means 0x01 of ASCII code) are set to `0'.  Then, it is not
used for multi-byte characters.  The 3rd character (0x02) is set to '1',
indicating that it is used for the first byte of a multi-byte character.
The 4th character(0x03) is set '3'.  It is used for both the first byte and
the second byte of a multi-byte character.  The 5th and 6th characters
(0x04,0x05) are set to '2', indicating that they are used for the second
byte of a multi-byte character.
The GNU fileutils version of ls cannot display multi-byte
filenames without the -N ( --literal ) option.   If you are using
this version, set the second word of dspmbyte to "ls".  If not, for
example, "ls-F -l" cannot display multi-byte filenames.
  Note:
This variable can only be used if KANJI and DSPMBYTE has been defined at
compile time.
from the stack before pushing it onto the stack.
If set, each command with its arguments is echoed just before it is
executed.  For non-builtin commands all expansions occur before
echoing.  Builtin commands are echoed before command and filename
substitution, because these substitutions are then done selectively.
bsd
sysv
Recognize backslashed escape sequences in echo strings.
both
none
Recognize neither.
Set by default to the local system default.  The BSD and System V
systems.
If set, the command-line editor is used.  Set by default in interactive
shells.
shell variable) indicate skipped directories with an ellipsis (`...')
The user's effective user ID.
The first matching passwd entry name corresponding to the effective user ID.
Lists file name suffixes to be ignored by completion.
by default. If 
The user's real group ID.
If set, wild-card glob patterns will match files and directories beginning
with `.' except for `.' and `..'
If set, the `**' and `***' file glob patterns will match any string of 
`ls **.c' will list all the .c files in the current directory tree).
If used by itself, it will match match zero or more sub-directories
To prevent problems with recursion, the `**' glob-pattern will not 
descend into a symbolic link containing a directory.  To override this,
use `***'
The user's group name.
highlighted in reverse video.
Highlighting requires more frequent terminal writes, which introduces extra
overhead. If you care about terminal performance, you may want to leave this
unset.
the history substitution character, replacing the default character
`!'.  The second character of its value replaces the character `^' in
quick substitutions.
Controls handling of duplicate entries in the history list.  If set to
`all' only unique history events are entered in the history list.  If
set to `prev' and the last history event is the same as the current
command, then the current command is not entered in the history.  If
set to `erase' and the same event is found in the history list, that
old event gets erased and the current one gets inserted.  Note that the
`prev' and `all' options renumber history events so there are no gaps.
useful when sharing the same home directory between different machines,
or when saving separate histories on different terminals.  Because only
use the literal (unexpanded) form of lines in the history list.  See
The first word indicates the number of history events to save.  The
optional second word (+) indicates the format in which history is
`%R'.  Set to `100' by default.
Initialized to the home directory of the invoker.  The filename
If set to the empty string or `0' and the input device is a terminal,
`^D' on an empty line) causes the shell to print `Use "exit" to leave
tcsh.' instead of exiting.  This prevents the shell from accidentally
being killed.  Historically this setting exited after 26 successive
single `^D'.
If set, the shell treats a directory name typed as a command as though
the change of directory is echoed to the standard output.  This behavior
is inhibited in non-interactive shell scripts, or for command strings
with more than one word.  Changing directory takes precedence over
executing a like-named command, but it is done after alias
substitutions.  Tilde and variable expansions work as expected.
If set to `insert' or `overwrite', puts the editor into that input mode
at the beginning of each line.
Controls handling of duplicate entries in the kill ring.  If set to
`all' only unique strings are entered in the kill ring.  If set to
`prev' and the last killed string is the same as the current killed
string, then the current string is not entered in the ring.  If set
to `erase' and the same string is found in the kill ring, the old
string is erased and the current one is inserted.
Indicates the number of killed strings to keep in memory.  Set to `30'
by default.  If unset or set to less than `2', the shell will only
keep the most recently killed string.
Strings are put in the killring by the editor commands that delete
can be used to yank earlier killed strings.
If set to `x', `a' or `A', or any combination thereof (e.g., `xA'), they
files (even if they start with a `.'), `A' shows all files but `.' and
`..', and `x' sorts across instead of down.  If the second word of
If set, all jobs are listed when a job is suspended.  If set to `long',
the listing is in long format.
each symbolic link points.
will list without asking first.
command will list without asking first.
Set by the shell if it is a login shell.  Setting or unsetting it
Set by the shell to `normal' before a normal logout, `automatic' before
an automatic logout, and `hangup' if the shell was killed by a hangup
shell variable.
A list of files and directories to check for incoming mail, optionally
preceded by a numeric word.  Before each prompt, if 10 minutes have
passed since the last check, the shell checks each file and says `You
and has a modification time greater than its access time.
If you are in a login shell, then no mail file is reported unless it has
been modified after the time the shell has started up, to prevent
redundant notifications.  Most login programs will tell you whether or not
you have mail when you log in.
file within that directory as a separate message, and will report `You have
This functionality is provided primarily for those systems which store mail
in this manner, such as the Andrew Mail System.
checking interval, in seconds.
Under very rare circumstances, the shell may report `You have mail.' instead
of `You have new mail.'
If set to `never', completion never beeps.
If set to `nomatch', it beeps only when there is no match.
If set to `ambiguous', it beeps when there are multiple matches.
If set to `notunique', it beeps when there is one exact and other longer matches.
If unset, `ambiguous' is used.
If set, beeping is completely disabled.
If set, restrictions are placed on output redirection to insure that files
are not accidentally destroyed and that `>>' redirections refer to existing
specifiers at the change of hour.
(q.v.) are inhibited.  This is most useful in shell scripts which do not deal
with filenames, or after a list of filenames has been obtained and further
expansions are not desirable.
it is disabled so that the meta key can be used.
(q.v.) which does not match any
existing files is left untouched rather than causing an error.
It is still an error for the substitution to be
malformed, e.g., `echo [' still gives an error.
A list of directories (or glob-patterns which match directories; see
completion operation.  This is usually used to exclude directories which
If set, the shell announces job completions asynchronously.
The default is to present job completions just before printing a prompt.
If set, enable the printing of padding '0' for hours, in 24 and 12 hour
formats.  E.G.: 07:45:42 vs. 7:45:42.
To retain compatibily with older versions numeric variables starting with
0 are not interpreted as octal. Setting this variable enables proper octal
parsing.
A list of directories in which to look for executable commands.
A null word specifies the current directory.
If set and an interactive program exits with a non-zero status, the shell
The string which is printed before reading each command from the terminal.
are replaced by the given information:
The current working directory.
%~
The current working directory, but with one's home directory
represented by `~' and other users' home directories represented by
in the current session.
are represented by an ellipsis so the whole becomes `...trailing'.
`~' substitution is done as in `%~' above, but the `~' component
is ignored when counting trailing components.
%C
Like %c, but without `~' substitution.
%h, %!, !
The current history event number.
%M
The full hostname.
%m
The hostname up to the first `.'.
%S (%s)
Start (stop) standout mode.
%B (%b)
Start (stop) boldfacing mode.
%U (%u)
Start (stop) underline mode.
%t, %@
%T
%p
%P
%%
A single `%'.
%n
The user name.
%N
The effective user name.
%j
The number of jobs.
%d
The weekday in `Day' format.
%D
The day in `dd' format.
%w
The month in `Mon' format.
%W
The month in `mm' format.
%y
The year in `yy' format.
%Y
The year in `yyyy' format.
%l
The shell's tty.
%L
Clears from the end of the prompt to end of the display or the end of the line.
%$
Expands the shell or environment variable name immediately after the `$'.
%#
for the superuser.
It should be used only to change terminal attributes and
should not move the cursor location.  This
%?
The return code of the command executed just before the prompt.
%R
The bold, standout and underline sequences are often used to distinguish a
superuser shell.  For example,
then print `DING!' on the change of hour (i.e, `:00' minutes) instead of
the actual time.
Set by default to `%# ' in interactive shells.
note the variable meaning of `%R'.
Set by default to `%R? ' in interactive shells.
The string with which to prompt when confirming automatic spelling correction.
note the variable meaning of `%R'.
Set by default to `CORRECT>%R (y|n|e|a)? ' in interactive shells.
If set (to a two-character string), the `%#' formatting sequence in the
normal users and the second character for the superuser.
If set, completion completes on an exact match even if a longer match is
possible.
If set, command listing displays only files in the path that are
executable.  Slow.
If set, the user is prompted before `rm *' is executed.
The string to print on the right-hand side of the screen (after
the command input) when the prompt is being displayed on the left.
It will automatically disappear and reappear as necessary, to ensure that
command input isn't obscured, and will appear only if the prompt,
command input, and itself will fit together on the first line.
the prompt and before the command input.
If the first word is set to a number, at most that many directory stack
entries are saved.
If the first word is set to a number, at most that many lines are saved.
If the second word is set to `merge', the history list is merged with
the existing history file instead of replacing it (if there is one) and
sorted by time stamp and the most recent events are retained.  (+)
note the variable meaning of `%R'.
The file in which the shell resides.  This is used in forking
shells to interpret files which have execute bits set, but
which are not executable by the system.  (See the description
(system-dependent) home of the shell.
The number of nested shells.
Reset to 1 in login shells.
The status returned by the last command, unless the variable
is set, and any error in a pipeline or a backquote expansion will be
propagated (this is the default
behavior, and the current
default). If it terminated
abnormally, then 0200 is added to the status.  Builtin commands
which fail return exit status `1', all other builtin commands
return status `0'.
Can be set to several different values to control symbolic link (`symlink')
resolution:
If set to `chase', whenever the current directory changes to a directory
containing a symbolic link, it is expanded to the real name of the directory
to which the link points.  This does not work for the user's home directory;
this is a bug.
If set to `ignore', the shell tries to construct a current directory
relative to the current directory before the link was crossed.
returns one to the original directory.  This affects only builtin commands
and filename completion.
If set to `expand', the shell tries to fix symbolic links by actually expanding
arguments which look like path names.  This affects any command, not just
builtins.  Unfortunately, this does not work for hard-to-recognize filenames,
such as those embedded in command options.  Expansion may be prevented by
quoting.  While this setting is usually the most convenient, it is sometimes
misleading and sometimes confusing when it fails to recognize an argument
which should be expanded.  A compromise is to use `ignore' and use the
Some examples are in order.  First, let's set up some play directories:
> cd ..; echo $cwd
> cd ..; echo $cwd
> cd ..; echo $cwd
> cd ..; echo $cwd
> cd ".."; echo $cwd
Note that `expand' expansion 1) works just like `ignore' for builtins
filenames are passed to non-builtin commands.
The version number of the shell in the format `R.VV.PP',
where `R' is the major release number, `VV' the current version
and `PP' the patchlevel.
after each command which takes more than that many CPU seconds.
If there is a second word, it is used as a format string for the output
format string:
%U
The time the process spent in user mode in cpu seconds.
%S
The time the process spent in kernel mode in cpu seconds.
%E
The elapsed (wall clock) time in seconds.
%P
%W
Number of times the process was swapped.
%X
The average amount in (shared) text space used in Kbytes.
%D
%K
The total space used (%X + %D) in Kbytes.
%M
The maximum memory the process had in use at any time in Kbytes.
%F
The number of major page faults (page needed to be brought from disk).
%R
The number of minor page faults.
%I
The number of input operations.
%O
The number of output operations.
%r
The number of socket messages received.
%s
The number of socket messages sent.
%k
The number of signals received.
%w
The number of voluntary context switches (waits).
%c
The number of involuntary context switches.
Only the first four sequences are supported on systems without BSD resource
limit functions.
The default time format is `%Uu %Ss %E %P %X+%Dk %I+%Oio %Fpf+%Ww' for
systems that support resource usage reporting and `%Uu %Ss %E %P' for
systems that do not.
available, but the following additional sequences are:
%Y
The number of system calls performed.
%Z
The number of pages which are zero-filled on demand.
%i
The number of times a process's resident set size was increased by the kernel.
%d
The number of times a process's resident set size was decreased by the kernel.
%l
The number of read system calls performed.
%m
The number of write system calls performed.
%p
The number of reads from raw disk devices.
%q
The number of writes to raw disk devices.
and the default time format is `%Uu %Ss %E %P %I+%Oio %Fpf+%Ww'.
Note that the CPU percentage can be higher than 100% on multi-processors.
The name of the tty, or empty if not attached to one.
The user's real user ID.
The user's login name.
If set, causes the words of each
command to be printed, after history substitution (if any).
list of options which were set at compile time.
Options which are set by default in the distribution are noted.
8b
The shell is eight bit clean; default
7b
The shell is not eight bit clean
wide
The shell is multibyte encoding clean (like UTF-8)
nls
The system's NLS is used; default for systems with NLS
lf
dl
nd
vi
dtr
Login shells drop DTR when exiting
bye
al
kan
Kanji is used if appropriate according to locale settings,
sm
hb
The `#!<program> <args>' convention is emulated when executing shell scripts
ng
rh
afs
The shell verifies your password with the kerberos server if local
An administrator may enter additional strings to indicate differences
in the local version.
If set, a screen flash is used rather than the audible bell.
If either the user is `any' all terminals are watched for the given user
and vice versa.
For example,
set watch = (george ttyd1 any console $user any)
reports activity of the user `george' on ttyd1, any user on the console, and
oneself (or a trespasser) on any terminal.
Logins and logouts are checked every 10 minutes by default, but the first
For example,
set watch = (1 any any)
are replaced by the given information:
%n
%a
%l
%M
from the local host.
%m
The hostname of the remote host up to the first `.'.
The full name is printed if it is an IP address or an X Window System display.
%M and %m are available on only systems that store the remote hostname in
If unset, `%n has %a %l from %m.' is used, or `%n has %a %l.' on systems
which don't store the remote hostname.
A list of non-alphanumeric characters to be considered part of a word by the
The pathname to a default editor.
Initialized to the name of the machine on which the shell
Initialized to the type of machine on which the shell
is running, as determined at compile time.  This variable is obsolete and
will be removed in a future version.
command looks for command documentation.
Gives the preferred character environment.
If set, only ctype character handling is changed.
file format; a colon-separated list of expressions of the form
variables with their associated defaults are:
no	0
Normal (non-filename) text
fi	0
Regular file
di	01;34
Directory
ln	01;36
Symbolic link
pi	33
Named pipe (FIFO)
so	01;35
Socket
do	01;35
Door
bd	01;33
Block device
cd	01;32
Character device
ex	01;32
Executable file
mi	(none)
Missing file (defaults to fi)
or	(none)
Orphaned symbolic link (defaults to ln)
lc	^[[
Left code
rc	m
Right code
ec	(none)
End code (replaces lc+no+rc)
You need to include only the variables you want to change from
the default.
File names can also be colorized based on filename extension.
to use, but less general.  The left, right and end codes are
provided so you don't have to type common parts over and over
again and to support weird terminals; you will generally not
need to change them at all unless your terminal does not use
ISO 6429 color sequences but a different system.
If your terminal does use ISO 6429 color codes, you can
most common commands are:
0
to restore default color
1
for brighter colors
4
for underlined text
5
for flashing text
30
for black foreground
31
for red foreground
32
for green foreground
33
for yellow (or brown) foreground
34
for blue foreground
35
for purple foreground
36
for cyan foreground
37
for white (or gray) foreground
40
for black background
41
for red background
42
for green background
43
for yellow (or brown) background
44
for blue background
45
for purple background
46
for cyan background
47
for white (or gray) background
Not all commands will work on all systems or display devices.
A few terminal programs do not recognize the default end code
properly.  If all text gets colorized after you do a directory
numerical codes for your standard fore- and background colors.
The machine type (microprocessor class or machine model), as determined at compile time.
The operating system, as determined at compile time.
A colon-separated list of directories in which to look for executables.
updated only after an actual directory change.
The host from which the user has logged in remotely, if this is the case and
the shell is able to determine it.  Set only if the shell was so compiled;
The vendor, as determined at compile time.
The pathname to a default full-screen editor.
Read first by every shell.
Read by login shells at logout.
Used to interpret shell scripts not starting with a `#'.
Temporary file for `<<'.
Source of home directories for `~name' substitutions.
The order in which startup files are read may differ if the shell was so
Programmable, interactive word completion and listing.
builtin commands.
An enhanced history mechanism.  Events in the history list are time-stamped.
the previously undocumented `#' event specifier and new modifiers
Enhanced directory parsing and directory stack handling.
builtin which uses them.
scheduled events, special aliases, automatic logout and terminal locking,
command timing and watching for logins and logouts.
Support for the Native Language System
OS variant features
New variables that make useful information easily available to the shell.
variables.
A new syntax for including useful information in the prompt string
and special prompts for loops and spelling correction
When a suspended command is restarted, the shell prints the directory
it started in if this is different from the current directory.  This can
be misleading (i.e., wrong) as the job may have changed directories internally.
of the form `a ; b ; c' are also not handled gracefully when stopping is
attempted.  If you suspend `b', the shell will then immediately execute
`c'.  This is especially noticeable if this expansion results from an
to a subshell, i.e., `( a ; b ; c )'.
Control over tty output after processes are started is primitive; perhaps
this will inspire someone to work on a good virtual terminal interface.
In a virtual terminal interface much more interesting things could be
done with output control.
Alias substitution is most often used to clumsily simulate shell procedures;
shell procedures should be provided rather than aliases.
Control structures should be parsed rather than being recognized as
built-in commands.  This would allow control commands to be placed anywhere,
to be combined with `|', and to be used with `&' and `;' metasyntax.
It should be possible to use the `:' modifiers on the output of command
substitutions.
The screen update for lines longer than the screen width is very poor
if the terminal cannot move the cursor up (i.e., terminal type `dumb').
Glob-patterns which do not use `?', `*' or `[]' or which use `{}' or `~'
are not negated correctly.
the expression is false and the command is not executed.
and does not handle control characters in filenames well.  It cannot be
interrupted.
Command substitution supports multiple commands and conditions, but not
help maintain and test tcsh, send mail to tcsh-request@mx.gw.com with the
text `subscribe tcsh' on a line by itself in the body.
In 1964, DEC produced the PDP-6.  The PDP-10 was a later re-implementation.  It
was re-christened the DECsystem-10 in 1970 or so when DEC brought out the
second model, the KI10.
TENEX was created at Bolt, Beranek & Newman (a Cambridge, Massachusetts
think tank) in
1972 as an experiment in demand-paged virtual memory operating systems.  They
built a new pager for the DEC PDP-10 and created the OS to go with it.  It was
extremely successful in academia.
In 1975, DEC brought out a new model of the PDP-10, the KL10; they intended to
have only a version of TENEX, which they had licensed from BBN, for the new
box.  They called their version TOPS-20 (their capitalization is trademarked).
A lot of TOPS-10 users (`The OPerating System for PDP-10') objected; thus DEC
found themselves supporting two incompatible systems on the same hardware--but
then there were 6 on the PDP-11!
TENEX, and TOPS-20 to version 3, had command completion
via a user-code-level subroutine library called ULTCMD.  With version 3, DEC
moved all that capability and more into the monitor (`kernel' for you Unix
types), accessed by the COMND% JSYS (`Jump to SYStem' instruction, the
supervisor call mechanism [are my IBM roots also showing?]).
The creator of tcsh was impressed by this feature and several others of TENEX
and TOPS-20, and created a version of csh which mimicked them.
The system limits argument lists to ARG_MAX characters.
The number of arguments to a command which involves filename expansion is
Command substitutions may substitute no more characters than are allowed in
an argument list.
substitutions on a single line to 20.
csh(1), emacs(1), ls(1), newgrp(1), sh(1), setpath(1), stty(1), su(1),
tset(1), vi(1), x(1), access(2), execve(2), fork(2), killpg(2),
pipe(2), setrlimit(2), sigvec(2), stat(2), umask(2), vfork(2), wait(2),
malloc(3), setlocale(3), tty(4), a.out(5), termcap(5), environ(7),
termio(7), Introduction to the C Shell
This manual documents tcsh 6.18.01 (Astron) 2012-02-14.
William Joy
J.E. Kulp, IIASA, Laxenburg, Austria
Job control and directory stack features
Ken Greer, HP Labs, 1981
File name completion
Mike Ellis, Fairchild, 1983
Paul Placeway, Ohio State CIS Dept., 1983-1993
Command line editor, prompt routines, new glob syntax and numerous fixes
and speedups
Karl Kleinpaste, CCI 1983-4
scheduled events, and the idea of the new prompt format
Rayan Zachariassen, University of Toronto, 1984
and speedups
Chris Kingsley, Caltech
Fast storage allocator routines
Chris Grevstad, TRW, 1987
Christos S. Zoulas, Cornell U. EE Dept., 1987-94
Ports to HPUX, SVR2 and SVR3, a SysV version of getwd.c, SHORT_STRINGS support
and a new version of sh.glob.c
James J Dempsey, BBN, and Paul Placeway, OSU, 1988
Daniel Long, NNSC, 1988
Patrick Wolfe, Kuck and Associates, Inc., 1988
David C Lawrence, Rensselaer Polytechnic Institute, 1989
Alec Wolman, DEC, 1989
Newlines in the prompt
Matt Landau, BBN, 1989
Ray Moody, Purdue Physics, 1989
Magic space bar history expansion
Mordechai ????, Intel, 1989
printprompt() fixes and additions
Kazuhiro Honda, Dept. of Computer Science, Keio University, 1989
Per Hedeland, Ellemtel, Sweden, 1990-
Various bugfixes, improvements and manual updates
Hans J. Albertsson (Sun Sweden)
Michael Bloom
Interrupt handling fixes
Michael Fine, Digital Equipment Corp
Extended key support
Eric Schnoebelen, Convex, 1990
save and restore of directory stack
Ron Flax, Apple, 1990
Dan Oscarsson, LTH Sweden, 1990
NLS support and simulated NLS support for non NLS sites, fixes
Johan Widen, SICS Sweden, 1990
Matt Day, Sanyo Icon, 1990
POSIX termio support, SysV limit fixes
Jaap Vermeulen, Sequent, 1990-91
Vi mode fixes, expand-line, window change fixes, Symmetry port
Martin Boyer, Institut de recherche d'Hydro-Quebec, 1991
the whole string from the beginning of the line to the cursor.
Scott Krotz, Motorola, 1991
Minix port
David Dawes, Sydney U. Australia, Physics Dept., 1991
SVR4 job control fixes
Jose Sousa, Interactive Systems Corp., 1991
Marc Horowitz, MIT, 1991
Bruce Sterling Woodcock, sterling@netcom.com, 1991-1995
various other portability changes and bug fixes
Jeff Fink, 1992
Harry C. Pulley, 1992
Coherent port
Andy Phillips, Mullard Space Science Lab U.K., 1992
VMS-POSIX port
Beto Appleton, IBM Corp., 1992
POSIX file tests, POSIX SIGHUP
Scott Bolte, Cray Computer Corp., 1992
CSOS port
Kaveh R. Ghazi, Rutgers University, 1992
Tek, m88k, Titan and Masscomp ports and fixes.  Added autoconf support.
Mark Linderman, Cornell University, 1992
Mika Liljeberg, liljeber@kruuna.Helsinki.FI, 1992
Linux port
Tim P. Starrin, NASA Langley Research Center Operations, 1993
Read-only variables
Dave Schweisguth, Yale University, 1993-4
New man page and tcsh.man2html
Larry Schwimmer, Stanford University, 1993
AFS and HESIOD patches
Luke Mewburn, RMIT University, 1994-6
Enhanced directory printing in prompt,
Edward Hutchins, Silicon Graphics Inc., 1996
Added implicit cd.
Martin Kraemer, 1997
Ported to Siemens Nixdorf EBCDIC machine
Amol Deshpande, Microsoft, 1997
and message catalog code to interface to Windows.
Taga Nayuta, 1998
Color ls additions.
Bryan Dunlap, Clayton Elwell, Karl Kleinpaste, Bob Manson, Steve Romig,
Diana Smetters, Bob Sutterfield, Mark Verber, Elizabeth Zwicky and all
the other people at Ohio State for suggestions and encouragement
All the people on the net, for putting up with,
reporting bugs in, and suggesting new additions to each and every version
Richard M. Alderson III, for writing the `T in tcsh' section
The
utility splits
into pieces using the patterns
If
is
a dash
reads from standard input.
The options are as follows:
Give created files names beginning with
The default is
Do not remove output files if an error occurs or a
or
signal is received.
Use
of decimal digits after the
to form the file name.
The default is 2.
Do not write the size of each output file to standard output as it is
created.
The
operands may be a combination of the following patterns:
Create a file containing the input from the current line to (but not including)
the next line matching the given basic regular expression.
An optional
from the line that matched may be specified.
Same as above but a file is not created for the output.
Create containing the input from the current line to (but not including)
the specified line number.
Repeat the previous pattern the specified number of times.
If it follows a line number pattern, a new file will be created for each
lines,
times.
The first line of the file is line number 1 for historic reasons.
After all the patterns have been processed, the remaining input data
(if there is any) will be written to a new file.
Requesting to split at a line before the current line number or past the
end of the file will result in an error.
The
and
environment variables affect the execution of
as described in
Split the
file
into one file for each section (up to 20):
Split standard input after the first 99 lines and every 100 lines thereafter:
The
utility conforms to
A
command appeared in PWB UNIX.
Input lines are limited to
(2048) bytes in length.
The
command manipulates Code Signing Requirement data.
It reads one requirement from a file or command arguments, converts it into
internal form, checks it, and then optionally outputs it in a different form.
The options are as follows:
Requests that the requirement read be written in binary form to the path given.
Specifies the input requirement. See "specifying requirements" below. This is
exactly the same format as is accepted by the -r and -R options of the codesign(1)
command.
Requests that the requirement read be written as text to standard output.
Increases the verbosity of output. Multiple instances of -v produce increasing levels
of commentary output.
In the first synopsis form,
reads a Code Requirement and writes it to standard output as canonical source text.
Note that with text input, this actually compiles the requirement into internal
form and then converts it back to text, giving you the system's view of the requirement code.
In the second synopsis form,
reads a Code Requirement and writes its binary representation to a file. This is the
same form produced by the SecRequirementCopyData API, and is readily acceptable
as input to Code Signing verification APIs. It can also be used as input to subsequent
invocations of
by passing the filename to the -r option.
The
argument (-r) can be given in various forms. A plain text argument is taken
to be a path to a file containing the requirement. This program will accept
both binary files containing properly compiled requirements code, and source files
that are automatically compiled for use.
An argument of "-" requests that the requirement(s) are read from standard input.
Again, standard input can contain either binary form or text.
Finally, an argument that begins with an equal sign "=" is taken as a literal
requirements source text, and is compiled accordingly for use.
To compile an explicit requirement program and write its binary form to file "output":
To display the requirement program embedded at offset 1234 of file "foo":
The
program exits 0 on success or 1 on failure. Errors in arguments yield exit code 2.
The
command first appeared in
Mac OS 10.5.0 .
[ options ] [ system | phone | "dir" ]
The
command is used to call up another system and act as a dial in
terminal.  It can also do simple file transfers with no error
checking.

takes a single argument, besides the options.  If the argument is the
string "dir" cu will make a direct connection to the port.  This may
only be used by users with write access to the port, as it permits
reprogramming the modem.

Otherwise, if the argument begins with a digit, it is taken to be a
phone number to call.  Otherwise, it is taken to be the name of a
system to call.  The
or
option may be used to name a system beginning with a digit, and the
or
option may be used to name a phone number that does not begin with a
digit.

locates a port to use in the UUCP configuration files.  If a simple
system name is given, it will select a port appropriate for that
system.  The
and
options may be used to control the port selection.

When a connection is made to the remote system,
forks into two processes.  One reads from the port and writes to the
terminal, while the other reads from the terminal and writes to the
port.

provides several commands that may be used during the conversation.
The commands all begin with an escape character, initially
(tilde).  The escape character is only recognized at the beginning of
a line.  To send an escape character to the remote system at the start
of a line, it must be entered twice.  All commands are either a single
character or a word beginning with
(percent sign).

recognizes the following commands:

Terminate the conversation.
Run command in a shell.  If command is empty, starts up a shell.
Run command, sending the standard output to the remote system.
Run command, taking the standard input from the remote system.
Run command, taking the standard input from the remote system and
sending the standard output to the remote system.
Send a break signal, if possible.
Change the local directory.
Send a file to the remote system.  This just dumps the file over the
communication line.  It is assumed that the remote system is expecting
it.
Receive a file from the remote system.  This prompts for the local
file name and for the remote command to execute to begin the file
transfer.  It continues accepting data until the contents of the
variable are seen.
Send a file to a remote Unix system.  This runs the appropriate
commands on the remote system.
Retrieve a file from a remote Unix system.  This runs the appropriate
commands on the remote system.
Set a
variable to the given value.  If value is not given, the variable is
set to
Set a
variable to
Suspend the cu session.  This is only supported on some systems.  On
systems for which ^Z may be used to suspend a job, 
will also suspend the session.
List all the variables and their values.
List all commands.

also supports several variables.  They may be listed with the
command, and set with the
or
commands.

The escape character.  Initially
(tilde).
If this variable is true,
will delay for a second after recognizing the escape character before
printing the name of the local system.  The default is true.
The list of characters which are considered to finish a line.  The
escape character is only recognized after one of these is seen.  The
default is carriage return, ^U, ^C, ^O, ^D, ^S, ^Q, ^R.
Whether to transfer binary data when sending a file.  If this is
false, then newlines in the file being sent are converted to carriage
returns.  The default is false.
A string used before sending a binary character in a file transfer, if
the
variable is true.  The default is ^V.
Whether to check file transfers by examining what the remote system
echoes back.  This probably doesn't work very well.  The default is
false.
The character to look for after sending each line in a file.  The
default is carriage return.
The timeout to use, in seconds, when looking for a character, either
when doing echo checking or when looking for the
character.  The default is 30.
The character to use delete a line if the echo check fails.  The
default is ^U.
The number of times to resend a line if the echo check continues to
fail.  The default is 10.
The string to write after sending a file with the
command.  The default is ^D.
The string to look for when receiving a file with the
command.  The default is $, which is intended to be a typical shell
prompt.
Whether to print accumulated information during a file transfer.  The
default is true.
The following options may be given to
Use even parity.
Use odd parity.
Use no parity.  No parity is also used if both
and
are given.
Echo characters locally (half-duplex mode).
Set the escape character.  Initially
(tilde).  To eliminate the escape character, use
The system to call.
The phone number to call.
Name the port to use.
Equivalent to
Name the line to use by giving a device name.  This may be used to
dial out on ports that are not listed in the UUCP configuration files.
Write access to the device is required.
The speed (baud rate) to use.
Where # is a number, equivalent to
Prompt for the phone number to use.
Enter debugging mode.  Equivalent to
Turn on particular debugging types.  The following types are
recognized: abnormal, chat, handshake, uucp-proto, proto, port,
config, spooldir, execute, incoming, outgoing.  Only abnormal, chat,
handshake, port, config, incoming and outgoing are meaningful for

Multiple types may be given, separated by commas, and the
option may appear multiple times.  A number may also be given, which
will turn on that many types from the foregoing list; for example,
is equivalent to
may be used to turn on all debugging options.
Set configuration file to use.  This option may not be available,
depending upon how
was compiled.
Report version information and exit.
Print a help message and exit.
This program does not work very well.
Ian Lance Taylor
<ian@airs.com>
displays information about the curl and libcurl installation.
Displays the built-in path to the CA cert bundle this libcurl uses.
Displays the compiler used to build libcurl.
Set of compiler options (CFLAGS) to use when compiling files that use
libcurl. Currently that is only the include path to the curl include files.
Specify the oldest possible libcurl version string you want, and this
script will return 0 if the current installation is new enough or it
returns 1 and outputs a text saying that the current version is not new
enough. (Added in 7.15.4)
Displays the arguments given to configure when building curl.
Lists what particular main features the installed libcurl was built with. At
the time of writing, this list may include SSL, KRB4 or IPv6. Do not assume
any particular order. The keywords will be separated by newlines. There may be
none, one, or several keywords in the list.
Displays the available options.
Shows the complete set of libs and other linker options you will need in order
to link your application with libcurl.
This is the prefix used when libcurl was installed. Libcurl is then installed
on. The prefix is set with "configure --prefix".
Lists what particular protocols the installed libcurl was built to support. At
the time of writing, this list may include HTTP, HTTPS, FTP, FTPS, FILE,
TELNET, LDAP, DICT. Do not assume any particular order. The protocols will
be listed using uppercase and are separated by newlines. There may be none,
one, or several protocols in the list. (Added in 7.13.0)
Shows the complete set of libs and other linker options you will need in order
to link your application with libcurl statically. (Added in 7.17.1)
Outputs version information about the installed libcurl.
Outputs version information about the installed libcurl, in numerical mode.
This outputs the version number, in hexadecimal, with 8 bits for each part;
major, minor, patch. So that libcurl 7.7.4 would appear as 070704 and libcurl
12.13.14 would appear as 0c0d0e... Note that the initial zero might be
omitted. (This option was broken in the 7.15.0 release.)
What linker options do I need when I link with libcurl?

  $ curl-config --libs

What compiler options do I need when I compile using libcurl functions?

  $ curl-config --cflags

How do I know if libcurl was built with SSL support?

  $ curl-config --feature | grep SSL

What's the installed libcurl version?

  $ curl-config --version

How do I build a single file with a one-line command?

  $ `curl-config --cc --cflags` -o example example.c `curl-config --libs`
is a tool to transfer data from or to a server, using one of the supported
protocols (DICT, FILE, FTP, FTPS, GOPHER, HTTP, HTTPS, IMAP, IMAPS, LDAP,
LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, TELNET
and TFTP). The command is designed to work without user interaction.

curl offers a busload of useful tricks like proxy support, user
authentication, FTP upload, HTTP post, SSL connections, cookies, file transfer
resume, Metalink, and more. As you will see below, the number of features will
make your head spin!

curl is powered by libcurl for all transfer-related features. See
The URL syntax is protocol-dependent. You'll find a detailed description in
RFC 3986.

You can specify multiple URLs or parts of URLs by writing part sets within
braces as in:


or you can get sequences of alphanumeric series by using [] as in:




Nested sequences are not supported, but you can use several ones next to each
other:


You can specify any amount of URLs on the command line. They will be fetched
in a sequential manner in the specified order.

You can specify a step counter for the ranges to get every Nth number or
letter:



When using [] or {} sequences when invoked from a command line prompt, you
probably have to put the full URL within double quotes to avoid the shell from
interfering with it. This also goes for other characters treated special, like
for example '&', '?' and '*'.

Provide the IPv6 zone index in the URL with an escaped percentage sign and the
interface name. Like in


protocol you might want. It will then default to HTTP but try other protocols
based on often-used host name prefixes. For example, for host names starting
with "ftp." curl will assume you want to speak FTP.

curl will do its best to use what you pass to it as a URL. It is not trying to
validate it as a syntactically correct URL by any means but is instead

curl will attempt to re-use connections for multiple file transfers, so that
handshakes. This improves speed. Of course this is only done on files
specified on a single command line and cannot be used between separate curl
invokes.
curl normally displays a progress meter during operations, indicating the
amount of transferred data, transfer speeds and estimated time left, etc.

curl displays this data to the terminal by default, so if you invoke curl to
do an operation and it is about to write data to the terminal, it
mixing progress meter and response data.

If you want a progress meter for HTTP POST or PUT requests, you need to
redirect the response output to a file, using shell redirect (>), -o [file] or
similar.

It is not the same case for FTP upload as that operation does not spit out
any response data to the terminal.

friend.
Options start with one or two dashes. Many of the options require an
additional value next to them.

The short "single-dash" form of the options, -d for example, may be used with
or without a space between it and its value, although a space is a recommended
separator. The long "double-dash" form, --data for example, requires a space
between it and its value.

Short version options that don't need any additional values can be used
immediately next to each other, like for example you can specify all the
options -O, -L and -v at once as -OLv.

but prefix it with "no-". However, in this list we mostly only list and show
the --option version of them. (This concept with --no options was added in
same command line option.)
Make curl display progress as a simple progress bar instead of the standard,
more informational, meter.
Tells curl to use a separate operation for the following URL and associated
options. This allows you to send several URL requests, each with their own
specific options, for example, such as different user names or custom requests
for each. (Added in 7.36.0)
(HTTP) Tells curl to use HTTP version 1.0 instead of using its internally
preferred: HTTP 1.1.
(HTTP) Tells curl to use HTTP version 1.1. This is the internal default
version. (Added in 7.33.0)
(HTTP) Tells curl to issue its requests using HTTP 2. This requires that the
underlying libcurl was built to support it. (Added in 7.33.0)
Disable the NPN TLS extension. NPN is enabled by default if libcurl was built
with an SSL library that supports NPN. NPN is used by a libcurl that supports
HTTP 2 to negotiate HTTP 2 support with the server during https sessions.

(Added in 7.36.0)
Disable the ALPN TLS extension. ALPN is enabled by default if libcurl was built
with an SSL library that supports ALPN. ALPN is used by a libcurl that supports
HTTP 2 to negotiate HTTP 2 support with the server during https sessions.

(Added in 7.36.0)
(SSL)
Forces curl to use TLS version 1.x when negotiating with a remote TLS server.
control the TLS version more precisely (if the SSL backend in use supports such
a level of control).
(SSL) Forces curl to use SSL version 2 when negotiating with a remote SSL
server. Sometimes curl is built without SSLv2 support. SSLv2 is widely
considered insecure.
(SSL) Forces curl to use SSL version 3 when negotiating with a remote SSL
server. Sometimes curl is built without SSLv3 support.
This option tells curl to resolve names to IPv4 addresses only, and not for
example try IPv6.
This option tells curl to resolve names to IPv6 addresses only, and not for
example try IPv4.
instead of overwriting it. If the remote file doesn't exist, it will be
created.  Note that this flag is ignored by some SFTP servers (including
OpenSSH).
(HTTP) Specify the User-Agent string to send to the HTTP server. Some badly
the string, surround the string with single quote marks. This can also be set

If this option is used several times, the last one will be used.
(HTTP) Tells curl to figure out authentication method by itself, and use the
most secure one the remote site claims to support. This is done by first
doing a request and checking the response-headers, thus possibly inducing an
extra network round-trip. This is used instead of setting a specific

Note that using --anyauth is not recommended if you do uploads from stdin,
since it may require data to be sent twice and then the client must be able to
rewind. If the need should arise when uploading from stdin, the upload
operation will fail.
(HTTP) Pass the data to the HTTP server as a cookie. It is supposedly the data
previously received from the server in a "Set-Cookie:" line.  The data should
be in the format "NAME1=VALUE1; NAME2=VALUE2".

If no '=' symbol is used in the line, it is treated as a filename to use to
read previously stored cookie lines from, which should be used in this session
if they match. Using this method also activates the "cookie parser" which will
make curl record incoming cookies too, which may be handy if you're using this
cookie file format.

option.

If this option is used several times, the last one will be used.
an URL that ends with ";type=A". This option causes data sent to stdout to be
in text mode for win32 systems.
(HTTP) Tells curl to use HTTP Basic authentication with the remote host. This
is the default and this option is usually pointless, unless you use it to
override a previously set option that sets a different authentication method


(HTTP) Specify to which file you want curl to write all cookies after a
completed operation. Curl writes all cookies previously read from a specified
file as well as all cookies received from remote server(s). If no cookies are
known, no data will be written. The file will be written using the Netscape
cookie file format. If you set the file name to a single dash, "-", the
cookies will be written to stdout.

This command line option will activate the cookie engine that makes curl

If the cookie jar can't be created or written to, the whole curl operation
won't fail or even report an error clearly. Using -v will get a warning
displayed, but that is the only visible feedback you get about this possibly
lethal situation.

If this option is used several times, the last specified file name will be
used.
is the exact number of bytes that will be skipped, counting from the beginning
of the source file before it is transferred to the destination.  If used with
uploads, the FTP server command SIZE will not be used by curl.


If this option is used several times, the last one will be used.
(SSL) Specifies which ciphers to use in the connection. The list of ciphers
must specify valid ciphers. Read up on SSL cipher list details on this URL:

NSS ciphers are done differently than OpenSSL and GnuTLS. The full list of NSS
ciphers is in the NSSCipherSuite entry at this URL:

If this option is used several times, the last one will be used.
(HTTP) Request a compressed response using one of the algorithms curl
supports, and save the uncompressed document.  If this option is used and the
server sends an unsupported encoding, curl will report an error.
Maximum time in seconds that you allow curl's connection to take.  This only
limits the connection phase, so if curl connects within the given period it
will continue - if not it will exit.  Since version 7.32.0, this option
accepts decimal values.


If this option is used several times, the last one will be used.
necessary local directory hierarchy as needed. This option creates the dirs
uses no dir or if the dirs it mentions already exist, no dir will be created.

To create remote directories when using FTP or SFTP, try

(SMTP added in 7.40.0)
List that may specify peer certificates that are to be considered revoked.

If this option is used several times, the last one will be used.

(Added in 7.19.7)
(HTTP) Sends the specified data in a POST request to the HTTP server, in the
same way that a browser does when a user has filled in an HTML form and
presses the submit button. This will cause curl to pass the data to the server

the same but does not have a special interpretation of the @ character. To

If any of these options is used more than once on the same command line, the
data pieces specified will be merged together with a separating
&-symbol. Thus, using '-d name=daniel -d skill=lousy' would generate a post

If you start the data with the letter @, the rest should be a file name to
read the data from, or - if you want curl to read the data from
stdin. Multiple files can also be specified. Posting data from a file
told to read from a file like that, carriage returns and newlines will be
stripped out. If you don't want the @ character to have a special
Write the protocol headers to the specified file.

This option is handy to use when you want to store the headers that an HTTP
site sends to you. Cookies from the headers could then be read in a second

When used in FTP, the FTP server response lines are considered being "headers"
and thus are saved there.

If this option is used several times, the last one will be used.
(HTTP) This posts data exactly as specified with no extra processing
whatsoever.

If you start the data with the letter @, the rest should be a filename.  Data
and carriage returns are preserved and conversions are never done.

If this option is used several times, the ones following the first will append
(Added in 7.43.0)
(HTTP) This posts data, similar to the other --data options with the exception
that this performs URL-encoding. (Added in 7.18.0)

by a separator and a content specification. The <data> part can be passed to
curl using one of the following syntaxes:
This will make curl URL-encode the content and pass that on. Just be careful
so that the content doesn't contain any = or @ symbols, as that will then make
the syntax match one of the other cases below!
This will make curl URL-encode the content and pass that on. The preceding =
symbol is not included in the data.
This will make curl URL-encode the content part and pass that on. Note that
the name part is expected to be URL-encoded already.
This will make curl load data from the given file (including any newlines),
URL-encode that data and pass it on in the POST.
This will make curl load data from the given file (including any newlines),
URL-encode that data and pass it on in the POST. The name part gets an equal
name is expected to be URL-encoded already.
Don't allow any delegation.
Delegates if and only if the OK-AS-DELEGATE flag is set in the Kerberos
service ticket, which is a matter of realm policy.
Unconditionally allow the server to delegate.
(HTTP) Enables HTTP Digest authentication. This is an authentication scheme
that prevents the password from being sent over the wire in clear text. Use
related options.

If this option is used several times, only the first one is used.
(FTP) Tell curl to disable the use of the EPRT and LPRT commands when doing
active FTP transfers. Curl will normally always first attempt to use EPRT,
then LPRT before using PORT, but with this option, it will use PORT right
away. EPRT and LPRT are extensions to the original FTP protocol, and may not
work on all servers, but they enable more functionality in a better way than
the traditional PORT command.


Disabling EPRT only changes the active behavior. If you want to switch to
(FTP) Tell curl to disable the use of the EPSV command when doing passive FTP
transfers. Curl will normally always first attempt to use EPSV before PASV,
but with this option, it will not try using EPSV.


Disabling EPSV only changes the passive behavior. If you want to switch to
Tell curl to send outgoing DNS requests through <interface>. This option
supplied string must be an interface name (not an address).

This option requires that libcurl was built with a resolver backend that
supports this operation. The c-ares backend is the only such one. (Added in
7.33.0)
Tell curl to bind to <ip-address> when making IPv4 DNS requests, so that
the DNS requests originate from this address. The argument should be a
single IPv4 address.

This option requires that libcurl was built with a resolver backend that
supports this operation. The c-ares backend is the only such one.  (Added in
7.33.0)
Tell curl to bind to <ip-address> when making IPv6 DNS requests, so that
the DNS requests originate from this address. The argument should be a
single IPv6 address.

This option requires that libcurl was built with a resolver backend that
supports this operation. The c-ares backend is the only such one.  (Added in
7.33.0)
Set the list of DNS servers to be used instead of the system default.
The list of IP addresses should be separated with commas. Port numbers
address.

This option requires that libcurl was built with a resolver backend that
supports this operation. The c-ares backend is the only such one.  (Added in
7.33.0)
(HTTP) Sends the "Referrer Page" information to the HTTP server. This can also
automatically set the previous URL when it follows a Location: header. The

If this option is used several times, the last one will be used.
(SSL) Tells curl to use the specified client certificate file when getting a
file with HTTPS, FTPS or another SSL-based protocol. The certificate must be
in PKCS#12 format if using Secure Transport, or PEM format if using any other
engine.  If the optional password isn't specified, it will be queried

If curl is built against the NSS SSL library then this option can tell
curl the nickname of the certificate to use within the NSS database defined
NSS PEM PKCS#11 module (libnsspem.so) is available then PEM files may be
loaded. If you want to use a file from the current directory, please precede

(iOS and Mac OS X only) If curl is built against Secure Transport, then the
system or user keychain, or the path to a PKCS#12-encoded certificate and
private key. If you want to use a file from the current directory, please

If this option is used several times, the last one will be used.
Select the OpenSSL crypto engine to use for cipher
engines. Note that not all (or none) of the engines may be available at
run-time.
(RISC OS ONLY) Sets a range of environment variables, using the names the
after having run curl.
(SSL) Specify the path name to the Entropy Gathering Daemon socket. The socket
is used to seed the random engine for SSL connections. See also the
(SSL) Tells curl what certificate type the provided certificate is in. PEM,
DER and ENG are recognized types.  If not specified, PEM is assumed.

If this option is used several times, the last one will be used.
(SSL) Tells curl to use the specified certificate file to verify the peer. The
file may contain multiple CA certificates. The certificate(s) must be in PEM
format. Normally curl is built to use a default file for this, so this option
is typically used to alter that default file.

curl recognizes the environment variable named 'CURL_CA_BUNDLE' if it is
set, and uses the given path as a path to a CA cert bundle. This option
overrides that variable.

The windows version of curl will automatically look for a CA certs file named
Current Working Directory, or in any folder along your PATH.

If curl is built against the NSS SSL library, the NSS PEM PKCS#11 module
(libnsspem.so) needs to be available for this option to work properly.

If this option is used several times, the last one will be used.
(SSL) Tells curl to use the specified certificate directory to verify the
peer. Multiple paths can be provided by separating them with ":" (e.g.
built against OpenSSL, the directory must have been processed using the
OpenSSL-powered curl to make SSL-connections much more efficiently than using

If this option is set, the default capath value will be ignored, and if it is
used several times, the last one will be used.
(SSL) Tells curl to use the specified public key file to verify the peer. The
file must contain a single public key in PEM or DER format.

When negotiating a TLS or SSL connection, the server sends a certificate
indicating its identity. A public key is extracted from this certificate and
if it does not exactly match the public key provided to this option, curl will
abort the connection before sending or receiving any data.

Added in 7.39.0 for OpenSSL, GnuTLS and GSKit. Added in 7.43.0 for NSS and

If this option is used several times, the last one will be used.
(SSL) Tells curl to verify the status of the server certificate by using the
Certificate Status Request (aka. OCSP stapling) TLS extension.

If this option is enabled and the server sends an invalid (e.g. expired)
response, if the response suggests that the server certificate has been revoked,
or no response at all is received, the verification fails.

This is currently only implemented in the OpenSSL, GnuTLS and NSS backends.
(Added in 7.41.0)

(SSL) Tells curl to use false start during the TLS handshake. False start is a
mode where a TLS client will start sending application data before verifying
the server's Finished message, thus saving a round trip when performing a full
handshake.

This is currently only implemented in the NSS and Secure Transport (on iOS 7.0
or later, or OS X 10.9 or later) backends.
(Added in 7.42.0)
(HTTP) Fail silently (no output at all) on server errors. This is mostly done
to better enable scripts etc to better deal with failed attempts. In normal
cases when an HTTP server fails to deliver a document, it returns an HTML
document stating so (which often also describes why and more). This flag will
prevent curl from outputting that and return error 22.

This method is not fail-safe and there are occasions where non-successful
response codes will slip through, especially when authentication is involved
(response codes 401 and 407).
(HTTP) This lets curl emulate a filled-in form in which a user has pressed the
submit button. This causes curl to POST data using the Content-Type
files etc. To force the 'content' part to be a file, prefix the file name with
an @ sign. To just get the content part from a file, prefix the file name with
the symbol <. The difference between @ and < is then that @ makes a file get
attached in the post as a file upload, while the < makes a text field and just
get the contents for that text field from a file.

Example, to send your password file to the server, where
input:


To read content from stdin instead of a file, use - as the filename. This goes
for both @ and < constructs.

You can also tell curl what Content-Type to use by using 'type=', in a manner
similar to:


or


You can also explicitly change the name field of a file upload part by setting
filename=, like this:




or


or backslash within the filename must be escaped by backslash.

See further examples and details in the MANUAL.

This option can be used multiple times.
(FTP) When an FTP server asks for "account data" after user name and password
has been provided, this data is sent off using the ACCT command. (Added in
7.13.0)

If this option is used several times, the last one will be used.
(FTP) If authenticating with the USER and PASS commands fails, send this
command.  When connecting to Tumbleweed's Secure Transport server over FTPS
using a client certificate, using "SITE AUTH" will tell the server to retrieve
the username from the certificate. (Added in 7.15.5)
currently exist on the server, the standard behavior of curl is to
fail. Using this option, curl will instead attempt to create missing
directories.
(FTP) Control what method curl should use to reach a file on an FTP(S)
server. The method argument should be one of the following alternatives:
curl does a single CWD operation for each path part in the given URL. For deep
hierarchies this means very many commands. This is how RFC 1738 says it should
be done. This is the default but the slowest behavior.
curl does no CWD at all. curl will do SIZE, RETR, STOR etc and give a full
path to the server for all these commands. This is the fastest behavior.
curl does one CWD with the full target directory and then operates on the file
compliant than 'nocwd' but without the full penalty of 'multicwd'.
(Added in 7.15.1)
(FTP) Use passive mode for the data connection. Passive is the internal default
behavior, but using this option can be used to override a previous

If this option is used several times, only the first one is used. Undoing an
enforced passive really isn't doable but you must then instead enforce the

Passive mode means that curl will try the EPSV command first and then PASV,
(FTP) Tell curl to not use the IP address the server suggests in its response
to curl's PASV command when curl connects the data connection. Instead curl
will re-use the same IP address it already uses for the control
connection. (Added in 7.14.2)

This option has no effect if PORT, EPRT or EPSV is used instead of PASV.
(FTP) Tell curl to send a PRET command before PASV (and EPSV). Certain
FTP servers, mainly drftpd, require this non-standard command for
directory listings as well as up and downloads in PASV mode.
(Added in 7.20.x)
(FTP) Use CCC (Clear Command Channel)
control channel communication will be unencrypted. This allows
NAT routers to follow the FTP transaction. The default mode is
(Added in 7.16.1)
(FTP) Use CCC (Clear Command Channel)
Sets the CCC mode. The passive mode will not initiate the shutdown, but
instead wait for the server to do it, and will not reply to the
shutdown from the server. The active mode initiates the shutdown and
waits for a reply from the server.
(Added in 7.16.2)
authentication, but non-encrypted data transfers for efficiency.  Fails the
that can still be used but will be removed in a future version.
This option switches off the "URL globbing parser". When you set this option,
you can specify URLs that contain the letters {}[] without having them being
interpreted by curl itself. Note that these letters are not normal legal URL
contents but they should be encoded according to the URI standard.
request instead of the POST request that otherwise would be used. The data
will be appended to the URL with a '?' separator.

If used in combination with -I, the POST data will instead be appended to the
URL with a HEAD request.

If this option is used several times, only the first one is used. This is
because undoing a GET doesn't make sense, but you should then instead enforce
the alternative method you prefer.
(HTTP) Extra header to include in the request when sending HTTP to a
server. You may specify any number of extra headers. Note that if you should
add a custom header that has the same name as one of the internal ones curl
would use, your externally set header will be used instead of the internal
one. This allows you to make even trickier stuff than curl would normally
do. You should not replace internally set headers without knowing perfectly
well what you're doing. Remove an internal header by giving a replacement
send the custom header with no-value then its header must be terminated with a

content: do not add newlines or carriage returns, they will only mess things up
for you.


intended for a proxy.

Example:


can lead to the header being sent to other hosts than the original host, so
sensitive headers should be used with caution combined with following
redirects.

be the 128 bit MD5 checksum of the remote host's public key, curl will refuse
the connection with the host unless the md5sums match. (Added in 7.17.1)
(HTTP)
Ignore the Content-Length header. This is particularly useful for servers
running Apache 1.x, which will report incorrect Content-Length for files
larger than 2 gigabytes.
(HTTP) Include the HTTP-header in the output. The HTTP-header includes things
like server-name, date of the document, HTTP-version and more...
Fetch the HTTP-header only! HTTP-servers feature the command HEAD
which this uses to get nothing but the header of a document. When used
on an FTP or FILE file, curl displays the file size and last modification
time only.
Perform an operation using a specified interface. You can enter interface
name, IP address or host name. An example could look like:


If this option is used several times, the last one will be used.
(HTTP) When curl is told to read cookies from a given file, this option will
make it discard all "session cookies". This will basically have the same effect
as if a new session is started. Typical browsers always discard session
cookies when they're closed down.
server-specified Content-Disposition filename instead of extracting a filename
from the URL.

There's no attempt to decode %-sequences (yet) in the provided file name, so
this option may provide you with rather unexpected file names.
(SSL) This option explicitly allows curl to perform "insecure" SSL connections
and transfers. All SSL connections are attempted to be made secure by using
the CA certificate bundle installed by default. This makes all connections

See this online resource for further details:
Specify which config file to read curl arguments from. The config file is a
text file in which command line arguments can be written which then will be
used as if they were written on the actual command line.

Options and their parameters must be specified on the same config file line,
separated by whitespace, colon, or the equals sign. Long option names can
optionally be given in the config file without the initial double dashes and
if so, the colon or equals characters can be used as separators. If the option
is specified with one or two dashes, there can be no colon or equals character
between the option and its parameter.

If the parameter is to contain whitespace, the parameter must be enclosed
within quotes. Within double quotes, the following escape sequences are
letter is ignored. If the first column of a config line is a '#' character,
the rest of the line will be treated as a comment. Only write one option per
physical line in the config file.

Specify the filename to -K, --config as '-' to make curl read the file from
stdin.

Note that to be able to specify a URL in the config file, you need to specify
line. So, it could look similar to this:


config file and uses it if found. The default config file is checked for in
the following places in this order:

1) curl tries to find the "home dir": It first checks for the CURL_HOME and
then the HOME environment variables. Failing that, it uses getpwuid() on
Unix-like systems (which returns the home dir given the current user in your
system). On Windows, it then checks for the APPDATA variable, or as a last

2) On windows, if there is no _curlrc file in the home dir, it checks for one
in the same dir the curl executable is placed. On Unix-like systems, it will
simply try to load .curlrc from the determined home dir.

# --- Example file ---
# this is a comment
url = "curl.haxx.se"
output = "curlhere.html"

# and fetch another URL too
-O
# --- End of example file ---

This option can be used multiple times to load multiple config files.
This option sets the time a connection needs to remain idle before sending
keepalive probes and the time between individual keepalive probes. It is
currently effective on operating systems offering the TCP_KEEPIDLE and
TCP_KEEPINTVL socket options (meaning Linux, recent AIX, HP-UX and more). This

If this option is used several times, the last one will be used. If
unspecified, the option defaults to 60 seconds.
separate file. For SSH, if not specified, curl tries the following candidates

If this option is used several times, the last one will be used.
private key is. DER, PEM, and ENG are supported. If not specified, PEM is
assumed.

If this option is used several times, the last one will be used.
(FTP) Enable Kerberos authentication and use. The level must be entered and
should be one of 'clear', 'safe', 'confidential', or 'private'. Should you use
a level that is not one of these, 'private' will instead be used.

This option requires a library built with kerberos4 support. This is not

If this option is used several times, the last one will be used.
(FTP)
When listing an FTP directory, this switch forces a name-only view. This is
especially useful if the user wants to machine-parse the contents of an FTP
directory since the normal directory view doesn't use a standard look or
format. When used like this, the option causes a NLST command to be sent to
the server instead of LIST.

Note: Some FTP servers list only files in their response to NLST; they do not
include sub-directories and symbolic links.

(POP3)
When retrieving a specific email from POP3, this switch forces a LIST command
to be performed instead of RETR. This is particularly useful if the user wants
to see if a specific message id exists on the server and what size it is.

to send an UIDL command instead, so the user may use the email's unique
identifier rather than it's message id to make the request. (Added in 7.21.5)
different location (indicated with a Location: header and a 3XX response code),
this option will make curl redo the request on the new place. If used together
will be shown. When authentication is used, curl only sends its credentials to
the initial host. If a redirect takes curl to a different host, it won't be
to change this. You can limit the amount of redirects to follow by using the

When curl follows a redirect and the request is not a plain GET (for example
POST or PUT), it will do the following request with a GET if the HTTP response
was 301, 302, or 303. If the response code was any other 3xx code, curl will
re-send the following request using the same unmodified method.

You can tell curl to not change the non-GET request method to GET after a 30x
Append this option to any ordinary curl command line, and you will get a
libcurl-using C source code written to the file that does the equivalent
of what your command-line operation does!

If this option is used several times, the last given file name will be
used. (Added in 7.16.1)
Specify the maximum transfer rate you want curl to use - for both downloads
and uploads. This feature is useful if you have a limited pipe and you'd like
your transfer not to use your entire bandwidth. To make it slower than it
otherwise would be.

Appending 'k' or 'K' will count the number as kilobytes, 'm' or M' makes it
megabytes, while 'g' or 'G' makes it gigabytes. Examples: 200K, 3m and 1G.

The given rate is the average speed counted during the entire transfer. It
means that curl might use higher transfer speeds in short bursts, but over
time it uses no more than the given rate.

precedence and might cripple the rate-limiting slightly, to help keeping the
speed-limit logic working.

If this option is used several times, the last one will be used.
Set a preferred number or range of local port numbers to use for the
connection(s).  Note that port numbers by nature are a scarce resource that
will be busy at times so setting this range to something too narrow might
cause unnecessary connection setup failures. (Added in 7.15.2)
password to all hosts that the site may redirect to. This may or may not
introduce a security breach if the site redirects you to a site to which
you'll send your authentication info (which is plaintext in the case of HTTP
Basic authentication).
Maximum time in seconds that you allow the whole operation to take.  This is
useful for preventing your batch jobs from hanging for hours due to slow
networks or links going down.  Since 7.32.0, this option accepts decimal
values, but the actual timeout will decrease in accuracy as the specified
option.

If this option is used several times, the last one will be used.
Specify the login options to use during server authentication.

You can use the login options to specify protocol specific options that may
be used during authentication. At present only IMAP, POP3 and SMTP support
login options. For more information about the login options please see
RFC 2384, RFC 5092 and IETF draft draft-earhart-url-smtp-00.txt (Added in
7.34.0).

If this option is used several times, the last one will be used.
(SMTP) Specify a single address. This will be used to specify the
authentication address (identity) of a submitted message that is being relayed
to another server.

(Added in 7.25.0)
(SMTP) Specify a single address that the given mail should get sent from.

(Added in 7.20.0)
Specify the maximum size (in bytes) of a file to download. If the file
requested is larger than this value, the transfer will not start and curl will
return with exit code 63.

files this option has no effect even if the file transfer ends up being larger
than this given limit. This concerns both FTP and HTTP transfers.
(SMTP) Specify a single address, user name or mailing list name.

When performing a mail transfer, the recipient should specify a valid email
address to send the mail to. (Added in 7.20.0)

When performing an address verification (VRFY command), the recipient should be
specified as the user name or user name and domain (as per Section 3.5 of
RFC5321). (Added in 7.34.0)

When performing a mailing list expand (EXPN command), the recipient should be
specified using the mailing list name, such as "Friends" or "London-Office".
(Added in 7.34.0)
is used, this option can be used to prevent curl from following redirections
option to -1 to make it limitless.

If this option is used several times, the last one will be used.
This option can tell curl to parse and process a given URI as Metalink file
(both version 3 and 4 (RFC 5854) are supported) and make use of the mirrors
listed within for failover if there are errors (such as the file or server not
being available). It will also verify the hash of the file after the download
completes. The Metalink file itself is downloaded and processed in memory and
not stored in the local file system.

Example to use a remote Metalink file:


To use a Metalink file in the local file system, use FILE protocol


Please note that if FILE protocol is disabled, there is no way to use
a local Metalink file at the time of this writing. Also note that if
ignored. This is because including headers in the response will break
Metalink parser and if the headers are included in the file described
in Metalink file, hash check will fail.

(Added in 7.27.0, if built against the libmetalink library.)
home directory for login name and password. This is typically used for FTP on
Unix. If used with HTTP, curl will enable user authentication. See
complain if that file doesn't have the right permissions (it should not be
either world- or group-readable). The environment variable "HOME" is used to
find the home directory.


Disables the buffering of the output stream. In normal work situations, curl
will use a standard buffered output stream that will have the effect that it
will output the data in chunks, not necessarily exactly when the data arrives.
Using this option will disable that buffering.

Note that this is the negated option name documented. You can thus use
(absolute or relative) to the netrc file that Curl should use.
You can only specify one netrc file per invocation. If several
(Added in 7.21.5)



(HTTP) Enables Negotiate (SPNEGO) authentication.

If you want to enable Negotiate (SPNEGO) for proxy authentication, then use


activate the authentication code properly. Sending a '-u :' is enough as the

If this option is used several times, only the first one is used.
Disables the use of keepalive messages on the TCP connection, as by default
curl enables them.

Note that this is the negated option name documented. You can thus use
(SSL) Disable curl's use of SSL session-ID caching.  By default all transfers
are done using the cache. Note that while nothing should ever get hurt by
attempting to reuse SSL session-IDs, there seem to be broken SSL
implementations in the wild that may require you to disable this in order for
you to succeed. (Added in 7.16.0)

Note that this is the negated option name documented. You can thus use
Comma-separated list of hosts which do not use a proxy, if one is specified.
The only wildcard is a single * character, which matches all hosts, and
effectively disables the proxy. Each name in this list is matched as either
a domain which contains the hostname, or the hostname itself. For example,
local.com would match local.com, local.com:80, and www.local.com, but not
www.notlocal.com.  (Added in 7.19.4).
(HTTP) Enables NTLM authentication. The NTLM authentication method was
designed by Microsoft and is used by IIS web servers. It is a proprietary
protocol, reverse-engineered by clever people and implemented in curl based
on their efforts. This kind of behavior should not be endorsed, you should
encourage everyone who uses NTLM to switch to a public and documented
authentication method instead, such as Digest.

If you want to enable NTLM for your proxy authentication, then use

This option requires a library built with SSL support. Use

If this option is used several times, only the first one is used.
Write output to <file> instead of stdout. If you are using {} or [] to fetch
multiple documents, you can use '#' followed by a number in the <file>
specifier. That variable will be replaced with the current string for the URL
being fetched. Like in:


or use several variables like:


You may use this option as many times as the number of URLs you have.

dynamically. Specifying the output as '-' (a single dash) will force the
output to be done to stdout.
Write output to a local file named like the remote file we get. (Only the file
part of the remote file is used, the path is cut off.)

The remote file name to use for saving is extracted from the given URL,
nothing else.

Consequentially, the file will be saved in the current working directory. If
you want the file saved in a different directory, make sure you change current

There is no URL decoding done on the file name. If it has %20 or other URL
encoded parts of the name, they will end up as-is as file name.

You may use this option as many times as the number of URLs you have.
(IMAP, POP3, SMTP)
Specify the Bearer Token for OAUTH 2.0 server authentication. The Bearer Token
is used in conjunction with the user name which can be specified as part of the

The Bearer Token and user name are formatted according to RFC 6750.

If this option is used several times, the last one will be used.
(HTTP) Extra header to include in the request when sending HTTP to a
proxy. You may specify any number of extra headers. This is the equivalent
CONNECT requests when you want a separate header sent to the proxy to what is
sent to the actual remote host.

content: do not add newlines or carriage returns, they will only mess things
up for you.

Headers specified with this option will not be included in requests that curl
knows will not be sent to a proxy.


(Added in 7.37.0)
protocols to attempt to tunnel through the proxy instead of merely using it to
do HTTP-like operations. The tunnel approach is made with the HTTP proxy
CONNECT request and requires that the proxy allows direct connect to the
remote port number curl wants to tunnel through to.
FTP. This switch makes curl use active mode. In practice, curl then tells the
server to connect back to the client's specified address and port, while
passive mode asks the server to setup an IP address and port for it to connect
to. <address> should be one of:
i.e "eth0" to specify which interface's IP address you want to use (Unix only)
i.e "192.168.10.1" to specify the exact IP address
i.e "my.host.domain" to specify the machine
make curl pick the same IP address that is already used for the control
connection
If this option is used several times, the last one will be used. Disable the

address, to tell curl what TCP port range to use. That means you specify a
port range, from a lower to a higher number. A single number works as well,
but do note that it increases the risk of failure since the port may not be
available.

If this option is used several times, the last one will be used.
path. Normally curl will squash or merge them according to standards but with
this option set you tell it not to do that.

(Added in 7.42.0)
into GET requests when following a 301 redirection. The non-RFC behaviour is
ubiquitous in web browsers, so curl does the conversion by default to maintain
consistency. However, a server may require a POST to remain a POST after such
(Added in 7.17.1)
into GET requests when following a 302 redirection. The non-RFC behaviour is
ubiquitous in web browsers, so curl does the conversion by default to maintain
consistency. However, a server may require a POST to remain a POST after such
(Added in 7.19.1)
into GET requests when following a 303 redirection. The non-RFC behaviour is
ubiquitous in web browsers, so curl does the conversion by default to maintain
consistency. However, a server may require a POST to remain a POST after such
(Added in 7.26.0)
Tells curl to use the listed protocols for its initial retrieval. Protocols
are evaluated left to right, are comma separated, and are each a protocol
name or 'all', optionally prefixed by zero or more modifiers. Available
modifiers are:
Permit this protocol in addition to protocols already permitted (this is
the default if no modifier is used).
Deny this protocol, removing it from the list of protocols already permitted.
Permit only this protocol (ignoring the list already permitted), though
subject to later modification by subsequent entries in the comma separated
list.
For example:
uses the default protocols, but disables ftps
only enables http and https
also only enables http and https
Unknown protocols produce a warning. This allows scripts to safely rely on
being able to disable potentially dangerous protocols, without relying upon
support for that protocol being built into curl to avoid an error.

This option can be used multiple times, in which case the effect is the same
as concatenating the protocols into one instance of the option.

(Added in 7.20.2)
Tells curl to use the listed protocols after a redirect. See --proto for
how protocols are represented.

(Added in 7.20.2)
Tells curl to pick a suitable authentication method when communicating with
in 7.13.2)
Tells curl to use HTTP Basic authentication when communicating with the given
the default authentication method curl uses with proxies.
Tells curl to use HTTP Digest authentication when communicating with the given
Tells curl to use HTTP Negotiate (SPNEGO) authentication when communicating
with a remote host. (Added in 7.17.1)
Tells curl to use HTTP NTLM authentication when communicating with the given
This option allows you to change the service name for proxy negotiation.

Use the specified HTTP 1.0 proxy. If the port number is not specified, it is
assumed at port 1080.

is that attempts to use CONNECT through the proxy will specify an HTTP 1.0
protocol instead of the default HTTP 1.1.
(SSH) Public key file name. Allows you to provide your public key in this
separate file.

If this option is used several times, the last one will be used.

(As of 7.39.0, curl attempts to automatically extract the public key from the
private key file, so passing this option is generally not required. Note that
this public key extraction requires libcurl to be linked against a copy of
libssh2 1.2.8 or higher that is itself linked against OpenSSL.)
default config file search path.
commands are sent BEFORE the transfer takes place (just after the initial PWD
command in an FTP transfer, to be exact). To make commands take place after a
successful transfer, prefix them with a dash '-'.  To make commands be sent
after curl has changed the working directory, just before the transfer
command(s), prefix the command with a '+' (this is only supported for
FTP). You may specify any number of commands. If the server returns failure
for one of the commands, the entire operation will be aborted. You must send
syntactically correct FTP commands as RFC 959 defines to FTP servers, or one
of the commands listed below to SFTP servers.  This option can be used
multiple times. When speaking to an FTP server, prefix the command with an
asterisk (*) to make curl continue even if the command fails as by default
curl will stop at first failure.

SFTP is a binary protocol. Unlike for FTP, curl interprets SFTP quote commands
itself before sending them to the server.  File names may be quoted
shell-style to embed spaces or special characters.  Following is the list of
all supported SFTP quote commands:
The chgrp command sets the group ID of the file named by the file operand to
the group ID specified by the group operand. The group operand is a decimal
integer group ID.
The chmod command modifies the file mode bits of the specified file. The
mode operand is an octal integer mode number.
The chown command sets the owner of the file named by the file operand to the
user ID specified by the user operand. The user operand is a decimal
integer user ID.
The ln and symlink commands create a symbolic link at the target_file location
pointing to the source_file location.
The mkdir command creates the directory named by the directory_name operand.
The pwd command returns the absolute pathname of the current working directory.
The rename command renames the file or directory named by the source
operand to the destination path named by the target operand.
The rm command removes the file specified by the file operand.
The rmdir command removes the directory entry specified by the directory
operand, provided it is empty.
See ln.
in a number of ways.
specifies the first 500 bytes
specifies the second 500 bytes
specifies the last 500 bytes
specifies the bytes from offset 9500 and forward
specifies the first and last byte only(*)(H)
specifies 300 bytes from offset 500(H)
specifies two separate 100-byte ranges(*)(H)
(*) = NOTE that this will cause the server to reply with a multipart
response!

Only digit characters (0-9) are valid in the 'start' and 'stop' fields of the
the server's response will be unspecified, depending on the server's
configuration.

enabled, so that when you attempt to get a range, you'll instead get the whole
document.

FTP and SFTP range downloads only support the simple 'start-stop' syntax
(optionally with one of the numbers omitted). FTP use depends on the extended
FTP command SIZE.

If this option is used several times, the last one will be used.
When used, this will make curl attempt to figure out the timestamp of the
remote file, and if that is available make the local file get that same
timestamp.
(SSL) Specify the path name to file containing what will be considered as
random data. The data is used to seed the random engine for SSL connections.
(HTTP) When used, it disables all internal HTTP decoding of content or transfer
encodings and instead makes them passed on unaltered, raw. (Added in 7.16.2)
This option changes the default action for all given URLs to be dealt with as
Provide a custom address for a specific host and port pair. Using this, you
can make the curl requests(s) use a specified address and prevent the
otherwise normally resolved address to be used. Consider it a sort of
the number used for the specific protocol the host will be used for. It means
you need several entries if you want to provide address for the same host but
different ports.

This option can be used many times to add many host names to resolve.

(Added in 7.21.3)
If a transient error is returned when curl tries to perform a transfer, it
will retry this number of times before giving up. Setting the number to 0
makes curl do no retries (which is the default). Transient error means either:
a timeout, an FTP 4xx response code or an HTTP 5xx response code.

When curl is about to retry a transfer, it will first wait one second and then
for all forthcoming retries it will double the waiting time until it reaches
10 minutes which then will be the delay between the rest of the retries.  By
retries. (Added in 7.12.3)

If this option is used several times, the last one will be used.
Make curl sleep this amount of time before each retry when a transfer has
failed with a transient error (it changes the default backoff time algorithm
used. Setting this delay to zero will make curl use the default backoff time.
(Added in 7.12.3)

If this option is used several times, the last one will be used.
The retry timer is reset before the first transfer attempt. Retries will be
given limit. Notice that if the timer hasn't reached the limit, the request
will be made and while performing, it may take longer than this given time
Set this option to zero to not timeout retries. (Added in 7.12.3)

If this option is used several times, the last one will be used.
Silent or quiet mode. Don't show progress meter or error messages.  Makes Curl
mute. It will still output the data you ask for, potentially even to the
Enable initial response in SASL authentication.
(Added in 7.31.0)
This option allows you to change the service name for SPNEGO.

encryption required. (Added in 7.20.0)

option name can still be used but will be removed in a future version.

option name can still be used but will be removed in a future version.
(SSL) This option tells curl to not work around a security flaw in the SSL3
and TLS1.0 protocols known as BEAST.  If this option isn't used, the SSL layer
may use workarounds known to cause interoperability problems with some older
SSL implementations. WARNING: this option loosens the SSL security, and by
using this flag you ask for exactly that.  (Added in 7.25.0)
Use the specified SOCKS4 proxy. If the port number is not specified, it is
assumed at port 1080. (Added in 7.15.2)

mutually exclusive.

Since 7.21.7, this option is superfluous since you can specify a socks4 proxy

If this option is used several times, the last one will be used.
Use the specified SOCKS4a proxy. If the port number is not specified, it is
assumed at port 1080. (Added in 7.18.0)

mutually exclusive.

Since 7.21.7, this option is superfluous since you can specify a socks4a proxy

If this option is used several times, the last one will be used.
Use the specified SOCKS5 proxy (and let the proxy resolve the host name). If
the port number is not specified, it is assumed at port 1080. (Added in
7.18.0)

mutually exclusive.

Since 7.21.7, this option is superfluous since you can specify a socks5

If this option is used several times, the last one will be used. (This option
was previously wrongly documented and used as --socks without the number
appended.)
Use the specified SOCKS5 proxy - but resolve the host name locally. If the
port number is not specified, it is assumed at port 1080.

mutually exclusive.

Since 7.21.7, this option is superfluous since you can specify a socks5 proxy

If this option is used several times, the last one will be used. (This option
was previously wrongly documented and used as --socks without the number
appended.)

allows you to change it.

not match the principal name.  (Added in 7.19.4).
As part of the GSS-API negotiation a protection mode is negotiated. RFC 1961
unprotected exchange of the protection mode negotiation. (Added in 7.19.4).
Redirect all writes to stderr to the specified file instead. If the file name
is a plain '-', it is instead written to stdout.

If this option is used several times, the last one will be used.
Pass options to the telnet protocol. Supported options are:

TTYPE=<term> Sets the terminal type.

XDISPLOC=<X display> Sets the X display location.

NEW_ENV=<var,val> Sets an environment variable.
This transfers the specified local file to the remote URL. If there is no file
part in the specified URL, Curl will append the local file name. NOTE that you
is no file name or curl will think that your last directory name is the remote
file name to use. That will most likely cause the upload operation to fail. If
this is used on an HTTP(S) server, the PUT command will be used.

Use the file name "-" (a single dash) to use stdin instead of a given file.
Alternately, the file name "." (a single period) may be specified instead
of "-" to use stdin in non-blocking mode to allow reading server output
while stdin is being uploaded.

You can specify one -T for each URL on the command line. Each -T + URL pair
specifies what to upload and to where. curl also supports "globbing" of the -T
argument, meaning that you can upload multiple files to a single URL by using
the same URL globbing style supported in the URL, like this:


or even

details about this option. (Added in 7.11.2)
(TFTP) Set TFTP BLKSIZE option (must be >512). This is the block size that
curl will try to use when transferring data to or from a TFTP server. By
default 512 bytes will be used.

If this option is used several times, the last one will be used.

(Added in 7.20.0)
Set TLS authentication type. Currently, the only supported option is "SRP",
(Added in 7.21.4)
Set password for use with the TLS authentication method specified with
7.21.4)
Set username for use with the TLS authentication method specified with
7.21.4)
(SSL)
Forces curl to use TLS version 1.0 when negotiating with a remote TLS server.
(Added in 7.34.0)
(SSL)
Forces curl to use TLS version 1.1 when negotiating with a remote TLS server.
(Added in 7.34.0)
(SSL)
Forces curl to use TLS version 1.2 when negotiating with a remote TLS server.
(Added in 7.34.0)
(HTTP) Request a compressed Transfer-Encoding response using one of the
algorithms curl supports, and uncompress the data while receiving it.

(Added in 7.21.6)
Enables a full trace dump of all incoming and outgoing data, including
descriptive information, to the given output file. Use "-" as filename to have
the output sent to stdout.


If this option is used several times, the last one will be used.
Enables a full trace dump of all incoming and outgoing data, including
descriptive information, to the given output file. Use "-" as filename to have
the output sent to stdout.

shows the ASCII part of the dump. It makes smaller output that might be easier
to read for untrained humans.


If this option is used several times, the last one will be used.
Prepends a time stamp to each trace or verbose line that curl displays.
(Added in 7.14.0)
(HTTP) Connect through this Unix domain socket, instead of using the
network. (Added in 7.40.0)
Specify the user name and password to use for server authentication. Overrides

If you simply specify the user name, curl will prompt for a password.

The user name and passwords are split up on the first colon, which makes it
impossible to use a colon in the user name with this option. The password can,
still.

When using Kerberos V5 with a Windows based server you should include the
Windows domain name in the user name, in order for the server to successfully
obtain a Kerberos Ticket. If you don't then the initial authentication
handshake may fail.

When using NTLM, the user name can be specified simply as the user name,
without the domain, if there is a single domain and forest in your setup
for example.

To specify the domain name use either Down-Level Logon Name or UPN (User
respectively.

If you use a Windows SSPI-enabled curl binary and perform Kerberos V5,
Negotiate, NTLM or Digest authentication then you can tell curl to select
the user name and password from your environment by specifying a single colon
with this option: "-u :".

If this option is used several times, the last one will be used.
Specify the user name and password to use for proxy authentication.

If you use a Windows SSPI-enabled curl binary and do either Negotiate or NTLM
authentication then you can tell curl to select the user name and password
from your environment by specifying a single colon with this option: "-U :".

If this option is used several times, the last one will be used.
Specify a URL to fetch. This option is mostly handy when you want to specify
URL(s) in a config file.

This option may be used any number of times. To control where this URL is
seeing what's going on "under the hood". A line starting with '>' means
"header data" sent by curl, '<' means "header data" received by curl that is
hidden in normal cases, and a line starting with '*' means additional info
provided by curl.

might be the option you're looking for.

If you think this option still doesn't give you enough details, consider using


Make curl display information on stdout after a completed transfer. The format
is a string that may contain plain text mixed with any number of
variables. The format can be specified as a literal "string", or you can have
curl read the format from a file with "@filename" and to tell curl to read the
format from stdin you write "@-".

The variables present in the output format will be substituted by the value or
text that curl thinks fit, as described below. All variables are specified
as %{variable_name} and to output a normal % you just write them as

The %-symbol is a special symbol in the win32-environment, where all
occurrences of % must be doubled when using this option.

The variables available are:
The Content-Type of the requested document, if there was any.
The ultimate filename that curl writes out to. This is only meaningful if curl
option. (Added in 7.25.1)
The initial path curl ended up in when logging on to the remote FTP
server. (Added in 7.15.4)
The numerical response code that was found in the last retrieved HTTP(S) or
same info.
The numerical code that was found in the last response (from a proxy) to a
curl CONNECT request. (Added in 7.12.4)
The IP address of the local end of the most recently done connection - can be
either IPv4 or IPv6 (Added in 7.29.0)
The local port number of the most recently done connection (Added in 7.29.0)
Number of new connects made in the recent transfer. (Added in 7.12.3)
Number of redirects that were followed in the request. (Added in 7.12.3)
When an HTTP request was made without -L to follow redirects, this variable
The remote IP address of the most recently done connection - can be either
IPv4 or IPv6 (Added in 7.29.0)
The remote port number of the most recently done connection (Added in 7.29.0)
The total amount of bytes that were downloaded.
The total amount of bytes of the downloaded headers.
The total amount of bytes that were sent in the HTTP request.
The total amount of bytes that were uploaded.
The average download speed that curl measured for the complete download. Bytes
per second.
The average upload speed that curl measured for the complete upload. Bytes per
second.
The result of the SSL peer certificate verification that was requested. 0
means the verification was successful. (Added in 7.19.0)
The time, in seconds, it took from the start until the TCP connect to the
remote host (or proxy) was completed.
The time, in seconds, it took from the start until the name resolving was
completed.
The time, in seconds, it took from the start until the file transfer was just
about to begin. This includes all pre-transfer commands and negotiations that
are specific to the particular protocol(s) involved.
The time, in seconds, it took for all redirection steps include name lookup,
connect, pretransfer and transfer before the final transaction was
started. time_redirect shows the complete execution time for multiple
redirections. (Added in 7.12.3)
The time, in seconds, it took from the start until the first byte was just
about to be transferred. This includes time_pretransfer and also the time the
server needed to calculate the result.
The total time, in seconds, that the full operation lasted. The time will be
displayed with millisecond resolution.
The URL that was fetched last. This is most meaningful if you've told curl
to follow location: headers.
If this option is used several times, the last one will be used.
Use the specified proxy.

protocol support was added in curl 7.21.7)

If the port number is not specified in the proxy string, it is assumed to be
1080.

This option overrides existing environment variables that set the proxy to
use. If there's an environment variable setting a proxy, you can set proxy to

All operations that are performed over an HTTP proxy will transparently be
converted to HTTP. It means that certain protocol specific operations might
not be available. This is not the case if you can tunnel through the proxy, as

User and password that might be provided in the proxy string are URL decoded
by curl. This allows you to pass in special characters such as @ by using %40
or pass in a colon with %3a.

The proxy host can be specified the exact same way as the proxy environment
password.

If this option is used several times, the last one will be used.
(HTTP) Specifies a custom request method to use when communicating with the
HTTP server.  The specified request method will be used instead of the method
otherwise used (which defaults to GET). Read the HTTP 1.1 specification for
details and explanations. Common additional HTTP requests include PUT and
DELETE, but related technologies like WebDAV offers PROPFIND, COPY, MOVE and
more.

Normally you don't need this option. All sorts of GET, HEAD, POST and PUT
requests are rather invoked by using dedicated command line options.

This option only changes the actual word used in the HTTP request, it does not
alter the way curl behaves. So for example if you want to make a proper HEAD
option.

The method string you set with -X will be used for all requests, which if you
curl doesn't change request method according to the HTTP 30x response codes -
and similar.

(FTP)
Specifies a custom FTP command to use instead of LIST when doing file lists
with FTP.

(POP3)
Specifies a custom POP3 command to use instead of LIST or RETR. (Added in
7.26.0)

(IMAP)
Specifies a custom IMAP command to use instead of LIST. (Added in 7.30.0)

(SMTP)
Specifies a custom SMTP command to use instead of HELP or VRFY. (Added in 7.34.0)

If this option is used several times, the last one will be used.
When saving output to a file, this option tells curl to store certain file
metadata in extended file attributes. Currently, the URL is stored in the
xdg.origin.url attribute and, for HTTP, the content type is stored in
the mime_type attribute. If the file system does not support extended
attributes, a warning is issued.

If a download is slower than speed-limit bytes per second during a speed-time
period, the download gets aborted. If speed-time is used, the default

This option controls transfers and thus will not affect slow connects etc. If

If this option is used several times, the last one will be used.
If a download is slower than this given speed (in bytes per second) for
if not set.

If this option is used several times, the last one will be used.
date, or one that has been modified before that time. The <date expression>
can be all sorts of date strings or if it doesn't match any internal ones, it
is taken as a filename and tries to get the modification date (mtime) from
details.

Start the date expression with a dash (-) to make it request for a document

If this option is used several times, the last one will be used.
Usage help. This lists all current command line options with a short
description.
Manual. Display the huge help text.
Displays information about curl and the libcurl version it uses.

The first line includes the full version of curl, libcurl and other 3rd party
libraries linked with the executable.

The second line (starts with "Protocols:") shows all protocols that libcurl
reports to support.

The third line (starts with "Features:") shows specific features libcurl
reports to offer. Available features include:
You can use IPv6 with this.
Krb4 for FTP is supported.
SSL versions of various protocols are supported, such as HTTPS, FTPS, POP3S
and so on.
Automatic decompression of compressed files over HTTP is supported.
NTLM authentication is supported.
This curl uses a libcurl built with Debug. This enables more error-tracking
and memory debugging etc. For curl-developers only!
This curl uses asynchronous name resolves. Asynchronous name resolves can be
done using either the c-ares or the threaded resolver backends.
SPNEGO authentication is supported.
This curl supports transfers of large files, files larger than 2GB.
This curl supports IDN - international domain names.
GSS-API is supported.
SSPI is supported.
SRP (Secure Remote Password) authentication is supported for TLS.
This curl supports Metalink (both version 3 and 4 (RFC 5854)), which
describes mirrors and hashes.  curl will use mirrors for failover if
there are errors (such as the file or server not being available).
The environment variables can be specified in lower case or upper case. The
lower case version has precedence. http_proxy is an exception as it is only
available in lower case.

Using an environment variable to set the proxy has the same effect as using

Sets the proxy server to use for HTTP.
Sets the proxy server to use for HTTPS.
Sets the proxy server to use for [url-protocol], where the protocol is a
protocol that curl supports and as specified in a URL. FTP, FTPS, POP3, IMAP,
SMTP, LDAP etc.
Sets the proxy server to use if no protocol-specific proxy is set.
list of host names that shouldn't go through any proxy. If set to a asterisk
Since curl version 7.21.7, the proxy string may be specified with a

If no protocol is specified in the proxy string or if the string doesn't match
a supported one, the proxy will be treated as an HTTP proxy.

The supported proxy protocol prefixes are as follows:
There are a bunch of different error codes and their corresponding error
messages that may appear during bad conditions. At the time of this writing,
the exit codes are:
Unsupported protocol. This build of curl has no support for this protocol.
Failed to initialize.
URL malformed. The syntax was not correct.
A feature or option that was needed to perform the desired request was not
enabled or was explicitly disabled at build-time. To make curl able to do
this, you probably need another build of libcurl!
Couldn't resolve proxy. The given proxy host could not be resolved.
Couldn't resolve host. The given remote host was not resolved.
Failed to connect to host.
FTP weird server reply. The server sent data curl couldn't parse.
FTP access denied. The server denied login or denied access to the particular
resource or directory you wanted to reach. Most often you tried to change to a
directory that doesn't exist on the server.
FTP weird PASS reply. Curl couldn't parse the reply sent to the PASS request.
FTP weird PASV reply, Curl couldn't parse the reply sent to the PASV request.
FTP weird 227 format. Curl couldn't parse the 227-line the server sent.
FTP can't get host. Couldn't resolve the host IP we got in the 227-line.
FTP couldn't set binary. Couldn't change transfer method to binary.
Partial file. Only a part of the file was transferred.
failed.
FTP quote error. A quote command returned error from the server.
HTTP page not retrieved. The requested url was not found or returned another
error with the HTTP error code being 400 or above. This return code only
Write error. Curl couldn't write data to a local filesystem or similar.
FTP couldn't STOR file. The server denied the STOR operation, used for FTP
uploading.
Read error. Various reading problems.
Out of memory. A memory allocation request failed.
Operation timeout. The specified time-out period was reached according to the
conditions.
FTP PORT failed. The PORT command failed. Not all FTP servers support the PORT
command, try doing a transfer using PASV instead!
FTP couldn't use REST. The REST command failed. This command is used for
resumed FTP transfers.
HTTP range error. The range "command" didn't work.
HTTP post error. Internal post-request generation error.
SSL connect error. The SSL handshaking failed.
FTP bad download resume. Couldn't continue an earlier aborted download.
FILE couldn't read file. Failed to open the file. Permissions?
LDAP cannot bind. LDAP bind operation failed.
LDAP search failed.
Function not found. A required LDAP function was not found.
Aborted by callback. An application told curl to abort the operation.
Internal error. A function was called with a bad parameter.
Interface error. A specified outgoing interface could not be used.
Too many redirects. When following redirects, curl hit the maximum amount.
Unknown option specified to libcurl. This indicates that you passed a weird
option to curl that was passed on to libcurl and rejected. Read up in the
manual!
Malformed telnet option.
The peer's SSL certificate or SSH MD5 fingerprint was not OK.
The server didn't reply anything, which here is considered an error.
SSL crypto engine not found.
Cannot set SSL crypto engine as default.
Failed sending network data.
Failure in receiving network data.
Problem with the local certificate.
Couldn't use specified SSL cipher.
Peer certificate cannot be authenticated with known CA certificates.
Unrecognized transfer encoding.
Invalid LDAP URL.
Maximum file size exceeded.
Requested FTP SSL level failed.
Sending the data requires a rewind that failed.
Failed to initialise SSL Engine.
The user name, password, or similar was not accepted and curl failed to log in.
File not found on TFTP server.
Permission problem on TFTP server.
Out of disk space on TFTP server.
Illegal TFTP operation.
Unknown TFTP transfer ID.
File already exists (TFTP).
No such user (TFTP).
Character conversion failed.
Character conversion functions required.
Problem with reading the SSL CA cert (path? access rights?).
The resource referenced in the URL does not exist.
An unspecified error occurred during the SSH session.
Failed to shut down the SSL connection.
Could not load CRL file, missing or wrong format (added in 7.19.0).
Issuer check failed (added in 7.19.0).
The FTP PRET command failed
RTSP: mismatch of CSeq numbers
RTSP: mismatch of Session Identifiers
unable to parse FTP file list
FTP chunk callback reported error
No connection available, the session will be queued
SSL public key does not matched pinned public key
More error codes will appear here in future releases. The existing ones
are meant to never change.
Daniel Stenberg is the main author, but the whole list of contributors is
found in the separate THANKS file.
The
utility cuts out selected portions of each line (as specified by
from each
and writes them to the standard output.
If no
arguments are specified, or a file argument is a single dash
reads from the standard input.
The items specified by
can be in terms of column position or in terms of fields delimited
by a special character.
Column numbering starts from 1.
The
option argument
number ranges.
Number ranges consist of a number, a dash
and a second number
and select the fields or columns from the first number to the second,
inclusive.
Numbers or number ranges may be preceded by a dash, which selects all
fields or columns from 1 to the last number.
Numbers or number ranges may be followed by a dash, which selects all
fields or columns from the last number to the end of the line.
Numbers and number ranges may be repeated, overlapping, and in any order.
If a field or column is specified multiple times, it will appear only
once in the output.
It is not an error to select fields or columns not present in the
input line.
The options are as follows:
The
specifies byte positions.
The
specifies character positions.
Use
as the field delimiter character instead of the tab character.
The
specifies fields, separated in the input by the field delimiter character
(see the
option.)
Output fields are separated by a single occurrence of the field delimiter
character.
Do not split multi-byte characters.
Characters will only be output if at least one byte is selected, and,
after a prefix of zero or more unselected bytes, the rest of the bytes
that form the character are selected.
Suppress lines with no field delimiter characters.
Unless specified, lines with no delimiters are passed through unmodified.
The
and
environment variables affect the execution of
as described in
Extract users' login names and shells from the system
file as
pairs:
Show the names and login times of the currently logged in users:
The
utility conforms to
A
command appeared in
System III
Copyright (c) 2010 Apple Inc.  All rights reserved.
@APPLE_BSD_LICENSE_HEADER_START@
Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions
are met:
1.  Redistributions of source code must retain the above copyright
    notice, this list of conditions and the following disclaimer.
2.  Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
3.  Neither the name of Apple Computer, Inc. ("Apple") nor the names of
    its contributors may be used to endorse or promote products derived
    from this software without specific prior written permission.
THIS SOFTWARE IS PROVIDED BY APPLE AND ITS CONTRIBUTORS "AS IS" AND ANY
EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL APPLE OR ITS CONTRIBUTORS BE LIABLE FOR ANY
DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF
THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
@APPLE_BSD_LICENSE_HEADER_END@
allows you to manage roots, or
archives, of files that replace parts of your system. This is useful
for installing a new version of a library or tool on your system while 
allowing you to uninstall the files and revert back to the originals 
safely and easily.
Do not run helpful automation. See HELPFUL AUTOMATION below.
Force. Some operations will fail gracefully due to potentially unsafe 
situations, such as a root that installs a file where a directory is.
In order to have darwinup continue through such a situation, you can
pass the -f option.
Dry run. Darwinup will go through an operation, including analyzing
be modified on your system and no records will be added to the depot.
This option implies -d.
Prefix path. Normally, darwinup will operate on the boot partition. You
can use the -p option to have darwinup work on another partition. You
can provide any arbitrary path, it does not need to be a mount point.
Restart. Gracefully restart after all operations are complete by telling
Finder to restart. 
Verbose. This option causes darwinup to print extra information. You can
pass 2 or 3 v's for even more information, but that is usually only needed
for development and debugging of darwinup itself.
Note that the
and
options listed below support globbing and multiple items. See the EXAMPLES 
section below for more details.
List the files and directories in the 
Install the root at 
List archives that are installed. You may optionally provide an
archive specification to limit which archives get listed. 
Rename an archive.
Uninstall the specified archive.
Find the last archive that was installed with the same name (basename of 
path), and replace it with the root at 
List all of the information about 
This includes status letters
detailing how the archive differs from whats on disk
Unknown state. Probably a bug.
Missing file during uninstall. Darwinup expected a file or directory to 
exist, but it did not. This could be a bug in darwinup, but most likely 
another tool or software update removed a file that darwinup had been 
tracking. It can also be caused by an installation failing due to an
object changing type (see FORCING OPERATIONS below), and the subsequent 
rollback finding the root only partially installed. Since these all 
happen during uninstall, they are typically safe to ignore, since darwinup 
was going to delete the object anyway.
Added. No previous file or directory existed so the file or directory was
added to your system.
External change. The file you are installing is different than the 
last file you installed, but it is identical to what was actually found
on disk. This probably means something manually installed a root or software
update without darwinup knowing about it. This is usually harmless. 
Mode change. Only changes to permission or ownership were needed to
uninstall the file or directory. 
Removed. No previous file or directory existed, so the uninstall process
removed the file. 
Updated. During installation, the file or directory replaces an existing 
object at the same path. During uninstallation, the previous version of
the file was restored.
Ignored. A file specified in the removal list was not removed. This usually
indicates that the file was a directory and the path in the removal list lacked
a trailing
character.
You can install archive files or directories by specifying a relative or 
absolute path. If the path is a directory, all files below it will be 
installed as a single root. If the path points to a file, it must be one of
the suported archive file types as described in the usage statement. 
like any other root.
archive file will be downloaded using curl to your machine and then
installed like any other archive file. You can not point darwinup at a
directory hosted via HTTP or HTTPS, only archive files such as tarballs.  
When running a subcommand which takes an 
argument, you can use one or more of the following items to specify which
archive to operate on. You can mix and match any of them as needed. 
You can use the list subcommand with these specifications to see what will 
match.
You can specify an archive with its serial number, which can be found using
the list subcommand.
You can specify an archive with its UUID, which can be found using the
list subcommand.
You can specify an archive with its name, which can be found using the
list subcommand.
The newest keyword will match the one archive which was most recently
installed. This should always be the first archive listed.
The oldest keyword will match the one archive which was installed the
longest time ago. This should always be the last archive listed. 
The superseded keyword will match zero or more archives. An archive is
superseded if every file it contains is contained in an archive that was
(and still is) installed after it. A file in an archive can also be superseded
by external changes, such as operating system updates. When uninstalling a
superseded archive, you should never see any status symbols, since being
superseded means there is a newer file on disk. 
The all keyword will match all archives. If you specify extra verbosity 
with -vv, then rollback archives will also be matched by the all keyword. This
means that 
will attempt to uninstall rollback archives, which will print a message
about not being able to uninstall rollback archives. This is normal and
not a problem. 
There are 2 cases where darwinup will require you to pass the force (-f)
option before proceeding with an operation.
If you install an archive which contains a file with the same path as a 
directory on your system, or vice versa, darwinup will give you a error
about not doing that unless you really want to force it. If you do force
the operation, darwinup will delete the existing object and replace it with
the object from the root. This can happen when a directory full of files
"type change", then it is probably safe to force the operation. 
Darwinup remembers the version (build) of the operating system when a root
is installed. The reason for this is darwinup saves the old (replaced)
files during the installation procedure. Those backups may have come from
the older operating system, and thus are not necessarily compatible with
the current build of the operating system. So if you try to uninstall an
archive that had been installed on a different version of the operating
system, darwinup will stop and provide a message asking you to force the
operation if you really want to. If the files you are uninstalling are all
superseded, then you should not get this error as the backup copies will
not be used anyway. 
Darwinup tries to detect common situations and run external tools that you
would otherwise have to remember to run yourself. The "dry run" (-n) and 
"disable automation" (-d) options prevent any of the following from 
happening.
If a root modifies any file, then darwinup will run 
update_dyld_shared_cache unless the -d option is specified.
kext cache is updated during the next boot. 
supports removing files from disk as part of installing a root. These files must
be enumerated in a list that is included in the root at the path
The list is a simple text file consisting of paths to remove, separated by new
lines. Directories may be present in this list. If a directory is to be removed,
be removed. When files are removed as part of root installation, they will be
restored when the root is uninstalled with the
command.
It is permissible for the root to contain files that are specified in its
removal list. This is primarily useful for replacing entire directory
hierarchies as singular entities.
Replacing a directory hierarchy can only be done safely is the root creator has
full knowledge of the contents of a given directory hierarchy and knows how to
completely populate it such that all dependencies will be satisfied. For
example, a project which installs content into
should
specify that path in its removal list since many other projects populate that
directory. The result of the removal operation in such a case would be the only
the contents of the root would exist in
after the installation completes.
cannot and does not protect against this scenario, so exercise extreme caution
when constructing roots with removal lists.
Neither the
directory nor its contents will be installed into the destination path.
$ darwinup install library-1.2.3.tar.gz
$ darwinup uninstall all
$ darwinup list superseded
$ darwinup uninstall superseded
$ darwinup uninstall 9 16 myroot oldest
When invoked without arguments, the
utility displays the current date and time.
Otherwise, depending on the options specified,
will set the date and time or print it in a user-defined way.
The
utility displays the date and time read from the kernel clock.
When used to set the date and time,
both the kernel clock and the hardware clock are updated.
Only the superuser may set the date,
and if the system securelevel (see
is greater than 1,
the time may not be changed by more than 1 second.
The options are as follows:
Set the kernel's value for daylight saving time.
If
is non-zero, future calls
to
will return a non-zero for
Use
as the format string to parse the
provided rather than using the default
format.
Parsing is done using
Do not try to set the date.
This allows you to use the
flag in addition to the
option to convert one date format to another.
By default, if the
daemon is running,
sets the time on all of the machines in the local group.
The
option suppresses this behavior and causes the time to be set only on the
current machine.
Print the date and time represented by
where
is the number of seconds since the Epoch
(00:00:00 UTC, January 1, 1970;
see
and can be specified in decimal, octal, or hex.
Set the system's value for minutes west of
specifies the number of minutes returned in
by future calls to
Display or set the date in
(Coordinated Universal) time.
Adjust (i.e., take the current date and display the result of the
adjustment; not actually set the date) the second, minute, hour, month
day, week day, month or year according to
If
is preceded with a plus or minus sign,
the date is adjusted forwards or backwards according to the remaining string,
otherwise the relevant part of the date is set.
The date can be adjusted as many times as required using these flags.
Flags are processed in the order given.
When setting values
(rather than adjusting them),
seconds are in the range 0-59, minutes are in the range 0-59, hours are
in the range 0-23, month days are in the range 1-31, week days are in the
range 0-6 (Sun-Sat),
months are in the range 1-12 (Jan-Dec)
and years are in the range 80-38 or 1980-2038.
If
is numeric, one of either
or
must be used to specify which part of the date is to be adjusted.
The week day or month may be specified using a name rather than a
number.
If a name is used with the plus
(or minus)
sign, the date will be put forwards
(or backwards)
to the next
(previous)
date that matches the given week day or month.
This will not adjust the date,
if the given week day or month is the same as the current one.
When a date is adjusted to a specific value or in units greater than hours,
daylight savings time considerations are ignored.
Adjustments in units of hours or less honor daylight saving time.
So, assuming the current date is March 26, 0:30 and that the DST adjustment
means that the clock goes forward at 01:00 to 02:00, using
will adjust the date to March 26, 2:30.
Likewise, if the date is October 29, 0:30 and the DST adjustment means that
the clock goes back at 02:00 to 01:00, using
will be necessary to reach October 29, 2:30.
When the date is adjusted to a specific value that does not actually exist
the date will be silently adjusted forwards in units of one hour until it
reaches a valid time.
When the date is adjusted to a specific value that occurs twice
(for example October 29, 1:30 2000),
the resulting timezone will be set so that the date matches the earlier of
the two times.
Adjusting the date by months is inherently ambiguous because
a month is a unit of variable length depending on the current date.
This kind of date adjustment is applied in the most intuitive way.
First of all,
tries to preserve the day of the month.
If it is impossible because the target month is shorter than the present one,
the last day of the target month will be the result.
For example, using
on May 31 will adjust the date to June 30, while using the same option
on January 30 will result in the date adjusted to the last day of February.
This approach is also believed to make the most sense for shell scripting.
Nevertheless, be aware that going forth and back by the same number of
months may take you to a different date.
Refer to the examples below for further details.
An operand with a leading plus
sign signals a user-defined format string
which specifies the format in which to display the date and time.
The format string may contain any of the conversion specifications
described in the
manual page, as well as any arbitrary text.
A newline
character is always output after the characters specified by
the format string.
The format string for the default display is
If an operand does not have a leading plus sign, it is interpreted as
a value for setting the system's notion of the current date and time.
The canonical representation for setting the date and time is:
Century
(either 19 or 20)
prepended to the abbreviated year.
Year in abbreviated form
(e.g., 89 for 1989, 06 for 2006).
Numeric month, a number from 1 to 12.
Day, a number from 1 to 31.
Hour, a number from 0 to 23.
Minutes, a number from 0 to 59.
Seconds, a number from 0 to 61
(59 plus a maximum of two leap seconds).
Everything but the minutes is optional.
Time changes for Daylight Saving Time, standard time, leap seconds,
and leap years are handled automatically.
The following environment variables affect the execution of
The timezone to use when displaying dates.
The normal format is a pathname relative to
For example, the command
displays the current time in California.
See
for more information.
record of the user setting the time
The
utility exits 0 on success, 1 if unable to set the date, and 2
if able to set the local date, but unable to set it globally.
The command:
will display:
DATE: 1987-11-21
TIME: 13:36:16
will display:
where it is currently
The command:
will display the last day of February in the year 2000:
So will do the command:
because there is no such date as the 30th of February.
The command:
will display the last Friday of the month:
where it is currently
The command:
sets the date to
may be used on one machine to print out the date
suitable for setting on another.
The command:
sets the time to
without modifying the date.
Finally the command:
can be used to parse the output from
and express it in Epoch time.
Occasionally, when
synchronizes the time on many hosts, the setting of a new time value may
require more than a few seconds.
On these occasions,
prints:
The message
occurs when the communication
between
and
fails.
As above, except for the second line, which is:
When invoked in legacy mode, the following exit values are returned:
The date was written successfully
Unable to set the date
Able to set the local date, but unable to set it globally
For more information about legacy mode, see
The
utility is expected to be compatible with
A
command appeared in
The
utility writes the pathnames of log files that are no longer in use (for example, no longer involved in active transactions), to the standard output, one pathname per line. These log files should be written to backup media to provide for recovery in the case of catastrophic failure (which also requires a snapshot of the database files), but they may then be deleted from the system to reclaim disk space.
The options are as follows:
Write all pathnames as absolute pathnames, instead of relative to the database home directories.
Remove log files that are no longer needed; no filenames are written. Automatic log file removal is likely to make catastrophic recovery impossible.
Specify a home directory for the database environment; by default, the current working directory is used.
Write out the pathnames of all the database log files, whether or not they are involved in active transactions.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
Write the pathnames of all the database files that need to be archived in order to recover the database from catastrophic failure. If any of the database files have not been accessed during the lifetime of the current log files, db_archive will not include them in this output.
It is possible that some of the files to which the log refers have since been deleted from the system. In this case, db_archive will ignore them. When db_recover is run, any files to which the log refers that are not present during recovery are assumed to have been deleted and will not be recovered.
Write the library version number to the standard output, and exit.
Run in verbose mode, listing the checkpoints in the log files as they are reviewed.
The db_archive utility uses a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, db_archive should always be given the chance to detach from the environment and exit gracefully. To cause db_archive to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
The
utility is a daemon process that monitors the database log, and periodically calls DB_ENV->txn_checkpoint to checkpoint it.
The options are as follows:
Checkpoint the log once, regardless of whether or not there has been activity since the last checkpoint and then exit.
Specify a home directory for the database environment; by default, the current working directory is used.
Checkpoint the database at least as often as every kbytes of log file are written.
Log the execution of the db_checkpoint utility to the specified file in the following format, where ### is the process ID, and the date is the time the utility was started.
This file will be removed if the db_checkpoint utility exits gracefully.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
Checkpoint the database at least every min minutes if there has been any activity since the last checkpoint.
Write the library version number to the standard output, and exit.
Write the time of each checkpoint attempt to the standard output.
At least one of the -1, -k, and -p options must be specified.
The db_checkpoint utility uses a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, db_checkpoint should always be given the chance to detach from the environment and exit gracefully. To cause db_checkpoint to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The db_checkpoint utility does not attempt to create the Berkeley DB shared memory regions if they do not already exist. The application that creates the region should be started first, and once the region is created, the db_checkpoint utility should be started.
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
The
utility traverses the database environment lock region, and aborts a lock request each time it detects a deadlock or a lock request that has timed out. By default, in the case of a deadlock, a random lock request is chosen to be aborted.
This utility should be run as a background daemon, or the underlying Berkeley DB deadlock detection interfaces should be called in some other way, whenever there are multiple threads or processes accessing a database and at least one of them is modifying it.
The options are as follows:
When a deadlock is detected, abort the locker:
with the greatest number of locks
with the fewest number of locks
with the oldest locker ID
with the fewest number of write locks
with the youngest locker ID
When lock or transaction timeouts have been specified:
abort any lock request that has timed out
Specify a home directory for the database environment; by default, the current working directory is used.
Log the execution of the db_deadlock utility to the specified file in the following format, where ### is the process ID, and the date is the time the utility was started.
This file will be removed if the db_deadlock utility exits gracefully.
Check the database environment every sec seconds plus usec microseconds to see if a process has been forced to wait for a lock; if one has, review the database environment lock structures.
Write the library version number to the standard output, and exit.
Run in verbose mode, generating messages each time the detector runs.
If the -t option is not specified, db_deadlock will run once and exit.
The db_deadlock utility uses a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, db_deadlock should always be given the chance to detach from the environment and exit gracefully. To cause db_deadlock to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The db_deadlock utility does not attempt to create the Berkeley DB shared memory regions if they do not already exist. The application which creates the region should be started first, and then, once the region is created, the db_deadlock utility should be started.
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
file
The
utility reads the database file file and writes it to the standard output using a portable flat-text format understood by the db_load utility. The file argument must be a file produced using the Berkeley DB library functions.
The options are as follows:
Dump the specified database in a format helpful for debugging the Berkeley DB library routines.
Display all information.
Display only page headers.
Do not display the free-list or pages on the free list. This mode is used by the recovery tests.
Write to the specified file instead of to the standard output.
Specify a home directory for the database environment; by default, the current working directory is used.
Dump record numbers from Queue and Recno databases as keys.
List the databases stored in the file.
Do not acquire shared region mutexes while running. Other problems, such as potentially fatal errors in Berkeley DB, will be ignored as well. This option is intended only for debugging errors, and should not be used under any other circumstances.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
If characters in either the key or data items are printing characters (as defined by isprint(3)), use printing characters in file to represent them. This option permits users to use standard text editors and tools to modify the contents of databases.
Note: different systems may have different notions about what characters are considered 
and databases dumped in this manner may be less portable to external systems.
Aggressively salvage data from a possibly corrupt file. The -R flag differs from the -r option in that it will return all possible data from the file at the risk of also returning already deleted or otherwise nonsensical items. Data dumped in this fashion will almost certainly have to be edited by hand or other means before the data is ready for reload into another database
Salvage data from a possibly corrupt file. When used on a uncorrupted database, this option should return equivalent data to a normal dump, but most likely in a different order.
Specify a single database to dump. If no database is specified, all databases in the database file are dumped.
Write the library version number to the standard output, and exit.
Dumping and reloading Hash databases that use user-defined hash functions will result in new databases that use the default hash function. Although using the default hash function may not be optimal for the new database, it will continue to work correctly.
Dumping and reloading Btree databases that use user-defined prefix or comparison functions will result in new databases that use the default prefix and comparison functions. 
The only available workaround for either case is to modify the sources for the db_load utility to load the database using the correct hash, prefix, and comparison functions.
The 
utility output format is documented in the Dump Output Formats section of the Berkeley DB Reference Guide.
The
utility may be used with a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, 
should always be given the chance to detach from the environment and exit gracefully. To cause
to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
Even when using a Berkeley DB database environment, the
utility does not use any kind of database locking if it is invoked with the -d, -R, or -r arguments. If used with one of these arguments, the
utility may only be safely run on databases that are not being modified by any other process; otherwise, the output may be corrupt.
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
file
The
utility reads from the standard input and loads it into the database file. The database file is created if it does not already exist.
The input to
must be in the output format specified by the db_dump utility, utilities, or as specified for the -T below.
The options are as follows:
Specify configuration options ignoring any value they may have based on the input. The command-line format is name=value. See the Supported Keywords section below for a list of keywords supported by the -c option.
Read from the specified input file instead of from the standard input.
Specify a home directory for the database environment.
If a home directory is specified, the database environment is opened using the Db.DB_INIT_LOCK, Db.DB_INIT_LOG, Db.DB_INIT_MPOOL, Db.DB_INIT_TXN, and Db.DB_USE_ENVIRON flags to DB_ENV->open. (This means that db_load can be used to load data into databases while they are in use by other processes.) If the DB_ENV->open call fails, or if no home directory is specified, the database is still updated, but the environment is ignored; for example, no locking is done.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
The -T option allows non-Berkeley DB applications to easily load text files into databases.
If the database to be created is of type Btree or Hash, or the keyword keys is specified as set, the input must be paired lines of text, where the first line of the pair is the key item, and the second line of the pair is its corresponding data item. If the database to be created is of type Queue or Recno and the keyword keys is not set, the input must be lines of text, where each line is a new data item for the database.
For this reason, any backslash or newline characters that naturally occur in the text input must be escaped to avoid misinterpretation by db_load.
If the -T option is specified, the underlying access method type must be specified using the -t option.
Specify the underlying access method. If no -t option is specified, the database will be loaded into a database of the same type as was dumped; for example, a Hash database will be created if a Hash database was dumped.
Btree and Hash databases may be converted from one to the other. Queue and Recno databases may be converted from one to the other. If the -k option was specified on the call to db_dump then Queue and Recno databases may be converted to Btree or Hash, with the key being the integer record number.
Write the library version number to the standard output, and exit.
The db_load utility may be used with a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, db_load should always be given the chance to detach from the environment and exit gracefully. To cause db_load to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The
Note that backslash characters naturally occurring in the text are escaped to avoid interpretation as escape characters by db_load.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
The following keywords are supported for the -c command-line option to the
utility. See DB->open for further discussion of these keywords and what values should be specified.
The parenthetical listing specifies how the value part of the name=value pair is interpreted. Items listed as (boolean) expect value to be 1 (set) or 0 (unset). Items listed as (number) convert value to a number. Items listed as (string) use the string value without modification.
The minimum number of keys per page.
Enable page checksums.
The database to load.
The byte order for integers in the stored database metadata.
The size of database pages, in bytes.
The value of the Db.DB_DUP flag.
The value of the Db.DB_DUPSORT flag.
The size of database extents, in pages, for Queue databases configured to use extents.
The density within the Hash database.
The size of the Hash database.
Specify whether keys are present for Queue or Recno databases.
Specify fixed-length records of the specified length.
Specify the fixed-length record pad character.
The value of the Db.DB_RECNUM flag.
The value of the Db.DB_RENUMBER flag.
The subdatabase to load.
The
utility is a debugging utility that dumps Berkeley DB log files in a human-readable format.
The options are as follows:
Specify a home directory for the database environment; by default, the current working directory is used.
Do not acquire shared region mutexes while running. Other problems, such as potentially fatal errors in Berkeley DB, will be ignored as well. This option is intended only for debugging errors, and should not be used under any other circumstances.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
Read the log files in reverse order.
Write the library version number to the standard output, and exit.
For more information on the
output and using it to debug applications, see Reviewing Berkeley DB log files.
The
utility uses a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment,
should always be given the chance to detach from the environment and exit gracefully. To cause
to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
The
utility must be run after an unexpected application, Berkeley DB, or system failure to restore the database to a consistent state. All committed transactions are guaranteed to appear after db_recover has run, and all uncommitted transactions will be completely undone.
The options are as follows:
Perform catastrophic recovery instead of normal recovery.
Retain the environment after running recovery. This option will rarely be used unless a DB_CONFIG file is present in the home directory. If a DB_CONFIG file is not present, then the regions will be created with default parameter values.
Specify a home directory for the database environment; by default, the current working directory is used.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
Recover to the time specified rather than to the most current possible date. The timestamp argument should be in the form [[CC]YY]MMDDhhmm[.SS] where each pair of letters represents the following:
The first two digits of the year (the century).
The second two digits of the year. If "YY" is specified, but "CC" is not, a value for "YY" between 69 and 99 results in a "YY" value of 19. Otherwise, a "YY" value of 20 is used.
The month of the year, from 1 to 12.
The day of the month, from 1 to 31.
The hour of the day, from 0 to 23.
The minute of the hour, from 0 to 59.
The second of the minute, from 0 to 61.
If the "CC" and "YY" letter pairs are not specified, the values default to the current year. If the "SS" letter pair is not specified, the value defaults to 0.
Write the library version number to the standard output, and exit.
Run in verbose mode.
In the case of catastrophic recovery, an archival copy -- or snapshot -- of all database files must be restored along with all of the log files written since the database file snapshot was made. (If disk space is a problem, log files may be referenced by symbolic links). For further information on creating a database snapshot, see Archival Procedures. For further information on performing recovery, see Recovery Procedures.
If the failure was not catastrophic, the files present on the system at the time of failure are sufficient to perform recovery.
If log files are missing, db_recover will identify the missing log file(s) and fail, in which case the missing log files need to be restored and recovery performed again.
The db_recover utility uses a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, db_recover should always be given the chance to detach from the environment and exit gracefully. To cause db_recover to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The db_recover utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
The
utility utility displays statistics for Berkeley DB environments.
The options are as follows:
Display internal information about the lock region. (The output from this option is often both voluminous and meaningless, and is intended only for debugging.)
Display all information.
Display lock conflict matrix.
Display lockers within hash chains.
Display region memory information.
Display objects within hash chains.
Display lock region parameters.
Display lock region statistics, as described in DB_ENV->lock_stat.
Display database statistics for the specified file, as described in DB->stat.
If the database contains multiple databases and the -s flag is not specified, the statistics are for the internal database that describes the other databases the file contains, and not for the file as a whole.
Display current environment statistics.
Display only those database statistics that can be acquired without traversing the database.
Specify a home directory for the database environment; by default, the current working directory is used.
Display log region statistics, as described in DB_ENV->log_stat.
Display internal information about the shared memory buffer pool. (The output from this option is often both voluminous and meaningless, and is intended only for debugging.)
Display all information.
Display buffers within hash chains.
Display region memory information.
Display shared memory buffer pool statistics, as described in DB_ENV->memp_stat.
Do not acquire shared region mutexes while running. Other problems, such as potentially fatal errors in Berkeley DB, will be ignored as well. This option is intended only for debugging errors, and should not be used under any other circumstances.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
Display replication statistics, as described in DB_ENV->rep_stat.
Display statistics for the specified database contained in the file specified with the -d flag.
Display transaction region statistics, as described in DB_ENV->txn_stat.
Write the library version number to the standard output, and exit.
Reset the statistics after reporting them; valid only with the -c, -e, -l, -m, and -t options.
Values normally displayed in quantities of bytes are displayed as a combination of gigabytes (GB), megabytes (MB), kilobytes (KB), and bytes (B). Otherwise, values smaller than 10 million are displayed without any special notation, and values larger than 10 million are displayed as a number followed by "M".
The
utility may be used with a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment,
should always be given the chance to detach from the environment and exit gracefully. To cause
to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
file ...
The
utility upgrades the Berkeley DB version of one or more files and the databases they contain to the current release version.
The options are as follows:
Specify a home directory for the database environment; by default, the current working directory is used.
Do not acquire shared region mutexes while running. Other problems, such as potentially fatal errors in Berkeley DB, will be ignored as well. This option is intended only for debugging errors, and should not be used under any other circumstances.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
This flag is only meaningful when upgrading databases from releases before the Berkeley DB 3.1 release.
As part of the upgrade from the Berkeley DB 3.0 release to the 3.1 release, the on-disk format of duplicate data items changed. To correctly upgrade the format requires that applications specify whether duplicate data items in the database are sorted or not. Specifying the -s flag means that the duplicates are sorted; otherwise, they are assumed to be unsorted. Incorrectly specifying the value of this flag may lead to database corruption.
Because the
utility upgrades a physical file (including all the databases it contains), it is not possible to use
to upgrade files where some of the databases it includes have sorted duplicate data items, and some of the databases it includes have unsorted duplicate data items. If the file does not have more than a single database, if the databases do not support duplicate data items, or if all the databases that support duplicate data items support the same style of duplicates (either sorted or unsorted),
will work correctly as long as the -s flag is correctly specified. Otherwise, the file cannot be upgraded using
and must be upgraded manually using the db_dump and db_load utilities.
Write the library version number to the standard output, and exit.
This means that if the system crashes during the upgrade procedure, or if the upgrade procedure runs out of disk space, the databases may be left in an inconsistent and unrecoverable state. See Upgrading databases for more information.
The
utility may be used with a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment,
should always be given the chance to detach from the environment and exit gracefully. To cause
to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
file ...
The
utility verifies the structure of one or more files and the databases they contain.
The options are as follows:
Specify a home directory for the database environment; by default, the current working directory is used.
Skip the database checks for btree and duplicate sort order and for hashing.
If the file being verified contains databases with non-default comparison or hashing configurations, calling the 
utility without the -o flag will usually return failure. The -o flag causes
to ignore database sort or hash ordering and allows
to be used on these files. To fully verify these files, verify them explicitly using the DB->verify method, after configuring the correct comparison or hashing functions.
Do not acquire shared region mutexes while running. Other problems, such as potentially fatal errors in Berkeley DB, will be ignored as well. This option is intended only for debugging errors, and should not be used under any other circumstances.
Specify an environment password. Although Berkeley DB utilities overwrite password strings as soon as possible, be aware there may be a window of vulnerability on systems where unprivileged users can see command-line arguments or where utilities are not able to overwrite the memory containing the command-line arguments.
Suppress the printing of any error descriptions, simply exit success or failure.
Write the library version number to the standard output, and exit.
utility does not perform any locking, even in Berkeley DB environments that are configured with a locking subsystem. As such, it should only be used on files that are not being modified by another thread of control.
The
utility may be used with a Berkeley DB environment (as described for the -h option, the environment variable DB_HOME, or because the utility was run in a directory containing a Berkeley DB environment). In order to avoid environment corruption when using a Berkeley DB environment, 
should always be given the chance to detach from the environment and exit gracefully. To cause 
to release all environment resources and exit cleanly, send it an interrupt signal (SIGINT).
The 
utility exits 0 on success, and >0 if an error occurs.
If the -h option is not specified and the environment variable DB_HOME is set, it is used as the path of the database home, as described in DB_ENV->open.
Create version diffs needs preversion
Upgrade the database to the current schema
Install the schema version tables to an existing database
Deploy the schema to the database
Select data from the schema
Insert data into the schema
Update data in the schema
Delete data from the schema
display this help
Supply the config file for parsing by Config::Any
The class of the schema to load
Where in the config to find the connection_info, supply in form MyApp::Model::DB
The resultset to operate on for data manipulation
The directory where sql diffs will be created
The RDBMs flavour you wish to use
Supply a version install
The previous version to diff against
Be forceful with some operations
Turn on DBIx::Class trace output
Be less verbose
You may distribute this code under the same terms as Perl itself
Create version diffs needs preversion
Upgrade the database to the current schema
Install the schema version tables to an existing database
Deploy the schema to the database
Select data from the schema
Insert data into the schema
Update data in the schema
Delete data from the schema
display this help
Supply the config file for parsing by Config::Any
The class of the schema to load
Where in the config to find the connection_info, supply in form MyApp::Model::DB
The resultset to operate on for data manipulation
The directory where sql diffs will be created
The RDBMs flavour you wish to use
Supply a version install
The previous version to diff against
Be forceful with some operations
Turn on DBIx::Class trace output
Be less verbose
You may distribute this code under the same terms as Perl itself
Create version diffs needs preversion
Upgrade the database to the current schema
Install the schema version tables to an existing database
Deploy the schema to the database
Select data from the schema
Insert data into the schema
Update data in the schema
Delete data from the schema
display this help
Supply the config file for parsing by Config::Any
The class of the schema to load
Where in the config to find the connection_info, supply in form MyApp::Model::DB
The resultset to operate on for data manipulation
The directory where sql diffs will be created
The RDBMs flavour you wish to use
Supply a version install
The previous version to diff against
Be forceful with some operations
Turn on DBIx::Class trace output
Be less verbose
You may distribute this code under the same terms as Perl itself
separate file for each run. Then compare using diff. (This example assumes
you're using a standard shell.)
will look like this:
separate file for each run. Then compare using diff. (This example assumes
you're using a standard shell.)
will look like this:
separate file for each run. Then compare using diff. (This example assumes
you're using a standard shell.)
will look like this:
See a report of the ten queries with the longest total runtime in the
See the top 10 most frequently run queries in the profile file
See the same report with 15 entries:
This tool is a command-line client for the DBI::ProfileData.  It
allows you to analyze the profile data file produced by
DBI::ProfileDumper and produce various useful reports.
This program accepts the following options:
Produce this many items in the report.  Defaults to 10.  If set to
Sort results by the given field. Sorting by multiple fields isn't currently
supported (patches welcome).  The available sort fields are:
Sorts by total time run time across all runs.  This is the default
sort.
Sorts by the longest single run.
Sorts by total number of runs.
Sorts by the time taken in the first run.
Sorts by the shortest single run.
Sorts by the value of the first element in the Path, which should be numeric.
Reverses the selected sort.  For example, to see a report of the
shortest overall time:
Consider only items where the specified key matches the given value.
Keys are numbered from 1.  For example, let's say you used a
DBI::Profile Path of:
And called dbiprof as in:
Your report would only show execute queries, leaving out prepares,
fetches, etc.
queries where key1 is the statement:
By default the match expression is matched case-insensitively, but
Remove items for where the specified key matches the given value.  For
example, to exclude all prepare entries where key2 is the method name:
By default the exclude expression is matched case-insensitively, but
case-sensitively.  Defaults to off.
files to be deleted after reading. See DBI::ProfileData for more details.
Print the list of nodes in the form of a perl data structure.
Print the dbiprof version number and exit.
Sam Tregar <sam@tregar.com>
Copyright (C) 2002 Sam Tregar
it under the same terms as Perl 5 itself.
DBI::ProfileDumper,
See a report of the ten queries with the longest total runtime in the
See the top 10 most frequently run queries in the profile file
See the same report with 15 entries:
This tool is a command-line client for the DBI::ProfileData.  It
allows you to analyze the profile data file produced by
DBI::ProfileDumper and produce various useful reports.
This program accepts the following options:
Produce this many items in the report.  Defaults to 10.  If set to
Sort results by the given field. Sorting by multiple fields isn't currently
supported (patches welcome).  The available sort fields are:
Sorts by total time run time across all runs.  This is the default
sort.
Sorts by the longest single run.
Sorts by total number of runs.
Sorts by the time taken in the first run.
Sorts by the shortest single run.
Sorts by the value of the first element in the Path, which should be numeric.
Reverses the selected sort.  For example, to see a report of the
shortest overall time:
Consider only items where the specified key matches the given value.
Keys are numbered from 1.  For example, let's say you used a
DBI::Profile Path of:
And called dbiprof as in:
Your report would only show execute queries, leaving out prepares,
fetches, etc.
queries where key1 is the statement:
By default the match expression is matched case-insensitively, but
Remove items for where the specified key matches the given value.  For
example, to exclude all prepare entries where key2 is the method name:
By default the exclude expression is matched case-insensitively, but
case-sensitively.  Defaults to off.
files to be deleted after reading. See DBI::ProfileData for more details.
Print the list of nodes in the form of a perl data structure.
Print the dbiprof version number and exit.
Sam Tregar <sam@tregar.com>
Copyright (C) 2002 Sam Tregar
it under the same terms as Perl 5 itself.
DBI::ProfileDumper,
See a report of the ten queries with the longest total runtime in the
See the top 10 most frequently run queries in the profile file
See the same report with 15 entries:
This tool is a command-line client for the DBI::ProfileData.  It
allows you to analyze the profile data file produced by
DBI::ProfileDumper and produce various useful reports.
This program accepts the following options:
Produce this many items in the report.  Defaults to 10.  If set to
Sort results by the given field. Sorting by multiple fields isn't currently
supported (patches welcome).  The available sort fields are:
Sorts by total time run time across all runs.  This is the default
sort.
Sorts by the longest single run.
Sorts by total number of runs.
Sorts by the time taken in the first run.
Sorts by the shortest single run.
Sorts by the value of the first element in the Path, which should be numeric.
Reverses the selected sort.  For example, to see a report of the
shortest overall time:
Consider only items where the specified key matches the given value.
Keys are numbered from 1.  For example, let's say you used a
DBI::Profile Path of:
And called dbiprof as in:
Your report would only show execute queries, leaving out prepares,
fetches, etc.
queries where key1 is the statement:
By default the match expression is matched case-insensitively, but
Remove items for where the specified key matches the given value.  For
example, to exclude all prepare entries where key2 is the method name:
By default the exclude expression is matched case-insensitively, but
case-sensitively.  Defaults to off.
files to be deleted after reading. See DBI::ProfileData for more details.
Print the list of nodes in the form of a perl data structure.
Print the dbiprof version number and exit.
Sam Tregar <sam@tregar.com>
Copyright (C) 2002 Sam Tregar
it under the same terms as Perl 5 itself.
DBI::ProfileDumper,
This tool is just a front end for the DBI::ProxyServer package. All it
does is picking options from the command line and calling
Available options include:
drivers in the config file or you have to create hard links to Unix
sockets, if your drivers are using them. For example, with MySQL, a
config file might contain the following lines:
Config files are assumed to return a single hash ref that overrides the
arguments of the new method. However, command line arguments in turn take
in the DBI::ProxyServer documentation for details on the config file.
Turn debugging mode on. Mainly this asserts that logging messages of
This is useful, if you want your server to bind to a privileged port
(<1024), but don't want the server to execute as root. See also
has. This attribute allows to restrict the server to the given
This attribute sets the port on which the daemon is listening. It
must be given somehow, as there's no default.
Be default logging messages will be written to the syslog (Unix) or
stderr. See Net::Daemon::Log for details.
The server can run in three different modes, depending on the environment.
If you are running Perl 5.005 and did compile it for threads, then the
server will create a new thread for each connection. The thread will
server will behave similar by creating a new process for each connection.
This mode will be used automatically in the absence of threads or if
Finally there's a single-connection mode: If the server has accepted a
for example on the Macintosh. For debugging purposes you can force this
given location. Default is to not create a pidfile.
This is useful, if you want your server to bind to a privileged port
(<1024), but don't want the server to execute as root. See also
Suppresses startup of the server; instead the version string will
be printed and the program exits immediately.
The DBI::ProxyServer module is free software; you can redistribute it
permission is granted to Tim Bunce for distributing this as a part of
This tool is just a front end for the DBI::ProxyServer package. All it
does is picking options from the command line and calling
Available options include:
drivers in the config file or you have to create hard links to Unix
sockets, if your drivers are using them. For example, with MySQL, a
config file might contain the following lines:
Config files are assumed to return a single hash ref that overrides the
arguments of the new method. However, command line arguments in turn take
in the DBI::ProxyServer documentation for details on the config file.
Turn debugging mode on. Mainly this asserts that logging messages of
This is useful, if you want your server to bind to a privileged port
(<1024), but don't want the server to execute as root. See also
has. This attribute allows to restrict the server to the given
This attribute sets the port on which the daemon is listening. It
must be given somehow, as there's no default.
Be default logging messages will be written to the syslog (Unix) or
stderr. See Net::Daemon::Log for details.
The server can run in three different modes, depending on the environment.
If you are running Perl 5.005 and did compile it for threads, then the
server will create a new thread for each connection. The thread will
server will behave similar by creating a new process for each connection.
This mode will be used automatically in the absence of threads or if
Finally there's a single-connection mode: If the server has accepted a
for example on the Macintosh. For debugging purposes you can force this
given location. Default is to not create a pidfile.
This is useful, if you want your server to bind to a privileged port
(<1024), but don't want the server to execute as root. See also
Supresses startup of the server; instead the version string will
be printed and the program exits immediately.
The DBI::ProxyServer module is free software; you can redistribute it
permission is granted to Tim Bunce for distributing this as a part of
This tool is just a front end for the DBI::ProxyServer package. All it
does is picking options from the command line and calling
Available options include:
drivers in the config file or you have to create hard links to Unix
sockets, if your drivers are using them. For example, with MySQL, a
config file might contain the following lines:
Config files are assumed to return a single hash ref that overrides the
arguments of the new method. However, command line arguments in turn take
in the DBI::ProxyServer documentation for details on the config file.
Turn debugging mode on. Mainly this asserts that logging messages of
This is useful, if you want your server to bind to a privileged port
(<1024), but don't want the server to execute as root. See also
has. This attribute allows to restrict the server to the given
This attribute sets the port on which the daemon is listening. It
must be given somehow, as there's no default.
Be default logging messages will be written to the syslog (Unix) or
stderr. See Net::Daemon::Log for details.
The server can run in three different modes, depending on the environment.
If you are running Perl 5.005 and did compile it for threads, then the
server will create a new thread for each connection. The thread will
server will behave similar by creating a new process for each connection.
This mode will be used automatically in the absence of threads or if
Finally there's a single-connection mode: If the server has accepted a
for example on the Macintosh. For debugging purposes you can force this
given location. Default is to not create a pidfile.
This is useful, if you want your server to bind to a privileged port
(<1024), but don't want the server to execute as root. See also
Suppresses startup of the server; instead the version string will
be printed and the program exits immediately.
The DBI::ProxyServer module is free software; you can redistribute it
permission is granted to Tim Bunce for distributing this as a part of


 
 
 
 

 
 
 
 

 
 
 
 
 
-d
crypt encryption (default, except on Win32, Netware)  
-m
MD5 encryption (default on Win32, Netware)  
-s
SHA1 encryption  
-p
  
 
 
add
adduser
check
delete
import
update
view
  
 
 
 
 
dc [-V] [--version] [-h] [--help]
   [-e scriptexpression] [--expression=scriptexpression]
   [-f scriptfile] [--file=scriptfile]
   [file ...]
unlimited precision arithmetic.
It also allows you to define and call macros.
if any command arguments are given to it, they are filenames,
from standard input.
All normal output is to standard output;
all error output is to standard error.
A reverse-polish calculator stores numbers on a stack.
Entering a number pushes it on the stack.
Arithmetic operations pop arguments off the stack and push the results.
To enter a number in
type the digits with an optional decimal point.
Exponential notation is not supported.
To enter a negative number,
begin the number with ``_''.
``-'' cannot be used for this,
as it is a binary operator for subtraction instead.
To enter two numbers in succession,
separate them with spaces or newlines.
These have no meaning as commands.
then exit.
Print a usage message briefly summarizing these command-line options
and the bug-reporting address,
then exit.
Add the commands in
to the set of commands to be run while processing the input.
Add the commands contained in the file
to the set of commands to be run while processing the input.
If any command-line parameters remain after processing the above,
these parameters are interpreted as the names of input files to
be processed.
A file name of
refers to the standard input stream.
The standard input will processed if no file names are specified.
Printing Commands
Prints the value on the top of the stack,
without altering the stack.
A newline is printed after the value.
Prints the value on the top of the stack, popping it off,
and does not print a newline after.
Pops off the value on top of the stack.
If it it a string, it is simply printed without a trailing newline.
Otherwise it is a number, and the integer portion of its absolute
value is printed out as a "base (UCHAR_MAX+1)" byte stream.
Assuming that (UCHAR_MAX+1) is 256
(as it is on most machines with 8-bit bytes),
could also accomplish this function,
except for the side-effect of clobbering the x register.
Prints the entire contents of the stack
and the contents of all of the registers,
without altering anything.
This is a good command to use if you are lost or want
to figure out what the effect of some command has been.
Arithmetic
Pops two values off the stack, adds them,
and pushes the result.
The precision of the result is determined only
by the values of the arguments,
and is enough to be exact.
Pops two values,
subtracts the first one popped from the second one popped,
and pushes the result.
Pops two values, multiplies them, and pushes the result.
The number of fraction digits in the result depends on
the current precision value and the number of fraction
digits in the two arguments.
Pops two values,
divides the second one popped from the first one popped,
and pushes the result.
The number of fraction digits is specified by the precision value.
Pops two values,
computes the remainder of the division that the
command would do,
and pushes that.
The value computed is the same as that computed by
Pops two values,
divides the second one popped from the first one popped.
The quotient is pushed first, and the remainder is pushed next.
The number of fraction digits used in the division
is specified by the precision value.
this function, with slightly different error checking.)
Pops two values and exponentiates,
using the first value popped as the exponent
and the second popped as the base.
The fraction part of the exponent is ignored.
The precision value specifies the number of fraction
digits in the result.
Pops three values and computes a modular exponentiation.
The first value popped is used as the reduction modulus;
this value must be a non-zero number,
and should be an integer.
The second popped is used as the exponent;
this value must be a non-negative number,
and any fractional part of this exponent will be ignored.
The third value popped is the base which gets exponentiated,
which should be an integer.
Pops one value,
computes its square root,
and pushes that.
The precision value specifies the number of fraction digits in the result.
Most arithmetic operations are affected by the ``precision value'',
which you can set with the
command.
The default precision value is zero,
which means that all arithmetic except for
addition and subtraction produces integer results.
Stack Control
Clears the stack, rendering it empty.
Duplicates the value on the top of the stack,
pushing another copy of it.
Thus, ``4d*p'' computes 4 squared and prints it.
Reverses the order of (swaps) the top two values on the stack.
Registers
each named by a single character.
You can store a number or a string in a register and retrieve it later.
Pop the value off the top of the stack and store
it into register
Copy the value in register
and push it onto the stack.
This does not alter the contents of
Each register also contains its own stack.
The current register value is the top of the register's stack.
Pop the value off the top of the (main) stack and
push it onto the stack of register
The previous value of the register becomes inaccessible.
Pop the value off the top of register
stack and push it onto the main stack.
The previous value
in register
stack, if any,
is now accessible via the
command.
The
command prints a list of all registers that have contents stored in them,
together with their contents.
Only the current contents of each register
(the top of its stack)
is printed.
Parameters
the precision, the input radix, and the output radix.
The precision specifies the number
of fraction digits to keep in the result of most arithmetic operations.
The input radix controls the interpretation of numbers typed in;
all numbers typed in use this radix.
The output radix is used for printing numbers.
The input and output radices are separate parameters;
you can make them unequal,
which can be useful or confusing.
The input radix must be between 2 and 16 inclusive.
The output radix must be at least 2.
The precision must be zero or greater.
The precision is always measured in decimal digits,
regardless of the current input or output radix.
Pops the value off the top of the stack
and uses it to set the input radix.
Pops the value off the top of the stack
and uses it to set the output radix.
Pops the value off the top of the stack
and uses it to set the precision.
Pushes the current input radix on the stack.
Pushes the current output radix on the stack.
Pushes the current precision on the stack.
Strings
The only things you can do with strings are
print them and execute them as macros
(which means that the contents of the string are processed as
All registers and the stack can hold strings,
Some commands such as arithmetic operations demand numbers
as arguments and print errors if given strings.
Other commands can accept either a number or a string;
for example, the
command can accept either and prints the object
according to its type.
Makes a string containing
(contained between balanced
and
characters),
and pushes it on the stack.
For example,
prints the characters
(with no newline).
The top-of-stack is popped.
If it was a number, then the low-order byte of this number
is converted into a string and pushed onto the stack.
Otherwise the top-of-stack was a string,
and the first character of that string is pushed back.
Pops a value off the stack and executes it as a macro.
Normally it should be a string;
if it is a number,
it is simply pushed back onto the stack.
For example,
executes the macro
which pushes
on the stack and prints
on a separate line.
Macros are most often stored in registers;
stores a macro to print
into register
and
invokes this macro.
Pops two values off the stack and compares them
assuming they are numbers,
executing the contents of register
as a macro if the original top-of-stack
is greater.
Thus,
will invoke register
contents and
will not.
Similar but invokes the macro if the original top-of-stack is
not greater than (less than or equal to) what was the second-to-top.
Similar but invokes the macro if the original top-of-stack is less.
Similar but invokes the macro if the original top-of-stack is
not less than (greater than or equal to) what was the second-to-top.
Similar but invokes the macro if the two numbers popped are equal.
Similar but invokes the macro if the two numbers popped are not equal.
This can also be validly used to compare two strings for equality.
Reads a line from the terminal and executes it.
This command allows a macro to request input from the user.
exits from a macro and also from the macro which invoked it.
If called from the top level,
or from a macro which was called directly from the top level,
the
Pops a value off the stack and uses it as a count
of levels of macro execution to be exited.
Thus,
exits three levels.
The
Status Inquiry
Pops a value off the stack,
calculates the number of digits it has
(or number of characters, if it is a string)
and pushes that number.
Pops a value off the stack,
calculates the number of fraction digits it has,
and pushes that number.
For a string,
the value pushed is
0.
Pushes the current stack depth:
the number of objects on the stack before the execution of the
command.
Miscellaneous
Will run the rest of the line as a system command.
Note that parsing of the !<, !=, and !> commands take precedence,
so if you want to run a command starting with <, =, or > you will
need to add a space after the !.
Will interpret the rest of the line as a comment.
Will pop the top two values off of the stack.
The old second-to-top value will be stored in the array
indexed by the old top-of-stack value.
Pops the top-of-stack and uses it as an index into
the array
The selected value is then pushed onto the stack.
Note that each stacked instance of a register has its own
array associated with it.
because the 2 was stored in an instance of 0:a that
was later popped.
BUGS
Email bug reports to
The
utility copies the standard input to the standard output.
Input data is read and written in 512-byte blocks.
If input reads are short, input from multiple reads are aggregated
to form the output block.
When finished,
displays the number of complete and partial input and output blocks
and truncated input records to the standard error output.
The following operands are available:
Set both input and output block size to
bytes, superseding the
and
operands.
If no conversion values other than
or
are specified, then each input block is copied to the output as a
single block without any aggregation of short blocks.
Set the conversion record size to
bytes.
The conversion record size is required by the record oriented conversion
values.
Copy only
input blocks.
Copy
input files before terminating.
This operand is only applicable when the input device is a tape.
Set the input block size to
bytes instead of the default 512.
Read input from
instead of the standard input.
Seek on the input file
blocks.
This is synonymous with
Set the output block size to
bytes instead of the default 512.
Write output to
instead of the standard output.
Any regular output file is truncated unless the
conversion value is specified.
If an initial portion of the output file is seeked past (see the
operand),
the output file is truncated at that point.
Seek on the output file
blocks.
This is synonymous with
Seek
blocks from the beginning of the output before copying.
On non-tape devices, an
operation is used.
Otherwise, existing blocks are read and the data discarded.
If the user does not have read permission for the tape, it is positioned
using the tape
function calls.
If the seek operation is past the end of file, space from the current
end of file to the specified offset is filled with blocks of
bytes.
Skip
blocks from the beginning of the input before copying.
On input which supports seeks, an
operation is used.
Otherwise, input data is read and discarded.
For pipes, the correct number of bytes is read.
For all other devices, the correct number of blocks is read without
distinguishing between a partial or complete block being read.
Where
is one of the symbols from the following list.
The same as the
value except that characters are translated from
to
before the
records are converted.
(These values imply
if the operand
is also specified.)
There are two conversion maps for
The value
specifies the recommended one which is compatible with
The value
specifies the one used in historic
and
systems.
Treats the input as a sequence of newline or end-of-file terminated variable
length records independent of input and output block boundaries.
Any trailing newline character is discarded.
Each input record is converted to a fixed length output record where the
length is specified by the
operand.
Input records shorter than the conversion record size are padded with spaces.
Input records longer than the conversion record size are truncated.
The number of truncated input records, if any, are reported to the standard
error output at the completion of the copy.
The same as the
value except that characters are translated from
to
after the
records are converted.
(These values imply
if the operand
is also specified.)
There are four conversion maps for
The value
specifies the recommended one which is compatible with
The value
is a slightly different mapping, which is compatible with the
value.
The values
and
are maps used in historic
and
systems.
Transform uppercase characters into lowercase characters.
Do not stop processing on an input error.
When an input error occurs, a diagnostic message followed by the current
input and output block counts will be written to the standard error output
in the same format as the standard completion message.
If the
conversion is also specified, any missing input data will be replaced
with
bytes (or with spaces if a block oriented conversion value was
specified) and processed as a normal input buffer.
If the
conversion is not specified, the input block is omitted from the output.
On input files which are not tapes or pipes, the file offset
will be positioned past the block in which the error occurred using
Do not truncate the output file.
This will preserve any blocks in the output file not explicitly written
by
The
value is not supported for tapes.
Pad the final output block to the full output block size.
If the input file is not a multiple of the output block size
after conversion, this conversion forces the final output block
to be the same size as preceding blocks for use on devices that require
regularly sized blocks to be written.
This option is incompatible with use of the
block size specification.
If one or more output blocks would consist solely of
bytes, try to seek the output file by the required space instead of
filling them with
resulting in a sparse file.
Swap every pair of input bytes.
If an input buffer has an odd number of bytes, the last byte will be
ignored during swapping.
Pad every input block to the input buffer size.
Spaces are used for pad bytes if a block oriented conversion value is
specified, otherwise
bytes are used.
Transform lowercase characters into uppercase characters.
Treats the input as a sequence of fixed length records independent of input
and output block boundaries.
The length of the input records is specified by the
operand.
Any trailing space characters are discarded and a newline character is
appended.
Where sizes are specified, a decimal, octal, or hexadecimal number of
bytes is expected.
If the number ends with a
or
the
number is multiplied by 512, 1024 (1K), 1048576 (1M), 1073741824 (1G)
or the number of bytes in an integer, respectively.
Two or more numbers may be separated by an
to indicate a product.
When finished,
displays the number of complete and partial input and output blocks,
truncated input records and odd-length byte-swapping blocks to the
standard error output.
A partial input block is one where less than the input block size
was read.
A partial output block is one where less than the output block size
was written.
Partial output blocks to tape devices are considered fatal errors.
Otherwise, the rest of the block will be written.
Partial output blocks to character devices will produce a warning message.
A truncated input block is one where a variable length record oriented
conversion value was specified and the input line was too long to
fit in the conversion record or was not newline terminated.
Normally, data resulting from input or conversion or both are aggregated
into output blocks of the specified size.
After the end of input is reached, any remaining output is written as
a block.
This means that the final output block may be shorter than the output
block size.
If
receives a
(see the
argument for
signal, the current input and output block counts will
be written to the standard error output
in the same format as the standard completion message.
If
receives a
signal, the current input and output block counts will
be written to the standard error output
in the same format as the standard completion message and
will exit.
The
utility is expected to be a superset of the
standard.
The
operand and the
and
values are extensions to the
standard.
Usage:
Where the options are:
Each file is expected to be a BinHex file.  By default, the output file is
given the name that the BinHex file dictates, regardless of the name of
the BinHex file.
Largely untested.
his grubby paws off anything...
SXren M. Andersen (somian), made it actually work under Perl 5.8.7 on MSWin32.
Usage:
Where the options are:
Each file is expected to be a BinHex file.  By default, the output file is
given the name that the BinHex file dictates, regardless of the name of
the BinHex file.
Largely untested.
his grubby paws off anything...
SXren M. Andersen (somian), made it actually work under Perl 5.8.7 on MSWin32.
read
read-type 
write
}
rename
delete 
| find
}
allows users to read, write, and delete Mac OS X user defaults from a command-line shell. Mac OS X applications and other programs use the defaults system to record user preferences and other information that must be maintained when the applications aren't running (such as default font for new documents, or the position of an Info panel). Much of this information is accessible through an application's Preferences panel, but some of it isn't, such as the position of the Info panel. You can access this information with
Since applications do access the defaults system while they're running, you shouldn't modify the defaults of a running application. If you change a default in a domain that belongs to a running application, the application won't see the change and might even overwrite the default.
User defaults belong to
Though all applications, system services, and other programs have their own domains, they also share a domain named
If a default isn't specified in the application's domain, but is specified in
then the application uses the value in that domain.
The commands are as follows:
Prints all of the user's defaults, for every domain, to standard output.
Prints all of the user's defaults for
to standard output.
Prints the value for the default of
identified by
Prints the plist type for the given
identified by
Writes
as the value for
in
must be a property list, and must be enclosed in single quotes.
For example:
defaults write com.companyname.appname "Default Color" '(255, 0, 0)'
sets the value for Default Color to an array containing the strings 255, 0, 0 (the red, green, and blue components). Note that the key is enclosed in quotation marks because it contains a space.
Overwrites the defaults information in
with that given as
must be a property list representation of a dictionary, and must be enclosed in single quotes.
For example: 
defaults write com.companyname.appname '{ "Default Color" = (255, 0, 0);
				"Default Font" = Helvetica; }';
erases any previous defaults for com.companyname.appname and writes the values for the two names into the defaults system.
Removes all default information for
Removes the default named
from
Prints the names of all domains in the user's defaults system.
Searches for
in the domain names, keys, and values of the user's defaults, and prints out a list of matches.
Prints a list of possible command formats.
Example:
defaults read com.apple.TextEdit
defaults read -app TextEdit
Domains may also be specified as a path to an arbitrary plist file, with or without the '.plist' extension. For example:
normally gives the same result as the two previous examples.
In the following example:
will write the key 'foo' with the value 'bar' into the plist file 'TestFile.plist' that is on the user's desktop. If the file does not exist, it will be created. If it does exist, the key-value pair will be added, overwriting the value of 'foo' if it already existed.
WARNING: The defaults command will be changed in an upcoming major release to only operate on preferences domains. General plist manipulation utilities will be folded into a different command-line program.
If no type flag is provided,
will assume the value is a string. For best results, use one of the type flags, listed below. 
Allows the user to specify a string as the value for the given preference key.
Allows the user to specify a bunch of raw data bytes as the value for the given preference key. 
The data must be provided in hexidecimal.
Allows the user to specify an integer as the value for the given preference key.
Allows the user to specify a floating point number as the value for the given preference key.
Allows the user to specify a boolean as the value for the given preference key.
Value must be TRUE, FALSE, YES, or NO.
Allows the user to specify a date as the value for the given preference key.
Allows the user to specify an array as the value for the given preference key:
defaults write somedomain preferenceKey -array element1 element2 element3
The specified array overwrites the value of the key if the key was present at the time of the write. If the key was not present, it is created with the new value.
Allows the user to add new elements to the end of an array for a key which has an array as its value. Usage is the same as -array above. If the key was not present, it is created with the specified array as its value.
Allows the user to add a dictionary to the defaults database for a domain.  Keys and values are specified in order:
defaults write somedomain preferenceKey -dict key1 value1 key2 value2
The specified dictionary overwrites the value of the key if the key was present at the time of the write. If the key was not present, it is created with the new value.
Operations on the defaults database normally apply to any host the user may log in on, but may be restricted to apply only to a specific host. 
If no host is provided, preferences operations will apply to any host the user may log in on.
Restricts preferences operations to the host the user is currently logged in on.
Defaults can be structured in very complex ways, making it difficult for the user to enter them with this command.
First appeared in NeXTStep.
The
utility
displays statistics about the amount of free disk space on the specified
or on the filesystem of which
is a part.
Values are displayed in 512-byte per block counts.
If neither a file or a filesystem operand is specified,
statistics for all mounted filesystems are displayed
(subject to the
option below).
The following options are available:
Show all mount points, including those that were mounted with the MNT_IGNORE
flag.
Use (the default) 512-byte blocks.
This is only useful as a way to override an
specification from the environment.
Use 1073741824-byte (1-Gbyte) blocks rather than the default.
Note that this overrides the
specification from the environment.
"Human-readable" output.  Use unit suffixes: Byte, Kilobyte, Megabyte,
Gigabyte, Terabyte and Petabyte in order to reduce the number of
digits to three or less using base 10 for sizes.
"Human-readable" output.  Use unit suffixes: Byte, Kilobyte, Megabyte,
Gigabyte, Terabyte and Petabyte in order to reduce the number of
digits to three or less using base 2 for sizes.
Include statistics on the number of free inodes. This option is now the default to conform to
Use
to suppress this output.
Use 1024-byte (1-Kbyte) blocks, rather than the default.
Note that this overrides the
specification from the environment.
Only display information about locally-mounted filesystems.
Use 1048576-byte (1-Mbyte) blocks rather than the default.  Note that
this overrides the
specification from the environment.
Print out the previously obtained statistics from the filesystems.
This option should be used if it is possible that one or more
filesystems are in a state such that they will not be able to provide
statistics without a long delay.
When this option is specified,
will not request new statistics from the filesystems, but will respond
with the possibly stale statistics that were previously obtained.
Use (the default) 512-byte blocks.
This is only useful as a way to override an
specification from the environment.
Only print out statistics for filesystems of the specified types.
More than one type may be specified in a comma separated list.
The list of filesystem types can be prefixed with
to specify the filesystem types for which action should
be taken.
For example, the
command:
df -T nonfs,mfs
lists all filesystems except those of type
and
The
command can be used to find out the types of filesystems
that are available on the system.
If used with no arguments,
this option is a no-op
(Mac OS X already prints the total allocated-space figures).
If used with an argument, it acts like
but this usage is deprecated and should not be relied upon.
If the environment variable
is set, the block counts will be displayed in units of that size block.
The
and
flags are ignored if a file or filesystem is specified.
The "capacity" percentage is normally rounded up to the next higher integer.
In legacy mode, it is rounded down to the next lower integer.
When the
option and the
option are used together,
sizes are reported in 1024-blocks.
In legacy mode, when the
option and
option are used together,
the last option specified dictates the reported block size.
The
option is normally a no-op
(Mac OS X already prints the total allocated-space figures).
In legacy mode, it is equivalent to
For more information about legacy mode, see
A
command appeared in
Compare files line by line.
Ignore case differences in file contents.
Ignore case when comparing file names.
Consider case when comparing file names.
Ignore changes due to tab expansion.
Ignore changes in the amount of white space.
Ignore all white space.
Ignore changes whose lines are all blank.
Ignore changes whose lines all match RE.
Strip trailing carriage return on input.
Treat all files as text.
Output NUM (default 3) lines of copied context.
Output NUM (default 3) lines of unified context.
Use LABEL instead of file name.
Show which C function each change is in.
Show the most recent line matching RE.
Output only whether files differ.
Output an ed script.
Output a normal diff.
Output an RCS format diff.
Output in two columns.
Output at most NUM (default 130) print columns.
Output only the left column of common lines.
Do not output common lines.
Output merged file to show `#ifdef NAME' diffs.
Similar, but format GTYPE input groups with GFMT.
Similar, but format all input lines with LFMT.
Similar, but format LTYPE input lines with LFMT.
LTYPE is `old', `new', or `unchanged'.
GTYPE is LTYPE or `changed'.
GFMT may contain:
%<
lines from FILE1
%>
lines from FILE2
%=
lines common to FILE1 and FILE2
%[-][WIDTH][.[PREC]]{doxX}LETTER
printf-style spec for LETTER
LETTERs are as follows for new group, lower case for old group:
F
first line number
L
last line number
N
number of lines = L-F+1
E
F-1
M
L+1
LFMT may contain:
%L
contents of line
%l
contents of line, excluding any trailing newline
%[-][WIDTH][.[PREC]]{doxX}n
printf-style spec for input line number
Either GFMT or LFMT may contain:
%%
%
%c'C'
the single character C
the character with octal code OOO
Pass the output through `pr' to paginate it.
Expand tabs to spaces in output.
Make tabs line up by prepending a tab.
Recursively compare any subdirectories found.
Treat absent files as empty.
Treat absent first files as empty.
Report when two files are the same.
Exclude files that match PAT.
Exclude files that match any pattern in FILE.
Start with FILE when comparing directories.
Compare FILE1 to all operands.  FILE1 can be a directory.
Compare all operands to FILE2.  FILE2 can be a directory.
Keep NUM lines of the common prefix and suffix.
Try hard to find a smaller set of changes.
Assume large files and many scattered small changes.
Output version info.
Output this help.
FILES are `FILE1 FILE2' or `DIR1 DIR2' or `DIR FILE...' or `FILE... DIR'.
If a FILE is `-', read standard input.
Written by Paul Eggert, Mike Haertel, David Hayes,
Richard Stallman, and Len Tower.
Report bugs to <bug-gnu-utils@gnu.org>.
This program comes with NO WARRANTY, to the extent permitted by law.
You may redistribute copies of this program
under the terms of the GNU General Public License.
For more information about these matters, see the file named COPYING.
The full documentation for
is maintained as a Texinfo manual.  If the
and
programs are properly installed at your site, the command
should give you access to the complete manual.
Compare three files line by line.
Output unmerged changes from OLDFILE to YOURFILE into MYFILE.
Output unmerged changes, bracketing conflicts.
Output all changes, bracketing conflicts.
Output overlapping changes.
Output overlapping changes, bracketing them.
Output unmerged nonoverlapping changes.
Use LABEL instead of file name.
Append `w' and `q' commands to ed scripts.
Treat all files as text.
Make tabs line up by prepending a tab.
Use PROGRAM to compare files.
Output version info.
Output this help.
If a FILE is `-', read standard input.
Written by Randy Smith.
Report bugs to <bug-gnu-utils@gnu.org>.
This program comes with NO WARRANTY, to the extent permitted by law.
You may redistribute copies of this program
under the terms of the GNU General Public License.
For more information about these matters, see the file named COPYING.
The full documentation for
is maintained as a Texinfo manual.  If the
and
programs are properly installed at your site, the command
should give you access to the complete manual.
of the insertions, deletions, and modifications per-file.
Diffstat is a program that is useful for reviewing large, complex patch files.
producing a histogram of the total lines changed for each file referenced.
If the input filename ends with .bz2, .gz, .lzma, .z or .Z,
diffstat will read the
uncompressed data via a pipe from the corresponding program.
It also can infer the compression type from files piped via the standard input.
Diffstat recognizes the most popular types of output from diff:
unified
context
best for readability, but not very compact.
default
not good for much, but simple to generate.
tell which files are compared, and then counts the markers in the
first column that denote the type of change (insertion, deletion
or modification).
If no filename is given on the command line,
ignore lines matching "Binary files XXX and YYY differ" in the diff
prefix each line of output with "#", making it a comment-line for shell
scripts.
add SGR color escape sequences to highlight the histogram.
specify a directory containing files which can be referred to as
the result of applying the differences.
to obtain the total number of lines in each file.
The remainder, after subtracting modified and deleted lines,
is shown as "unchanged lines".
specify the format of the histogram.
0
for concise, which shows only the value and a single histogram code for each of
insert (+),
modify (!)
1
for normal output,
2
to fill in the histogram with dots,
4
to print each value with the histogram.
Any nonzero value gives a histogram.
The dots and individual values can be combined,
prints the usage message and exits.
suppress the merging of filenames in the report.
lists only the filenames.
No histogram is generated.
approximate a count of the modified lines.
specify the minimum width used for filenames.
filename, after stripping common prefixes.
specify the maximum width used for filenames.
Names longer than this limit are truncated on the left.
suppress the "0 files changed" message for empty diffs.
provides optional rounding of the data shown in histogram,
rather than truncating with error adjustments.
0
is the default.
No rounding is performed,
but accumulated errors are added to following columns.
1
rounds the data
2
rounds the data and adjusts the histogram to ensure that
it displays something if there are any differences even if
those would normally be rounded to zero.
Assume patch was created with old and new files swapped.
show only the summary line, e.g., number of insertions and deletions.
the original files (before applying differences) can be found.
overrides the histogram,
generates output of comma separated values.
suppress the sorting of filenames in the report.
show progress,
e.g., if the output is redirected to a file,
write progress messages to the standard error.
prints the current version number and exits.
specify the maximum width of the histogram.
The histogram will never be shorter than 10 columns,
just in case the filenames get too large.
You can override the compiled-in paths of programs used for decompressing
input files by setting environment variables corresponding to their name:
DIFFSTAT_BZCAT_PATH
DIFFSTAT_BZIP2_PATH
DIFFSTAT_COMPRESS_PATH
DIFFSTAT_GZIP_PATH
DIFFSTAT_LZCAT_PATH
DIFFSTAT_PCAT_PATH
DIFFSTAT_UNCOMPRESS_PATH
DIFFSTAT_XZ_PATH
DIFFSTAT_ZCAT_PATH
There is no way to obtain a filename from the standard diff between
two files with no options.
Context diffs work,
as well as unified diffs.
There's no easy way to determine the degree of overlap between the
"before" and "after" displays of modified lines.
Thomas Dickey <dickey@invisible-island.net>.
(domain information groper) is a flexible tool for interrogating DNS name servers. It performs DNS lookups and displays the answers that are returned from the name server(s) that were queried. Most DNS administrators use
to troubleshoot DNS problems because of its flexibility, ease of use and clarity of output. Other lookup tools tend to have less functionality than
Although
option is given. Unlike earlier versions, the BIND 9 implementation of
allows multiple lookups to be issued from the command line.
Unless it is told to query a specific name server,
will try each of the servers listed in
When no command line arguments or options are given,
will perform an NS query for "." (the root).
via
The IN and CH class names overlap with the IN and CH top level domains names. Either use the
and
options to specify the type and class, use the
the specify the domain name, or use "IN." and "CH." when looking up these top level domains.
A typical invocation of
looks like:
 dig @server name type 
where:
argument is a hostname,
resolves that name before querying that name server. If no
argument is provided,
consults
and queries the name servers listed there. The reply from the name server that responds is displayed.
is the name of the resource record that is to be looked up.
can be any valid query type. If no
argument is supplied,
will perform a lookup for an A record.
The
option sets the source IP address of the query to
The default query class (IN for internet) is overridden by the
option.
is any valid class, such as HS for Hesiod records or CH for Chaosnet records.
The
option makes
operate in batch mode by reading a list of lookup requests to process from the file
The
option enables memory usage debugging.
option is used.
is the port number that
The
option forces
to only use IPv4 query transport. The
option forces
to only use IPv6 query transport.
The
option sets the query type to
option is supplied to indicate a reverse lookup. A zone transfer can be requested by specifying a type of AXFR. When an incremental zone transfer (IXFR) is required,
is set to
ixfr=N. The incremental zone transfer will contain the changes made to the zone since the serial number in the zone's SOA record was
The
option sets the query name to
from other arguments.
option.
and
arguments.
automatically performs a lookup for a name like
and sets the query type and class to PTR and IN respectively. By default, IPv6 addresses are looked up using nibble format under the IP6.ARPA domain. To use the older RFC1886 method using the IP6.INT domain specify the
option. Bit string labels (RFC2874) are now experimental and are not attempted.
To sign the DNS queries sent by
and their responses using transaction signatures (TSIG), specify a TSIG key file using the
option. You can also specify the TSIG key itself on the command line using the
option;
is the name of the TSIG key and
or in the shell's history file. When using TSIG authentication with
and
statements in
The
command does not use the host name and address resolution or the DNS query routing mechanisms used by other processes running on Mac OS X.
The results of name or address queries printed by
may differ from those found by other processes that use the Mac OS X native name and address resolution mechanisms.
The results of DNS queries may also differ from queries that use the Mac OS X DNS routing library.
provides a number of query options which affect the way in which lookups are made and the results displayed. Some of these set or reset flag bits in the query header, some determine which sections of the answer get printed, and others determine the timeout and retry strategies.
Each query option is identified by a keyword preceded by a plus sign (+). Some keywords set or reset an option. These may be preceded by the string
no
to negate the meaning of that keyword. Other keywords assign values to options like the timeout interval. They have the form
Use [do not use] TCP when querying name servers. The default behavior is to use UDP unless an AXFR or IXFR query is requested, in which case a TCP connection is used.
Use [do not use] TCP when querying name servers. This alternate syntax to
is provided for backwards compatibility. The "vc" stands for "virtual circuit".
Ignore truncation in UDP responses instead of retrying with TCP. By default, TCP retries are performed.
Set the search list to contain the single domain
directive in
option were given.
Use [do not use] the search list defined by the searchlist or domain directive in
(if any). The search list is not used by default.
Perform [do not perform] a search showing intermediate results.
Deprecated, treated as a synonym for
Sets the "aa" flag in the query.
A synonym for
Set [do not set] the CD (checking disabled) bit in the query. This requests the server to not perform DNSSEC validation of responses.
Display [do not display] the CLASS when printing the record.
Display [do not display] the TTL when printing the record.
Toggle the setting of the RD (recursion desired) bit in the query. This bit is set by default, which means
normally sends recursive queries. Recursion is automatically disabled when the
or
query options are used.
When this option is set,
attempts to find the authoritative name servers for the zone containing the name being looked up and display the SOA record that each name server has for the zone.
Toggle tracing of the delegation path from the root name servers for the name being looked up. Tracing is disabled by default. When tracing is enabled,
makes iterative queries to resolve the name being looked up. It will follow referrals from the root servers, showing the answer from each server that was used to resolve the lookup.
Toggles the printing of the initial comment in the output identifying the version of
and the query options that have been applied. This comment is printed by default.
Provide a terse answer. The default is to print the answer in a verbose form.
Show [or do not show] the IP address and port number that supplied the answer when the
option is enabled. If short form answers are requested, the default is not to show the source address and port number of the server that provided the answer.
Toggle the display of comment lines in the output. The default is to print comments.
This query option toggles the printing of statistics: when the query was made, the size of the reply and so on. The default behavior is to print the query statistics.
Print [do not print] the query as it is sent. By default, the query is not printed.
Print [do not print] the question section of a query when an answer is returned. The default is to print the question section as a comment.
Display [do not display] the answer section of a reply. The default is to display it.
Display [do not display] the authority section of a reply. The default is to display it.
Display [do not display] the additional section of a reply. The default is to display it.
Set or clear all display flags.
Sets the timeout for a query to
seconds. The default timeout is 5 seconds. An attempt to set
to less than 1 will result in a query timeout of 1 second being applied.
Sets the number of times to try UDP queries to server to
instead of the default, 3. If
is less than or equal to zero, the number of tries is silently rounded up to 1.
Sets the number of times to retry UDP queries to server to
instead of the default, 2. Unlike
Set the number of dots that have to appear in
to
for it to be considered absolute. The default value is that defined using the ndots statement in
or
directive in
Set the UDP message buffer size advertised using EDNS0 to
bytes. The maximum and minimum sizes of this buffer are 65535 and 0 respectively. Values outside this range are rounded up or down appropriately. Values other than zero will cause a EDNS query to be sent.
Specify the EDNS version to query with. Valid values are 0 to 255. Setting the EDNS version will cause a EDNS query to be sent.
clears the remembered EDNS version.
output.
Print only one (starting) SOA record when performing an AXFR. The default is to print both the starting and ending SOA records.
Do not try the next server if you receive a SERVFAIL. The default is to not try the next server which is the reverse of normal stub resolver behavior.
Attempt to display the contents of messages which are malformed. The default is to not display malformed answers.
Requests DNSSEC records be sent by setting the DNSSEC OK bit (DO) in the OPT record in the additional section of the query.
Specifies a file containing trusted keys to be used with
If not specified,
will look for
then
in the current directory.
Include an EDNS name server ID request when sending a query.
The BIND 9 implementation of
supports specifying multiple queries on the command line (in addition to supporting the
batch file option). Each of those queries can be supplied with its own set of flags, options and query options.
In this case, each
A global set of query options, which should be applied to all queries, can also be supplied. These global query options must precede the first tuple of name, class, type, options, flags, and query options supplied on the command line. Any global query options (except the
shows how
could be used from the command line to make three lookups: an ANY query for
www.isc.org, a reverse lookup of 127.0.0.1 and a query for the NS records of
isc.org. A global query option of
is applied, so that
shows the initial query it made for each lookup. The final query has a local query option of
which means that
will not print the initial query when it looks up the NS records for
isc.org.
If
appropriately converts character encoding of domain name before sending a request to DNS server or displaying a reply from the server. If you'd like to turn off the IDN support for some reason, defines the
environment variable. The IDN support is disabled if the variable is set when
runs.
RFC1035.
There are probably too many query options.


In its first form, 
copies one or more source files or directories to a destination
directory.  If the destination directory does not exist it will be
created before the first source is copied.  If the destination
directory already exists then the source directories are merged
with the previous contents of the destination.
In its second form, 
copies a file to the supplied 
pathname.
The next two forms reflect
ability to create and extract
archives.  These archives can be either CPIO format (preferred for unix 
content) or PKZip (for Windows compatibility).
(and
can be the single character '-', causing ditto to read (write) archive data
from stdin (or to stdout, respectively).
follows symbolic links provided as arguments but does not follow any links
as it traverses the source or destination hierarchies.
overwrites existing files, symbolic links, and devices in the destination
when these are copied from a source.  The resulting files, links, and
devices will have the same mode, access time, modification time, owner,
and group as the source items from which they are copied.  Pipes, sockets,
and files with names beginning with .nfs or .afpDeleted will be ignored.
does not modify the mode, owner, group, extended attributes, or ACLs of existing
directories in the
destination.  Files and symbolic links cannot overwrite directories or
vice-versa.
can be used to "thin" Universal Mach-O binaries during a copy. 
can also copy files selectively based on the contents of a BOM
("Bill of Materials") file.
preserves file hard links (but not directory hard links) present in the source directories and preserves
setuid and setgid modes when run as the superuser. 
will preserve resource forks and HFS meta-data information
when copying unless instructed otherwise using
Similarly,
will preserve extended attributes and Access Control Lists (ACLs) unless
or
is passed.
can be set in the environment as an alias to
on the command line.
Print full usage.
Print a line of output to stderr for each source directory copied.
Print a line of output to stderr for every file, symbolic link, and device copied.
When copying one or more source directories, do not descend into directories
that have a different device ID.
Create an archive at the destination path.  The default format is CPIO, unless
is given.
CPIO archives should be stored in files with names ending in .cpio.
Compressed CPIO archives should be stored in files with names ending in
Create compressed CPIO archives, using
compression.
Create compressed CPIO archives, using
compression.
Extract the archives given as source arguments. The format is assumed to
be CPIO, unless
is given.  Compressed CPIO is automatically handled.
Create or extract from a PKZip archive instead of the default CPIO.
PKZip archives should be stored in filenames ending in .zip.
When creating an archive, embed the parent directory name
in
Thin Universal binaries to the specified
architecture.  If multiple
options are specified then the resulting destination file will contain
each of the specified architectures (if they are present in the source
file).
should be specified as "i386", "x86_64", etc.
Copy only files, links, devices, and directories that are present in the
specified BOM.
Preserve resource forks and HFS meta-data.
will store this data in Carbon-compatible ._ AppleDouble files on
filesystems that do not natively support resource forks.  As of Mac OS X 10.4,
is default behavior.
Do not preserve resource forks and HFS meta-data.  If both
and
are passed, whichever is passed last will take precedence.  Both options
override
also implies
and
to match the behavior of Mac OS X 10.4.
Preserve extended attributes (requires
As of Mac OS X 10.5,
is the default.
Do not preserve extended attributes (requires 
Preserve quarantine information.
As of Mac OS X 10.5,
is the default.
Do not preserve quarantine information.
Preserve Access Control Lists (ACLs).
As of Mac OS X 10.5,
is the default.
Do not preserve ACLs.
Do not perform copies using the Mac OS X Unified Buffer Cache. Files read
and written will not be cached, although if the file is already present
in the cache, the cached information will be used.
When copying files or extracting content from an archive, if the destination 
is an HFS+ volume that supports compression, all the content will be compressed
if appropriate. This is only supported on Mac OS X 10.6 or later, and is only
intended to be used in installation and backup scenarios that involve system 
files. Since files using HFS+ compression are not readable on versions of 
Mac OS X earlier than 10.6, this flag should not be used when dealing with
non-system files or other user-generated content that will be used on a 
version of Mac OS X earlier than 10.6. 
Do not compress files with HFS+ compression when copying or extracting content
from an archive unless the content is already compressed with HFS+ compression. 
This flag is only supported on Mac OS X 10.6 or later. 
is the default.
When copying files to an HFS+ volume that supports compression, ditto will 
preserve the compression of any source files that were using HFS+ compression. 
This flag is only supported on Mac OS X 10.6 or later. 
is the default.
Do not preserve HFS+ compression when copying files that are already compressed with
HFS+ compression. This is only supported on Mac OS X 10.6 or later.
When creating a PKZip archive, preserve resource forks and HFS meta-data
in the subdirectory __MACOSX.  PKZip extraction will automatically find
these resources.
Sets the compression level to use when creating a PKZip archive. The compression
level can be set from 0 to 9, where 0 represents no compression, and 9 
represents optimal (slowest) compression. By default, ditto will use the default compression
level as defined by zlib.
When extracting a password-encrypted ZIP archive, you must specify --password to allow ditto 
to prompt for a password to use to extract the contents of the file. If this option is not 
provided, and a password-encrypted file is encountered, ditto will emit an error message.
The command:
copies the contents of src_directory into dst_directory, creating
dst_directory if it does not already exist.
The command:
dir and dst_directory if they don't already exist.
The command:
copies the contents of all of the src directories into dst_directory,
creating dst_directory if it does not already exist.
The command:
copies the contents of universal_file into thin_file, thinning executable
code to ppc-only on the fly.
The command:
copies Scripts, skipping any resources or meta-data, to rhost.
The command:
will list the files in the CPIO archive archive.cpio.
The command:
will list the files in the compressed CPIO archive archive.cpgz.
The command:
will create a PKZip archive similarly to the Finder's Compress functionality.
The command:
will list the files in the PKZip archive archive.zip.
returns 0 if everything is copied, otherwise non-zero.
almost never gives up, preferring to report errors along the way.
Diagnostic messages will be printed to standard error.
If the environment variable
is set,
will call
if it encounters a fatal error.
If
is set but
and
are not specified,
will not preserve those additional types of metadata.
doesn't copy directories into directories in the same way as
In particular,
will copy the contents of foo into bar, whereas 
copies foo itself into bar. Though this is not a bug, some may
consider this bug-like behavior.
for non-archive copies will eventually alleviate this problem.
The
command is a network diagnostic tool, much like
or
However, unlike those tools, most of its functionality is not implemented in the
executable itself, but in library code that is available to any application.
The library API that
uses is documented in
The
command replaces the older
mDNS
command.
The
command is primarily intended for interactive use.
Because its command-line arguments and output format are subject to change,
invoking it from a shell script will generally be fragile. Additionally,
the asynchronous nature of DNS Service Discovery does
not lend itself easily to script-oriented programming. For example,
calls like "browse" never complete; the action of performing a "browse"
sets in motion machinery to notify the client whenever instances of
that service type appear or disappear from the network. These
notifications continue to be delivered indefinitely, for minutes,
hours, or even days, as services come and go, until the client
explicitly terminates the call. This style of asynchronous interaction
works best with applications that are either multi-threaded, or use a
main event-handling loop to receive keystrokes, network data, and other
asynchronous event notifications as they happen.
If you wish to perform DNS Service Discovery operations from a
scripting language, then the best way to do this is not to execute the
command and then attempt to decipher the textual output, but instead to
directly call the DNS-SD APIs using a binding for your chosen language.
For example, if you are programming in Ruby, then you can
directly call DNS-SD APIs using the dnssd package documented at
Similar bindings for other languages are also in development.
return a list of domains recommended for registering(advertising) services.
return a list of domains recommended for browsing services.
Normally, on your home network, the only domain you are likely to see is "local". 
However if your network administrator has created Domain Enumeration records, 
then you may also see other recommended domains for registering and browsing.
register (advertise) a service in the specified
with the given
and
as listening (on the current machine) on
can be arbitrary unicode text, containing any legal unicode characters
(including dots, spaces, slashes, colons, etc. without restriction),
up to 63 UTF-8 bytes long.
must be of the form "_app-proto._tcp" or "_app-proto._udp", where
"app-proto" is an application protocol name registered at
is the domain in which to register the service.
In current implementations, only the local multicast domain "local" is
supported. In the future, registering will be supported in any arbitrary
domain that has a working DNS Update server [RFC 2136]. The
"." is a synonym for "pick a sensible default" which today
means "local".
is a number from 0 to 65535, and is the TCP or UDP port number upon
which the service is listening.
Additional attributes of the service may optionally be described by
record. Allowable keys and values are listed with the service
registration at
browse for instances of service
in
For valid 
see
as described above. Omitting the
or using "." means "pick a sensible default."
look up and display the information necessary to contact and use the
named service: the hostname of the machine where that service is
available, the port number on which the service is listening, and (if
present) TXT record attributes describing properties of the service.
Note that in a typical application, browsing may only happen rarely, while lookup
(or "resolving") happens every time the service is used. For example, a
user browses the network to pick a default printer fairly rarely, but once
a default printer has been picked, that named service is resolved to its
current IP address and port number every time the user presses Cmd-P to
print.
create a proxy advertisement for a service running on(offered by) some other machine.
The two new options are Host, a name for the device and IP, the address of it.
The service for which you create a proxy advertisement does not necessarily have to be on your local network. 
You can set up a local proxy for a website on the Internet.
look up any DNS name, resource record type, and resource record class, 
not necessarily DNS-SD names and record types.
If rrtype is not specified, it queries for the IPv4 address of the name, 
if rrclass is not specified, IN class is assumed. If the name is not a fully 
qualified domain name, then search domains may be appended.
browse for service instances and display output in zone file format.
look up the IP address information of the name.
If v4 is specified, the IPv4 address of the name is looked up, 
if v6 is specified the IPv6 address is looked up. If v4v6 is specified both the IPv4 and IPv6 
address is looked up. If the name is not a fully qualified domain name, 
then search domains may be appended.
To advertise the existence of LPR printing service on port 515 on this
machine, such that it will be discovered by the Mac OS X printing software
and other DNS-SD compatible printing clients, use:
For this registration to be useful, you need to actually have LPR service
available on port 515. Advertising a service that does not exist is not
very useful, and will be confusing and annoying to other people on the
network.
Similarly, to advertise a web page being served by an HTTP
server on port 80 on this machine, such that it will show up in the
Bonjour list in Safari and other DNS-SD compatible Web clients, use:
To find the advertised web pages on the local network (the same list that
Safari shows), use:
While that command is running, in another window, try the
example given above to advertise a web page, and you should see the
"Add" event reported to the
window. Now press Ctrl-C in the
window and you should see the "Remove" event reported to the
window.
In the example below, the www.apple.com web page is advertised as a service called "apple", 
running on a target host called apple.local, which resolves to 17.149.160.49.
The Bonjour menu in the Safari web browser will now show "apple".
The same IP address can be reached by entering apple.local in the web browser.
In either case, the request will be resolved to the IP address and browser will show
contents associated with www.apple.com.
If a client wants to be notified of changes in server state, it can
initiate a query for the service's particular record and leave it running.
For example, to monitor the status of an iChat user you can use:
Everytime status of that user(someone) changes, you will see a new TXT record result reported.
You can also query for a unicast name like www.apple.com and monitor its status.
bugs are tracked in Apple Radar component "mDNSResponder".
The
command first appeared in Mac OS X 10.4 (Tiger).
The
The super-user can
set the domain name by supplying an argument; this is usually done
at startup by specifying a domain name in the contents of the file
domain name does not necessarily have anything to do with the Domain
Name System domain name, although they are often set equal for administrative
convenience.
The
command appeared in
based on a similar command in
For each
,
recursively merges all ._* files with their corresponding native files according to the rules specified with the given arguments.  By default, if there is an attribute on the native file that is also present in the ._ file, the most recent attribute will be used.
If no operands are given, a usage message is output.
If more than one directory is given, directories are merged in the order in which they are specified.
Flat merge.  Do not recursively merge all directories in the given
This is off by default.
Help. Prints verbose usage message.
Always delete dot underbar files.
Delete dot underbar file if there is no matching native file.
Follow symbolic links.  This will follow symbolic dot underbar files when they are found.
Print verbose output.
The default option.  If an attribute is associated with a data fork, use that.  Otherwise, use information stored in the AppleDouble file.  Note that the native fork's data is preferred even if the data in the AppleDouble file is newer.
Always use information stored in the AppleDouble file, replacing any extended attributes associated with the native file.
Always use the information associated with the data fork, ignoring any AppleDouble files.
The following is how to do an
merge on the mounted volume test, always using the dot underbar information.
None known.
uses the DiscRecording framework to interact with attached 
burning devices.  Common verbs include
and
The rest of the verbs are:
and
Each verb is listed with its description and individual arguments.
Drive selection arguments must appear before individual arguments.
Drive selection and argument descriptions can be found after the verb
descriptions in the Drive Selection Criteria section.
Lets you specify a drive or drives, per the output of
for those verbs that can operate on one or more drives.
See the Drive Selection Criterion section for more info.
Display the usage information for the specified verb.
Starts bulk erase mode, in which the drive will continually
erase inserted -RW media, eject it, and prompt for another disc until
terminated.
Types of erase:
Performs a quick erase, doing the minimal amount of work to make the 
disc appear blank. This operation typically takes only a minute or two. 
Performs a complete erase, erasing every block on the disk. This 
operation is slow (on the order of 30 minutes) to complete.
Burns a valid directory or image file to disc. The default is to burn the
specified directory to a new filesystem. The 
option creates an
audio CD (redbook) in which any valid QuickTime audio file present in the path
is converted to a track (in alphabetical order). If a file is specified (valid 
are burned. Pre-burn and post-burn options, and filesystem exclusions can be
specificed for enhanced functionality. Last option takes precedence. Invalid commands are ignored.
A valid path to a directory or file.
Specify an arbitrary valid burn option(s):
Or specify a default burn option:
Reads and displays any CD-Text information reported by the drive. The drive
must contain an audio CD, and be capable of reading CD-Text.
Displays detailed information about present media.
From the MMC command of the same name.
Tool to inspect and interpret ISO-9660 and Joliet structures on the media.
Block number to dump (in decimal or 0x hex notation). Blocks are
assumed to be 2048-byte blocks.
How to interpret the block. If format is not specified, dumpiso will attempt to guess. 
If present, this argument should be one of the following:
Tool to inspect and interpret UDF structures on the media.
Block number to dump (in decimal or 0x hex notation). Blocks are
assumed to be 2048-byte blocks.
Synonym for
Erases -RW media in the drive(s) and ejects it.
Types of erase:
Performs a quick erase, doing the minimal amount of work to make the 
disc appear blank. This operation typically takes only a minute or two. 
Performs a complete erase, erasing every block on the disk. This 
operation is slow (on the order of 30 minutes) to complete.
Shows how the specified filename will be modified to comply with the
naming rules of the filesystems that DiscRecording generates.
Displays device feature and profile list.
Types of config information:
Displays current features and profiles for a drive.
Displays all supported features and profiles for a drive.
Displays various pieces of information for each drive,
including how it's connected to the computer and a summary
of capabilities.
Lists all burning devices connected to the machine.
Displays device and media notifications until terminated.
Estimates the size of a valid directory or image file (in blocks). The default is to estimate 
the size of the specified path as a hybrid filesystem. The 
option calculates the contents of the directory as an audio CD (redbook) (for applicable files). If a file
will be calculated. Filesystem exclusions can be specificed for enhanced functionality. Calculated size will
be compared against blank media that is found unless the 
argument is specified. Last option takes precedence. Invalid commands are ignored.
A valid path to a directory or file.
Specify an arbitrary valid burn option(s):
Or specify a default burn option:
Displays detailed media-specific information.
Displays information from the subchannels on CD media. This
prints the MCN (media catalog number) for the disc, and the
ISRC (international standard recording code) for all tracks.
This command only works when CD media is present.
From the MMC command of the same name.
Displays table of contents (TOC) of inserted media.
Displays detailed information about all tracks present
on the media.
From the MMC command of the same name.
do not have trays, and some have trays but may lack motorized
eject or inject capability.
Tray commands:
Opens a drive's tray, if no media is present and the
drive has a tray capable of motorized eject.
Closes a drive's tray, if the drive has a tray capable
of motorized inject.
Ejects media from the drive, if the drive has a tray capable
of motorized eject. If no media is present, this is equivalent
to
If media is present and can be unmounted, it will be unmounted
and then ejected.
If media is present but cannot be unmounted, the eject will fail.
Displays operating system and DiscRecording framework version numbers.
When specified (valid options only:
the output for the specified verb will be shown in xml format.
Some functions of
operate on a specific drive. Since any number of
drives may be available, and they may come and go at any time, the device
selection arguments provide a method for selecting among them.
The candidate list starts out as a list of all attached drives. One or more
arguments of the form
may be specified. Each argument has the
effect of narrowing the candidate list, depending on what
is. It may be:
A positive decimal number, assumed to be a 1-based index into the
candidate list. The candidate list is trimmed to just that device.
One of the following keywords:
The candidate list is trimmed to devices which match the specified 
candidate list is trimmed to devices whose vendor or product 
strings exactly match the argument. Case (but not whitespace) is 
ignored in this comparison.
Multiple
arguments may be specified; each argument narrows the
candidate list further. After all the
arguments have been processed, the candidate list is considered. If
it contains exactly one item, that drive is used. If it contains
zero items,
prints an error message and exits. If it contains more than one item,
the selected function is executed on all drives remaining in the list.
Simple verbs with no drive commands
        Displays help for the verb "status".
        Displays a list of attached devices.
		Displays miscellaneous information for all attached devices.
		Displays media-specific information for all attached devices.
        Burns the Documents directory to the internal drive without
        verifying, then ejects the disc.
        Creates a XML file containing info about internal drives.
Examples of drive selection
        Closes the tray of the first burning device seen, if possible.
        Lists drive specific information for all externally
        connected burning devices.
        Lists media specific information for media present in
        attached firewire burning devices.
        Opens the tray of all burning devices whose vendor id is 
        VENDOR, if possible.
        Lists supported features and profiles for attached devices
        whose product id is 'CD-RW CDW827ES'.
first appeared in MacOS X 10.3.
does various operations against the Directory Service cache including gathering statistics, initiating lookups, inspection, cache flush, etc.  This tool replaces most of the functionality of the lookupd tool previously available in the OS.  
A list of flags and their descriptions:
Lists the options for calling
Initiate a query using standard calls.  These calls will either return results from the cache or go fetch live data and place them in the cache.  By default if no specific query is requested via
then all results within that category will be returned.
Optional flag to 
for a specific key with a value.
Dumps an overview of the cache by default.  Additional flags will provide more detailed information.
Used in conjunction with
to also print hash bucket usage of the current cache.
Used in conjunction with
to dump detailed information about cache entries.  An optional category can be supplied to only see types of interest.  Dumping 'host' entries can only be done by administrative users.
Prints current configuration information, such as the search policy from Directory Service and cache parameters.
Flushes the entire cache.  This should only be used in extreme cases.  Validation information is used within the cache along with other techniques to ensure the OS has valid information available to it.
Prints statistics from the cache including an overview and detailed call statistics.  Some calls are not cached but are derived from other calls internally.  Cache hits and cache misses may not always be equal to external calls.  For example getaddrinfo is actually a combination of gethostbyname with other calls internally to the cache to maximize cache hit rate.
Available categories and associated keys:
name or gid
name or ip_address (used for both IPv6 and IPv4)
name
name or number
name or number
name or port
name or uid
options:
prompt for password
authenticate as user
authentication password
targeted local node database file path
don't strip off prefix from DirectoryService API constants
print out record(s) or attribute(s) in XML plist format
print record attribute values in URL-style encoding
quiet - no interactive prompt
commands:
available only in interactive mode:
is a general-purpose utility for operating on Directory Service directory nodes.  Its commands allow one to create, read, and manage Directory Service data.  If invoked without any commands,
runs in an interactive mode, reading commands from standard input.  Interactive processing is terminated by the
command.  Leading dashes ("-") are optional for all commands.
option and either the
of
options to specify an administrative user and password on the remote host to authenticate with to the remote host. The exception to this is if "localhost" is specified.  Passing passwords on the command line is inherently insecure and can cause password exposure.  For better security do not provide the password as part of the command and you will be securely prompted.
The datasource may also be specified as "localonly" in which case a separate DirectoryService daemon process is activated which contains only the Local plugin for use by dscl.  If no file path is provided then access goes only to the registered local nodes on the system. However, if the
There are two modes of operation when specifying paths to operate on. The two modes correspond to whether the datasource is a node or a host. In the case of specifying a node, the top level of paths will be record types. Example top level paths would be:
In the case of specifying a host as a data source, the top level of paths correspond to Open Directory plug-ins and Search Paths. One can specify the plug-in to traverse to a node name, after which the paths are equivalent to the former usage. The following might be the equivalent paths as the above paths:
All pathnames are case-sensitive.
The action of each command is described below.  Some commands have aliases.  For example, "cat" and "." are aliases for "read".  Command aliases are listed in parentheses.
Usage: read
Prints a directory.  The property key is followed by colon, then a space-separated list of the values for that property. If any value contains embedded spaces, the list will instead be displayed one entry per line, starting on the line after the key.
If The 
flag for raw output has been given, then
prints the full DirectoryService API constant for record and attribute types.
If the
flag has been specified then printed record path attribute values are encoded in the style of URLs. This is useful if a script or program is trying to process the output since values will not have any spaces or other control characters.
Usage: readall
prints all the records of a given type.  The output of readall is formatted in the same way as
with a "-" on a line as a delimeter between records.
Usage: readpl
Prints the contents of
The
is followed by a colon, then a whitespace, and then the value for the path.
If the
is the key for a dictionary or array, the contents of it are displayed in plist form after the
If
is the key for a string, number, bool, date, or data object, only the value is printed out after the
Usage: readpli
Prints the contents of
for the plist at
of the key.
The
is followed by a colon, then a whitespace, and then the value for the path.
If the
is the key for a dictionary or array, the contents of it are displayed in plist form after the
If
is the key for a string, number, bool, date, or data object, only the value is printed out after the
Usage: list
Lists the subdirectories of the given directory.  Subdirectories are listed one per line.  In the case of listing a search path, the names are preceded by an index number that can act as a shortcut and used in place of the name when specifying a path.
When used in interactive mode, the path is optional.  With no path given, the current directory will be used.
Searches for records that match a pattern.  The search is rooted at the given path.  The path may be a node path or a record type path.  Valid keys are Directory Service record attribute types.
Usage: create
Creates a record, property, or value.  If only a record path is given, the
command will create the record if it does not exist.  If a key is given, then a property with that key will be created.
WARNING - If a property with the given key already exists, it will be destroyed and a new property will be created in its place.  To add values to an existing property, use the
or 
commands.
If values are included in the command, these values will be set for the given key.
NOTE - Not all directory nodes support a property without a value. An error will be given if you attempt to create a property with no value in such a directory node.
Usage: createpl
Creates a string, or array of strings at
If you are creating a value at the root of a plist that is an array, simply use "0" as the
If only
is specified, a string will be created at
If
are specified, an array of strings will be created at
WARNING - If a value with the given
already exists, it will be destroyed and a new value will be created in its place.
Usage: createpli
Creates a string, or array of strings at
for the plist at
of the key.
If you are creating a value at the root of a plist that is an array, simply use "0" as the
If only
is specified, a string will be created at
If
are specified, an array of strings will be created at
WARNING - If a value with the given
already exists, it will be destroyed and a new value will be created in its place.
Usage: append
Appends one or more values to a property in a given record.  The property is created if it does not exist.
Usage: merge
Appends one or more values to a property in a given directory if the property does not already have those values.  The property is created if it does not exist.
Usage: change
Replaces the given old value in the list of values of the given key with the new value in the specified record.
Usage: changei
Replaces the value at the given index in the list of values of the given key with the new value in the specified record.  
is an integer value.  An index of 1 specifies the first value.  An index greater than the number of values in the list will result in an error.
Usage: diff
Compares the data from path1 and path2 looking at the specified keys (or all if no keys are specified).
Usage: delete
Delete a directory, property, or value.  If a directory path is given, the
command will delete the directory.  This can only be used on record type and record paths.  If a key is given, then a property with that key will be deleted.  If one or more values are given, those values will be removed from the property with the given key.
Usage: deletepl
Deletes a value in a plist.  If no values are given
deletes the
If one or more values are given,
deletes the values within
Usage: deletepli
Deletes a value for the plist at
of the key.  If no values are given
deletes the
If one or more values are given,
deletes the values within
Usage: passwd
Changes a password for a user. The user must be specified by full path, not just a username.  If you are authenticated to the node (either by specifying the
and
flags or by using the auth command when in interactive node) then you can simply specify a new password.  If you are not authenticated or if FileVault is enabled then the user's old password must be specified.  If passwords are not specified while in interactive mode, you will be prompted for them.  Passing these passwords on the command line is inherently insecure and can cause password exposure.  For better security do not provide the password as part of the command and you will be securely prompted.
Usage: cd dir
Sets the current directory.  Path names for other
commands may be relative to the current directory.
Usage: pushd path
Similar to the pushd command commonly found in Unix shells.  When a path is specified it sets the current directory while pushing the previous directory on to the directory stack.  If no path is specified it exchanges the top two elements of the directory stack.  It will also print the final directory stack.
Usage: popd
Pops the directory stack and returns to the new top directory.  It will also print the final directory stack.
Usage: auth
Authenticate as the named user, or as "root" if no user is specified.  If a password is supplied, then that password is used for authentication, otherwise the command prompts for a password.
If
is run in host mode, then when this command is run the current directory must be in the subdirectories of a node.
Usage: authonly
Used to verify the password of a named user, or of "root" if no user is specified.  If a password is supplied, then that password is used for authentication, otherwise the command prompts for a password.
If
is run in host mode, then when this command is run the current directory must be in the subdirectories of a node.
Usage: quit
Ends processing of interactive commands and terminates the program.
The up and down arrow keys will scan through the command history. 
When pathnames are being typed, pressing the tab key will result in a search to auto-complete the typed partial subdirectory name. It will also attempt to correct capitilization in the process.
will return -1 (255) on error.
options:
verbose logging to stdout
prompt for passwords as required
choose SSL connection
enforce secure authentication only
enforce packet signing security policy
enforce man-in-middle security policy
enforce encryption security policy
do not update search policies
do not prompt about adding certificates
display usage statement
add config of servername
remove config of servername
name given to LDAP server config
name used if binding to directory
privileged network username
privileged network user password
local admin username
local admin password
allows addition or removal of LDAP server configurations. Presented below is a discussion of possible parameters. Usage has three intents: add server config, remove server config, or display help.
Options list and their descriptions:
Bindings will be established or dropped in conjunction with the addition or removal of the LDAP server configuration.
This enables the logging to stdout of the details of the operations. This can be redirected to a file.
You will be prompted for a password to use in conjunction with a specified username.
This ensures that no clear text passwords will be sent to the LDAP server during authentication.  This will only be enabled if the server supports non-cleartext methods.
This ensures that if the server is capable of supporting encryption methods (i.e., SSL or Kerberos) that encryption will be enforced at all times via policy.
This ensures that man-in-the-middle capabilities will be enforced via Kerberos, if the server supports the capability.
This ensures that packet signing capabilities will be enforced via Kerberos, if the server supports the capability.
Connection to the LDAP server will only be made over SSL.
Will skip updating the search policies.
Will assume Yes for installing certificates
Display usage statement.
This is either the fully qualified domain name or correct IP address of the LDAP server to be added to the DirectoryService LDAPv3 configuration.
This is either the fully qualified domain name or correct IP address of the LDAP server to be removed from the DirectoryService LDAPv3 configuration.
This is the UI configuration label that is to be given the LDAP server configuration.
This is the name to be used for directory binding to the LDAP server. If none is given the first substring, before a period, of the hostname (the defined environment variable "HOST") is used.
Username of a privileged network user to be used in authenticated directory binding.
Password for the privileged network user.  This is a less secure method of providing a password, as it may be viewed via process list.  For stronger security leave the option off and you will be prompted for a password.
Username of a local administrator.
Password for the local administrator.  This is a less secure method of providing a password, as it may be viewed via process list.  For stronger security leave the option off and you will be prompted for a password.
-a ldap.company.com
The LDAP server config for the LDAP server myldap.company.com will be added. If authenticated directory binding is required by the LDAP server, then this call will fail. Otherwise, the following parameters configname, computerid, and local admin name will respectively pick up these defaults: ip address of the LDAP servername, substring up to first period of fully qualified hostname, and username of the user in the shell this tool was invoked.
-r ldap.company.com
The LDAP server config for the LDAP server myldap.company.com will be removed but not unbound since no network user credentials were supplied.  The local admin name will be the username of the user in the shell this tool was invoked.
opendirectoryd(8), odutil(1)
The
utility exports records from Open Directory.
The first argument is the path to the output file.
If the file already exists it will be overwritten.
The second argument is the path to the OpenDirectory node from which the records will be read.
The third argument is the type of record to export.
If the record type does not begin with
or
the
utility will determine if the node supports a standard attribute by the specified name;
otherwise,
will assume that the record type is native.
A warning will be printed if the record type is converted.
Standard record types can be listed using the following command:
The options are as follows:
Export all attributes, including native attributes.
By default,
only exports standard attributes.
Comma-separated list of records to export from the specified node.
The
option may be used multiple times to specify additional records to export.
If the
option is not specified,
will attempt to export all records.
Comma-separated list of attributes that should not be exported.
The
option may be used multiple times to specify additional attributes to exclude.
The following attributes are always excluded:
Address of the desired proxy machine.
Username to use for the proxy connection
Password to use for the proxy connection.
If the
option is not specified,
will interactively prompt for the password.
When using an LDAP node, please be aware that
can only export as many records as the LDAP server is willing to return.
If the LDAP server has several thousand users, you may want to raise the maximum number of search results that the server returns.
This can be done in Server Admin (my.server.com>OpenDirectory>Settings>Protocols tab).
By default this is set to 11000 results.
Export all user records from the local node to
Export the group records for
and
from the LDAPv3 node on a proxy machine
Export augmented users from the LDAPv3 node, including native attributes but excluding the PasswordPlus attribute:
is a tool for importing records into an Open Directory source.
is the path of the file to be imported.
is the path of the Open Directory node where the records should be imported.
overwrite of any existing records that have the same record name, UID or GID. All previous attribute values are deleted.
merge import data with existing records or create the record if it does not exist.
ignore the record if there is a conflicting name, UID or GID.
append the data to existing records, but do not create a record if it does not exist.
A list of options and their descriptions:
is used to signify that all user passwords are crypt-based. Entries in the import file can also be prefixed with {CRYPT} on a per record basis if not all users are crypt-based.  By default all passwords are assumed to be provided as listed in the import file.
forces a specific value for the named attribute for all records during the import. The new value will overwrite any value specified in the import file. This option may be specified multiple times for forcing more than one attribute.
is the GID used for any records that do not specify a primary GID.
designate a preset record to be applied to imported group records.
changes the amount of logging detail output to the log file.
Outputs a plist to the specified file with a list of changed users or groups and rejected records due to name conflicts.
Also includes a list of deleted records (overwrite mode), and lists of records that failed and succeeded during import.
The format of this file is likely to change in a future release of Mac OS X.
is the admin's password for import operations. Used to authenticate to the directory node during import. A secure prompt will be used for interactive input if not supplied via parameter.  Using the prompt method is the most secure method of providing password to 
passes in the delimiters and attributes and record type to specify the order and names of attributes in the file to be imported. An example record format string: 
0x0A 0x5C 0x3A 0x2C dsRecTypeStandard:Users 7 dsAttrTypeStandard:RecordName dsAttrTypeStandard:Password dsAttrTypeStandard:UniqueID dsAttrTypeStandard:PrimaryGroupID dsAttrTypeStandard:RealName dsAttrTypeStandard:NFSHomeDirectory dsAttrTypeStandard:UserShell
A special value of IGNORE can be used for values that should be ignored in the import file on a record-by-record basis.
Override the record type defined in the import file. For example, to import ComputerGroups as ComputerLists, use:
The opposite works for importing ComputerLists as ComputerGroups, and so on.
connects to a remote host at the network address specified.  Commonly used to import to a remote Mac OS X Server.
specifies user name to use for the remote connection.
specifies password to use for the remote connection. A secure prompt will be used to ask for the password if
is specified and
is not.  Using the prompt method is the most secure method of providing password to 
indicates the ID number to start with when the import tool generates user or group IDs for any import file that lacks an ID as part of the import data. 
is used for delimited import of files that lack field descriptions.
contains the following fields in the order: 
RecordName
Password
UniqueID
PrimaryGroupID
DistinguishedName
NFSHomeDirectory
UserShell 
contains the following fields in the order:
RecordName
Password
PrimaryGroupID
GroupMembership 
is the admin username to use when importing records. If this is not specified the current user is the default name.  Also, if used in conjunction with 
then this admin user will be used for the Open Directory node whereas the username provided in
will be used for the remote connection.  If this option is left off but
is provided, then the remote username will be used for both the connection and for importing records.
designate a preset record to be applied to imported user records.
To import a standard dsexport file into the Local database:
administrator
adminpassword
is a program that implements the membership API calls in a command line utility.  
A list of flags and their descriptions:
Lists the options for calling
Causes
to operate in verbose mode.
The action of each command is described below:
Takes any of the options and returns the associated UUID.
Takes any of the options and returns the associated UID or GID depending on option provided.
Takes any of the options and returns the associated SID.
Returns if a user or group with the associated option is a member of the group.
Flushes the current membership cache.
Legacy commands such as dumpstate and statistics are gone. See 
for show cache and statistics operations.
A list of options available. In some cases 
and
can be used synonymously due to nature of the value.
Using user with UID
Using user with name
Using user with SID
Using user with UUID
Using group with GID
Using group with name
Using group with SID
Using group with UUID
Users new to DTrace are encouraged to read:
Options to list the set of probes and providers currently published by DTrace
Options to enable probes directly using any of the probe description specifiers (provider, module, function, name)
Options to run the D compiler and compile one or more D program files or programs written directly on the command-line
Options to generate anonymous tracing programs
Options to generate program stability reports
Options to modify DTrace tracing and buffering behavior and enable additional D compiler features
have exited, reporting the exit status for each child process as it terminates. The process-ID of the first command is made available to any D programs specified 
Note that with successive invocations of dtrace with the -o option, dtrace does not overwrite, but rather appends to the output file.
exits when all commands have exited, reporting the exit status for each process as it terminates. The first process-ID is made available to any D programs spe
Show D compiler intermediate code.  The D compiler will produce a report of the intermediate code generated for each D program to stderr.
Allow destructive actions. D programs containing destructive actions will fail to compile unless this flag is specified.
Enable or modify a DTrace runtime option or D compiler option.  Boolean options are enabled by specifying their name.  Options with values are set by separating the option name and value with an equals sign (=).
The Objective C provider is similar to the pid provider, and allows instrumentation of Objective C classes and methods. Objective C probe specifiers use the following format:
The id number of the process.
The name of the Objective C class.
The name of the category within the Objective C class.
The name of the Objective C method.
Every instance method of class NSString in process 123.
Every method on every category of class NSString in process 123.
Every class method in NSString's foo category in process 123.
Every instance method in every class and category in process 123.
The dealloc method in the foo category of class NSString in process 123.
Name the provider and specify its probes, using the following form:
};
Process the provider description into a header file.
Add probe invocations to the application
For each probe defined in the provider, the provider.h file will contain two macros.The naming is as follows:
In the Example provider, the increment probe becomes:
Place a macro invocation in the code at each site to be traced. If the arguments passed to a probe are expensive to calculate, you may guard the probe placement like this:
if (EXAMPLE_INCREMENT_ENABLED()) {
};
The if test will only succeed when the increment probe is active.
Compile and link your program normally. No additional compiler or linker flags are required.
A small number of DTrace builtin variables have OS X specific changes:
A string giving the name that was passed to exec(2) to execute the current process.
The string consists of at most MAXCOMLEN-1 characters.
A uint64_t timestamp returning mach_absolute_time().
A uint64_t thread ID of the currently executing thread. The thread ID is guaranteed to be unique and non repeating. The tid value is not equivalent to pthread_self.
The pidresume(pid) action is a destructive action meant to be used in conjunction with the stop() action.  
While the stop() action will task_suspend the currently running process, the pidresume(pid) action will task_resume it.  
The pidresume(pid) action will only act on a process that has been stopped using the dtrace stop() action.
Passing a pid for a process that does not exist, or that was not stopped using dtrace stop() action, will result in an error.
The default behavior of the pid provider is to bail out when it detects a jump
table. This results in missing return probes. The nojtanalysis option disables
the jump table analysis. Please note that use of this option is discouraged,
inappropriately placed probes may cause data corruption or even crashes in the
target process.
A fatal error occurred.  For D program requests, the 1 exit status indicates that program compilation failed or that the specified request could not be satisfied.
Invalid command-line options or arguments were specified.

The
utility displays the file system block usage for each file argument
and for each directory in the file hierarchy rooted in each directory
argument.
If no file is specified, the block usage of the hierarchy rooted in
the current directory is displayed.
The options are as follows:
Display an entry for each file in a file hierarchy.
Display a grand total.
Display an entry for all files and directories
directories deep.
Symbolic links on the command line are followed, symbolic links in file
hierarchies are not followed.
"Human-readable" output.
Use unit suffixes: Byte, Kilobyte, Megabyte,
Gigabyte, Terabyte and Petabyte.
Ignore files and directories matching the specified
Display block counts in 1073741824-byte (1-Gbyte) blocks.
Display block counts in 1024-byte (1-Kbyte) blocks.
Symbolic links on the command line and in file hierarchies are followed.
Display block counts in 1048576-byte (1-Mbyte) blocks.
No symbolic links are followed.
This is the default.
Generate messages about directories that cannot be read, files
that cannot be opened, and so on.
This is the default case.
This option exists solely for conformance with
Display an entry for each specified file.
(Equivalent to
File system mount points are not traversed.
The
utility counts the storage used by symbolic links and not the files they
reference unless the
or
option is specified.
If either the
or
options are specified, storage used by any symbolic links which are
followed is not counted or displayed.
If more than one of the
and
options is specified, the last one given is used.
Files having multiple hard links are counted (and displayed) a single
time per
execution.
Directories having multiple hard links (typically Time Machine backups) are
counted a single time per
execution.
If the environment variable
is set, and the
option is not specified, the block counts will be displayed in units of that
size block.
If
is not set, and the
option is not specified, the block counts will be displayed in 512-byte blocks.
In legacy mode, only one of the
or
options may be specified.
The command will detect and report a SYMLOOP error
(loop involving symbolic links).
In legacy mode, this is not the case.
For more information about legacy mode, see
A
command appeared in
DYLD_FRAMEWORK_PATH
DYLD_FALLBACK_FRAMEWORK_PATH
DYLD_VERSIONED_FRAMEWORK_PATH
DYLD_LIBRARY_PATH
DYLD_FALLBACK_LIBRARY_PATH
DYLD_VERSIONED_LIBRARY_PATH
DYLD_PRINT_TO_FILE
DYLD_ROOT_PATH
DYLD_SHARED_REGION
DYLD_INSERT_LIBRARIES
DYLD_FORCE_FLAT_NAMESPACE
DYLD_IMAGE_SUFFIX
DYLD_PRINT_OPTS
DYLD_PRINT_ENV
DYLD_PRINT_LIBRARIES
DYLD_PRINT_LIBRARIES_POST_LAUNCH
DYLD_BIND_AT_LAUNCH
DYLD_DISABLE_DOFS
DYLD_PRINT_APIS
DYLD_PRINT_BINDINGS
DYLD_PRINT_INITIALIZERS
DYLD_PRINT_REBASINGS
DYLD_PRINT_SEGMENTS
DYLD_PRINT_STATISTICS
DYLD_PRINT_DOFS
DYLD_PRINT_RPATHS
DYLD_SHARED_CACHE_DIR
DYLD_SHARED_CACHE_DONT_VALIDATE
The dynamic linker uses the following environment variables.
They affect any program that uses the dynamic linker.
This is a colon separated list of directories that contain frameworks.
The dynamic linker searches these directories before it searches for the
framework by its install name.
It allows you to test new versions of existing
frameworks. (A framework is a library install name that ends in the form
name.)
For each framework that a program uses, the dynamic linker looks for the
framework in each directory in 
in turn. If it looks in all the directories and can't find the framework, it
searches the directories in  
in turn. If it still can't find the framework, it then searches 
and
in turn.
Use the
option to 
to discover the frameworks and shared libraries that the executable
is linked against.
This is a colon separated list of directories that contain frameworks.
It is used as the default location for frameworks not found in their install
path.

By default, it is set to
This is a colon separated list of directories that contain potential override frameworks. 
The dynamic linker searches these directories for frameworks.  For
each framework found dyld looks at its LC_ID_DYLIB and gets the current_version 
and install name.  Dyld then looks for the framework at the install name path.
Whichever has the larger current_version value will be used in the process whenever
a framework with that install name is required.  This is similar to DYLD_FRAMEWORK_PATH
except instead of always overriding, it only overrides is the supplied framework is newer.
Note: dyld does not check the framework's Info.plist to find its version.  Dyld only
checks the -currrent_version number supplied when the framework was created.
This is a colon separated list of directories that contain libraries. The
dynamic linker searches these directories before it searches the default
locations for libraries. It allows you to test new versions of existing
libraries. 
For each library that a program uses, the dynamic linker looks for it in each
directory in 
in turn. If it still can't find the library, it then searches 
and
in turn.
Use the
option to 
to discover the frameworks and shared libraries that the executable
is linked against.
This is a colon separated list of directories that contain libraries.
It is used as the default location for libraries not found in their install
path.
By default, it is set
This is a colon separated list of directories that contain potential override libraries. 
The dynamic linker searches these directories for dynamic libraries.  For
each library found dyld looks at its LC_ID_DYLIB and gets the current_version 
and install name.  Dyld then looks for the library at the install name path.
Whichever has the larger current_version value will be used in the process whenever
a dylib with that install name is required.  This is similar to DYLD_LIBRARY_PATH
except instead of always overriding, it only overrides is the supplied library is newer.
This is a path to a (writable) file. Normally, the dynamic linker writes all
logging output (triggered by DYLD_PRINT_* settings) to file descriptor 2 
(which is usually stderr).  But this setting causes the dynamic linker to
write logging output to the specified file.  
This is a colon separated list of directories.  The dynamic linker will prepend each of
this directory paths to every image access until a file is found.    
This can be "use" (the default), "avoid", or "private".  Setting it to 
"avoid" tells dyld to not use the shared cache.  All OS dylibs are loaded 
dynamically just like every other dylib.  Setting it to "private" tells
dyld to remove the shared region from the process address space and mmap()
back in a private copy of the dyld shared cache in the shared region address
range. This is only useful if the shared cache on disk has been updated 
and is different than the shared cache in use.
This is a colon separated list of dynamic libraries to load before the ones
specified in the program.  This lets you test new modules of existing dynamic
shared libraries that are used in flat-namespace images by loading a temporary
dynamic shared library with just the new modules.  Note that this has no
effect on images built a two-level namespace images using a dynamic shared
library unless
is also used.
Force all images in the program to be linked as flat-namespace images and ignore
any two-level namespace bindings.  This may cause programs to fail to execute
with a multiply defined symbol error if two-level namespace images are used to
allow the images to have multiply defined symbols.
This is set to a string of a suffix to try to be used for all shared libraries
used by the program.  For libraries ending in ".dylib" the suffix is applied
just before the ".dylib".  For all other libraries the suffix is appended to the
library name.  This is useful for using conventional "_profile" and "_debug"
libraries and frameworks.
When this is set, the dynamic linker writes to file descriptor 2 (normally
standard error) the command line options.
When this is set, the dynamic linker writes to file descriptor 2 (normally
standard error) the environment variables.
When this is set, the dynamic linker writes to file descriptor 2 (normally
standard error) the filenames of the libraries the program is using.
This is useful to make sure that the use of
is getting what you want.
This does the same as
but the printing starts after the program gets to its entry point.
When this is set, the dynamic linker binds all undefined symbols
the program needs at launch time. This includes function symbols that can are normally 
lazily bound at the time of their first call.
Right before the process's main() is called, dyld prints out information about how
dyld spent its time.  Useful for analyzing launch performance.
Causes dyld not register dtrace static probes with the kernel.
Causes dyld to print out a line when running each initializers in every image.  Initializers
run by dyld included constructors for C++ statically allocated objects, functions marked with
__attribute__((constructor)), and -init functions.
Causes dyld to print a line whenever a dyld API is called (e.g. NSAddImage()).
Causes dyld to print out a line containing the name and address range of each mach-o segment
that dyld maps.  In addition it prints information about if the image was from the dyld 
shared cache.
Causes dyld to print a line each time a symbolic name is bound.  
Causes dyld to print out information about dtrace static probes registered with the kernel. 
Cause dyld  to print a line each time it expands an @rpath variable and whether
that expansion was successful or not.
This is a directory containing dyld shared cache files.  This variable can be used in
conjunction with DYLD_SHARED_REGION=private and DYLD_SHARED_CACHE_DONT_VALIDATE
to run a process with an alternate shared cache.
Causes dyld to not check that the inode and mod-time of files in the shared cache match
the requested dylib on disk. Thus a program can be made to run with the dylib in the
shared cache even though the real dylib has been updated on disk.
Unlike many other operating systems, Darwin does not locate dependent dynamic libraries
But there are times when a full path is not appropriate; for instance, may want your
binaries to be installable in anywhere on the disk.
This variable is replaced with the path to the directory containing the main executable for 
the framework load path could be encoded as 
moved around in the file system and dyld will still be able to load the embedded framework.
This variable is replaced with the path to the directory containing the mach-o binary which
contains the load command using @loader_path. Thus, in every binary, @loader_path resolves to
a different path, whereas @executable_path always resolves to the same path. @loader_path is
system location of the plugin-in unknown (so absolute paths cannot be used) or if the plug-in 
is used by multiple applications (so @executable_path cannot be used). If the plug-in mach-o
the framework load path could be encoded as 
be moved around in the file system and dyld will still be able to load the embedded framework.
Dyld maintains a current stack of paths called the run path list.  When @rpath is encountered
it is substituted with each path in the run path list until a loadable dylib if found.  
The run path stack is built from the LC_RPATH load commands in the depencency chain
that lead to the current dylib load.
You can add an LC_RPATH load command to an image with the -rpath option to ld(1).  You can
on the run path stack that relative to the image containing the LC_RPATH.  
The use of @rpath is most useful when you have a complex directory structure of programs and
dylibs which can be installed anywhere, but keep their relative positions.  This scenario
could be implemented using @loader_path, but every client of a dylib could need a different 
load path because its relative position in the file system is different. The use of @rpath
introduces a level of indirection that simplies things.  You pick a location in your directory
structure as an anchor point.  Each dylib then gets an install path that starts with @rpath 
and is the path to the dylib relative to the anchor point. Each main executable is linked
At runtime dyld sets it run path to be the anchor point, then each dylib is found relative
to the anchor point.  
libtool(1), ld(1), otool(1)
The
utility writes any specified operands, separated by single blank
characters and followed by a newline
character, to the standard
output.
The following option is available:
Do not print the trailing newline character.
This may also be achieved by appending
to the end of the string, as is done
by iBCS2 compatible systems.
Note that this option as well as the effect of
are implementation-defined in
Applications aiming for maximum
portability are strongly encouraged to use
to suppress the newline character.
Some shells may provide a builtin
command which is similar or identical to this utility.
Most notably, the builtin
in
does not accept the
option.
Consult the
manual page.
The
utility conforms to
The
utility is a line-oriented text editor.
It is used to create, display, modify and otherwise manipulate text
files.
When invoked as
the editor runs in
mode, in which the only difference is that the editor restricts the
use of filenames which start with
(interpreted as shell commands by
or contain a
Note that editing outside of the current directory is only prohibited
if the user does not have write access to the current directory.
If a user has write access to the current directory, then symbolic
links can be created in the current directory, in which case
will not stop the user from editing the file that the symbolic link
points to.
If invoked with a
argument, then a copy of
is read into the editor's buffer.
Changes are made to this copy and not directly to
itself.
Upon quitting
any changes not explicitly saved with a
command are lost.
Editing is done in two distinct modes:
and
When first invoked,
is in command mode.
In this mode commands are read from the standard input and
executed to manipulate the contents of the editor buffer.
A typical command might look like:
which replaces all occurrences of the string
with
When an input command, such as
(append),
(insert) or
(change), is given,
enters input mode.
This is the primary means
of adding text to a file.
In this mode, no commands are available;
instead, the standard input is written
directly to the editor buffer.
Lines consist of text up to and
including a
character.
Input mode is terminated by
entering a single period
on a line.
All
commands operate on whole lines or ranges of lines; e.g.,
the
command deletes lines; the
command moves lines, and so on.
It is possible to modify only a portion of a line by means of replacement,
as in the example above.
However even here, the
command is applied to whole lines at a time.
In general,
commands consist of zero or more line addresses, followed by a single
character command and possibly additional parameters; i.e.,
commands have the structure:
The address(es) indicate the line or range of lines to be affected by the
command.
If fewer addresses are given than the command accepts, then
default addresses are supplied.
The following options are available:
Suppress diagnostics.
This should be used if
standard input is from a script.
Prompt for an encryption key to be used in subsequent reads and writes
(see the
command).
Unsupported on Mac OS X.
Specify a command prompt.
This may be toggled on and off with the
command.
Specify the name of a file to read.
If
is prefixed with a
bang (!), then it is interpreted as a shell command.
In this case,
what is read is
the standard output of
executed via
To read a file whose name begins with a bang, prefix the
The default filename is set to
only if it is not prefixed with a bang.
An address represents the number of a line in the buffer.
The
utility maintains a
which is
typically supplied to commands as the default address when none is specified.
When a file is first read, the current address is set to the last line
of the file.
In general, the current address is set to the last line
affected by a command.
A line address is
constructed from one of the bases in the list below, optionally followed
by a numeric offset.
The offset may include any combination
of digits, operators (i.e.,
and
and whitespace.
Addresses are read from left to right, and their values are computed
relative to the current address.
One exception to the rule that addresses represent line numbers is the
address
(zero).
This means "before the first line,"
and is legal wherever it makes sense.
An address range is two addresses separated either by a comma or
semi-colon.
The value of the first address in a range cannot exceed the
value of the second.
If only one address is given in a range, then
the second address is set to the given address.
If an
of addresses is given where
then the corresponding range is determined by the last two addresses in
the
If only one address is expected, then the last address is used.
Each address in a comma-delimited range is interpreted relative to the
current address.
In a semi-colon-delimited range, the first address is
used to set the current address, and the second address is interpreted
relative to the first.
The following address symbols are recognized:
The current line (address) in the buffer.
The last line in the buffer.
The
line in the buffer
where
is a number in the range
The previous line.
This is equivalent to
and may be repeated with cumulative effect.
The
previous line, where
is a non-negative number.
The next line.
This is equivalent to
and may be repeated with cumulative effect.
The
next line, where
is a non-negative number.
The first through last lines in the buffer.
This is equivalent to
the address range
The current through last lines in the buffer.
This is equivalent to
the address range
The next line containing the regular expression
The search wraps to the beginning of the buffer and continues down to the
current line, if necessary.
The
previous line containing the regular expression
The search wraps to the end of the buffer and continues up to the
current line, if necessary.
?? repeats the last search.
The
line previously marked by a
(mark) command, where
is a lower case letter.
Regular expressions are patterns used in selecting text.
For example, the command:
prints all lines containing
Regular expressions are also
used by the
command for selecting old text to be replaced with new.
In addition to a specifying string literals, regular expressions can
represent
classes of strings.
Strings thus represented are said to be matched
by the corresponding regular expression.
If it is possible for a regular expression
to match several strings in a line, then the left-most longest match is
the one selected.
The following symbols are used in constructing regular expressions:
Any character
not listed below, including
and
matches itself.
Any backslash-escaped character
except for
and
matches itself.
Match any single character.
Match any single character in
To include a
in
it must be the first character.
A range of characters may be specified by separating the end characters
of the range with a
e.g.,
specifies the lower case characters.
The following literal expressions can also be used in
to specify sets of characters:
If
appears as the first or last
character of
then it matches itself.
All other characters in
match themselves.
Patterns in
of the form:
or,
where
is a
are interpreted according to the current locale settings
(not currently supported).
See
and
for an explanation of these constructs.
Match any single character, other than newline, not in
is defined
as above.
If
is the first character of a regular expression, then it
anchors the regular expression to the beginning of a line.
Otherwise, it matches itself.
If
is the last character of a regular expression, it
anchors the regular expression to the end of a line.
Otherwise, it matches itself.
Anchor the single character regular expression or subexpression
immediately following it to the beginning of a word.
(This may not be available)
Anchor the single character regular expression or subexpression
immediately following it to the end of a word.
(This may not be available)
Define a subexpression
Subexpressions may be nested.
A subsequent backreference of the form
where
is a number in the range [1,9], expands to the text matched by the
subexpression.
For example, the regular expression
matches any string
consisting of identical adjacent substrings.
Subexpressions are ordered relative to
their left delimiter.
Match the single character regular expression or subexpression
immediately preceding it zero or more times.
If
is the first
character of a regular expression or subexpression, then it matches
itself.
The
operator sometimes yields unexpected results.
For example, the regular expression
matches the beginning of
the string
(as opposed to the substring
since a null match
is the only left-most match.
Match the single character regular expression or subexpression
immediately preceding it at least
and at most
times.
If
is omitted, then it matches at least
times.
If the comma is also omitted, then it matches exactly
times.
Additional regular expression operators may be defined depending on the
particular
implementation.
All
commands are single characters, though some require additional parameters.
If a command's parameters extend over several lines, then
each line except for the last
In general, at most one command is allowed per line.
However, most commands accept a print suffix, which is any of
(print),
(list),
or
(enumerate),
to print the last line affected by the command.
An interrupt (typically ^C) has the effect of aborting the current command
and returning the editor to command mode.
The
utility
recognizes the following commands.
The commands are shown together with
the default address or address range supplied if none is
specified (in parenthesis).
Append text to the buffer after the addressed line.
Text is entered in input mode.
The current address is set to last line entered.
Change lines in the buffer.
The addressed lines are deleted
from the buffer, and text is appended in their place.
Text is entered in input mode.
The current address is set to last line entered.
Delete the addressed lines from the buffer.
If there is a line after the deleted range, then the current address is set
to this line.
Otherwise the current address is set to the line
before the deleted range.
Edit
and sets the default filename.
If
is not specified, then the default filename is used.
Any lines in the buffer are deleted before
the new file is read.
The current address is set to the last line read.
Edit the standard output of
(see
below).
The default filename is unchanged.
Any lines in the buffer are deleted before the output of
is read.
The current address is set to the last line read.
Edit
unconditionally.
This is similar to the
command,
except that unwritten changes are discarded without warning.
The current address is set to the last line read.
Set the default filename to
If
is not specified, then the default unescaped filename is printed.
Apply
to each of the addressed lines matching a regular expression
The current address is set to the
line currently matched before
is executed.
At the end of the
command, the current address is set to the last line affected by
Each command in
must be on a separate line,
and every line except for the last must be terminated by a backslash
Any commands are allowed, except for
and
A newline alone in
is equivalent to a
command.
Interactively edit the addressed lines matching a regular expression
For each matching line,
the line is printed,
the current address is set,
and the user is prompted to enter a
At the end of the
command, the current address
is set to the last line affected by (the last)
The format of
is the same as that of the
command.
A newline alone acts as a null command list.
A single
repeats the last non-null command list.
Toggle the printing of error explanations.
By default, explanations are not printed.
It is recommended that ed scripts begin with this command to
aid in debugging.
Print an explanation of the last error.
Insert text in the buffer before the current line.
Text is entered in input mode.
The current address is set to the last line entered.
Join the addressed lines.
The addressed lines are
deleted from the buffer and replaced by a single
line containing their joined text.
The current address is set to the resultant line.
Mark a line with a lower case letter
The line can then be addressed as
(i.e., a single quote followed by
in subsequent commands.
The mark is not cleared until the line is
deleted or otherwise modified.
Print the addressed lines unambiguously.
If a single line fills for than one screen (as might be the case
when viewing a binary file, for instance), a
prompt is printed on the last line.
The
utility waits until the RETURN key is pressed
before displaying the next screen.
The current address is set to the last line
printed.
Move lines in the buffer.
The addressed lines are moved to after the
right-hand destination address, which may be the address
(zero).
The current address is set to the
last line moved.
Print the addressed lines along with
their line numbers.
The current address is set to the last line
printed.
Print the addressed lines.
The current address is set to the last line
printed.
Toggle the command prompt on and off.
Unless a prompt was specified by with command-line option
the command prompt is by default turned off.
Quit
Quit
unconditionally.
This is similar to the
command,
except that unwritten changes are discarded without warning.
Read
to after the addressed line.
If
is not specified, then the default
filename is used.
If there was no default filename prior to the command,
then the default filename is set to
Otherwise, the default filename is unchanged.
The current address is set to the last line read.
Read
to after the addressed line
the standard output of
(see the
below).
The default filename is unchanged.
The current address is set to the last line read.
Replace text in the addressed lines
matching a regular expression
with
By default, only the first match in each line is replaced.
If the
(global) suffix is given, then every match to be replaced.
The
suffix, where
is a positive number, causes only the
match to be replaced.
It is an error if no substitutions are performed on any of the addressed
lines.
The current address is set the last line affected.
and
may be delimited by any character other than space and newline
(see the
command below).
If one or two of the last delimiters is omitted, then the last line
affected is printed as though the print suffix
were specified.
An unescaped
in
is replaced by the currently matched text.
The character sequence
where
is a number in the range [1,9], is replaced by the
backreference expression of the matched text.
If
consists of a single
then
from the last substitution is used.
Newlines may be embedded in
Repeat the last substitution.
This form of the
command accepts a count suffix
or any combination of the characters
and
If a count suffix
is given, then only the
match is replaced.
The
suffix causes
the regular expression of the last search to be used instead of the
that of the last substitution.
The
suffix toggles the global suffix of the last substitution.
The
suffix toggles the print suffix of the last substitution
The current address is set to the last line affected.
Copy (i.e., transfer) the addressed lines to after the right-hand
destination address, which may be the address
(zero).
The current address is set to the last line
copied.
Undo the last command and restores the current address
to what it was before the command.
The global commands
and
are treated as a single command by undo.
is its own inverse.
Apply
to each of the addressed lines not matching a regular expression
This is similar to the
command.
Interactively edit the addressed lines not matching a regular expression
This is similar to the
command.
Write the addressed lines to
Any previous contents of
is lost without warning.
If there is no default filename, then the default filename is set to
otherwise it is unchanged.
If no filename is specified, then the default
filename is used.
The current address is unchanged.
Write the addressed lines to
and then executes a
command.
Write the addressed lines to the standard input of
(see the
below).
The default filename and current address are unchanged.
Append the addressed lines to the end of
This is similar to the
command, expect that the previous contents of file is not clobbered.
The current address is unchanged.
Prompt for an encryption key which is used in subsequent reads and
writes.
If a newline alone is entered as the key, then encryption is
turned off.
Otherwise, echoing is disabled while a key is read.
Unsupported on Mac OS X.
Scroll
lines at a time starting at addressed line.
If
is not specified, then the current window size is used.
The current address is set to the last line printed.
Execute
via
If the first character of
is
then it is replaced by text of the
previous
The
utility does not process
However, an unescaped
is replaced by the default filename.
When the shell returns from execution, a
is printed to the standard output.
The current line is unchanged.
Print the line number of the addressed line.
Print the addressed line, and sets the current address to
that line.
buffer file
the file to which
attempts to write the buffer if the terminal hangs up
When an error occurs,
prints a
and either returns to command mode
or exits if its input is from a script.
An explanation of the last error can be
printed with the
(help) command.
Since the
(global) command masks any errors from failed searches and substitutions,
it can be used to perform conditional operations in scripts; e.g.,
replaces any occurrences of
with
If the
(undo) command occurs in a global command list, then
the command list is executed only once.
If diagnostics are not disabled, attempting to quit
or edit another file before writing a modified buffer
results in an error.
If the command is entered a second time, it succeeds,
but any changes to the buffer are lost.
USD:12-13
The
utility processes
arguments for backslash escapes, i.e., in a filename,
interpreted literally.
If a text (non-binary) file is not terminated by a newline character,
then
In the case of a binary file,
per line overhead: 4 ints
An
command appeared in
Version 1 AT&T UNIX.
The
utility does not recognize multibyte characters.


[
]
[
]


default is "A".

set the local modem capabilities.  See the section on
Class 1 the default is 1,n,0,2,0,0,0,0 where n is the highest
speed supported by the modem.  For Class 2 the default is
determined by the modem.


is a built-in 8x16 font.  See the efix(1) -f option for the font
file format.

6 %d escapes which are replaced by the baud rate following the
getty(8).

put string `hdr' at the top of each page.  The first %d in `hdr'
is replaced by the page number and the second, if any, is
replaced by the number of pages being sent.

-i commands are sent before the modem is put into fax mode, -j
commands after the modem is in fax mode, and -k commands just
before efax exits.  The only default is a hang-up (ATH) command
that is sent before exiting only if no other -k options are
given.  Multiple options may be used.

be the local telephone number in international format (for
example "+1 800 555-1212").  This is passed to the remote fax
machine.  Some fax machines may not accept characters other than
numbers, space, and '+'.  

protocol.  See the MODEM REQUIREMENTS section below for more

    0
Force use of Class 2.0 fax modem commands.  The modem must
support Class 2.0.

    2
Force use of Class 2 fax modem commands.  The modem must support
Class 2.

    1 
Force use of Class 1 fax modem commands. The modem must support
Class 1.  By default efax queries the modem and uses the first of
the three above classes which is supported by the modem.

    a
use software adaptive answer method.  If the first attempt to
answer the call does not result in a data connection within 8
seconds the phone is hung up temporarily and answered again in
fax mode (see "Accepting both fax and data calls" below).

    e 
ignore errors in modem initialization commands.

    f
use "virtual flow control".  efax tries to estimate the number of
bytes in the modem's transmit buffer and pauses as necessary to
avoid filling it.  The modem's buffer is assumed to hold at least
96 bytes.  This feature does not work properly with Class 2
modems that add redundant padding to scan lines.  Use this option
only if you have problems configuring flow control.

    h 
control.  Many modems will stop responding if this option is
used.  See the section `Resolving Problems' before using this
option.

    l
halve the time between testing lock files when waiting for other
programs to complete.  By default this is 8 seconds. For example
-olll sets the interval to 1 second.

    n
ignore requests for pages to be retransmitted. Use this option if
you don't care about the quality of the received fax or if the
receiving machine is too fussy.  Otherwise each page may be
retransmitted up to 3 times.

    r
do not reverse bit order during data reception for Class 2
modems.  Only Multitech modems require this option. Not normally
required since efax detects these modems.

    x
send XON (DC1) instead of DC2 to start data reception.  Applies
to a very few Class 2 modems only.

    z
delay an additional 100 milliseconds before each modem
initialization or reset command.  The initial delay is 100
ms. For example, -ozzz produces a 400 ms delay.  Use with modems
that get confused when commands arrive too quickly.


errors.  Default is 10.

each received fax page is stored in a separate file.  The file
A page number of the form .001, .002, ...  is appended to the
default string of "%m%d%H%M%S" is used.


remove lock file(s) after initializing the modem.  This allows
outgoing calls to proceed when efax is waiting for an incoming
call.  If efax detects modem activity it will attempt to re-lock
the device.  If the modem has been locked by the other program
efax will exit and return 1 (``busy'').  Normally a new efax
process is then started by launchd(8). The new efax process will
then check periodically until the lock file disappears and
then re-initialize the modem.

may contain any dial modifiers that the modem supports such as a
T prefix for tone dialing or commas for delays.  If no file names
are given the remote fax machine will be polled. If no -t
argument is given efax will answer the phone and attempt to
receive a fax.


e - 
errors
w - 
warnings
i - 
session progress information
n - 
capability negotiation information
c - 
modem (AT) commands and responses
h - 
HDLC frame data (Class 1 only)
m - 
modem output
a - 
program arguments
r -
reception error details
t -
transmission details
f -
image file details 
x -
lock file processing

Up to two -v options may be used.  The first is for messages
printed to the standard error and the second is for messages to
the standard output. The default is "ewin" to the standard error
only.

wait for an OK or CONNECT prompt instead of issuing an answer
program has already answered the call.

before opening it.  If the device is locked, efax checks every 15
seconds until it is free.  Up to 16 -x options may be used if
there are several names for the same device.  A `#' prefix on the
file name creates an binary rather than text (HDB-style) lock
file.  This is the reverse of what was used by previous efax
versions.


text, T.4 (Group 3), PBM, single- and multi-page TIFF (G3 and
uncompressed).  efax automatically determines the type of file
from its contents.  TIFF files are recommended as they contain
information about the image size and resolution.

Each page to be sent should be converted to a separate TIFF
format file with Group 3 (G3) compression.  Received files are
also stored in this format.  The EXAMPLES section below shows how
efix and other programs can be used to create, view and print
these files.


The operating system must provide short response times to avoid
protocol timeouts.  For Class 2 and 2.0 modems the delay should
not exceed 1 or 2 seconds.

When using Class 1 modems the program must respond to certain
events within 55 milliseconds.  Longer delays may cause the fax
protocol to fail in certain places (between DCS and TCF or
between RTC and MPS).  Class 1 modems should therefore not be
used on systems that cannot guarantee that the program will
respond to incoming data in less than 55 milliseconds.  In
particular, some intelligent serial cards and terminal servers
may introduce enough delay to cause problems with Class 1
operation.

The operating system must also provide sufficient low-level
buffering to allow uninterrupted transfer of data between the
modem and a disk file at the selected baud rate, typically 9600
bps.  Since the fax protocol does not provide end-to-end flow
control the effectiveness of flow control while receiving is
limited by the size of the modem's buffer. This can be less than
100 bytes.  Efax does not use flow control during reception.


The "Group" is the protocol used to send faxes between fax
machines.  Efax supports the Group 3 protocol used over the
public telephone network.

The "Class" is the protocol used by computers to control fax
modems.  Efax supports Class 1, 2 and 2.0 fax modems.

type of flow control adds very little overhead for fax use. Many
-oh option must be used to add hardware flow control.

While some modems have serial buffers of about 1k bytes, many
inexpensive modems have buffers of about one hundred bytes and
are thus more likely to suffer overruns when sending faxes.

A few older modems may need a delay between commands of more than
the default value used by efax (100 milliseconds).  If the delay
is too short, commands may not echo properly, may time out, or
options to increase the delay between modem initialization
commands and use the E0 modem initialization command to disable
echoing of modem commands.

By default efax sends DC2 to start the data flow from the modem
when receiving faxes from Class 2 modems.  A few older modems
require XON instead.  Use of DC2 would cause the modem to give an
option should be used in this case.

A few older Class 2 modems (e.g. some Intel models) don't send
DC2 or XON to start the data flow to the modem when sending
faxes.  After waiting 2 seconds efax will print a warning and
start sending anyways.

A very few Class 2 modems do not reverse the bit order (MSB to
LSB) by default on receive.  This might cause errors when trying
be used in this case.

9600 bps and reception is limited to 4800 bps.

The following Class 1 modems have been reported to work with efax:
AT&T DataPort,
Cardinal Digital Fax Modem (14400),
Digicom Scout+,
Motorola Lifestyle 28.8,
Motorola Power 28.8,
QuickComm Spirit II,
Smartlink 9614AV-Modem,
Supra Faxmodem 144LC,
USR Courier V.32bis Terbo,
USR Sportster (V.32 and V.34),
Zoom AFC 2.400,
Zoom VFX14.4V.

The following Class 2 modems have been reported to work with efax:
askey modem type 1414VQE,
AT&T DataPort,
AT&T Paradyne PCMCIA,
Boca modem,
BOCA M1440E, 
Crosslink 9614FH faxmodem,
FuryCard DNE 5005,
GVC 14.4k internal,
Intel 14.4 fax modem,
Megahertz 14.4,
Microcom DeskPorte FAST ES 28.8,
Motorola UDS FasTalk II,
MultiTech 1432MU,
Practical Peripherals PM14400FXMT,
Supra V32bis,
Telebit Worldblazer,
TKR DM-24VF+,
Vobis Fax-Modem (BZT-approved),
Zoom VFX14.4V,
ZyXEL U-1496E[+], 
ZyXEL Elite 2864I.


The required modem initialization commands are generated by efax.
Additional commands may be supplied as command-line arguments.
The modem must be set up to issue verbose(text) result codes.
The following command does this and is sent by efax before trying
to initialize the modem.

respond to commands with verbose result codes

The following commands may be useful for special purposes:

don't wait for dial tone before dialing.  This may be used to
send a fax when the call has already been dialed manually.  In
this case use an empty string ("") as the first argument to the
result codes.

leave the monitor speaker turned on for the duration of the call


disable echoing of modem commands.  See the Resolving Problems
section below.

returns the modem to command mode when DTR is dropped.  The
program drops DTR at the start and end of the call if it can't
reset the modem when DTR is dropped.

wait up to two minutes (120 seconds) for carrier.  This may be
useful if the answering fax machine takes a long time to start
with a long announcement).


The capabilities of the local hardware and software can be set
using a string of 8 digits separated by commas:


where:

0 for 98 lines per inch
1 for 196 lpi

0 for 2400 bps
1 for 4800
2 for 7200
3 for 9600
4 for 12000 (V.17)
5 for 14400 (V.17)

0 for 8.5" (21.5 cm) page width
1 for 10" (25.5 cm)
2 for 12" (30.3 cm)

0 for 11" (A4: 29.7 cm) page length
1 for 14" (B4: 36.4 cm)
2 for unlimited page length

0 for 1-D coding
1 for 2-D coding (not supported)

0 for no error correction

0 for no binary file transfer

0 for zero delay per line
1 for 5 ms per line
3 for 10 ms per line
5 for 20 ms per line
7 for 40 ms per line


fields of the capability string should be set to the maximum
values that your display software supports.  The default is 196


If the receiving fax machine does not support high resolution
pairs of scan lines.  If the receiving fax machine does not
support the image's width then efax will truncate or pad as



efax adds blank scan lines at the top of each image when it is
sent.  This allows room for the page header but increases the
length of the image (by default about 0.1" or 2.5mm of blank
space is added).

The header placed in this area typically includes the date and
time, identifies the, and shows the page number and total pages.
Headers cannot be disabled but the header string can be set to a
blank line.

The default font for generating the headers is the built-in 8x16
pixel font scaled to 12x24 pixels (about 9 point size).

Note that both efax and efix have -f options to specify the font.
efIx uses the font to generate text when doing text-to-fax
conversions (during "fax make") while efAx uses the font to
generate the header (during "fax send").


A session log is written to the standard error stream.  This log
gives status and error messages from the program as selected by
minutes and seconds is printed before each message.  Times
printed along with modem responses also show milliseconds.


The program returns an error code as follows:

0
The fax was successfully sent or received.

1
The dialed number was busy or the modem device was in use.  Try
again later.

2
Something failed (e.g. file not found or disk full). Don't retry.
Check the session log for more details.

3 
Modem protocol error.  The program did not receive the expected
response from the modem.  The modem may not have been properly
report may be in order.  Check the session log for more details.

4
The modem is not responding.  Operator attention is required.
Check that the modem is turned on and connected to the correct
port.

5
The program was terminated by a signal.

6
The program was terminated due to a system power event (i.e. the computer is about to sleep).

7
The operator canceled the call.



The efix program can be used to convert text files to TIFF-G3
format.  For example, the following command will convert the text

efix -nletter.%03d letter

TIFF-G3 format from postscript files.  For example, the command:


will convert the Postscript file
into high-resolution

the fax standard only requires that fax machines print a central
portion of the image 196.6mm (7.7 inches) wide by 281.5mm (11.1
inches) high.

The efix program can also insert bitmaps in images to create
letterhead, signatures, etc.


On CUPS based systems you can use lpr(1) to print faxes. For example, to 

lpr reply.001

On lpd based systems you can use the efix program to print faxes on Postscript or
HP-PCL (LaserJet) printers.  For example, to print the received

efix -ops reply.001 | lpr


The following command will dial the number 222-2222 using tone
dialing and send a two-page fax from the TIFF-G3 files letter.001

     -t T222-2222 letter.001 letter.002


You can use efax to answer the phone immediately and start fax
reception.  Use this mode if you need to answer calls manually to
see if they are fax or voice.

For example, the following command will make the fax modem on
fax.  The received fax will be stored in the files
identify itself as "555-1212" and receive faxes at high or low

   -c 1,5 -r reply


available from the modem (indicating an incoming call) before
rings.  The example below will make the modem answer incoming
calls in fax mode on the fourth ring and save the received faxes
using files names corresponding to the reception date and time.



The modem device can be shared by programs that use the UUCP
device locking protocol.  This includes pppd, chat, minicom,
kermit, uucico, efax, cu, and many others others.  However,
locking will only work if all programs use the same lock file.

efax will lock the modem device before opening it if one or more
directory that is to be locked.

while waiting for incoming calls so other programs can use the
same device.

If efax detects another program using the modem while it is
waiting to receive a fax, efax exits with a termination code of
1.  A subsequent efax process using this device will wait until
the other program is finished before re-initializing the modem
and starting to wait for incoming calls again.

Programs that try to lock the modem device by using device
locking facilities other than UUCP lock files not be able to use
this arbitration mechanism because the device will still be open
to the efax process.  In this case you will need to kill the efax
process (e.g. "fax stop") before starting the other program.

When efax is waiting for a fax it leaves the modem ready to
receive in fax mode but removes the lock file.  When a slip or
PPP program takes over the modem port by setting up its own lock
file efax cannot send any more commands to the modem -- not even
to reset it.  Therefore the other program has to set the modem
back to data mode when it starts up.  To do this add a modem
reset command (send ATZ expect OK) to the beginning of your slip
or PPP chat script.


(for Class 2[.0]) initialization string.  The type of call (data
or fax) can then be deduced from the modem's responses.

Some modems have limited adaptive answer features (e.g. only
working properly at certain baud rates or only in Class 2) or
none at all.  In this case use the initialization string
option to then hang up and try again in fax mode if the first
answer attempt was not successful.  This method only works if
your telephone system waits a few seconds after you hang up
before disconnecting incoming calls.

run as a shell command when an incoming data call is detected.
should expect to find the modem already off-hook and a lock file
present so it should not try to hang up the line or create a lock
file.  Note that the modem should be set up to report the DCE-DTE
(modem-computer, e.g. CONNECT 38400) speed, not the DCE-DCE
(modem-modem, e.g. CONNECT 14400) speed.  For many modems the
initialization option -iW0 will set this.

The following command will make efax answer incoming calls on
using two different lock files but these lock files will be
process.  Received fax files will be stored using names like
directory and the log file will be appended to


Note that adaptive answer of either type will not work for all
callers.  For some data calls the duration of the initial
data-mode answer may be too short for data handshaking to
complete.  In other cases this duration may be so long that
incoming fax calls will time out before efax switches to fax
mode.  In addition, some calling fax modems mistake data-mode
answering tones for fax signaling tones and initiate fax
negotiation too soon.  If you use software adaptive answer you
can reduce the value of the initial data-mode answer (set by
TO_DATAF in efax.c) to get more reliable fax handshaking or
increase it for more reliable data handshaking.  However, if you
need to provide reliable fax and data service to all callers you
should use separate phone numbers for the two types of calls.

When a call is answered the modem goes on-line with the
computer-to-modem baud rate fixed at the speed used for the most
recent AT command.  When efax is waiting for a fax or data call
it sets the interface speed to 19200 bps since this is the speed
required for fax operation.  This prevents full use of 28.8kbps
modem capabilities.



efax can answer all incoming calls if you create a launchd.plist(5)
process will run a new copy of efax when the system boots up and
whenever the previous efax process terminates.  The configuration

For example, the following XML Property List keeps efax running 
continuously:

  <?xml version="1.0" encoding="UTF-8"?>
  <plist version="1.0">
  <dict>
	  <array>

You should protect the fax script and configuration files against
tampering since launchd will execute them as a privileged (root)
process.  If you will be allowing data calls via getty and login
you should ensure that your system is reasonably secure
(e.g. that all user id's have secure passwords).

If efax exec()'s getty properly but you get a garbled login
prompt then there is probably a baud rate mismatch between the
modem and the computer.  First, check the efax log file to make
sure the modem's CONNECT response reported the serial port speed
getty manually with the same arguments and verify the port
want to enable hardware flow control for data connections (-h for
agetty, CRTSCTS for getty_ps).

A few programs won't work properly when efax is set up to answer
calls because they don't create lock files.  You can put the
shell script ``wrapper'' below around such programs to make them
work properly.  Change BIN and LOCKF to suit.

if [ -f $LOCKF ]
then
        echo lock file $LOCKF exists
        exit 1
else
        $BIN $*
        rm $LOCKF
fi



The "fax answer" script described above can be configured to
e-mail the fax files received by the previous fax answer process
to a "fax manager" who can then forward the fax to the correct
recipient.  The received fax files are send as MIME attachments,
one file per page, using the ``base64'' text encoding and the

To view the fax images directly from your e-mail reader you will
have to configure it with an application that can display files
will cause the fax file attachments to be displayed using the
``fax view'' command.



You can configure a "fax" printer into the lpr print spooler that
will fax a document out using efax instead of printing it. To set up a
fax printer do the following:



You should now be able to send a fax using the lpr interface by
using a command such as:

lpr -P fax -ophone="555-1212" file.ps

You can use lpq(1) to check the fax queue, lprm(1) to remove fax
jobs and lpc(8) to control the spooler.  In each case use the
-Pfax option to specify the fax ``printer.'' A log file will be
mailed to the user when the fax is sent.

See the lpr(1) man page for information on the print spooler.


Double check the configuration setup in the first part of the fax
script, particularly the modem device name and the lock file
names.

If efax hangs when trying to open the modem device (typically
process (e.g. pppd) or it requires the carrier detect line to be
true before it can be opened.  Many systems define an alternate
device name for the same physical device (typically cuaX) that
can be opened even if carrier is not present or other programs
are already using it.

If responses to modem initialization commands are being lost or
generated at random, another processes (e.g. getty or an efax
auto-answer process) may be trying to use the modem at the same
time.  Try running efax while this other program is running.  If
the lock files names are not specified correctly.

Attempt to send a fax. Check that the modem starts making the
calling signal (CNG, a 0.5 second beep every 3 seconds) as soon
as it's finished dialing.  This shows the modem is in fax mode.
You may need to set the SPKR variable to -iM2L3 to monitor the
phone line to do this.

Listen for the answering fax machine and check that it sends the
answer signal (CED, a 3 second beep) followed by "warbling"
sounds (DIS frames) every 3 seconds.  If you hear a continuous
sound (tones or noise) instead, then you've connected to a data
modem instead.

Your modem should send back its own warble (DCS frame) in
response to DIS immediately followed by 1.5 seconds of noise (a
channel check).  If everything is OK, the receiving end will send
another warble (CFR frame) and your modem will start to send
data.  If you have an external modem, check its LEDs.  If flow
control is working properly the modem's send data (SD) LED will
turn off periodically while the fax data is sent.

Check the message showing the line count and the average bit rate
when the page transmission is done.  Low line counts (under 1000
for a letter size image) or the warning "fax output buffer
overflow" while sending indicate that the image data format is
incorrect. Check the file being sent using the "fax view"
command.

If you get the error message ``flow control did not work'' then
flow control was not active.  This usually results in a garbled
transmission and the receiving machine may reject the page, abort

The warning "characters received while sending" or an <XOFF>
character appearing after the transmission means that the
operating system ignored the modem's XOFF flow control character.
Ensure that you are not running other programs such as getty or
flow control.

If you cannot get flow control to work properly then enable

Check that the remote machine confirms reception with a +FPTS:1
response (Class 2) or an MCF frame (Class 1).

For Class 2 modems, the error message "abnormal call termination
hung up.

Many companies advertise services that will fax back information
on their products.  These can be useful for testing fax
reception.

The message "run length buffer overflow" when receiving indicates
an error with the image data format.  You may need to use the

If efax displays the message "can't happen (<details>)" please
send a bug report to the author.

Finally, don't play "option bingo," if you can't resolve the
problem send a verbose log of the failed session (the output from


A Web Page with pointers to the latest version, known bugs and
patches is available at:


For Linux Systems

Independent packages provide more user-friendly interfaces to
efax (xfax, tefax) and provide an e-mail-to-fax (Qfax) gateway
using efax. All are available by anonymous FTP from

For Amiga Systems

A port of an early version of efax for the Amiga is available as
a component of a shareware voice mail package, AVM, distributed
by Al Villarica (rvillari@cat.syr.edu).

Other Ports

efax is relatively easy to port.  All system-dependent code is in
Version 0.8a was ported to Win32 by Luigi Capriotti.  Contact the
author if you would like to integrate the Win32 code into the
current version.


Efax was written by Ed Casas.  Please send comments or bug
reports to edc@cce.com.


Bug reports should include the operating system, the type of the
modem and a copy of a verbose session log that demonstrates the
problem.  It's usually impossible to help without a verbose log.


efax is copyright 1993 -- 1999 Ed Casas.  It may be used, copied
and modified under the terms of the GNU Public License.


prevent it from working correctly on your system.  Some of these
errors may cause serious problems including loss of data and
interruptions to telephone service.


CCITT Recommendation T.30, "Procedures for Document Facsimile
Transmission in the General Switched Telephone Network". 1988

CCITT Recommendation T.4, "Standardization of Group 3 Facsimile
Apparatus for Document Transmission". 1988.

For documentation on Class 1 and Class 2 fax commands as
implemented by Connexant (formerly Rockwell) modems see

For the TIFF specification see

For information on Ghostscript see

The pbm utilities can be obtained by ftp from wuarchive.wustl.edu

PCX and many other file formats are described in: Gunter Born,
The File Formats Handbook, International Thomson Computer Press,
1995.

The "Fax Modem Source Book" by Andrew Margolis, published by John
Wiley & Sons in 1994 (ISBN 0471950726), is a book on writing fax
applications which includes source code.

Dennis Bodson et. al., "FAX: Digital Facsimile Technology and
Applications", Second Edition. Artech House, Boston. 1992.




Can't read TIFF files with more than 1 strip

Class 1 operation may fail if the program can't respond to
certain data received from the modem within 55 milliseconds.

May fail if multitasking delays cause the received data to
overflow the computer's serial device buffer or if an under-run
of transmit data exceeds 5 seconds.

Polling does not work.

Does not support 2-D coding, ECM, or BFT.

[
]



determine the input type from its contents.

   fax
fax ("Group3") 1-D coded image

   text
text.  Line feeds separate lines, form feeds cause page breaks
and tabs are expanded assuming tabs every 8 columns.

   pbm
raw PBM (portable bit map)

   tiffg3
TIFF format with Group 3 (fax) compression.

   tiffraw
TIFF format with no compression.


   fax
fax ("Group3") 1-D coded image

   pbm
raw PBM

   pgm
raw PGM (Portable Gray Map).  Gray-scale values are produced by
the size given by -p.  The resulting image has 17 discrete values
between 0 and 255.

   pcl
HP-PCL (e.g. HP LaserJet).

   ps
encapsulated Postscript (e.g. Apple Laserwriter).  The file is
compressed using differential coding vertically and run-length
coding horizontally.  There is no provision for positioning the
image within the page and so the image will appear at the lower
left corner of the page when printed.

   tiffg3
TIFF format with Group 3 (fax) compression.

   tiffraw
TIFF format with no compression.

name.  Up to three %d escapes will be replaced by the page number
starting with 1 (e.g. -n order.%03d will create file names
order.001, order.002, etc.)


e - 
errors
w - 
warnings
i - 
information messages
a - 
program arguments
f - 
file format details

The default is "ewi".

should be a bit map of an image of H rows and 256*W columns.
Each successive WxH cell contains the bit map for characters with
codes from 0 to 255.  The default is to use a built-in 8x16 font.

scale the input by a factor of X horizontally and Y vertically.
Scaling does not change the size of the output (use -p).  If Y is
not specified it is assumed to be the same as X.  Any floating
point value may be used for X and Y. The default is 1,1.

displace the output right by R and down by D (opposite if
negative). See below for units.  Default is 0,0.

truncate or pad the output to generate an image of width W and
height H.  This does not scale the input.  See below for units.
The default is the size of the input image if it can be
determined or A4 (215x297mm) if it can't.

assume an output device resolution of X by Y dots per inch.  If Y
is not specified it is assumed to be the same as X.  The default
is the input resolution if it can be determined or the fax
resolution of 204.1x195.6 dpi if it can't.

assume an input device resolution of X by Y dots per inch.  If Y
is not specified it is assumed to be the same as X.  The default
is the input resolution if it can be determined or the fax
resolution of 204.1x195.6 dpi if it can't.

place n lines per page during text input. Default is 66.

overlay (logical OR) the image from file f into the output.  Use
"-" for standard input (-O-).  Default is no overlay file.

ignore all other options and copy the standard input to the
standard output while applying base64 (MIME) encoding as
specified by RFC 1521.



If no -n options are given, output is written to the standard
output.


The units of the W, H, R, and D values above are in inches by
default.  Any floating point value may be used.  Units of inches,
centimetres, millimetres or points (72 per inch) can be used
instead by appending one of the strings `in', `cm', `mm', or `pt'
to the argument (e.g. -d2,4cm).


The -d and -p options allow efix to cut out images from received
faxes for use in other faxes or documents.  The -d option specifies
the top left portion of the desired image and the -p option gives
the size of the cut image.  For example, the command
	efix -d-5,-8 -p2,1 sample.001 >sig.001
would cut out part of the input with its top left corner 5 inches
from the left edge and 8 inches from top of the input image.  The
output image would be 2 inches wide and 1 inch high.

The -O option allows efix to superimpose two or more images.  The
overlay image must be in fax format and cannot be scaled,
truncated or shifted. However, multiple efix commands may be used
to transform images before combining them.  For example, the
commands
	efix -d4,8 signature >sig.fax
	efix -O sig.fax letterhead >letterhead.fax
	efix -O letterhead.fax letter.002 >letter.002.new
will shift the image in the file signature down 8 inches and
right 4 inches and combine (overlay) it with the images in the
files letterhead and letter.002.


Gunter Born, "The File Formats Handbook", International Thompson
Computer Press, 1995.


efix is copyright 1994 -- 1999 by Ed Casas.  It may be used,
copied and modified under the terms of the GNU Public License.


prevent it from working correctly on your system.  Some of these
errors may cause serious problems including loss of data.




Only reads two types of TIFF compression formats.

Does not write multi-page TIFF files (a feature).

The
utility searches any given input files,
selecting lines that match one or more patterns.
By default, a pattern matches an input line if the regular expression
(RE) in the pattern matches the input line
without its trailing newline.
An empty expression matches every line.
Each input line that matches at least one of the patterns is written
to the standard output.
is used for simple patterns and
basic regular expressions
can handle extended regular expressions
See
for more information on regular expressions.
is quicker than both
and
but can only handle fixed patterns
(i.e. it does not interpret regular expressions).
Patterns may consist of one or more lines,
allowing any of the pattern lines to match a portion of the input.
and
act like
and
respectively, but accept input files compressed with the
or
compression utilities.
The following options are available:
Print
lines of trailing context after each match.
See also the
and
options.
Treat all files as ASCII text.
Normally
will simply print
if files contain binary characters.
Use of this option forces
to output lines matching the specified pattern.
Print
lines of leading context before each match.
See also the
and
options.
The offset in bytes of a matched pattern is
displayed in front of the respective matched line.
Print
lines of leading and trailing context surrounding each match.
The default is 2 and is equivalent to
Note:
no whitespace may be given between the option and its argument.
Only a count of selected lines is written to standard output.
Mark up the matching text with the expression stored in
environment variable.
The possible values of when can be `never', `always' or `auto'.
Specify the demanded action for devices, FIFOs and sockets.
The default action is `read', which means, that they are read
as if they were normal files.
If the action is set to `skip', devices will be silently skipped.
Specify the demanded action for directories.
It is `read' by default, which means that the directories
are read in the same manner as normal files.
Other possible values are `skip' to silently ignore the
directories, and `recurse' to read them recursively, which
has the same effect as the
and
option.
Interpret
as an extended regular expression
(i.e. force
to behave as
Specify a pattern used during the search of the input:
an input line is selected if it matches any of the specified patterns.
This option is most useful when multiple
options are used to specify multiple patterns,
or when a pattern begins with a dash
If specified, it excludes files matching the given
filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all files are searched that are
not excluded.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, it excludes directories matching the
given filename pattern from the search.
Note that
patterns take priority over
patterns, and if no
pattern is specified, all directories are searched that are
not excluded.
Interpret
as a set of fixed strings
(i.e. force
to behave as
Read one or more newline separated patterns from
Empty pattern lines match every input line.
Newlines are not considered part of a pattern.
If
is empty, nothing is matched.
Interpret
as a basic regular expression
(i.e. force
to behave as traditional
Always print filename headers with output lines.
Never print filename headers
with output lines.
Print a brief help message.
Ignore binary files.
This option is equivalent to
option.
Perform case insensitive matching.
By default,
is case sensitive.
If specified, only files matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Patterns are matched to the full path specified,
not only to the filename component.
If
is specified, only directories matching the
given filename pattern are searched.
Note that
patterns take priority over
patterns.
Decompress the
compressed file before looking for the text.
Only the names of files not containing selected lines are written to
standard output.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Only the names of files containing selected lines are written to
standard output.
will only search a file until a match has been found,
making searches potentially less expensive.
Pathnames are listed once per file searched.
If the standard input is searched, the string
is written.
Use
instead of
to read input, which can result in better performance under some
circumstances but can cause undefined behaviour.
Stop reading the file after
matches.
Each output line is preceded by its relative line number in the file,
starting at line 1.
The line number counter is reset for each file processed.
This option is ignored if
or
is
specified.
Prints a zero-byte after the file name.
If
is specified, follow symbolic links only if they were explicitly listed
on the command line.
The default is not to follow symbolic links.
Prints only the matching part of the lines.
If
is specified, no symbolic links are followed.
This is the default.
Quiet mode:
suppress normal output.
will only search a file until a match has been found,
making searches potentially less expensive.
Recursively search subdirectories listed.
If
is specified, all symbolic links are followed.
The default is not to follow symbolic links.
Silent mode.
Nonexistent and unreadable files are ignored
(i.e. their error messages are suppressed).
Search binary files, but do not attempt to print them.
Display version information and exit.
Selected lines are those
matching any of the specified patterns.
The expression is searched for as a word (as if surrounded by
and
see
Only input lines selected against an entire fixed string or regular
expression are considered to be matching lines.
Equivalent to
Obsoleted.
Force
to behave as
Controls searching and printing of binary files.
Options are
the default: search binary files but do not print them;
do not search binary files;
and
treat all files as text.
Print
lines of leading and trailing context.
The default is 2.
Force output to be line buffered.
By default, output is line buffered when standard output is a terminal
and block buffered otherwise.
If no file arguments are specified, the standard input is used.
May be used to specify default options that will be placed at the beginning
of the argument list.
Backslash-escaping is not supported, unlike the behavior in GNU grep.
The
utility exits with one of the following values:
One or more lines were selected.
No lines were selected.
An error occurred.
To find all occurrences of the word
in a file:
To find all occurrences of the pattern
at the beginning of a line:
The apostrophes ensure the entire expression is evaluated by
instead of by the user's shell.
The caret
matches the null string at the beginning of a line,
and the
escapes the
which would otherwise match any character.
To find all lines in a file which do not contain the words
or
A simple example of an extended regular expression:
Peruses the file
looking for either 19, 20, or 25.
The
utility is compliant with the
specification.
The flags
are extensions to that specification, and the behaviour of the
flag when used with an empty pattern file is left undefined.
All long options are provided for compatibility with
GNU versions of this utility.
Historic versions of the
utility also supported the flags
This implementation supports those options;
however, their use is strongly discouraged.
The
command first appeared in
The
utility does not normalize Unicode input, so a pattern containing composed
characters will not match decomposed input, and vice versa.
Not intended for end users.
[
] [
]
is a version of
written by the author of the original (PDP-10)
Richard Stallman.
The primary documentation of GNU Emacs is in the GNU Emacs Manual,
which you can read using Info, either from Emacs or as a standalone
program.  Please look there for complete and up-to-date documentation.
This man page is updated only when someone volunteers to do so; the
Emacs maintainers' priority goal is to minimize the amount of time
this man page takes away from other more useful projects.
The user functionality of GNU Emacs encompasses
everything other
editors do, and it is easily extensible since its
editing commands are written in Lisp.
has an extensive interactive help facility,
but the facility assumes that you know how to manipulate
windows and buffers.
CTRL-h or F1 enters the Help facility.  Help Tutorial (CTRL-h t)
starts an interactive tutorial which can teach beginners the fundamentals
of
in a few minutes.
Help Apropos (CTRL-h a) helps you
find a command given its functionality, Help Character (CTRL-h c)
describes a given character's effect, and Help Function (CTRL-h f)
describes a given Lisp function specified by name.
Undo can undo several steps of modification to your buffers, so it is
easy to recover from editing mistakes.
many special packages handle mail reading (RMail) and sending (Mail),
outline editing (Outline), compiling (Compile), running subshells
within
windows (Shell), running a Lisp read-eval-print loop
(Lisp-Interaction-Mode), automated psychotherapy (Doctor), and much more.
There is an extensive reference manual, but
users of other Emacses
should have little trouble adapting even
without a copy.  Users new to
will be able
to use basic features fairly rapidly by studying the tutorial and
using the self-documentation features.
The following options are of general interest:
Edit
Go to the line specified by
(do not insert a space between the "+" sign and
the number).  This applies only to the next file specified.
Go to the specified
and
Do not load an init file.
Do not load the site-wide startup file.
Enable
Lisp debugger during the processing of the user init file
This is useful for debugging problems in the init file.
Load
init file.
Use specified
This must be the first argument specified in the command line.
Display
version information and exit.
The following options are lisp-oriented
(these options are processed in the order encountered):
Execute the lisp function
Load the lisp code in the file
Evaluate the Lisp expression
The following options are useful when running
as a batch editor:
Edit in batch mode.  The editor will send messages to stderr.  This
options to specify files to execute and functions to call.
Exit
while in batch mode.
Add
to the list of directories
searches for Lisp files.
has been tailored to work well with the X window system.
If you run
from under X windows, it will create its own X window to
display in.  You will probably want to start the editor
as a background process
so that you can continue using your original window.
can be started with the following X switches:
Specifies the name which should be assigned to the initial
window.  This controls looking up X resources as well as the window title.
Specifies the title for the initial X window.
Display the
window in reverse video.
Set the
window's font to that specified by
You will find the various
fonts in the
directory.
Note that
will only accept fixed width fonts.
Under the X11 Release 4 font-naming conventions, any font with the
value "m" or "c" in the eleventh field of the font name is a fixed
width font.  Furthermore, fonts whose name are of the form
are generally fixed width, as is the font
See
for more information.

When you specify a font, be sure to put a space between the
switch and the font name.
Set the
window's border width to the number of pixels specified by
Defaults to one pixel on each side of the window.
Set the window's internal border width to the number of pixels specified
by
Defaults to one pixel of padding on each side of the window.
Set the
window's width, height, and position as specified.  The geometry
specification is in the standard X format; see
for more information.
The width and height are specified in characters; the default is 80 by
24.  See the Emacs manual, section "Options for Window Size and Position",
for information on how window sizes interact
with selecting or deselecting the tool bar and menu bar.
On color displays, sets the color of the text.

Use the command
for a list of valid
color names.
On color displays,
sets the color of the window's background.
On color displays,
sets the color of the window's border.
On color displays,
sets the color of the window's text cursor.
On color displays,
sets the color of the window's mouse cursor.
Create the
window on the display specified by
Must be the first option specified in the command line.
Tells
not to use its special interface to X.  If you use this
switch when invoking
from an
window, display is done in that window.
You can set
default values for your
windows in your
file (see
Use the following format:
emacs.keyword:value
where
specifies the default value of
lets you set default values for the following keywords:
Sets the window's text font.
If
value is set to
the window will be displayed in reverse video.
If
value is set to
the window will iconify into the "kitchen sink."
Sets the window's border width in pixels.
Sets the window's internal border width in pixels.
For color displays,
sets the window's text color.
For color displays,
sets the window's background color.
For color displays,
sets the color of the window's border.
For color displays,
sets the color of the window's text cursor.
For color displays,
sets the color of the window's mouse cursor.
Sets the geometry of the
window (as described above).
Sets the title of the
window.
Sets the icon name for the
window icon.
If you try to set color values while using a black and white display,
the window's characteristics will default as follows:
the foreground color will be set to black,
the background color will be set to white,
the border color will be set to grey,
and the text and mouse cursors will be set to black.
The following lists the mouse button bindings for the
window under X11.

l l.
MOUSE BUTTON	FUNCTION
left	Set point.
middle	Paste text.
right	Cut text into X cut buffer.
SHIFT-middle	Cut text into X cut buffer.
SHIFT-right	Paste text.
CTRL-middle	Cut text into X cut buffer and kill it.
CTRL-right	T{
Select this window, then split it into
two windows.  Same as typing CTRL-x 2.
T}
CTRL-SHIFT-left	T{
down, wait for menu to appear, select
buffer, and release.  Move mouse out of
menu and release to cancel.
T}
CTRL-SHIFT-right	T{
Select window with mouse, and delete all
other windows.  Same as typing CTRL-x 1.
T}
You can order printed copies of the GNU Emacs Manual from the Free
Software Foundation, which develops GNU software.  See the file ORDERS
for ordering information.
Your local Emacs maintainer might also have copies available.  As
with all software and publications from FSF, everyone is permitted to
make and distribute copies of the Emacs manual.  The TeX source to the
manual is also included in the Emacs source distribution.
The complete text of the Emacs reference manual is included in a
convenient tree structured form.  Also includes the Emacs Lisp
Reference Manual, useful to anyone wishing to write programs in the
Emacs Lisp extension language.

that define most editing commands.  Some are preloaded;
others are autoloaded from this directory when used.

used with GNU Emacs.


strings for the Lisp primitives and preloaded Lisp functions
of GNU Emacs.  They are stored here to reduce the size of
Emacs proper.

various services to assist users of GNU Emacs, including education,
troubleshooting, porting and customization.

There is a mailing list, bug-gnu-emacs@gnu.org, for reporting Emacs
bugs and fixes.  But before reporting something as a bug, please try
to be sure that it really is a bug, not a misunderstanding or a
deliberate feature.  We ask you to read the section ``Reporting Emacs
Bugs'' near the end of the reference manual (or Info system) for hints
on how and when to report bugs.  Also, include the version number of

Do not expect a personal answer to a bug report.  The purpose of reporting
bugs is to get them fixed for everyone in the next release, if possible.
For personal assistance, look in the SERVICE file (see above) for
a list of people who offer it.

Please do not send anything but bug reports to this mailing list.
For more information about Emacs mailing lists, see the
fixed if they can be isolated, so it is in your interest to report
them in such a way that they can be easily reproduced.
is free; anyone may redistribute copies of
to
anyone under the terms stated in the
General Public License,
a copy of which accompanies each copy of
and which also
appears in the reference manual.
Copies of
may sometimes be received packaged with distributions of Unix systems,
but it is never included in the scope of any license covering those
systems.  Such inclusion violates the terms on which distribution
is permitted.  In fact, the primary purpose of the General Public
License is to prohibit anyone from attaching any other restrictions
to redistribution of
Richard Stallman encourages you to improve and extend
and urges that
you contribute your extensions to the GNU library.  Eventually GNU
(Gnu's Not Unix) will be a complete replacement for Unix.
Everyone will be free to use, copy, study and change the GNU system.
emacsclient(1), etags(1), X(1), xlsfonts(1), xterm(1), xrdb(1)
was written by Richard Stallman and the Free Software Foundation.
Joachim Martillo and Robert Krawitz added the X features.
Copyright
1995, 1999, 2000, 2001, 2002, 2003, 2004, 2005,
      2006, 2007 Free Software Foundation, Inc.
Permission is granted to make and distribute verbatim copies of this
document provided the copyright notice and this permission notice are
preserved on all copies.
Permission is granted to copy and distribute modified versions of
this document under the conditions for verbatim copying, provided that
the entire resulting derived work is distributed under the terms of
a permission notice identical to this one.
Permission is granted to copy and distribute translations of this
document into another language, under the above conditions for
modified versions, except that this permission notice may be stated
in a translation approved by the Free Software Foundation.

This manual page documents briefly the
command.  Full documentation is available in the GNU Info format; see
below.
distribution, but is not specific to that system.
works in conjunction with the built-in Emacs server.
You can either call
directly or let other programs run it for you when necessary.  On
GNU and Unix systems many programs consult the environment
variable EDITOR (sometimes also VISUAL) to obtain the command used for
editing.  Thus, setting this environment variable to 'emacsclient'
will allow these programs to use an already running Emacs for editing.
Other operating systems might have their own methods for defining the
default editor.

For
to work, you need an already running Emacs with a server.  Within Emacs,
call the functions `server-start' or `server-mode'.  (Your `.emacs' file
can do this automatically if you add either `(server-start)' or
`(server-mode 1)' to it.)

When you've finished editing the buffer, type `C-x #'
(`server-edit').  This saves the file and sends a message back to the
`emacsclient' program telling it to exit.  The programs that use
`EDITOR' wait for the "editor" (actually, `emacsclient') to exit.  `C-x
#' also checks for other pending external requests to edit various
files, and selects the next such file.

If you set the variable `server-window' to a window or a frame, `C-x
#' displays the server buffer in that window or in that frame.

The programs follow the usual GNU command line syntax, with long
options starting with two dashes (`-').
returns
immediately without waiting for you to "finish" the buffer in Emacs.
do not visit files but instead evaluate the arguments as Emacs
Lisp expressions.
use socket named FILENAME for communication.
use TCP configuration file FILENAME for communication.
This can also be specified via the `EMACS_SERVER_FILE' environment variable.
if the Emacs server is not running, run the specified editor instead.
This can also be specified via the `ALTERNATE_EDITOR' environment variable.
tell the server to display the files on the given display.
print version information and exit
print this usage information message and exit
The program is documented fully in
available via the Info system.
This manual page was written by Stephane Bortzmeyer <bortzmeyer@debian.org>,
This manual page is in the public domain.

Unicode Character Mapping files (.ucm) or Tcl Encoding Files (.enc).
Besides being used internally during the build process of the Encode
If you want to know as little about Perl as possible but need to
add a new encoding, just read this chapter and forget the rest.
Have a .ucm file ready.  You can get it from somewhere or you can write
your own from scratch or you can grab one from the Encode distribution
example below, I'll call my theoretical encoding myascii, defined
Issue a command as follows;
Now take a look at your current directory.  It should look like this.
The following files were created.
If you want *.ucm installed together with the modules, do as follows;
intention to give it to someone else.  But it is a good idea to edit
the pod and to add more tests.
Now issue a command all Perl Mongers love:
Now all you have to do is make.
The time it takes varies depending on how fast your machine is and
how large your encoding is.  Unless you are working on something big
like euc-tw, it won't take too long.
If you want to add your encoding to Encode's demand-loading list
to update Encode::ConfigLocal, a module that controls local settings.
more flexible than Tcl's Encoding Map and far more user-friendly,
this is the recommended format for Encode now.
The header section continues until a line containing the word
pair per line.  Strings used as values must be quoted. Barewords are
substitution character, not subcharacter.  When you decode a Unicode
sequence to this encoding but no matching character is found, the byte
sequence defined here will be used.  For most cases, the value here is
follows:
The format is roughly the same as a header section except for the
fallback flag: | followed by 0..3.   The meaning of the possible
values is as follows:
Round trip safe.  A character decoded to Unicode encodes back to the
same byte sequence.  Most characters have this flag.
character for the encode map only.
Skip sub-char mapping should there be no code point.
character for the decode map only.
or an existing encoding which is close to yours, rather than write
your own from scratch.
icu:state is not used.  Because of that, you need to write a perl
module if you want to support algorithmical encodings, notably
Encode::KR::2022_KR, and Encode::TW::HZ.
how to make sure:
Sort your map in Unicode order.
When you have a duplicate entry, mark either one with '|1' or '|3'.
this;
down, here is what happens.
ICU:Conversion Data
Encode,
perlmod,
perlpod
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Unicode Character Mapping files (.ucm) or Tcl Encoding Files (.enc).
Besides being used internally during the build process of the Encode
If you want to know as little about Perl as possible but need to
add a new encoding, just read this chapter and forget the rest.
Have a .ucm file ready.  You can get it from somewhere or you can write
your own from scratch or you can grab one from the Encode distribution
example below, I'll call my theoretical encoding myascii, defined
Issue a command as follows;
Now take a look at your current directory.  It should look like this.
The following files were created.
If you want *.ucm installed together with the modules, do as follows;
intention to give it to someone else.  But it is a good idea to edit
the pod and to add more tests.
Now issue a command all Perl Mongers love:
Now all you have to do is make.
The time it takes varies depending on how fast your machine is and
how large your encoding is.  Unless you are working on something big
like euc-tw, it won't take too long.
If you want to add your encoding to Encode's demand-loading list
to update Encode::ConfigLocal, a module that controls local settings.
more flexible than Tcl's Encoding Map and far more user-friendly,
this is the recommended format for Encode now.
The header section continues until a line containing the word
pair per line.  Strings used as values must be quoted. Barewords are
substitution character, not subcharacter.  When you decode a Unicode
sequence to this encoding but no matching character is found, the byte
sequence defined here will be used.  For most cases, the value here is
follows:
The format is roughly the same as a header section except for the
fallback flag: | followed by 0..3.   The meaning of the possible
values is as follows:
Round trip safe.  A character decoded to Unicode encodes back to the
same byte sequence.  Most characters have this flag.
character for the encode map only.
Skip sub-char mapping should there be no code point.
character for the decode map only.
or an existing encoding which is close to yours, rather than write
your own from scratch.
icu:state is not used.  Because of that, you need to write a perl
module if you want to support algorithmical encodings, notably
Encode::KR::2022_KR, and Encode::TW::HZ.
how to make sure:
Sort your map in Unicode order.
When you have a duplicate entry, mark either one with '|1' or '|3'.
this;
down, here is what happens.
ICU:Conversion Data
Encode,
perlmod,
perlpod
Unicode Character Mapping files (.ucm) or Tcl Encoding Files (.enc).
Besides being used internally during the build process of the Encode
If you want to know as little about Perl as possible but need to
add a new encoding, just read this chapter and forget the rest.
Have a .ucm file ready.  You can get it from somewhere or you can write
your own from scratch or you can grab one from the Encode distribution
example below, I'll call my theoretical encoding myascii, defined
Issue a command as follows;
Now take a look at your current directory.  It should look like this.
The following files were created.
If you want *.ucm installed together with the modules, do as follows;
intention to give it to someone else.  But it is a good idea to edit
the pod and to add more tests.
Now issue a command all Perl Mongers love:
Now all you have to do is make.
The time it takes varies depending on how fast your machine is and
how large your encoding is.  Unless you are working on something big
like euc-tw, it won't take too long.
If you want to add your encoding to Encode's demand-loading list
to update Encode::ConfigLocal, a module that controls local settings.
more flexible than Tcl's Encoding Map and far more user-friendly,
this is the recommended format for Encode now.
The header section continues until a line containing the word
pair per line.  Strings used as values must be quoted. Barewords are
substitution character, not subcharacter.  When you decode a Unicode
sequence to this encoding but no matching character is found, the byte
sequence defined here will be used.  For most cases, the value here is
follows:
The format is roughly the same as a header section except for the
fallback flag: | followed by 0..3.   The meaning of the possible
values is as follows:
Round trip safe.  A character decoded to Unicode encodes back to the
same byte sequence.  Most characters have this flag.
character for the encode map only.
Skip sub-char mapping should there be no code point.
character for the decode map only.
or an existing encoding which is close to yours, rather than write
your own from scratch.
icu:state is not used.  Because of that, you need to write a perl
module if you want to support algorithmical encodings, notably
Encode::KR::2022_KR, and Encode::TW::HZ.
how to make sure:
Sort your map in Unicode order.
When you have a duplicate entry, mark either one with '|1' or '|3'.
this;
down, here is what happens.
ICU:Conversion Data
Encode,
perlmod,
perlpod
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
Expected text after =item, not a number
encode_keychange - produce the KeyChange string for SNMPv3
-t md5|sha1
produces a KeyChange string using the old and new passphrases 
as described in Section 5 of RFC 2274 "User-based Security Model (USM) for 
option is mandatory and specifies the hash transform type to use.

The transform is used to convert passphrase to master key for a given
user (Ku), convert master key to the localized key (Kul), and to hash the 
old Kul with the random bits. 

Passphrases are obtained by examining a number of sources until success
(in order listed):
command line options (see 
and
options below);
the file 
which should only contain two lines with old and new passphrase;

specified, it is constructed from the first IP address for the local
host.
Force passphrases to be read from standard input.
Display the help message.
Passphrase used to generate the new Ku.
Passphrase used to generate the old Ku.
Turn off the prompt for passphrases when getting data from standard input.
Be verbose.
Echo passphrases to terminal.
                
The localized key method is defined in RFC 2274, Sections 2.6 and A.2, and
originally documented in
U. Blumenthal, N. C. Hien, B. Wijnen,
"Key Derivation for Network Management Applications",
The
utility executes another
after modifying the environment as
specified on the command line.
Each
option specifies the setting of an environment variable,
with a value of
All such environment variables are set before the
is executed.
The options are as follows:
Execute the
with only those environment variables specified by
options.
The environment inherited
by
is ignored completely.
Search the set of directories as specified by
to locate the specified
program, instead of using the value of the
environment variable.
Split apart the given
into multiple strings, and process each of the resulting strings
as separate arguments to the
utility.
The
option recognizes some special character escape sequences and
also supports environment-variable substitution, as described
below.
If the environment variable
is in the environment, then remove it before processing the
remaining options.
This is similar to the
command in
The value for
must not include the
character.
Print verbose information for each step of processing done by the
utility.
Additional information will be printed if
is specified multiple times.
The above options are only recognized when they are specified
before any
options.
If no
is specified,
prints out the names and values
The processing of the
option will split the given
into separate arguments based on any space or <tab> characters found in the
Each of those new arguments will then be treated as if it had been
specified as a separate argument on the original
command.
Spaces and tabs may be embedded in one of those new arguments by using
single
or double
quotes, or backslashes
Single quotes will escape all non-single quote characters, up to
the matching single quote.
Double quotes will escape all non-double quote characters, up to
the matching double quote.
It is an error if the end of the
is reached before the matching quote character.
If
would create a new argument that starts with the
character, then that argument and the remainder of the
will be ignored.
The
sequence can be used when you want a new argument to start
with a
character, without causing the remainder of the
to be skipped.
While processing the
value,
processing will treat certain character combinations as escape
sequences which represent some action to take.
The character escape sequences are in backslash notation.
The characters and their meanings are as follows:
Ignore the remaining characters in the
This must not appear inside a double-quoted string.
Replace with a <form-feed> character.
Replace with a <new-line> character.
Replace with a <carriage return> character.
Replace with a <tab> character.
Replace with a <vertical tab> character.
Replace with a
character.
This would be useful when you need a
as the first character in one of the arguments created
by splitting apart the given
Replace with a
character.
If this is found inside of a double-quoted string, then replace it
with a single blank.
If this is found outside of a quoted string, then treat this as the
separator character between new arguments in the original
Replace with a <double quote> character.
Replace with a <single quote> character.
Replace with a backslash character.
The sequences for <single-quote> and backslash are the only sequences
which are recognized inside of a single-quoted string.
The other sequences have no special meaning inside a single-quoted
string.
All escape sequences are recognized inside of a double-quoted string.
It is an error if a single
character is followed by a character other than the ones listed above.
The processing of
also supports substitution of values from environment variables.
To do this, the name of the environment variable must be inside of
such as:
The common shell syntax of
is not supported.
All values substituted will be the values of the environment variables
as they were when the
utility was originally invoked.
Those values will not be checked for any of the escape sequences as
described above.
And any settings of
will not effect the values used for substitution in
processing.
Also,
processing can not reference the value of the special parameters
which are defined by most shells.
For instance,
can not recognize special parameters such as:
or
if they appear inside the given
The
utility is often used as the
on the first line of interpreted scripts, as
described in
Note that the way the kernel parses the
(first line) of an interpreted script has changed as of
Prior to that, the
kernel would split that first line into separate arguments based
on any whitespace (space or <tab> characters) found in the line.
So, if a script named
had a first line of:
then the
program would have been started with the arguments of:
arg[1] = '-n'
arg[2] = '-q'
arg[3] = '-dsafe_mode=0'
plus any arguments the user specified when executing
However, this processing of multiple options on the
line is not the way any other operating system parses the
first line of an interpreted script.
So after a change which was made for
release, that script will result in
being started with the arguments of:
arg[1] = '-n -q -dsafe_mode=0'
plus any arguments the user specified.
This caused a significant change in the behavior of a few scripts.
In the case of above script, to have it behave the same way under
as it did under earlier releases, the first line should be
changed to:
The
utility will be started with the entire line as a single
argument:
and then
processing will split that line into separate arguments before
executing
The
utility uses the
environment variable to locate the requested
if the name contains no
characters, unless the
option has been specified.
An exit status of 126 indicates that
was found, but could not be executed.
An exit status of 127 indicates that
could not be found.
Since the
utility is often used as part of the first line of an interpreted script,
the following examples show a number of ways that the
utility can be useful in scripts.
The kernel processing of an interpreted script does not allow a script
to directly reference some other script as its own interpreter.
As a way around this, the main difference between
and
is that the latter works even if
is itself an interpreted script.
Probably the most common use of
is to find the correct interpreter for a script, when the interpreter
may be in different directories on different systems.
The following example will find the
interpreter by searching through the directories specified by
One limitation of that example is that it assumes the user's value
for
is set to a value which will find the interpreter you want
to execute.
The
option can be used to make sure a specific list of directories is
used in the search for
Note that the
option is also required for this example to work correctly.
The above finds
only if it is in
or
That could be combined with the present value of
to provide more flexibility.
Note that spaces are not required between the
and
options:
The
utility accepts the
option as a synonym for
The
utility conforms to
The
and
options are non-standard extensions supported by
but which may not be available on other operating systems.
The
command appeared in
The
and
options were added in
The
utility does not handle values of
which have an equals sign
in their name, for obvious reasons.
The
utility does not take multibyte characters into account when
processing the
option, which may lead to incorrect results in some locales.
Copyright (C) 1989-2000, 2001, 2004, 2005 Free Software Foundation, Inc.

Permission is granted to make and distribute verbatim copies of
this manual provided the copyright notice and this permission notice
are preserved on all copies.

Permission is granted to copy and distribute modified versions of this
manual under the conditions for verbatim copying, provided that the
entire resulting derived work is distributed under the terms of a
permission notice identical to this one.

Permission is granted to copy and distribute translations of this
manual into another language, under the above conditions for modified
versions, except that this permission notice may be included in
translations approved by the Free Software Foundation instead of in
the original English.
It is possible to have whitespace between a command line option and its
parameter.
This manual page describes the GNU version of
which is part of the groff document formatting system.
compiles descriptions of equations embedded within
input files into commands that are understood by
Normally, it should be invoked using the
option of
The syntax is quite compatible with Unix eqn.
The output of GNU
cannot be processed with Unix troff;
it must be processed with GNU troff.
If no files are given on the command line, the standard input
will be read.
A filename of
will cause the standard input to be read.
searches for the file
in the directories given with the
option first, then in
and finally in the standard macro directory
If it exists,
will process it before the other input files.
The
option prevents this.
GNU
does not provide the functionality of neqn:
it does not support low-resolution, typewriter-like devices
(although it may work adequately for very simple input).
Specify delimiters
for the left and right end, respectively, of in-line equations.
Any
statements in the source file overrides this.
Recognize
and
even when followed by a character other than space or newline.
Don't allow newlines within delimiters.
This option allows
to recover better from missing closing delimiters.
Print the version number.
Only one size reduction.
will not reduce the size of subscripts or superscripts to
The output is for device
The only effect of this is to define a macro
Typically
will use this to provide definitions appropriate for the output device.
The default output device is
Search
for
before the default directories.
Don't load
This is equivalent to a
command.
This is equivalent to a
command.
This option is deprecated.
will normally set equations at whatever the current point size
is when the equation is encountered.
This says that subscripts and superscripts should be
points smaller than the surrounding text.
This option is deprecated. 
Normally
makes sets subscripts and superscripts at 70% 
of the size of the surrounding text.
Only the differences between GNU
and Unix eqn are described here.
Most of the new features of GNU
below;
gives each component of an equation a type, and adjusts the spacing
between components using that type.
Possible types are:
ordinary
operator
a large operator such as
binary
relation
a relation such as `=';
opening
a opening bracket such as `(';
closing
a closing bracket such as `)';
punctuation
a punctuation character such as `,';
inner
a subformula contained within brackets;
suppress
spacing that suppresses automatic spacing adjustment.
Components of an equation get a type in one of two ways.
where
is one of the types mentioned above.
For example,
is defined as
The name of the type doesn't have to be quoted, but quoting protects
from macro expansion.
Unquoted groups of characters are split up into individual characters,
and the type of each character is looked up;
this changes the type that is stored for each character;
it says that the characters in
For example,
chartype "punctuation" .,;:
would make the characters `.,;:' have type punctuation
whenever they subsequently appeared in an equation.
can also be
or
in these cases
changes the font type of the characters.
See the
subsection.
This is similar to
reduces the size of
and
it also puts less vertical space between
or
and the fraction bar.
The
primitive in display styles;
corresponds to
in non-display styles.
This vertically centers
about the math axis.
The math axis is the vertical position about which characters
used for the bar of fractions.
For example,
is defined as
This sets
as an accent over
is assumed to be at the correct height for a lowercase letter;
will be moved down according if
is taller or shorter than a lowercase letter.
For example,
is defined as
accent { "^" }
and
are also defined using the
primitive.
This sets
as an accent under
is assumed to be at the correct height for a character without a descender;
will be moved down if
has a descender.
is pre-defined using
as a tilde accent below the baseline.
This has the same effect as simply
but
is not subject to macro expansion because it is quoted;
will be split up and the spacing between individual characters
will be adjusted.
This has the same effect as
but because
is not quoted it will be subject to macro expansion;
will not be split up
and the spacing between individual characters will not be adjusted.
This is a variant of
It produces a different result from
in a case such as
with
(as is conventional in mathematical typesetting),
whereas with
will be a subscript to the prime character.
The precedence of
is the same as that of
and
which is higher than that of everything except
and
that is not the first character will be treated like
using a
macro named
When the macro is called,
the string
and the number registers
and
(The
of an object says how much a subscript on that object should be tucked in;
the
of an object says how far to the right of the center of the object an
accent over the object should be placed.)
The macro must modify
so that it will output the desired result with its origin at the current
point, and increase the current horizontal position by the width
of the object.
The number registers must also be modified so that they correspond to the
result.
For example, suppose you wanted a construct that `cancels' an expression
by drawing a diagonal line through it.
define cancel 'special Ca'
with
Here's a more complicated construct that draws a box round an expression:
define box 'special Bx'
(in hundredths of an em) sets the vertical spacing before the equation,
a negative value sets the spacing after the equation, replacing the
default values.
This primitive provides an interface to
escape (but with opposite sign).
This keyword has no effect if the equation is part of a
picture.
(in hundredths of an em) increases the vertical spacing between rows,
using
escape.
Negative values are possible but have no effect.
If there is more than a single value given in a matrix, the biggest one
is used.
The appearance of equations is controlled by a large number of parameters.
These can be set using
the
command.
is an integer.
For example,
set x_height 45
says that
Possible parameters are as follows.
Values are in units of hundredths of an em unless otherwise stated.
These descriptions are intended to be expository rather than
definitive.
will not set anything at a smaller point-size than this.
The value is in points.
The
primitive emboldens an equation
by overprinting two copies of the equation
horizontally offset by this amount.
A fraction bar will be longer by twice this amount than
the maximum of the widths of the numerator and denominator;
in other words, it will overhang the numerator and
denominator by at least this amount.
When
or
is applied to a single character,
the line will be this long.
Normally,
or
produces a line whose length is the width of the object to which it applies;
in the case of a single character,
this tends to produce a line that looks too long.
Extensible delimiters produced with the
and
primitives will have a combined height and depth of at least this many
thousandths of twice the maximum amount by which the sub-equation that
the delimiters enclose extends away from the axis.
Extensible delimiters produced with the
and
primitives will have a combined height and depth
not less than the difference of
twice the maximum amount by which the sub-equation that
the delimiters enclose extends away from the axis
and this amount.
This much horizontal space is inserted
on each side of a fraction.
The width of subscripts and superscripts is increased by this amount.
This amount of space is automatically inserted after punctuation
characters.
This amount of space is automatically inserted on either side
of binary operators.
This amount of space is automatically inserted on either side of
relations.
The height of lowercase letters without ascenders such as `x'.
The height above the baseline of the center of characters
It is important that this value is correct for the font
you are using.
This should set to the thickness of the
character, or the thickness of horizontal lines produced with the
escape sequence.
The
command will shift up the numerator by at least this amount.
The
command will shift up the numerator by at least this amount.
The
command will shift down the denominator by at least this amount.
The
command will shift down the denominator by at least this amount.
Normally superscripts will be shifted up by at least this amount.
Superscripts within superscripts or upper limits
or numerators of
fractions
will be shifted up by at least this amount.
This is usually less than sup1.
Superscripts within denominators or square roots
or subscripts or lower limits will be shifted up by at least
this amount.
This is usually less than sup2.
Subscripts will normally be shifted down by at least this amount.
When there is both a subscript and a superscript, the subscript
will be shifted down by at least this amount.
The baseline of a superscript will be no more
than this much amount below the top of the object on
which the superscript is set.
The baseline of a subscript will be at least this much below
the bottom of the object on which the subscript is set.
The baseline of an upper limit will be at least this
much above the top of the object on which the limit is set.
The baseline of a lower limit will be at least this
much below the bottom of the object on which the limit is set.
The bottom of an upper limit will be at least this much above the
top of the object on which the limit is set.
The top of a lower limit will be at least this much below
the bottom of the object on which the limit is set.
This much vertical space will be added above and below limits.
The baselines of the rows in a pile or matrix will normally be
this far apart.
In most cases this should be equal to the sum of
and
The midpoint between the top baseline and the bottom baseline
in a matrix or pile will be shifted down by this much from the axis.
In most cases this should be equal to
This much space will be added between columns in a matrix.
This much space will be added at each side of a matrix.
If this is non-zero, lines will be drawn using the
escape sequence, rather than with the
escape sequence and the
character.
The amount by which the height of the equation exceeds this
will be added as extra space before the line containing the equation
(using
The default value is 85.
The amount by which the depth of the equation exceeds this
will be added as extra space after the line containing the equation
(using
The default value is 35.
If this is non-zero,
then
will behave like
and
will be ignored,
otherwise
will behave like
and
will be ignored.
file for the
and
devices.)
A more precise description of the role of many of these
Macros can take arguments.
In a macro body,
where
will be replaced by the
argument if the macro is called with arguments;
if there are fewer than
arguments, it will be replaced by nothing.
A word containing a left parenthesis where the part of the word
before the left parenthesis has been defined using the
command
will be recognized as a macro call with arguments;
characters following the left parenthesis
up to a matching right parenthesis will be treated as comma-separated
arguments;
commas inside nested parentheses do not terminate an argument.
This is like the
command, but
will not be recognized if called with arguments.
Include the contents of
and
are synonyms).
Lines of
beginning with
or
will be ignored.
If
has been defined by
(or has been automatically defined because
is the output device)
process
otherwise ignore
can be any character not appearing in
Remove definition of
making it undefined.
Besides the macros mentioned above, the following definitions are available:
(this is the same as
(three dots on the base line),
and
normally uses at least two fonts to set an equation:
an italic font for letters,
and a roman font for everything else.
The existing
command
changes the font that is used as the italic font.
The font that is used as the roman font can be changed
using the new
command.
The
primitive uses the current italic font set by
the
primitive uses the current roman font set by
There is also a new
command, which changes the font used by the
primitive.
If you only use the
and
primitives to changes fonts within an equation,
you can change all the fonts used by your equations
just by using
and
commands.
You can control which characters are treated as letters
(and therefore set in italics) by using the
command described above.
A type of
will cause a character to be set in italic type.
A type of
will cause a character to be set in roman type.
Initialization file.
Inline equations will be set at the point size that is current at the
beginning of the input line.
[
]
[
]
Reads an EQN equation (one line) as input; produces an image
file (by default in Portable Network Graphics format) suitable for the
Web as output.
that normally precedes it within 
macros; nor do you need to have dollar-sign or other delimiters
around the equation.
The output image will be a black-on-white graphic clipped to the
smallest possible bounding box that contains all the black pixels.
By specifying command-line options to be passed to 
you can give it a border, set the background transparent, set the
image's pixel density, or perform other useful transformations.
This program uses 
and the ImageMagick 
program.
These programs must be installed on your system and accessible on your
Run 
in the `unsafe' mode enabling the PIC macro
to execute arbitrary commands.
The default is to forbid this.
Specify an output format; the default is PNG (Portable Network Graphics).
Any format that
can emit is supported.
Command-line switches and arguments not listed above are passed to
The 
initialization file.
The directory in which temporary files will be created.
If this is not set
searches the environment variables
and
(in that order).
Otherwise, temporary files will be created in
Eric S. Raymond <esr@thyrsus.com>.
is a command line front-end for
library, which is an implementation of eRuby.
ERB provides an easy to use but powerful templating system for Ruby.
Using ERB, actual Ruby code can be added to any plain text document for the
is a part of
Prints the version of
Specifies the default value(s) for external encodings and internal encoding. Values should be separated with colon (:).
You can omit the one for internal encodings, then the value
Evaluates lines starting with
as Ruby code and removes the tailing EOLs.
Specifies the safe level in which eRuby script will run.
Specifies trim mode (default 0).
can be one of
EOL remains after the embedded ruby script is evaluated.
EOL is removed if the line ends with
EOL is removed if the line starts with
and ends with
EOL is removed if the line ends with
And leading whitespaces are removed if the erb directive starts with
can be one of
Sets the default value for internal encodings
Turns on debug mode.
will be set to true.
Prints a summary of the options.
Used with
Prepends the line number to each line in the output.
Enables verbose mode.
will be set to true.
Converts the eRuby script into Ruby script and prints it without line numbers.
Here is an eRuby script
<?xml version="1.0" ?>
<% require 'prime' -%>
<erb-example>
Command
prints
<?xml version="1.0" ?>
<erb-example>
And see
documentation for
class.
Reported problems will be published after being fixed.
Do not report security vulnerabilities
via the system because it publishes the vulnerabilities immediately.
Written by Masatoshi SEKI.


understood by
format understood by
the syntax of C, Objective C, C++, Java, Fortran, Ada, Cobol, Erlang, HTML,
Python, Prolog, Scheme and
Both forms read the files specified on the command line, and write a tag
Files specified with relative file names will be recorded in the tag
table with file names relative to the directory where the tag table
relative to the working directory.  Files specified with absolute file
names will be recorded
the name of the source file.
The programs recognize the language used in an input file based on its
parsing of the file names following the switch according to the given
language, overriding guesses based on filename extensions.
by ctags;
The programs accept unambiguous abbreviations for long option names.
through files.
In C and derived languages, create tags for function declarations,
Create tag entries for C preprocessor constant definitions
and enum constants, too.  Since this is the default behavior of
Do not create tag entries for C preprocessor constant definitions
and enum constants.
This may make the tags file much smaller if many header files are tagged.
accepts this option.
Create tag entries for global variables in C, C++, Objective C, Java,
and Perl.
accepts this option.
Do not tag global variables.  Typically this reduces the file size by
Include a note in the tag file indicating that, when searching for a
Don't rely on indentation as much as we normally do.  Currently, this
means not to assume that a closing brace in the first column is the
final brace of a function or structure definition in C and C++.
Parse the following files according to the given language.  More than
to get a list of the available languages and their default filename
extensions.  The `auto' language can be used to restore automatic
detection of language based on the file name.  The `none'
language may be used to disable language parsing altogether; only
Create tag entries for variables that are members of structure-like
constructs in C++, Objective C, Java.  This is the default for etags.
Do not tag member variables.  This is the default for ctags.
Only tag packages in Ada files.
May be used (only once) in place of a file name on the command line.

Make tags based on regexp matching for the files following this option,
in addition to the tags made with the standard parsing based on
option.  The regexps are cumulative, i.e. each such option will add to
the previous ones.  The regexps are of one of the forms:

useless characters.  If the match is such that more characters than
the same as in emacs.  The following character escape sequences are
respectively stand for the ASCII characters BEL, BS, DEL, ESC, FF, NL,
CR, TAB, VT.
at once, rather than line by line, and the matching sequence can match
character is needed inside the regular expression, it must be quoted
should be
otherwise.  This is particularly useful when storing many predefined
regexps in a file.
one per line.  Lines beginning with a space or tab are assumed
to be comments, and ignored.

Here are some examples.  All the regexps are quoted to protect them
from shell interpretation.

Tag the DEFVAR macros in the emacs source files:

Tag VHDL files (this example is a single long line, broken here for
formatting reasons):

